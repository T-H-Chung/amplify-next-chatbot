[
  {
    "title": "Telemetry - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/reference/telemetry/",
    "html": "Next.js\n/\nReference\n/\nTelemetry\nTelemetry\n\nAmplify Gen 2 collects anonymous telemetry data about general usage of the CLI. Participation is optional, and you may opt out by using ampx configure telemetry disable.\n\nYour decision to opt out is stored for your user, meaning all Amplify apps you work with on that computer will not send telemetry data.\n\nHow do I opt out?\n\nYou may opt out by using the configure telemetry disable command from the root of your Amplify app:\n\nTerminal\nCopy\nTerminal code example\nnpx ampx configure telemetry disable\n\nYou can opt back in to the program by running the following from the root of your Amplify app:\n\nTerminal\nCopy\nTerminal code example\nnpx ampx configure telemetry enable\n\nIn the event you would like to disable telemetry on a one-time basis, you can opt out by defining an environment variable:\n\nTerminal\nCopy\nTerminal code example\nexport AMPLIFY_DISABLE_TELEMETRY=1"
  },
  {
    "title": "IAM Permissions Boundary - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/reference/permissions-boundary/",
    "html": "Next.js\n/\nReference\n/\nIAM Permissions Boundary\nIAM Permissions Boundary\n\nTo set the maximum permissions that can be granted to IAM Roles created by Amplify, configure a permissions boundary for the AWS environment (i.e. AWS account & region). Then, Amplify-generated IAM roles can perform only the actions that are allowed by both the roles’ policies and permissions boundary.\n\nThe IAM permissions boundary will apply to all IAM Roles created by Amplify. This includes the \"auth role\" assumed by users that log into the app and the \"unauth role\" assumed by guest users. It also applies to Lambda execution roles, Cognito user group roles, and any role configured in a custom resource stack.\n\nThe IAM Policy to be used as a permissions boundary must be configured outside of Amplify. A permissions boundary is an IAM Policy. This is usually part of an AWS Organization rule or some other corporate governance requirement. Once you have created an IAM Policy to use as a permissions boundary, copy the IAM Policy ARN for the next steps.\n\nSet up a permissions boundary in an AWS environment\nTerminal\nCopy\nTerminal code example\ncdk bootstrap --custom-permissions-boundary <iam-policy-arn>\n\nThe cdk bootstrap command is a one-time operation that configures the AWS account and region for CDK deployments. Once executed, users can continue to utilize Amplify commands (e.g. sandbox) without interruption. Any custom IAM permissions boundary set by cdk bootstrap will be automatically applied to the roles created by Amplify.\n\nCheck this guide to learn more about bootstrapping"
  },
  {
    "title": "IAM policy - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/reference/iam-policy/",
    "html": "Next.js\n/\nReference\n/\nIAM policy\nIAM policy\nBranch deployments\n\nBranch deployments require the AmplifyBackendDeployFullAccess managed policy to be able to deploy backend resources during a fullstack deployment. When connecting your project through the console, a role with this policy attached will be automatically created for you.\n\nCloud sandbox deployments\n\nSandbox deployments, by design, use local credentials to deploy resources. You need to ensure that the local profile has the AmplifyBackendDeployFullAccess policy attached to it."
  },
  {
    "title": "Cross-account deployments - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/deploy-and-host/fullstack-branching/cross-account-deployments/",
    "html": "Next.js\n/\nDeployment\n/\nFullstack workflows\n/\nCross-account deployments\nCross-account deployments\n\nThis guide walks you through how to create a trunk-based, multi-region deployment pipeline for applications built using AWS Amplify Gen 2. We will be using Amazon CodeCatalyst and AWS Amplify Hosting in this guide, but you can choose any CI/CD provider.\n\nNote: You can deploy this custom pipeline either in the us-west-2 or eu-west-1 Regions, as Amazon CodeCatalyst is currently only available in those two AWS Regions.\n\nStep 1: Set up an Amazon CodeCatalyst space\n\nPlease refer to this Amazon CodeCatalyst guide for a detailed step-by-step walkthrough to set up your space.\n\nStep 2: Deploy a fullstack Amplify Gen 2 app\nUse our Next.js starter template to create a repository in your GitHub account.\nSign in to the AWS Management Console.\nNavigate to the Amplify console and select Create new app.\nSelect the next-pages-template repository, then select Next.\nReview the details on the Create Git Repository page, then select Save and deploy.\nDone! You have successfully deployed a fullstack Gen 2 app. You can review the status of the app deployment in the Amplify console.\n\nStep 3: Update build specification\n\nAdd the npx ampx generate outputs --branch $AWS_BRANCH --app-id $AWS_APP_ID command to the build spec and comment out the npx ampx pipeline-deploy --branch $AWS_BRANCH --app-id $AWS_APP_ID command. ampx pipeline-deploy runs a script to deploy backend updates, while ampx generate outputs fetches the latest amplify_outputs.json for the specified environment.\n\nStep 4: Disable automatic builds on the branch\n\nYou can configure Amplify to disable automatic builds on every code commit. Navigate to the app in the Amplify console. Under App settings, select Branch settings. From the Branches section, select the branch and then choose Disable auto build from the Actions dropdown menu.\n\nStep 5: Create an incoming webhook\n\nYou can set up an incoming webhook to trigger a build without committing code to your Git repository. Use the Amplify Console to create an incoming webhook.\n\nNavigate to the app, under Hosting > Build settings select Create webhook. Provide a name for the webhook and select the target branch to build on incoming webhook requests.\n\nNext, select the webhook and copy the curl command which will be used to trigger a build for the app.\n\nStep 6: Create a new Amazon CodeCatalyst project\n\nPlease refer to this Amazon CodeCatalyst guide for a detailed step-by-step walkthrough to create a new project.\n\nNote: When creating your project, select the next-pages-template GitHub repository, which we used to deploy the app in Step 2.\n\nStep 7: Set up the resources in a different or target AWS account\n\nTo achieve a cross-account deployment, you will need to implement Steps 1 through 6 outlined previously in this guide in a different AWS account (for example, production account).\n\nStep 8: Add the target AWS account to the CodeCatalyst space\n\nNavigate to the CodeCatalyst space created as part of Step 1, select Settings, and then select AWS accounts. Add the target AWS account ID (Step 7) to it and select Associate AWS account.\n\nYou will also need to create an IAM role in the target AWS account which will be assumed by the staging environment to perform actions and deploy resources in the production environment. As a best practice, we recommend attaching the AmplifyBackendDeployFullAccess AWS managed policy to the IAM role as it contains all the required permissions to deploy Gen 2 resources in your account. You can learn more about adding IAM roles to account connections in the CodeCatalyst documentation.\n\nStep 9: Create a workflow in the Amazon CodeCatalyst project\n\nA workflow is an automated procedure that describes how to build, test, and deploy your code as part of a continuous integration and continuous delivery (CI/CD) system. You can learn more about workflows in the Amazon CodeCatalyst User Guide.\n\nWithin the CodeCatalyst project, navigate to the CI/CD feature and select Workflows.\nSelect Create workflow.\nChoose the next-pages-template GitHub repository and the branch main from the dropdown menu.\nNext, select Create.\n\nOnce you create the workflow, you should see a yaml editor in the CodeCatalyst console.\n\nSwitch the experience in the console to the Visual editor. Select the Actions button to see a list of workflow actions that you can add to your workflow.\n\nAdd the Build action to the workflow and select the Add variable button in the Inputs section. Add the following environment variables to it:\n\nAWS_APP_ID_STAGING: amplify app id for staging app\nAWS_APP_ID_PRODUCTION: amplify app id for production app\nAWS_BRANCH: git branch name\n\nAdd another Build action to the workflow and select the Depends on button in the Inputs section. From the dropdown menu, select the name of the previous build action to set up the pipeline.\n\nNext, select the Configuration section and add the following information to each of the build actions:\n\nEnvironment information (optional): staging, production, etc.\nAWS account connection: your account connection\nRole: role setup with your account connection\n\nYou will then need to add the following shell commands to each of the build actions:\n\nTerminal\nCopy\nTerminal code example\n// This environment variable is required to run the pipeline-deploy command in a non Amplify CI environment\n- Run: export CI=1\n\n\n// Perform a clean install of the dependencies\n- Run: npm ci\n\n\n// Deploy the backend for your Amplify Gen 2 app\n- Run: npx ampx pipeline-deploy --branch $AWS_BRANCH --app-id $AWS_APP_ID\n\n\n// Trigger frontend build using incoming webhooks\n- Run: if [ $AWS_BRANCH = \"main\" ]; then curl -X POST -d {} \"`webhookUrl`&operation=startbuild\" -H \"Content-Type:application/json\"; fi\n\nYou can now run Validate to ensure your workflow definition yaml file is valid. Lastly, select Commit to save your changes.\n\nNote: Since workflows are saved as commits, and this workflow has a code push trigger enabled, committing the workflow will automatically start a new workflow run.\n\nNext, you can review the result of the workflow run from the Runs tab:\n\nDone! You have successfully set up a custom cross-account pipeline to deploy your frontend and backend for apps built using Amplify Gen 2. To summarize, this custom pipeline will enable you to deploy your backend initially with your staging environment using ampx pipeline-deploy in the CodeCatalyst workflow and ampx generate outputs will generate the amplify_outputs.json file for the main branch. Amplify Hosting will not deploy backend resources as part of the build and instead will use the deployed backend resources from the main branch. Once the staging environment deploys successfully, a similar process will be followed to deploy your production environment in a different AWS account.\n\nPREVIOUS\nCustom pipelines"
  },
  {
    "title": "CDK constructs - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/reference/cdk-constructs/",
    "html": "Next.js\n/\nReference\n/\nCDK constructs\nCDK constructs\n\nConstructs—the basic building blocks of AWS Cloud Development Kit (AWS CDK) apps—abstract away the complexity of configuring cloud resources, so you can concentrate on your application code. In the following sections, we summarize the available Amplify backend constructs.\n\nAmplify Data\n\nThe official AmplifyData construct can be found on Construct Hub.\n\nThis package provides a Level 3 (L3) CDK construct wrapping the behavior of the Amplify GraphQL API. This enables quick development and iteration of AppSync APIs that support the Amplify GraphQL directives.\n\nFor more information on data modeling, visit the data-modeling documentation.\n\nAmplify Auth\n\nThe official AmplifyAuth construct can be found on the npm registry."
  },
  {
    "title": "Reference - Next.js - AWS Amplify Gen 1 Documentation",
    "url": "https://docs.amplify.aws/gen1/nextjs/reference/",
    "html": "Reference"
  },
  {
    "title": "About amplify_outputs.json - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/reference/amplify_outputs/",
    "html": "Next.js\n/\nReference\n/\nAbout amplify_outputs.json\nAbout amplify_outputs.json\n\nIn Amplify Gen 2, the CLI will generate an amplify_outputs.json file with your backend's outputs such as your Data endpoint and Auth metadata. This file -- also known as the \"client configuration file\" -- is used to configure the client libraries in order to interact with your backend resources. Locally, this file is created while using ampx sandbox. In Amplify's CI/CD, this is created automatically for you based on the current Amplify app ID and git branch.\n\nYou can also manually create this file for a specified Amplify app ID and branch, or an AWS CloudFormation stack name with ampx generate outputs.\n\nExtending Amplify outputs file\n\nThe amplify_outputs.json file is not just a static artifact; it is designed to be extendable to suit the evolving needs of your application. By leveraging the addOutput method from your backend, you can programmatically add configurations. This is particularly useful for customizing outputs that are not directly exposed through the Amplify constructs or for dynamically adjusting your app's configuration in response to changes in your backend strategy.\n\nOverriding Amplify-managed configurations on amplify_outputs.json is not supported.\n\nOne common scenario where extending the configuration becomes handy is when you need to add custom outputs or extend existing configurations without manual file edits.\n\nConsider a scenario where you want to add output parameters in your amplify_outputs.json that specify an S3 bucket and its region that your application will use for storing files.\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\n\n\nconst backend = defineBackend({\n  auth, \n  data, \n});\n\n\nbackend.addOutput({\n  storage: {\n    aws_region: \"us-east-1\",\n    bucket_name: \"my-externally-managed-bucket\",\n  },\n});\n\nIn your frontend end application, you can configure Amplify as follows:\n\nsrc/index.ts\nCopy\nsrc/index.ts code example\nimport { Amplify } from \"aws-amplify\";\nimport outputs from \"@/amplify_outputs.json\";\n\n\nAmplify.configure(outputs);\nCustom configuration\n\nIn addition to extending existing configurations, you can also add custom output parameters to your amplify_outputs.json. This is useful for surfacing arbitrary outputs, values from custom CDK resources, or any other information that might be necessary for your application's logic or configuration.\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\n\n\nconst backend = defineBackend({\n  auth, \n  data, \n});\n\n\nbackend.addOutput({\n  custom: {\n    api_id: \"restAPIId\",\n    api_endpoint: \"https://api.example.com\",\n    api_name: \"restApiName\",\n  },\n});\n\nIn your frontend application, you can access these custom configurations as follows:\n\nsrc/index.ts\nCopy\nsrc/index.ts code example\nimport { Amplify } from \"aws-amplify\";\nimport outputs from \"@/amplify_outputs.json\";\n\n\nAmplify.configure(outputs);\nconst currentConfig = Amplify.getConfig(); \nAmplify.configure({\n  ...currentConfig,\n  API: {\n    REST: {\n      [outputs.custom.api_name]: {\n        endpoint: outputs.custom.api_endpoint,\n        region: \"us-east-1\",\n      },\n    },\n  },\n});\nSchema reference\n\nThe Amplify outputs file is defined using a JSON schema. You can find this schema in the aws-amplify/amplify-backend repository.\n\n{\n  \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n  \"$id\": \"https://amplify.aws/2024-02/outputs-schema.json\",\n  \"title\": \"AWS Amplify Backend Outputs\",\n  \"description\": \"Config format for Amplify Gen 2 client libraries to communicate with backend services.\",\n  \"type\": \"object\",\n  \"additionalProperties\": false,\n  \"properties\": {\n    \"$schema\": {\n      \"description\": \"JSON schema\",\n      \"type\": \"string\"\n    },\n    \"version\": {\n      \"description\": \"Version of this schema\",\n      \"const\": \"1\"\n    },\n    \"analytics\": {\n      \"description\": \"Outputs manually specified by developers for use with frontend library\",\n      \"type\": \"object\",\n      \"additionalProperties\": false,\n      \"properties\": {\n        \"amazon_pinpoint\": {\n          \"type\": \"object\",\n          \"additionalProperties\": false,\n          \"properties\": {\n            \"aws_region\": {\n              \"description\": \"AWS Region of Amazon Pinpoint resources\",\n              \"$ref\": \"#/$defs/aws_region\"\n            },\n            \"app_id\": {\n              \"type\": \"string\"\n            }\n          },\n          \"required\": [\n            \"aws_region\",\n            \"app_id\"\n          ]\n        }\n      }\n    },\n    \"auth\": {\n      \"description\": \"Outputs generated from defineAuth\",\n      \"type\": \"object\",\n      \"additionalProperties\": false,\n      \"properties\": {\n        \"aws_region\": {\n          \"description\": \"AWS Region of Amazon Cognito resources\",\n          \"$ref\": \"#/$defs/aws_region\"\n        },\n        \"user_pool_id\": {\n          \"description\": \"Cognito User Pool ID\",\n          \"type\": \"string\"\n        },\n        \"user_pool_client_id\": {\n          \"description\": \"Cognito User Pool Client ID\",\n          \"type\": \"string\"\n        },\n        \"identity_pool_id\": {\n          \"description\": \"Cognito Identity Pool ID\",\n          \"type\": \"string\"\n        },\n        \"password_policy\": {\n          \"description\": \"Cognito User Pool password policy\",\n          \"type\": \"object\",\n          \"additionalProperties\": false,\n          \"properties\": {\n            \"min_length\": {\n              \"type\": \"integer\",\n              \"minimum\": 6,\n              \"maximum\": 99\n            },\n            \"require_numbers\": {\n              \"type\": \"boolean\"\n            },\n            \"require_lowercase\": {\n              \"type\": \"boolean\"\n            },\n            \"require_uppercase\": {\n              \"type\": \"boolean\"\n            },\n            \"require_symbols\": {\n              \"type\": \"boolean\"\n            }\n          }\n        },\n        \"oauth\": {\n          \"type\": \"object\",\n          \"additionalProperties\": false,\n          \"properties\": {\n            \"identity_providers\": {\n              \"description\": \"Identity providers set on Cognito User Pool\",\n              \"type\": \"array\",\n              \"items\": {\n                \"type\": \"string\",\n                \"enum\": [\n                  \"GOOGLE\",\n                  \"FACEBOOK\",\n                  \"LOGIN_WITH_AMAZON\",\n                  \"SIGN_IN_WITH_APPLE\"\n                ]\n              },\n              \"minItems\": 0,\n              \"uniqueItems\": true\n            },\n            \"domain\": {\n              \"description\": \"Domain used for identity providers\",\n              \"type\": \"string\"\n            },\n            \"scopes\": {\n              \"type\": \"array\",\n              \"items\": {\n                \"type\": \"string\"\n              },\n              \"minItems\": 0,\n              \"uniqueItems\": true\n            },\n            \"redirect_sign_in_uri\": {\n              \"description\": \"URIs used to redirect after signing in using an identity provider\",\n              \"type\": \"array\",\n              \"items\": {\n                \"type\": \"string\"\n              },\n              \"minItems\": 1,\n              \"uniqueItems\": true\n            },\n            \"redirect_sign_out_uri\": {\n              \"description\": \"URIs used to redirect after signing out\",\n              \"type\": \"array\",\n              \"items\": {\n                \"type\": \"string\"\n              },\n              \"minItems\": 1,\n              \"uniqueItems\": true\n            },\n            \"response_type\": {\n              \"type\": \"string\",\n              \"enum\": [\n                \"code\",\n                \"token\"\n              ]\n            }\n          },\n          \"required\": [\n            \"identity_providers\",\n            \"domain\",\n            \"scopes\",\n            \"redirect_sign_in_uri\",\n            \"redirect_sign_out_uri\",\n            \"response_type\"\n          ]\n        },\n        \"standard_required_attributes\": {\n          \"description\": \"Cognito User Pool standard attributes required for signup\",\n          \"type\": \"array\",\n          \"items\": {\n            \"$ref\": \"#/$defs/amazon_cognito_standard_attributes\"\n          },\n          \"minItems\": 0,\n          \"uniqueItems\": true\n        },\n        \"username_attributes\": {\n          \"description\": \"Cognito User Pool username attributes\",\n          \"type\": \"array\",\n          \"items\": {\n            \"type\": \"string\",\n            \"enum\": [\n              \"email\",\n              \"phone_number\",\n              \"username\"\n            ]\n          },\n          \"minItems\": 1,\n          \"uniqueItems\": true\n        },\n        \"user_verification_types\": {\n          \"type\": \"array\",\n          \"items\": {\n            \"type\": \"string\",\n            \"enum\": [\n              \"email\",\n              \"phone_number\"\n            ]\n          }\n        },\n        \"unauthenticated_identities_enabled\": {\n          \"type\": \"boolean\",\n          \"default\": true\n        },\n        \"mfa_configuration\": {\n          \"type\": \"string\",\n          \"enum\": [\n            \"NONE\",\n            \"OPTIONAL\",\n            \"REQUIRED\"\n          ]\n        },\n        \"mfa_methods\": {\n          \"type\": \"array\",\n          \"items\": {\n            \"enum\": [\n              \"SMS\",\n              \"TOTP\"\n            ]\n          }\n        }\n      },\n      \"required\": [\n        \"aws_region\",\n        \"user_pool_id\",\n        \"user_pool_client_id\"\n      ]\n    },\n    \"data\": {\n      \"description\": \"Outputs generated from defineData\",\n      \"type\": \"object\",\n      \"additionalProperties\": false,\n      \"properties\": {\n        \"aws_region\": {\n          \"$ref\": \"#/$defs/aws_region\"\n        },\n        \"url\": {\n          \"description\": \"AppSync endpoint URL\",\n          \"type\": \"string\"\n        },\n        \"model_introspection\": {\n          \"description\": \"generated model introspection schema for use with generateClient\",\n          \"type\": \"object\"\n        },\n        \"api_key\": {\n          \"type\": \"string\"\n        },\n        \"default_authorization_type\": {\n          \"$ref\": \"#/$defs/aws_appsync_authorization_type\"\n        },\n        \"authorization_types\": {\n          \"type\": \"array\",\n          \"items\": {\n            \"$ref\": \"#/$defs/aws_appsync_authorization_type\"\n          }\n        }\n      },\n      \"required\": [\n        \"aws_region\",\n        \"url\",\n        \"default_authorization_type\",\n        \"authorization_types\"\n      ]\n    },\n    \"geo\": {\n      \"description\": \"Outputs manually specified by developers for use with frontend library\",\n      \"type\": \"object\",\n      \"additionalProperties\": false,\n      \"properties\": {\n        \"aws_region\": {\n          \"description\": \"AWS Region of Amazon Location Service resources\",\n          \"$ref\": \"#/$defs/aws_region\"\n        },\n        \"maps\": {\n          \"description\": \"Maps from Amazon Location Service\",\n          \"type\": \"object\",\n          \"additionalProperties\": false,\n          \"properties\": {\n            \"items\": {\n              \"type\": \"object\",\n              \"additionalProperties\": false,\n              \"propertyNames\": {\n                \"description\": \"Amazon Location Service Map name\",\n                \"type\": \"string\"\n              },\n              \"patternProperties\": {\n                \".*\": {\n                  \"$ref\": \"#/$defs/amazon_location_service_config\"\n                }\n              }\n            },\n            \"default\": {\n              \"type\": \"string\"\n            }\n          },\n          \"required\": [\n            \"items\",\n            \"default\"\n          ]\n        },\n        \"search_indices\": {\n          \"description\": \"Location search (search by places, addresses, coordinates)\",\n          \"type\": \"object\",\n          \"additionalProperties\": false,\n          \"properties\": {\n            \"items\": {\n              \"type\": \"array\",\n              \"uniqueItems\": true,\n              \"minItems\": 1,\n              \"items\": {\n                \"description\": \"Actual search name\",\n                \"type\": \"string\"\n              }\n            },\n            \"default\": {\n              \"type\": \"string\"\n            }\n          },\n          \"required\": [\n            \"items\",\n            \"default\"\n          ]\n        },\n        \"geofence_collections\": {\n          \"description\": \"Geofencing (visualize virtual perimeters)\",\n          \"type\": \"object\",\n          \"additionalProperties\": false,\n          \"properties\": {\n            \"items\": {\n              \"type\": \"array\",\n              \"uniqueItems\": true,\n              \"minItems\": 1,\n              \"items\": {\n                \"description\": \"Geofence name\",\n                \"type\": \"string\"\n              }\n            },\n            \"default\": {\n              \"type\": \"string\"\n            }\n          },\n          \"required\": [\n            \"items\",\n            \"default\"\n          ]\n        }\n      },\n      \"required\": [\n        \"aws_region\"\n      ]\n    },\n    \"notifications\": {\n      \"type\": \"object\",\n      \"description\": \"Outputs manually specified by developers for use with frontend library\",\n      \"additionalProperties\": false,\n      \"properties\": {\n        \"aws_region\": {\n          \"$ref\": \"#/$defs/aws_region\"\n        },\n        \"amazon_pinpoint_app_id\": {\n          \"type\": \"string\"\n        },\n        \"channels\": {\n          \"type\": \"array\",\n          \"items\": {\n            \"$ref\": \"#/$defs/amazon_pinpoint_channels\"\n          },\n          \"minItems\": 1,\n          \"uniqueItems\": true\n        }\n      },\n      \"required\": [\n        \"aws_region\",\n        \"amazon_pinpoint_app_id\",\n        \"channels\"\n      ]\n    },\n    \"storage\": {\n      \"type\": \"object\",\n      \"description\": \"Outputs generated from defineStorage\",\n      \"additionalProperties\": false,\n      \"properties\": {\n        \"aws_region\": {\n          \"$ref\": \"#/$defs/aws_region\"\n        },\n        \"bucket_name\": {\n          \"type\": \"string\"\n        }\n      },\n      \"required\": [\n        \"aws_region\",\n        \"bucket_name\"\n      ]\n    },\n    \"custom\": {\n      \"description\": \"Outputs generated from backend.addOutput({ custom: <config> })\",\n      \"type\": \"object\"\n    }\n  },\n  \"required\": [\n    \"version\"\n  ],\n  \"$defs\": {\n    \"aws_region\": {\n      \"type\": \"string\"\n    },\n    \"amazon_cognito_standard_attributes\": {\n      \"description\": \"Amazon Cognito standard attributes for users -- https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-settings-attributes.html\",\n      \"type\": \"string\",\n      \"enum\": [\n        \"address\",\n        \"birthdate\",\n        \"email\",\n        \"family_name\",\n        \"gender\",\n        \"given_name\",\n        \"locale\",\n        \"middle_name\",\n        \"name\",\n        \"nickname\",\n        \"phone_number\",\n        \"picture\",\n        \"preferred_username\",\n        \"profile\",\n        \"sub\",\n        \"updated_at\",\n        \"website\",\n        \"zoneinfo\"\n      ]\n    },\n    \"aws_appsync_authorization_type\": {\n      \"description\": \"List of supported auth types for AWS AppSync\",\n      \"type\": \"string\",\n      \"enum\": [\n        \"AMAZON_COGNITO_USER_POOLS\",\n        \"API_KEY\",\n        \"AWS_IAM\",\n        \"AWS_LAMBDA\",\n        \"OPENID_CONNECT\"\n      ]\n    },\n    \"amazon_location_service_config\": {\n      \"type\": \"object\",\n      \"additionalProperties\": false,\n      \"properties\": {\n        \"style\": {\n          \"description\": \"Map style\",\n          \"type\": \"string\"\n        }\n      }\n    },\n    \"amazon_pinpoint_channels\": {\n      \"description\": \"supported channels for Amazon Pinpoint\",\n      \"type\": \"string\",\n      \"enum\": [\n        \"IN_APP_MESSAGING\",\n        \"FCM\",\n        \"APNS\",\n        \"EMAIL\",\n        \"SMS\"\n      ]\n    }\n  }\n}"
  },
  {
    "title": "Project structure - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/reference/project-structure/",
    "html": "Next.js\n/\nReference\n/\nProject structure\nProject structure\n\nAmplify Gen 2 backends are defined using TypeScript, and enable you to collocate resources depending on their function. For example, you can author a post confirmation trigger for Amazon Cognito that creates a UserProfile model right next to your auth's resource file.\n\nWhen you create your first Amplify project using npm create amplify@latest, it will automatically set up the scaffolding for Data and Authentication resources:\n\nCopy\ncode example\n├── amplify/\n│   ├── auth/\n│   │   └── resource.ts\n│   ├── data/\n│   │   └── resource.ts\n│   ├── backend.ts\n│   └── package.json\n├── node_modules/\n├── .gitignore\n├── package-lock.json\n├── package.json\n└── tsconfig.json\n\nAs your project grows and you build out your backend, the structure of your project may look like the following:\n\nCopy\ncode example\n├── amplify/\n│   ├── auth/\n│   │   ├── custom-message/\n│   │   │   ├── custom-message.tsx\n│   │   │   ├── handler.ts\n│   │   │   ├── package.json\n│   │   │   └── resource.ts\n│   │   ├── post-confirmation.ts\n│   │   ├── pre-sign-up.ts\n│   │   ├── resource.ts\n│   │   └── verification-email.tsx\n│   ├── data/\n│   │   ├── resolvers/\n│   │   │   ├── list-featured-posts.ts\n│   │   │   └── list-top-10-posts.ts\n│   │   ├── resource.ts\n│   │   └── schema.ts\n│   ├── jobs/\n│   │   ├── monthly-report/\n│   │   │   ├── handler.ts\n│   │   │   └── resource.ts\n│   │   ├── process-featured-posts/\n│   │   │   ├── handler.py\n│   │   │   ├── requirements.txt\n│   │   │   └── resource.ts\n│   │   └── store-top-10-posts/\n│   │       ├── handler.ts\n│   │       └── resource.ts\n│   ├── storage/\n│   │   ├── photos/\n│   │   │   ├── resource.ts\n│   │   │   └── trigger.ts\n│   │   └── reports/\n│   │       └── resource.ts\n│   ├── backend.ts\n│   └── package.json\n├── node_modules/\n├── .gitignore\n├── package-lock.json\n├── package.json\n└── tsconfig.json\n\nBackend resources are defined in resource files using the define* helpers:\n\namplify/auth/resource.ts\nCopy\namplify/auth/resource.ts code example\nimport { defineAuth } from '@aws-amplify/backend';\n\n\nexport const auth = defineAuth({\n  loginWith: {\n    email: true\n  }\n});\n\nAfter the resources are defined, they are set up on the backend:\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource';\nimport { data } from './data/resource';\n\n\ndefineBackend({\n  auth,\n  data\n});\n\nYou can extend backends by using the AWS Cloud Development Kit (AWS CDK), which is installed by default as part of the create-amplify workflow. With the CDK, you can build using any AWS service, such as an Amazon S3 bucket that authenticated users have read and write access to. To get started with the CDK, add it to your backend:\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport { defineBackend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource';\nimport { data } from './data/resource';\n\n\nconst backend = defineBackend({\n  auth,\n  data\n});\n\n\n// create the bucket and its stack\nconst bucketStack = backend.getStack('BucketStack');\nconst bucket = new s3.Bucket(bucketStack, 'Bucket', {\n  blockPublicAccess: s3.BlockPublicAccess.BLOCK_ALL\n});\n\n\n// allow any authenticated user to read and write to the bucket\nconst authRole = backend.auth.resources.authenticatedUserIamRole;\nbucket.grantReadWrite(authRole);\n\n\n// allow any guest (unauthenticated) user to read from the bucket\nconst unauthRole = backend.auth.resources.unauthenticatedUserIamRole;\nbucket.grantRead(unauthRole);\nNext steps\nLearn the concepts\nLearn how to add AWS services to your backend"
  },
  {
    "title": "CLI commands - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/reference/cli-commands/",
    "html": "Next.js\n/\nReference\n/\nCLI commands\nCLI commands\n\nThis page serves as a reference for commands found in the @aws-amplify/backend-cli package.\n\nAll commands can be prefixed with AWS CLI environment variables to change the AWS account behavior with Amplify Gen 2 commands.\n\nnpx ampx sandbox\n\nSandbox enables you to develop your backend alongside your frontend's development server. Run npx ampx sandbox to deploy to your personal cloud sandbox, this command will automatically watch for changes in the amplify/ folder, and redeploy each time you save a file.\n\nOptions\n--dir-to-watch (string) - Directory to watch for file changes. All subdirectories and files will be included. Defaults to the amplify directory.\n--exclude (string[]) - An array of paths or glob patterns to ignore. Paths can be relative or absolute and can either be files or directories.\n--identifier (string) - An optional name to distinguish between different sandbox environments. Default is the name of the system user executing the process\n--outputs-out-dir (string) - A path to a directory where the client config file is written. If not provided, defaults to the working directory of the current process.\n--outputs-format (string) - Format in which the client config file is written (choices: json, dart).\n--outputs-version (string) - Version of the configuration. Version 0 represents classic amplify-cli config file amplify-configuration and 1 represents newer config file amplify_outputs (choices: 0, 1).\n--profile (string) - An AWS profile name.\n--stream-function-logs (boolean) - Whether to stream function execution logs. (default: false)\n--logs-filter (string[]) - Regex pattern to filter logs from only matched functions. E.g. to stream logs for a function, specify it's name, and to stream logs from all functions starting with auth specify 'auth' (default: Stream all logs)\n--logs-out-file (string) - File to append the streaming logs. The file is created if it does not exist. (default: stdout)\nUsage\nTerminal\nCopy\nTerminal code example\nnpx ampx sandbox\nUse with an alternate profile\n\nYou can use the --profile flag to run sandbox with an AWS profile other than default:\n\nTerminal\nCopy\nTerminal code example\nnpx ampx sandbox --profile my-other-profile\n\nAdditionally, you can use AWS CLI environment variables to specify a different profile:\n\nTerminal\nCopy\nTerminal code example\nAWS_PROFILE=my-other-profile ampx sandbox\nUse with an alternate Region\n\nUse AWS environment variables to deploy to a Region other than your AWS profile's configured Region:\n\nTerminal\nCopy\nTerminal code example\nAWS_REGION=us-west-2 ampx sandbox\nUse with mobile applications\n\nFor mobile applications, you will need to set the output directory and format of the generated configuration file, specifically amplify_outputs.json:\n\nTerminal\nCopy\nTerminal code example\n# for Android\nnpx ampx sandbox --outputs-out-dir app/src/main/res\nTerminal\nCopy\nTerminal code example\n# for Swift/iOS\nnpx ampx sandbox\nTerminal\nCopy\nTerminal code example\n# for Flutter\nnpx ampx sandbox --outputs-format dart --outputs-out-dir lib\nnpx ampx sandbox delete\n\nDelete your personal cloud sandbox. This should only be used if you have an active cloud sandbox that you opted to not delete when exiting npx ampx sandbox.\n\nOptions\n--name (string) - An optional name to distinguish between different sandbox environments. Default is the name in your package.json.\n--profile (string) - An AWS profile name.\n-y, --yes (boolean) - Do not ask for confirmation before deleting the sandbox environment.\nUsage\nTerminal\nCopy\nTerminal code example\nnpx ampx sandbox delete\nnpx ampx sandbox secret\n\nManage backend secrets used with your personal cloud sandbox.\n\nOptions\n--profile (string) - An AWS profile name.\nUsage\nTerminal\nCopy\nTerminal code example\nnpx ampx sandbox secret\nUsing with an alternate AWS profile\n\nYou can use the --profile flag to run sandbox with an AWS profile other than default:\n\nTerminal\nCopy\nTerminal code example\nnpx ampx sandbox secret list --profile my-other-profile\n\nAdditionally, you can use AWS environment variables to specify a different profile:\n\nTerminal\nCopy\nTerminal code example\nAWS_PROFILE=my-other-profile ampx sandbox secret list\nCreating a secret\n\nCreate secrets for use with your personal cloud sandbox by using sandbox secret set:\n\nTerminal\nCopy\nTerminal code example\nnpx ampx sandbox secret set LOGINWITHAMAZON_CLIENT_ID\n\nThis is how you configure secrets to be retrieved and used within your backend using secret().\n\nRemoving a secret\n\nIf you want to remove a secret you previously set, use sandbox secret remove:\n\nTerminal\nCopy\nTerminal code example\nnpx ampx sandbox secret remove LOGINWITHAMAZON_CLIENT_ID\nListing secrets\n\nList all available secrets for your personal sandbox in the default AWS profile and Region:\n\nTerminal\nCopy\nTerminal code example\nnpx ampx sandbox secret list\nGet a secret and view its details\n\nYou can view an existing secret and its details, such as the current version and when it was last updated:\n\nTerminal\nnpx ampx sandbox secret get LOGINWITHAMAZON_CLIENT_ID\n name: LOGINWITHAMAZON_CLIENT_ID\n version: 1\n value: ****\n lastUpdated: Fri Nov 17 2023 12:00:00 GMT-0800 (Pacific Standard Time)\nnpx ampx generate\n\nGenerate is not intended to be used standalone; however, it does offer a few subcommands to generate information or code that is supplemental to your frontend development.\n\nEach of the following generate subcommands require either a CloudFormation stack name or an existing Amplify App ID and corresponding git branch:\n\nTerminal\nCopy\nTerminal code example\n# with CloudFormation stack name\nnpx ampx generate <subcommand> --stack <cloudformation-stack-name>\nTerminal\nCopy\nTerminal code example\n# with Amplify App ID and git branch\nnpx ampx generate <subcommand> --app-id <app-id> --branch <git-branch-name>\nnpx ampx generate outputs\n\nGenerate the backend outputs file (e.g. amplify_outputs.json) for your frontend application to consume. This is intended to be used to manually generate a configuration file for an environment other than your personal cloud sandbox. For example, you might use it if you would like to verify something your coworker is seeing in their cloud sandbox, or to demonstrate frontend changes locally using a pre-existing \"staging\" branch.\n\nOptions\n\nIn addition to the required options noted in ampx generate:\n\n--profile (string) - An AWS profile name.\n--format (string) - The format into which the configuration should be exported (choices: json, dart).\n--out-dir (string) - A path to the directory where config is written. If not provided, it defaults to the working directory of the current process.\n--outputs-version (string) - Version of the configuration. Version 0 represents classic amplify-cli config file amplify-configuration and 1 represents newer config file amplify_outputs (choices: 0, 1).\nUsage\n\nAs mentioned above, you can specify a team member's cloud sandbox CloudFormation stack:\n\nTerminal\nCopy\nTerminal code example\nnpx ampx generate outputs --stack amplify-nextamplifygen2-josef-sandbox-ca85e1081b\nUse with mobile applications\n\nSimilar to sandbox, you can specify an alternate outputs file format by using --format:\n\nTerminal\nCopy\nTerminal code example\nnpx ampx generate outputs --stack amplify-nextamplifygen2-josef-sandbox-ca85e1081b\nnpx ampx generate graphql-client-code\n\nGenerate GraphQL statements and types for your frontend application to consume.\n\nOptions\n\nThe available parameters for npx ampx generate graphql-client-code are:\n\nRequired parameters:\n\nStack identifier\n--stack(string) - A stack name that contains an Amplify backend.\nProject identifier\n--app-id(string) - The Amplify App ID of the project.\n--branch(string) - A git branch of the Amplify project.\n\nOptional parameters:\n\n--out(string) - Specifies the path to the directory where the config is written. If not provided, defaults to the current process working directory.\n--format(string) (choices: modelgen, graphql-codegen, introspection) - Specifies the format of the GraphQL client code to be generated.\n--model-target (string) (choices: java, swift, javascript, typescript, dart) - Specifies the modelgen export target. Only applies when the --format parameter is set to modelgen.\n--statement-target(string) (choices: javascript, graphql, flow, typescript, angular) - Specifies the graphql-codegen statement export target. Only applies when the --format parameter is set to graphql-codegen.\n--type-target(string) (choices: json, swift, typescript, flow, scala, flow-modern, angular) - Specifies the optional graphql-codegen type export target. Only applies when the --format parameter is set to graphql-codegen.\n--all(boolean)- Shows hidden options.\n--profile(string) - Specifies an AWS profile name.\n--debug (boolean) - Print debug logs to the console.\n--help(boolean) - Displays help information about the command.\nUsage\nGenerate GraphQL client code using the Amplify App ID and branch.\nTerminal\nCopy\nTerminal code example\nnpx ampx generate graphql-client-code --app-id <your-amplify-app-id>\t--branch staging\nGenerate GraphQL client code for a branch that is connected to Amplify\n\nSometimes you want to test your latest local changes with the backend of another deployed branch. If you want to generate the GraphQL client code file(s) for the latest deployment of another branch, you can run the following command:\n\nTerminal\nCopy\nTerminal code example\nnpx ampx generate graphql-client-code --branch staging\nGenerate codegen for CDK app using a joint \"AmplifyBackendStack\" construct\n\nAssume you have deployed your Amplify project with the CDK construct. You will need to remember your app's project name (designated as the second parameter in your CDK construct) and stack name (designated as part of your npx cdk deploy context)\n\nlib/stack.ts\nCopy\nlib/stack.ts code example\nimport { Construct } from 'constructs';\nimport { App, Backend } from 'aws-cdk-lib/aws-amplify';\n\n\nexport class MyAmplifyStack extends cdk.Stack {\n  constructor(scope: cdk.Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n\n    new Backend(this, \"Backend\", { /* ... */ });\n  }\n}\nDeployment command for CDK project\nTerminal\nCopy\nTerminal code example\nnpx cdk deploy\n\nRun Amplify codegen command to generate GraphQL codegen:\n\nTerminal\nCopy\nTerminal code example\nnpx ampx generate graphql-client-code --stack Backend --platform ts --out ./src\nGenerate codegen in specific language and format\nTerminal\nCopy\nTerminal code example\nnpx ampx generate graphql-client-code --format modelgen --type-target angular\nSupported GraphQL client code combinations:\nFormat\tPlatform\tCodegen command in Amplify CLI\tCommand in Amplify Gen2\tDefault generated file/path\nIntrospection schema\tAmplify Javascript\tN/A\tnpx ampx generate graphql-client-code --format introspection\t<path_to_app>/\nGraphQL codegen\tAmplify Javascript\tamplify codegen\tnpx ampx generate graphql-client-code --format graphql-codegen --statement-target javascript --out <path_to_app>/src/graphql/\t<path_to_app>/src/graphql/\nModelgen\tAmplify Javascript\tamplify codegen model\tnpx ampx generate graphql-client-code --format modelgen --model-target javascript --out <path_to_app>/src/models/\t<path_to_app>/src/models/\nModelgen\tAmplify Android\tamplify codegen model\tnpx ampx generate graphql-client-code --format modelgen --model-target java --out <path_to_app/src/main/java/>\t<path_to_app>/src/main/java/com/amplifyframework/datastore/generated/model\nModelgen\tAmplify Swift\tamplify codegen model\tnpx ampx generate graphql-client-code --format modelgen --model-target swift --out <path_to_swift_project>/AmplifyModels\t<path_to_swift_project>/AmplifyModels\nModelgen\tAmplify Flutter\tamplify codegen model\tnpx ampx generate graphql-client-code --format modelgen --model-target dart --out <path_to_flutter_project>/AmplifyModels\t<path_to_flutter_project>/AmplifyModels\nnpx ampx generate forms\n\nGenerate React form components derived from your backend data models for your frontend application to consume.\n\nOptions\n--stack(string) - A stack name that contains an Amplify backend.\n--branch (string) - Name of the git branch being deployed.\n--app-id (string) - The app id of the target Amplify app.\n--out-dir (string) - A path to directory where generated forms are written. Defaults to the ./ui-components directory.\n--models (array) - Model name to generate.\n--profile (string) - An AWS profile name.\nUsage\nTerminal\nCopy\nTerminal code example\nnpx ampx generate forms --branch $BRANCH_NAME --app-id $AWS_APP_ID --out-dir ./src\nnpx ampx info\n\nGenerates information on system, binaries, npm packages, and environment variables for troubleshooting Amplify issues.\n\nTerminal\nCopy\nTerminal code example\nnpx ampx info\n\nThis command will print system information as follows:\n\nTerminal\nCopy\nTerminal code example\nSystem:\n  OS: macOS 14.3.1\n  CPU: (10) arm64 Apple M1 Pro\n  Memory: 165.89 MB / 32.00 GB\n  Shell: /opt/homebrew/bin/fish\nBinaries:\n  Node: 20.12.2 - ~/Library/Caches/fnm_multishells/1063_1714573452292/bin/node\n  Yarn: 1.22.19 - ~/Library/Caches/fnm_multishells/1063_1714573452292/bin/yarn\n  npm: 10.5.0 - ~/Library/Caches/fnm_multishells/1063_1714573452292/bin/npm\n  pnpm: 9.0.5 - ~/Library/Caches/fnm_multishells/1063_1714573452292/bin/pnpm\nNPM Packages:\n  @aws-amplify/backend: 1.0.0\n  @aws-amplify/backend-cli: 1.0.1\n  aws-amplify: 6.2.0\n  aws-cdk: 2.139.1\n  aws-cdk-lib: 2.139.1\n  typescript: 5.4.5\nAWS environment variables:\n  AWS_PROFILE = amplify-admin\n  AWS_STS_REGIONAL_ENDPOINTS = regional\n  AWS_NODEJS_CONNECTION_REUSE_ENABLED = 1\n  AWS_SDK_LOAD_CONFIG = 1\nNo CDK environment variables\nnpx ampx pipeline-deploy\n\nDeploys the Amplify project in a CI/CD pipeline for a specified Amplify app and branch.\n\nOptions\n--branch (string) - Name of the git branch being deployed.\n--app-id (string) - The app id of the target Amplify app.\n--outputs-out-dir (string) - A path to a directory where the client config file is written. If not provided, defaults to the working directory of the current process.\n--outputs-version (string) - Version of the configuration. Version 0 represents classic amplify-cli config file amplify-configuration and 1 represents newer config file amplify_outputs (choices: 0, 1).\nUsage\nTerminal\nCopy\nTerminal code example\nnpx ampx pipeline-deploy --branch $BRANCH_NAME --app-id $AWS_APP_ID"
  },
  {
    "title": "Custom pipelines - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/deploy-and-host/fullstack-branching/custom-pipelines/",
    "html": "Next.js\n/\nDeployment\n/\nFullstack workflows\n/\nCustom pipelines\nCustom pipelines\n\nWhile building with Amplify CI/CD offers benefits such as zero-config setup, fullstack previews, centralized secrets management, Amplify Gen 2 makes it easy to integrate fullstack CI/CD into your custom pipelines (for example, AWS CodePipeline, Amazon CodeCatalyst, GitHub Actions, and more).\n\nSet up backend deployments\n\nYou can set up your backend deployments using the following steps:\n\nCreate an Amplify app by connecting a fullstack Gen 2 branch from your Git repository. This is a one time setup as for subsequent deployments, we will be using a custom pipeline.\n\nDisable Auto-build for your branch. This will ensure code commits to your branch will not trigger a build.\n\nUpdate the Amplify build specification file to add npx ampx generate outputs --branch $AWS_BRANCH --app-id $AWS_APP_ID and comment out the pipeline-deploy script. ampx pipeline-deploy runs a script to deploy backend updates, while ampx generate outputs fetches the latest amplify_outputs.json for the specified environment.\n\nNow go to your pipeline provider and update the build settings to include the following:\nRun npm ci.\nRun export CI=1 to tell the deployment script that is a CI environment.\nRun npx ampx pipeline-deploy --branch BRANCH_NAME --app-id AMPLIFY_APP_ID. BRANCH_NAME refers to the branch you're deploying. AMPLIFY_APP_ID is the Amplify App ID. To locate the App ID for your backend application, navigate to the Amplify console and select your backend-app. On the Overview page, the App ID is displayed under the project name.\n\nThe example below demonstrates how you would set up the build-spec when using Amazon CodeCatalyst.\n\nCopy\ncode example\nActions:\n  Build_82:\n    # Identifies the action. Do not modify this value.\n    Identifier: aws/build@v1.0.0\n    # Specifies the source and/or artifacts to pass to the action as input.\n    Inputs:\n      # Optional\n      Sources:\n        - WorkflowSource # This specifies that the action requires this Workflow as a source\n      Variables:\n        - Name: BRANCH_NAME\n          Value: main\n        - Name: AMPLIFY_APP_ID\n          Value: #####\n    Configuration:\n      # Required - Steps are sequential instructions that run shell commands\n      Steps:\n        - Run: export CI=1\n        - Run: npm ci\n        - Run: npx ampx pipeline-deploy --branch $BRANCH_NAME --app-id $AMPLIFY_APP_ID\nTrigger a git push to your branch. Your build logs should show that there is an AWS CloudFormation deployment underway.\nSet up frontend deployments\n\nIf you want to complete the fullstack CI/CD setup, we have to build, deploy, and host the frontend in addition to the backend.\n\nUse the Amplify Console to create an incoming webhook.\n\nNavigate to the frontend app, under Hosting > Build settings select Create webhook. Provide a name for the webhook and select the target branch to build on incoming webhook requests.\n\nNext, select the webhook and copy the curl command which will be used to trigger a build for the frontend app.\n\nNow update your custom-pipeline build settings to include the curl command to trigger a frontend build after the pipeline-deploy succeeds. Using the same Amazon CodeCatalyst example above, this step includes:\nCopy\ncode example\nConfiguration:\n      # Required - Steps are sequential instructions that run shell commands\n      Steps:\n        - Run: export CI=1\n        - Run: npm ci\n        - Run: npx ampx pipeline-deploy --branch $BRANCH_NAME --app-id $AMPLIFY_APP_ID\n        - Run: if [ $BRANCH_NAME = \"main\" ]; then curl -X POST -d {}\n            \"https://webhooks.amplify.us-west-2.amazonaws.com/prod/webhooks?id=WEBHOOK-ID&token=TOKEN&operation=startbuild\"\n            -H \"Content-Type:application/json\"; fi\nThis should trigger a build in your Amplify app. Amplify CI will build and first generate the amplify_outputs.json for the branch and then build, deploy, and host the frontend.\nPREVIOUS\nFullstack previews\nNEXT\nCross-account deployments"
  },
  {
    "title": "Fullstack previews - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/deploy-and-host/fullstack-branching/pr-previews/",
    "html": "Next.js\n/\nDeployment\n/\nFullstack workflows\n/\nFullstack previews\nFullstack previews\n\nWith fullstack previews, you can set up ephemeral fullstack environments on every pull request. This allows you to test features in isolation from production. Once fullstack previews are enabled, your typical workflow would look like the following diagram:\n\nYour main (production branch) and featureA branch are deployed on Amplify.\nYou and your team work on featureA until it's ready.\nThe featureA branch is updated to main HEAD and then a pull request to main is opened.\nThe pull request preview is deployed on Amplify and available at pr-1.appid.amplifyapp.com.\nOnce the pull request is merged into main, the request is closed and the fullstack environment is also automatically torn down.\nPrerequisites\n\nBefore you get started, make sure you have the following:\n\nA fullstack Amplify app deployed\nEnsure that your git repository is private. For security purposes, fullstack previews are disabled for public repositories with Amplify backend templates.\nEnable fullstack previews\n\nTo enable fullstack web previews for your Amplify app, follow these steps:\n\nLogin to the Amplify console and select your app.\n\nNavigate to Hosting > Previews. Select the main branch and click on Edit settings. \n\nClick on the Pull request previews toggle button and choose Confirm to enable previews. \n\nDone! You have successfully enabled previews on the production branch. \n\nShip updates to the dev branch. Now, when you create a pull request for the main branch, Amplify will build and deploy your fullstack PR and provide you with a preview URL. \n\nFor GitHub repositories only, you can access your preview URL directly on the pull request from the Amplify Hosting's bot comment:\n\nAfter the pull request is merged or closed, the preview URL is deleted and any ephemeral fullstack environment is also deleted.\n\nShare backend resources across Preview branches\n\nFullstack previews allow teams a way to preview changes from pull requests before merging code to a production branch. Pull requests let you tell others about changes you’ve pushed to a branch in a repository and the changes can be reviewed by accessing the preview URL. When previews are enabled on a git branch, by default every pull request created against the git branch creates an ephemeral fullstack environment.\n\nIn some instances, you may not want to deploy new resources for every preview branch. For example, you might want all your preview branches to point to the backend resources deployed by the dev branch so you can reuse seed data, users, and groups.\n\nTo achieve this, you can update your app build settings to reuse backend resources across your preview branches. In the Amplify console, select your app on the All apps page. From the App overview page, select Hosting > Build settings to view your app's build specification YAML file.\n\nUpdate the build settings for the backend phase to run npx ampx generate outputs --branch dev app-id $AWS_APP_ID to generate the amplify_outputs.json file for all preview branches. After this update, any new deployed preview branches will not deploy backend resources as part of the build and instead will use the deployed backend resources from the dev branch.\n\namplify.yml\nversion: 1\nbackend:\n    phases:\n        build:\n            commands:\n                - 'npm ci --cache .npm --prefer-offline'\n                - 'echo $AWS_BRANCH'\n                - |\nCopy\nhighlighted code example\n                  case \"${AWS_BRANCH}\" in\n                      main)\n                          echo \"Deploying main branch...\"\n                          npx ampx pipeline-deploy --branch $AWS_BRANCH --app-id $AWS_APP_ID\n                          ;;\n                      dev)\n                          echo \"Deploying dev branch...\"\n                          npx ampx pipeline-deploy --branch $AWS_BRANCH --app-id $AWS_APP_ID\n                          ;;\n                      pr-*)\n                          echo \"Deploying pull request branch...\"\n                          npx ampx generate outputs --branch dev --app-id $AWS_APP_ID \n                          ;;\n                      *)\n                          echo \"Deploying to staging branch...\"\n                          npx ampx generate outputs --branch staging --app-id $AWS_APP_ID \n                          ;;\n                  esac\nfrontend:\n    phases:\n        build:\n            commands:\n                - 'npm run build'\n    artifacts:\n        baseDirectory: .amplify-hosting\n        files:\n            - '**/*'\n    cache:\n        paths:\n            - .next/cache/**/*\n            - .npm/**/*\n            - node_modules/**/*\nPREVIOUS\nMonorepo setup\nNEXT\nCustom pipelines"
  },
  {
    "title": "Separate frontend and backend teams - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/deploy-and-host/fullstack-branching/mono-and-multi-repos/",
    "html": "Next.js\n/\nDeployment\n/\nFullstack workflows\n/\nSeparate frontend and backend teams\nSeparate frontend and backend teams\n\nYou might have different frontend and backend teams that maintain their own repositories. With Amplify Gen 2, you can deploy repositories that have backend-only code, so frontend and backend teams can operate independently of each other.\n\nDeploy the backend app\n\nRun mkdir backend-app && cd backend-app && npm create amplify@latest to set up a backend-only Amplify project. Commit the code to a Git provider of your choice.\n\nConnect the backend-app in the new console. Navigate to the Amplify console and select Create new app.\n\nWhen you connect the repository, notice the only auto-detected framework is Amplify.\n\nOnce you choose Save and deploy, your backend project will build.\n\nDeploy the frontend app\nNow let's set up the frontend app and connect to the deployed backend.\nTerminal\nCopy\nTerminal code example\nnpm create next-app@14 -- multi-repo-example --typescript --eslint --no-app --no-src-dir --no-tailwind --import-alias '@/*'\nInstall Amplify dependencies.\nTerminal\nCopy\nTerminal code example\ncd multi-repo-example\nnpm add @aws-amplify/backend-cli aws-amplify @aws-amplify/ui-react\nTo connect to the deployed backend, run the following command. To locate the App ID for your backend application, navigate to the Amplify console and select your backend-app. On the Overview page, the App ID is displayed under the project name.\nTerminal\nCopy\nTerminal code example\nnpx ampx generate outputs --branch main --app-id <your-backend-app-id>\n\nThis will generate the amplify_outputs.json file that contains all the information about your backend at the root of your project.\n\nTo validate that your frontend can connect to the backend, add the Authenticator login form to your app.\npages/_app.tsx\nCopy\npages/_app.tsx code example\nimport { withAuthenticator } from '@aws-amplify/ui-react';\nimport { Amplify } from 'aws-amplify';\nimport outputs from '@/amplify_outputs.json';\nimport '@aws-amplify/ui-react/styles.css';\nimport '@/styles/globals.css';\nimport type { AppProps } from 'next/app';\n\n\n// configure the Amplify client library with the configuration generated by `ampx sandbox`\nAmplify.configure(outputs);\n\n\nfunction App({ Component, pageProps }: AppProps) {\n  return <Component {...pageProps} />;\n}\n\n\nexport default withAuthenticator(App);\nLet's also add an amplify.yml build-spec to our repository.\nCopy\ncode example\nversion: 1\nbackend:\n  phases:\n    build:\n      commands:\n        - npm ci --cache .npm --prefer-offline\n        - npx ampx generate outputs --branch main --app-id BACKEND-APPID\nfrontend:\n  phases:\n    build:\n      commands:\n        - npm run build\n  artifacts:\n    baseDirectory: .next\n    files:\n      - '**/*'\n  cache:\n    paths:\n      - .next/cache/**/*\n      - .npm/**/*\n      - node_modules/**/*\nNow let's deploy the app. In the Amplify console, choose Create new app. Connect the repository with the default settings. You should see that the build generates the output and does not deploy a frontend. Validate that your app is working fine.\n\nTrigger a frontend build on backend updates\n\nThe ideal scenario is that the frontend automatically retrieves the latest updates from the backend every time there is a modification made to the backend code.\n\nUse the Amplify Console to create an incoming webhook.\n\nNavigate to the multi-repo-example app, under Hosting > Build settings select Create webhook. Provide a name for the webhook and select the target branch to build on incoming webhook requests.\n\nNext, select the webhook and copy the curl command which will be used to trigger a build for the multi-repo-example app.\n\nNow update the build settings for the backend-app to include the curl command to trigger a frontend build any time there are changes to the backend.\namplify.yml\nCopy\namplify.yml code example\nversion: 1\nbackend:\n  phases:\n    build:\n      commands:\n        - npm ci --cache .npm --prefer-offline\n        - npx ampx pipeline-deploy --branch $AWS_BRANCH --app-id $AWS_APP_ID\nfrontend:\n  phases:\n    build:\n      commands:\n        - mkdir ./dist && touch ./dist/index.html\n        - curl -X POST -d {} \"https://webhooks.amplify.ca-central-1.amazonaws.com/prod/webhooks?id=WEBHOOK-ID&token=TOKEN&operation=startbuild\" -H \"Content-Type:application/json\"\n  artifacts:\n    baseDirectory: dist\n    files:\n      - '**/*'\n  cache:\n    paths:\n      - node_modules/**/*\nSharing schema type definitions\n\nIf you're using Amplify Data, we recommend adding a paths entry in the tsconfig.json of your frontend app that points to the amplify/data/resource.ts file in your backend app to easily access your schema type definitions from your frontend apps.\n\nFirst, cone your backend repo into the same parent directory as your frontend app, then add the following entry:\n\ntsconfig.json\nCopy\ntsconfig.json code example\n{\n  \"compilerOptions\": {\n    \"paths\": {\n      \"@/data-schema\": [\"../backend-app/amplify/data/resource\"]\n    }\n  }\n}\n\nYou can then import the Schema type from this path in your frontend code to get code completion and strong typing for your API calls:\n\napps/admin-dashboard/page.tsx\nCopy\napps/admin-dashboard/page.tsx code example\nimport { generateClient } from \"aws-amplify/data\";\nimport type { Schema } from \"@/data-schema\";\n\n\nconst client = generateClient<Schema>();\n\n\nconst createTodo = async () => {\n  await client.models.Todo.create({\n    content: window.prompt(\"Todo content?\"),\n    isDone: false,\n  });\n}\nPREVIOUS\nShare resources across branches\nNEXT\nMonorepo setup"
  },
  {
    "title": "Monorepo setup - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/deploy-and-host/fullstack-branching/monorepos/",
    "html": "Next.js\n/\nDeployment\n/\nFullstack workflows\n/\nMonorepo setup\nMonorepo setup\n\nSome teams choose a monorepo approach, or single repositories that contain multiple packages or components to simplify the deployment process for shared libraries and components. Without a monorepo, you have to deploy each package individually, keep track of package versions and dependencies across packages, and ensure version compatibility. This can become exponentially more complex as the number of packages grows. With a monorepo, all packages and dependencies are contained within a single repository.\n\nAmplify Gen 2 supports monorepo workflows for fullstack builds with monorepo tools such as Nx and yarn workspaces. When building with Gen 2, we recommend creating the amplify/ folder in a shared workspace. We will use the following example for this guide:\n\nCopy\ncode example\n├── apps/\n│   ├── admin-dashboard/\n│   │   ├── next.config.mjs\n│   │   └── package.json\n│   └── marketing-site/\n│       ├── astro.config.mjs\n│       └── package.json\n├── packages/\n│   └── my-shared-backend/\n│       ├── amplify/\n│       │   ├── auth/\n│       │   │   └── resource.ts\n│       │   ├── data/\n│       │   │   └── resource.ts\n│       │   └── backend.ts\n│       |── package.json\n        └── tsconfig.json\n└── package.json\n\nMonorepos require a slightly different setup. We are going to deploy 3 Amplify apps:\n\nmy-shared-backend\nadmin-dashboard\nmarketing-site\nDeploy backend app\n\nThe first app, my-shared-backend, will be the only app that updates changes to the backend. The other apps will only run frontend builds that point to the shared backend.\n\nTo get started, deploy the shared backend Amplify app. With Gen 2, you can now setup backend-only CI/CD apps. Navigate to the Amplify console and select Create new app.\n\nOnce you connect your repository, select your monorepo project. Check the box that says My app is a monorepo and enter the path to your amplify backend.\n\nYour build settings should be automatically detected. Save and deploy.\nDeploy frontend apps\nFor the frontend apps, connect the frontend projects in the Amplify console separately, and update the build commands to include:\nTerminal\nCopy\nTerminal code example\nnpx ampx generate outputs --branch main --app-id BACKEND-APP-ID\nTo locate the App ID for your backend application, navigate to the Amplify console and select your backend-app. On the Overview page, the App ID is displayed under the project name.\nTerminal\nCopy\nTerminal code example\nnpx ampx generate outputs --branch main --app-id BACKEND-APP-ID\nSharing schema type definitions\n\nIf you're using Amplify Data, we recommend adding a paths entry in your tsconfig.json file that points to the amplify/data/resource.ts file to easily access your schema type definitions from your frontend apps.\n\ntsconfig.json\nCopy\ntsconfig.json code example\n{\n  \"compilerOptions\": {\n    \"paths\": {\n      \"@/data-schema\": [\"./packages/my-shared-backend/amplify/data/resource\"]\n    }\n  }\n}\n\nYou can then import the Schema type from this path in your frontend code to get code completion and strong typing for your API calls:\n\napps/admin-dashboard/page.tsx\nCopy\napps/admin-dashboard/page.tsx code example\nimport { generateClient } from \"aws-amplify/data\";\nimport type { Schema } from \"@/data-schema\";\n\n\nconst client = generateClient<Schema>();\n\n\nconst createTodo = async () => {\n  await client.models.Todo.create({\n    content: window.prompt(\"Todo content?\"),\n    isDone: false,\n  });\n}\nPREVIOUS\nSeparate frontend and backend teams\nNEXT\nFullstack previews"
  },
  {
    "title": "Secrets and environment vars - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/deploy-and-host/fullstack-branching/secrets-and-vars/",
    "html": "Next.js\n/\nDeployment\n/\nFullstack workflows\n/\nSecrets and environment vars\nSecrets and environment vars\n\nAmplify Gen 2 offers centralized management of secrets and environment variables for all fullstack branches. Secrets allow you to securely configure environment-specific values like social sign-in keys, function environment variables, function secrets, and other sensitive data needed by your application across environments.\n\nFAQ\nHow is this different from Amplify Gen 1?\nSet secrets\n\nYou can set secrets for your fullstack branch deployments or your local dev server.\n\nBranch environment\n\nYou can add secrets for branch deployments in the Amplify console. From the App home page, navigate to Hosting > Secrets, and then choose the Manage secrets button. You can add a secret key or value that applies to all deployed branches or just specific branches.\n\nSecrets are stored in AWS Systems Manager Parameter Store under the following naming conventions:\n\nSecrets that apply to all branches: /amplify/shared/<app-id>/<secret-key>\nSecrets that apply to a specific branch: /amplify/<app-id>/<branchname>/<secret-key>\nLocal environment\n\nSecrets set in a sandbox do not show up in the Amplify console. You can view them in the AWS Parameter Store console.\n\nWhen testing features locally, you might want to test with real secrets. You can add secrets while running the cloud sandbox with the following command:\n\nTerminal\nCopy\nTerminal code example\nnpx ampx sandbox secret set foo\n? Enter secret value: ###\nDone!\n\n\n> npx ampx sandbox secret set bar\n? Enter secret value: ###\nDone!\nAccess secrets\n\nOnce you have set a secret, you can access the values in code by calling the secret() function. The following example shows how to set up social sign-in with authentication in your app. Depending on your environment, Amplify will automatically load the correct secret value with no extra configuration.\n\nCopy\ncode example\nimport { defineAuth, secret } from '@aws-amplify/backend';\n\n\nexport const auth = defineAuth({\n  loginWith: {\n    email: true,\n    externalProviders: {\n      facebook: {\n        clientId: secret('foo'),\n        clientSecret: secret('bar')\n      }\n    }\n  }\n});\nRemove secrets\n\nWhen deleting branch environments or sandbox environments, you need to manually delete the secrets as well.\n\nBranch environment\n\nSecrets that are used in branch deployments can be managed directly in the Amplify console. You can remove them under Secret management by choosing Remove.\n\nLocal environment\n\nTo remove a secret in your local environment, run the following command in your terminal:\n\nTerminal\nCopy\nTerminal code example\nnpx ampx sandbox secret remove foo\nSet environment variables\n\nEnvironment variables work like key-value pairs to help manage configurable settings across different deployment environments, including development, staging, and production. Unlike secrets, which store sensitive data, environment variables are typically nonconfidential and are used for controlling application behavior in different environments. Another key difference is that environment variables are stored and managed by the Amplify managed service. You can set environment variables in the Amplify console (view the AWS Amplify Hosting User Guide for detailed instructions).\n\nAccess environment variables\n\nYou can enable access to environment variables for your fullstack branch deployments or your local dev server.\n\nBranch environment\n\nYou can manage your branch environment access through the Amplify console.\n\nFirst, create an environment variable in the Amplify console (in this example, you will name it REACT_APP_TEST_VARIABLE)\n\nNext, navigate to the Build Settings in console (or to the amplify.yml file) and update the build settings to pipe the environment variable into a file. Here is an example of writing it into an .env file:\n\namplify.yml\nbuild:\n  commands:\nCopy\nhighlighted code example\n    - echo \"REACT_APP_TEST_VARIABLE=$REACT_APP_TEST_VARIABLE\" >> .env\n    - npm run build\n\nWith the implementation above, the environment variable is written in a .env file. However, you can write it to any file depending on your platform.\n\nFor Flutter, you can still use .env with an external package or generate your configuration file in Dart or JSON format.\nFor Android, you can use Build Configurations or Gradle variables.\nFor iOS, you can update your plist file with the necessary code or create a configuration file in JSON format.\n\nNow the .env can access the environment variable through process.env in your client code:\n\nCopy\ncode example\nconsole.log('REACT_APP_TEST_VARIABLE', process.env.REACT_APP_TEST_VARIABLE);\nLocal environment\n\nWhen working on your local machine, you must manually load the sandbox's environment variables. First, add the environment variable in your .env.local file. Then, a library such as @dotenvx/dotenvx can load the environment variables, which you can then reference with process.env.\n\nPREVIOUS\nFullstack branch deployments\nNEXT\nShare resources across branches"
  },
  {
    "title": "Share resources across branches - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/deploy-and-host/fullstack-branching/share-resources/",
    "html": "Next.js\n/\nDeployment\n/\nFullstack workflows\n/\nShare resources across branches\nShare resources across branches\n\nIn some instances, you may not want to deploy new resources for every branch. For example, you might want all your feature branches to point to the backend resources deployed by the dev branch so you can reuse seed data, users, and groups.\n\nYou can update your app build settings to share resources across branches. From the Amplify console, go to your App overview page, select Build settings under the Hosting for viewing your app's build specification YAML file.\n\nUpdate the build settings for the backend phase to run npx ampx generate outputs --branch dev app-id $AWS_APP_ID to generate the amplify_outputs.json file for all branches other than main or dev. After this update, any new deployed branches will not deploy backend resources as part of the build and instead will use the deployed backend resources from the dev branch. Update the build settings for the backend phase to run npx ampx generate outputs --branch dev app-id $AWS_APP_ID to generate the amplify_outputs.json file for all branches other than main or dev. After this update, any new deployed branches will not deploy backend resources as part of the build and instead will use the deployed backend resources from the dev branch.\n\namplify.yml\nCopy\namplify.yml code example\nversion: 1\nbackend:\n    phases:\n        build:\n            commands:\n                - 'npm ci --cache .npm --prefer-offline'\n                - 'echo $AWS_BRANCH'\n                - |\n                  case \"${AWS_BRANCH}\" in\n                      main)\n                          echo \"Deploying main branch...\"\n                          npx ampx pipeline-deploy --branch $AWS_BRANCH --app-id $AWS_APP_ID\n                          ;;\n                      dev)\n                          echo \"Deploying dev branch...\"\n                          npx ampx pipeline-deploy --branch $AWS_BRANCH --app-id $AWS_APP_ID\n                          ;;\n                      pr-*)\n                          echo \"Deploying pull request branch...\"\n                          npx ampx generate outputs --branch previews --app-id $AWS_APP_ID\n                          ;;\n                      *)\n                          echo \"Deploying to staging branch...\"\n                          npx ampx generate outputs --branch dev --app-id $AWS_APP_ID\n                          ;;\n                  esac\nfrontend:\n    phases:\n        build:\n            commands:\n                - 'npm run build'\n    artifacts:\n        baseDirectory: .next\n        files:\n            - '**/*'\n    cache:\n        paths:\n            - .next/cache/**/*\n            - .npm/**/*\n            - node_modules/**/*\nPREVIOUS\nSecrets and environment vars\nNEXT\nSeparate frontend and backend teams"
  },
  {
    "title": "Fullstack branch deployments - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/deploy-and-host/fullstack-branching/branch-deployments/",
    "html": "Next.js\n/\nDeployment\n/\nFullstack workflows\n/\nFullstack branch deployments\nFullstack branch deployments\n\nAmplify code-first DX (Gen 2) offers fullstack branch deployments that allow you to automatically deploy infrastructure and application code changes from feature branches. This enables testing changes in an isolated environment before merging to the main branch.\n\nSet up feature branch deployments\n\nAfter you've deployed your first branch, you can manually connect more, but the recommended workflow is to use the branch auto-detection feature.\n\nLog in to the Amplify console and choose your app.\n\nNavigate to App settings > Branch settings, select Edit and enable Branch auto-detection and Branch auto-disconnection. The following video uses the default settings, which will connect any branch in your repo automatically. Branch auto-disconnection will ensure that if you delete a branch from your repository, the branch will also be deleted.\n\nYou can also define a pattern to connect only certain branches. For example, setting dev, staging, and feature/* will automatically connect all three branch types. Your dev and staging branches, as well as any branch that begins with feature/, will be connected.\n\nPush a commit to your feature/A and staging branches that match the pattern. You should start seeing deployments on the console page. You will now have three fullstack branches deployed.\n\nPromote changes to production\n\nIn Gen 2, promoting changes to production follows the normal Git-based workflow.\n\nMake a change in your feature/A branch.\nTerminal\nCopy\nTerminal code example\ngit checkout -b feature/A\n\n\n## make some edits to your code\n\n\ngit commit --am \"New data model to track comments for todos added\"\n\n\ngit push origin feature/A\nSubmit a pull request to your main branch. Once your team has validated the changes, merge the pull request to main. This will initiate a build on your main branch and update any frontend or backend resources that you changed.\nGenerate client config\n\nYou can generate the config for a branch environment by running:\n\nFor Web and React Native, generating the config with the default format and output directory.\n\nTerminal\nCopy\nTerminal code example\nnpx ampx generate outputs --app-id <your-amplify-app-id> --branch <your-git-branch-name> --out-dir <path/to/config>\nNEXT\nSecrets and environment vars"
  },
  {
    "title": "Fullstack workflows - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/deploy-and-host/fullstack-branching/",
    "html": "Next.js\n/\nDeployment\n/\nFullstack workflows\nFullstack workflows\nFullstack branch deployments\nUse fullstack branch deployments to test changes from feature branches.\nSecrets and environment vars\nManage secrets and environment variables across your fullstack branch and local dev environments.\nShare resources across branches\nUpdate app build settings to share resources across branches.\nSeparate frontend and backend teams\nSet up multiple repositories with the Amplify CI/CD pipeline.\nMonorepo setup\nSet up monorepos with the Amplify CI/CD pipeline.\nFullstack previews\nSet up ephemeral fullstack environments with pull request previews.\nCustom pipelines\nSet up fullstack CI/CD in a custom pipeline.\nCross-account deployments\nSet up a cross-account deployment pipeline powered by Amazon CodeCatalyst and AWS Amplify Hosting."
  },
  {
    "title": "Sandbox features - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/deploy-and-host/sandbox-environments/features/",
    "html": "Next.js\n/\nDeployment\n/\nCloud sandbox environments\n/\nSandbox features\nSandbox features\n\nSandbox environments include additional features for managing secrets, deploying multiple sandboxes, config generation, and client codegen for your Amplify app.\n\nSecure secrets in your sandbox\n\nSecrets set in a sandbox do not show up in the Amplify Console. You can view them in the AWS Systems Manager (SSM) Parameter Store console.\n\nAmplify Gen 2 offers secure secret storage to manage sensitive data like API keys and database credentials. Secrets are similar to environment variables, but they are encrypted AWS Systems Manager Parameter Store key value pairs. Secrets are stored in AWS Parameter Store under the /amplify prefix.\n\nSet secrets\n\nYou can add secrets to your sandbox environment using the following command:\n\nCopy\ncode example\nnpx ampx sandbox secret set foo\n? Enter secret value: ###\nDone!\n\n\nnpx ampx sandbox secret set bar\n? Enter secret value: ###\nDone!\n\nAfter these commands, your sandbox will have two secrets named foo and bar.\n\nList secrets\n\nYou can list all of the secret names available in your sandbox environment with the following command:\n\nCopy\ncode example\nnpx ampx sandbox secret list\n - foo\n - bar\nRetrieve a secret\n\nNote: This will print a secret value in plain text to the terminal. Do not use this command anywhere that terminal logs may be stored (such as CI/CD jobs).\n\nTo show the value of a secret, run the following command.\n\nCopy\ncode example\nnpx ampx sandbox secret get foo\nname: foo\nversion: 1\nvalue: abc123\nlastUpdated: Mon Nov 13 2023 22:19:12 GMT-0800 (Pacific Standard Time)\nRemove secrets\n\nTo remove a secret from from the sandbox, run the following command in your terminal:\n\nCopy\ncode example\nnpx ampx sandbox secret remove foo\nReference secrets\n\nOnce you have set a secret, you can reference the secret in your backend definition using the secret() function. The following example shows how to set up social sign-in with authentication in your app. Depending on your environment, Amplify will automatically load the correct secret value.\n\nimport { defineAuth, secret } from '@aws-amplify/backend';\n\n\nexport const auth = defineAuth({\n  loginWith: {\n    email: true,\n    externalProviders: {\n      facebook: {\nCopy\nhighlighted code example\n        clientId: secret('foo'),\n        clientSecret: secret('bar')\n      }\n    }\n  }\n});\n\nThe secret() function does NOT retrieve the value of the secret. It places a reference to the secret value in the backend definition. The secret value is only resolved during deployment of your backend.\n\nThe secret() function can only be used in specific places in your backend definition such as configuring auth providers and function secrets.\n\nTo deploy a backend that uses secret() references via Amplify hosting, the secret values must be configured for the Amplify app or branch\n\nWork with multiple AWS profiles\n\nSometimes you might have multiple AWS profiles set up locally. To run ampx sandbox secret commands, use the --profile flag to deploy to a specific profile. For example, let's say you have two AWS profiles set up locally—default and work. To add secrets to the sandbox in the work profile, run the following command in your terminal:\n\nCopy\ncode example\nnpx ampx sandbox secret set foo --profile work\nWork with multiple named sandboxes\n\nProvisioning multiple sandboxes per app is possible but not recommended because managing multiple ephemeral environments for a single developer introduces complexity. With multiple sandboxes, it can be difficult to keep track of what code version or configuration is deployed where. Sticking to a single sandbox per developer keeps your workflows simpler.\n\nYou can create multiple sandboxes if you want to have different features or test environments available in different sandboxes. By default, your sandbox is named based on the local machine username. To override this name, use the --identifier option:\n\nCopy\ncode example\nnpx ampx sandbox --identifier feature1sandbox\n\nThis will start a sandbox named feature1sandbox.\n\nOnce the deployment completes, exit sandbox and run the following command in the terminal:\n\nCopy\ncode example\nnpx ampx sandbox --identifier feature2sandbox\n\nAfter successful deployment, you will have two sandboxes feature1sandbox and feature2sandbox. You can switch between them but only one can be running at a time.\n\nSecret management with named sandboxes\n\nWhen working with multiple sandboxes, secrets must be configured for each one. All of the sandbox secret commands accept the --identifier argument to manage secrets for named sandboxes. For example, to add a secret to feature1sandbox, use:\n\nCopy\ncode example\nnpx ampx sandbox --identifier feature1sandbox secret set baz\nStream function logs\n\nAmplify offers the ability to stream function logs directly to your terminal or a file. Learn more about streaming function logs.\n\nGenerate client config\n\nThe client config, or amplify_outputs.json file, contains the configuration strings for interacting with AWS resources specific to an environment. The Amplify client libraries need the client config in order to use the library APIs to connect to backend resources. By default, the cloud sandbox generates the client configuration file at the root of the project (such as @/amplify_outputs.json). If you want to place the file at a different path (such as for a monorepo or Android app), run the following command in the terminal:\n\nTerminal\nCopy\nTerminal code example\nnpx ampx sandbox --outputs-out-dir ./path/to/config --outputs-format [\"json\", \"dart\"]\n\nAlternatively, if you want to generate the config for a branch environment to test against, run the following command in the terminal.\n\nCopy\ncode example\nnpx ampx generate outputs --app-id <your-amplify-app-id> --branch main --format [\"json\", \"dart\"] --out-dir ./path/to/config\nDeployment Environment\n\nAlternatively, if you want to generate the config for a branch environment to test against, you can run the following command below in the terminal:\n\nFor Web and React Native, generating the config with the default format and output directory.\n\nTerminal\nCopy\nTerminal code example\nnpx ampx generate outputs --app-id <app-id> --branch main\nGenerate client codegen\n\nAmplify Gen 2 introduces a fully typed experience for data that no longer requires an explicit codegen step, unlike in Amplify Gen 1. You will only need this command if you are building a mobile app or have Gen 1 requirements.\n\nCodegen generates native code for Swift (iOS), Java (Android), and JavaScript that represents your GraphQL API's data models. It can also generate GraphQL statements (queries, mutations, and subscriptions) so that you don't have to manually code them.\n\nOnce your sandbox completes a deployment, you can run the following command in the terminal to generate client code that is specific to your needs:\n\nCopy\ncode example\nnpx ampx generate graphql-client-code\n--format [choices: \"modelgen\", \"graphql-codegen\", \"introspection\"]\nDelete a sandbox\n\nYou can delete a cloud sandbox environment in several ways:\n\nCtrl+C your sandbox and choose to delete resources.\nRun npx ampx sandbox delete or npx ampx sandbox delete --name\nVisit the Amplify console and delete sandboxes.\nPREVIOUS\nUse cloud sandbox in dev environment"
  },
  {
    "title": "Use cloud sandbox in dev environment - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/deploy-and-host/sandbox-environments/setup/",
    "html": "Next.js\n/\nDeployment\n/\nCloud sandbox environments\n/\nUse cloud sandbox in dev environment\nUse cloud sandbox in dev environment\n\nYou can use a personal cloud sandbox environment that provides an isolated development space to rapidly build, test, and iterate on a fullstack app. Each developer on your team can use their own disposable sandbox environment connected to cloud resources.\n\nCloud sandbox environments are not intended for production workloads.\n\nCreate a new sandbox environment\n\nYou can set up a new sandbox environment on your machine once you have an Amplify app set up. If you have not yet created an Amplify Gen 2 app, visit the Quickstart.\n\nFirst, open the terminal and run the following command:\n\nTerminal\nCopy\nTerminal code example\nnpx ampx sandbox\n\nWhen you deploy a cloud sandbox, Amplify creates an AWS CloudFormation stack following the naming convention of amplify-<app-name>-<$(whoami)>-sandbox in your AWS account with the resources configured in your amplify/ folder.\n\nAfter a successful deployment, sandbox watches for file changes in your amplify/ folder and performs real-time updates to the associated CloudFormation stack. This functionality is built leveraging the hot swap capability of the AWS Cloud Development Kit (CDK).\n\nTerminating a sandbox environment\n\nAfter testing all the changes associated with the backend, you can terminate the sandbox session via Ctrl+c and can then choose whether you want to keep or delete all the resources in the sandbox environment.\n\nManage sandbox environments\n\nYou can view and manage all the sandbox environments for your team in the new Amplify console. This is useful for a team leader to audit all of the Amplify sandbox environments deployed within an account.\n\nChoose Manage Sandboxes to get started:\n\nYou can then check the number, status, and last updates for sandbox environments across your team. You can also use the console to delete sandbox environments when no longer needed.\n\nBest practices\n\nKeep the following best practices in mind when working with cloud sandbox environments:\n\nSandboxes are identical in fidelity to your production environments.\nCode changes are continuously deployed to your sandbox on every save for fast iterations.\nUse sandboxes for experimentation and testing, not for production workloads.\nDeploy one sandbox per Amplify app per developer to prevent conflicts.\nReset sandboxes occasionally to clear out unused resources and save costs.\nNEXT\nSandbox features"
  },
  {
    "title": "Cloud sandbox environments - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/deploy-and-host/sandbox-environments/",
    "html": "Next.js\n/\nDeployment\n/\nCloud sandbox environments\nCloud sandbox environments\nUse cloud sandbox in dev environment\nSet up a cloud sandbox environment you can use with your frontend dev environment.\nSandbox features\nExplore sandbox features such as secrets, client codegen, and config generation for mobile and cross-platform."
  },
  {
    "title": "Manage form lifecycle - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-ui/formbuilder/lifecycle/",
    "html": "Next.js\n/\nBuild UI\n/\nConnected forms\n/\nManage form lifecycle\nManage form lifecycle\n\nHook into the form's lifecycle events to customize user input before submission, run validations, or handle errors.\n\nInitial state - The inputs are either empty or pre-populated based on a default value provided by you.\n\nUse case: If your user clicks on the Clear or Reset button, they'll be brought back to this state.\n\nonChange - Event when form data is changed by the user.\n\nUse case: Use this to get the form data after every user input.\n\nonValidate - Event hook for custom validations. This event triggers after onChange.\n\nUse case: Use this to extend validation rules via code. onValidate also supports asynchronous validation rules, which enable you to validate the form input against external APIs.\n\nonSubmit - Event when your user clicks the Submit button.\n\nUse case: If your form is not connected to a data model, use set this event handler to retrieve the form data. If your form is connected to a data model, use this to customize the provided form data before they are saved to the cloud.\n\nonSuccess - Event when saving form data to the cloud succeeds.\n\nUse case: Use this to dismiss the form or reroute your user after a successful form submission. Only use this if your form is connected to a data model.\n\nonError - Event when saving form data to the cloud fails.\n\nUse case: Use this to log the error and investigate further if your validation rules need to be enhanced to catch input formatting issues. Only use this if your form is connected to a data model.\n\nonCancel - Event when your user clicks on the Cancel button.\n\nUse case: Use this to dismiss the form without saving the form data.\n\nGet form data as your user inputs data - onChange\n\nIn some cases, you want to get the form data in real-time as the user is filling the form. The onChange event provides you the form data in the fields parameter.\n\nCopy\ncode example\nimport { useState } from 'react'\nimport { HomeCreateForm } from './ui-components'\n\n\nfunction App() {\n  const [formData, setFormData] = useState()\n\n\n  return (\n    <HomeCreateForm onChange={fields => setFormData(fields)}/>\n  )\n}\nExtend validation rules in code - onValidate\n\nWith the onValidate event, you can extend the validation rules in code. Learn more about How to add validation rules.\n\nHandle form data submissions - onSubmit\n\nonSubmit should be your default way to handle form submission. It is triggered every time the user clicks on the Submit action button.\n\nYou can use the onSubmit handler to customize the form data before they are saved to the cloud. The form data that's returned from the onSubmit handler will be saved to the cloud.\n\nFor example, if you want to trim all the string data before saving it:\n\nCopy\ncode example\n<HomeCreateForm\n    onSubmit={(fields) => {\n        const updatedFields = {}\n        Object.keys(fields).forEach(key => {\n            if (typeof fields[key] === 'string') {\n                updatedFields[key] = fields[key].trim()\n            } else {\n                updatedFields[key] = fields[key]\n            }\n        })\n        return updatedFields\n    }}\n/>\nHandle form data successfully saving to the cloud - onSuccess\n\nYou can use the onSuccess handler to take an action after the form data has been successfully submitted. The example below hides the form after it has been successfully submitted.\n\nCopy\ncode example\nimport { useState } from 'react'\nimport { HomeCreateForm } from './ui-components'\n\n\nfunction App() {\n  const [showForm, setShowForm] = useState(true)\n\n\n  return (\n    {showForm &&\n      <HomeCreateForm onSuccess={() => {\n        setShowForm(false) // Hide the form\n      }}/>}\n  )\n}\nHandle form submission errors - onError\n\nYou might encounter additional errors during the submit process. You can log these errors and present an alert to customers by using the onError handler.\n\nCopy\ncode example\nimport { HomeCreateForm } from './ui-components'\n\n\nfunction App() {\n  return (\n    <HomeCreateForm onError={(error) => {\n      console.log(error)\n    }}/>\n  )\n}\nHandle user clicking on Cancel action button - onCancel\n\nIf the user clicks on the Cancel action button, you can use the onCancel event to hide the form or route the customer to another page.\n\nCopy\ncode example\nimport { useState } from 'react'\nimport { HomeCreateForm } from './ui-components'\n\n\nfunction App() {\n  const [showForm, setShowForm] = useState(true)\n\n\n  return (\n    {showForm &&\n      <HomeCreateForm onCancel={() => {\n        setShowForm(false) // Hide the form\n      }}/>}\n  )\n}\nPREVIOUS\nValidate form data"
  },
  {
    "title": "Deployment - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/deploy-and-host/",
    "html": "Next.js\n/\nDeployment\nDeployment\nFrontend hosting\nHost static and server-rendered web apps built with modern JS frameworks like Next.js, Vue, and React.\nCloud sandbox environments\nLearn about sandbox development.\nFullstack workflows\nOverview of fullstack branching capabilities."
  },
  {
    "title": "Frontend hosting - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/deploy-and-host/hosting/",
    "html": "Next.js\n/\nDeployment\n/\nFrontend hosting\nFrontend hosting\n\nAWS Amplify Hosting is a fully managed CI/CD and hosting service for fast, secure, and reliable static and server-side rendered apps that scale with your business. This service supports modern web frameworks such as React, Angular, Vue, Next.js, Nuxt.js, Gatsby, and more.\n\nBecause AWS Amplify Hosting is a fully managed service, its documentation lives on the AWS Documentation site. To learn about hosting features such as custom domains, redirects, and more, please visit the Hosting documentation.\n\nView Hosting Docs"
  },
  {
    "title": "Figma-to-React - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-ui/figma-to-code/",
    "html": "Next.js\n/\nBuild UI\n/\nFigma-to-React\nFigma-to-React\n\nYou can generate React code using the Amplify UI Figma file and the Amplify UI Builder plugin.\n\nStep 1: Duplicate the Amplify UI Figma file\n\nThis file contains the following pages:\n\nREADME: The README page explains how to use the Figma file to create new components, theme primitives, and customize layout and styling.\nTheme: The theme page displays the theme values and design tokens Amplify UI uses to style the primitives. If you want to theme the primitives, use the AWS Amplify UI Builder Figma plugin to make changes to the theme. Any changes you make on the theme page itself will not be generated in code.\nPrimitives: Primitives are building-block components such as alerts, buttons, and badges. These primitives correspond to the Amplify UI primitives and get exported to code with all the primitive properties. This page is read-only. Changes to the primitives on this page will not be reflected in code that is generated.\nMy components: This page contains all of the custom components built using the primitives. Amplify provides dozens of components such as news feed, social media, and marketing hero components to get you started. Customize these to match your needs or build your own components.\nExamples: This is for demonstration purposes only, to show designers how to use our components to build entire pages.\n\nPlease follow the README in our Figma file to learn how to create your components to optimize for code quality.\n\nStep 2: Run the Amplify UI Builder Figma plugin in dev mode\n\nAfter you duplicate the Figma file, you run the Amplify UI Builder figma plugin in dev mode or non-dev mode to generate Amplify UI React code.\n\nDev Mode\nTurn on Figma dev mode in your Figma file.\nClick on the Plugins tab.\nSelect the AWS Amplify UI Builder plugin.\nChoose any layer in your file to get React code and a live preview of the generated code.\nNon-dev Mode\nClick on the Plugins tab.\nSelect the AWS Amplify UI Builder plugin.\nChoose Download component code to download the React code for your components."
  },
  {
    "title": "Validate form data - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-ui/formbuilder/validations/",
    "html": "Next.js\n/\nBuild UI\n/\nConnected forms\n/\nValidate form data\nValidate form data\n\nSanitize user input by adding validation rules to your form. By default, Amplify generated forms infers a range of validation rules based on the data model. For example, given a data model with an AWSEmail field, the generated form input will automatically run an email validation rule.\n\nConfigurable validation rules\n\nBy default, the following validation rules are available for you to configure:\n\nInput type\tConfigurable validation rule\nString\t- Start With\n- End With\n- Contain\n- Does not contain\n- Be less than N characters long\n- Be at least N characters long\n\nInt, Float\t- Be greater than\n- Be less than\n- Be equal to\n\nAWSDate, AWSTime, AWSDateTime\t- Be before\n- Be after\n\nAutomatically configured validation rules\n\nFor the types below, we automatically apply validation rules on form inputs:\n\nAWSIPAddress: input value must be a valid IPv4 or IPv6 address.\nAWSURL: input value must consist of a schema (http, mailto) and a path part. Path part can't contain two forward slashes (//).\nAWSEmail: input value must be an email address in the format <local-part>@<domain-part>.\nAWSJSON: input value must be a valid JSON.\nAWSPhone: input value must be a phone number that can contain either spaces or hyphens to separate digit groups.\nAdd validation rules\n\nEvery form provides an onValidate event handler to provide additional validation rules via code. Return an object with validation functions for the fields you want to validate. In the example below, address must start with a number, otherwise return any existing auto-generated validation responses.\n\nCopy\ncode example\n<HomeCreateForm\n  onValidate={{\n    address: (value, validationResponse) => {\n      const firstWord = value.split('')[0];\n      if (!isNaN(str)) {\n        // check if the first word is a number\n        return {\n          hasError: true,\n          errorMessage: 'Address must start with a number'\n        };\n      }\n      return validationResponse;\n    }\n  }}\n/>\n\nNote: the validation function must return a validation response of the following shape:\n\nCopy\ncode example\ntype ValidationResponse = {\n  hasError: boolean;\n  errorMessage?: string;\n};\nAdd validation rules for nested JSON data\n\nAmplify generated forms can also produce nested JSON object. For example, you can create a new ProductForm component based on the following JSON object:\n\nCopy\ncode example\n{\n  \"name\": \"Piano\",\n  \"price\": {\n    \"maxDiscount\": 0.15,\n    \"default\": 999,\n    \"currency\": \"$\"\n  }\n}\n\nTo add validation rules to the nested objects, pass in validation functions in the same nested structure as the data:\n\nCopy\ncode example\n<ProductForm\n  onValidate={{\n    price: {\n      currency: (value, validationResponse) => {\n        // Pass validation function to match the nested object\n        const allowedCurrencies = ['$', '€', '￥', '₹'];\n        if (!allowedCurrencies.includes(value)) {\n          return {\n            hasError: true,\n            errorMessage: 'Currency must be either \"$\", \"€\", \"￥\", or \"₹\".'\n          };\n        }\n        return validationResponse;\n      }\n    }\n  }}\n  onSubmit={(fields) => {\n    /* handle form data submission */\n  }}\n/>\nCall external APIs for asynchronous form validation\n\nSometimes your form needs to asynchronously validate an input with an external API or database before the form data is submitted.\n\nReturn a Promise in the onValidate prop to run an asynchronous validation rule. In the following example, we check with an external API if a real estate agent exist based on a given license number:\n\nCopy\ncode example\n<AgentContactForm\n  onValidate={{\n    licenseNumber: (value, validationResponse) => {\n      // fetch calls an external API,\n      // which ultimately returns a Promise<ValidationResponse>\n      return fetch(`http://localhost:3000/api/agent/${value}`).then(\n        (response) => {\n          if (response.status !== 200) {\n            return {\n              // If the request failed, return a validation error\n              hasError: true,\n              errorMessage: 'No agent was not found with that license number.'\n            };\n          }\n          return validationResponse;\n        }\n      );\n    }\n  }}\n  onSubmit={(fields) => {\n    /* Handle form submission */\n  }}\n/>\nPREVIOUS\nConfigure special inputs\nNEXT\nManage form lifecycle"
  },
  {
    "title": "Configure special inputs - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-ui/formbuilder/special-inputs/",
    "html": "Next.js\n/\nBuild UI\n/\nConnected forms\n/\nConfigure special inputs\nConfigure special inputs\nStorage Manager\n\nStorage Manager fields allow your forms to accept file uploads, which are stored in an Amazon S3 bucket connected to your Amplify app. After uploading, that file's S3 key is stored in your data model, allowing for systematic retrieval using the Amplify JS library.\n\nPrerequisites\n\nIn order to use the Storage Manager field, your Amplify app must have an Amplify app with Authentication and Storage enabled.\n\nHow it works\n\nThe Storage Manager input will allow users to select from files on their local device and upload them to an S3 bucket. Storage Manager automatically connects to your S3 bucket added as part of Amplify Storage.\n\nFiles are uploaded immediately upon selection, and an S3 key is generated. By default, Storage Manager will generate a unique S3 key based on the file uploaded. On form submission, Storage Manager will return the S3 key of the uploaded file as a String.\n\nAdding it to your form\n\nTo use the StorageManager component with an autogenerated form you will first need a data model that has an attribute that is either a string or an array of strings (a.string().array() in amplify/data/resource.ts). Then make sure to run npx ampx generate forms after you update your data model.\n\nThen go into the generated form JSX file you want to use the StorageManager, for example: ui-components/TodoCreateForm.jsx. If your attribute is an array of strings, look for an <ArrayField> with items={images} (if your attribute name is \"images\"). Remove that entire component and replace it with the StorageManager component like this:\n\nui-components/TodoCreateForm.jsx\nCopy\nui-components/TodoCreateForm.jsx code example\n// imports\nimport { StorageManager } from \"@aws-amplify/ui-react-storage\";\n// import the processFile helper function which will create unique filenames based on the file contents\nimport { processFile } from \"./utils\";\n\n\n//...\n<StorageManager\n  accessLevel=\"public\"\n  maxFileCount={10}\n  acceptedFileTypes={['image/*']}\n  processFile={processFile}\n  onUploadSuccess={({key}) => {\n    // assuming you have an attribute called 'images' on your data model that is an array of strings\n    setImages(prevImages => [...prevImages, key])\n  }}\n  onFileRemove={({key}) => {\n    setImages(prevImages => prevImages.filter(img => img !== key))\n  }}\n/>\n\nIf you want your data model to have only one image instead of an array of images, look for the <TextField> component with value={image} and replace it with the StorageManager component like this:\n\nui-components/TodoCreateForm.jsx\nCopy\nui-components/TodoCreateForm.jsx code example\n// imports\nimport { StorageManager } from \"@aws-amplify/ui-react-storage\";\n// import the processFile helper function which will create unique filenames based on the file contents\nimport { processFile } from \"./utils\";\n\n\n//...\n<StorageManager\n  accessLevel=\"public\"\n  maxFileCount={1}\n  acceptedFileTypes={['image/*']}\n  processFile={processFile}\n  onUploadSuccess={({key}) => {\n    // assuming you have an attribute called 'images' on your data model that is an array of strings\n    setImage(key)\n  }}\n  onFileRemove={({key}) => {\n    setImage(undefined)\n  }}\n/>\n\nSee the documentation for the StorageManager for all configuration options.\n\nUnique S3 keys\n\nIf files with identical S3 keys are uploaded to the same path, S3 will overwrite those files. To prevent accidental overwriting of files, Storage Manager generates a unique S3 key by hashing the file contents. Uploading different files with the same name will not overwrite the original file.\n\nHowever, if a form submitter uploads two identical files to the same path - even with different file names - Storage Manager will prevent file duplication in your S3 bucket.\n\nFile overwriting only occurs for identical S3 keys in the same path. If the File level access for your Storage Manager is set to private or protected, identical files uploaded by separate users will be saved separately.\n\n\n\n\nIf your File level access is set to public, identical files will overwrite each other.\n\nPREVIOUS\nCustomize form inputs\nNEXT\nValidate form data"
  },
  {
    "title": "Customize form inputs - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-ui/formbuilder/customize/",
    "html": "Next.js\n/\nBuild UI\n/\nConnected forms\n/\nCustomize form inputs\nCustomize form inputs\n\nIn this guide, you will learn how to customize connected forms that are generated by running npx ampx generate forms. Before you begin you will need:\n\nYour cloud sandbox with an Amplify Data resource up and running (npx ampx sandbox)\nA frontend application that has generated a connected form\n\nAll Amplify forms are built with the Amplify UI library. The generated form provides a mechanism to override properties for each individual input component, like TextField, TextAreaField, SelectField. You can override any props to those components with the overrides prop on the form component. For example, if you want to change the variation and label of the content field in the TodoCreateForm:\n\nimport TodoCreateForm from '@/ui-components/TodoCreateForm'\n\n\n<TodoCreateForm\nCopy\nhighlighted code example\n  overrides={{\n    content: {\n      variation: 'quiet',\n      label: 'Todo'\n    }\n  }}\n/>\n\nNote: We do not recommend overriding properties that are already set by the generated form. This could lead to unexpected behavior during runtime. Verify the set properties by navigating to the component in the src/ui-components/[your-form-component].jsx file.\n\nYou own updating the code directly for the generated form. Here's how you can customize the form.\n\nManually add form input field\n\nYou can manually add a form input connected to a data model to the generated form. For example, let's say you add a priority field to your data model. Make the following edits to the generated form:\n\nsrc/ui-components/TodoCreateForm.js\n// 1. Set initialValues\n  const initialValues = {\n    content: \"\",\nCopy\nhighlighted code example\n    priority: \"\" // Initial value for priority\n  };\n\n\n  // 2. State setup\n  const [priority, setPriority] = React.useState(initialValues.priority);\n\n\n  // 3. Update resetValues\n  const resetStateValues = () => {\n    .. // previous fields\nCopy\nhighlighted code example\n    setPriority(initialValues.priority)\n    setErrors({});\n  };\n\n\n  // 4. Validation setup\n  const validations = {\n    content: [],\nCopy\nhighlighted code example\n    priority: [] // Assuming no special validations for now\n  };\n\n\n  // 5. Update form submission\n   onSubmit={async (event) => {\n        event.preventDefault();\n        let modelFields = {\n          ..,\nCopy\nhighlighted code example\n          priority\n        };\n\n\n  // 6. Add TextField\n  <TextField\n     label=\"Priority\"\n     isRequired={false}\n     isReadOnly={false}\n     value={priority}\n     onChange={(e) => {\n       let { value } = e.target;\n       if (onChange) {\n         const modelFields = {\n           priority: value,\n         };\n         const result = onChange(modelFields);\n         value = result?.priority ?? value;\n       }\n       if (errors.priority?.hasError) {\n         runValidationTasks(\"priority\", value);\n       }\n       setPriority(value);\n     }}\n     onBlur={() => runValidationTasks(\"priority\", priority)}\n     errorMessage={errors.priority?.errorMessage}\n     hasError={errors.priority?.hasError}\n     {...getOverrideProps(overrides, \"priority\")}\n   />\nManually add option fields\n\nSelect Fields, Radio Group Fields, and Autocomplete Fields require a set of options for your users to choose from. For example, a \"Status\" input can only have the options \"Not started\", \"In progress\", and \"Done\". This would be identical to the above 6 steps, but in step 6 you would replace <TextField> with <SelectField>\n\nsrc/ui-components/TodoCreateForm.js\nCopy\nsrc/ui-components/TodoCreateForm.js code example\n// 6. Import <SelectField> component and add to form return\n  <SelectField\n    label=\"Label\" \n    placeholder=\"Please select an option\" \n    value={status} \n    onChange={(e) => {\n      let { value } = e.target;\n      if (onChange) {\n          const modelFields = {\n              status: value\n          };\n          const result = onChange(modelFields);\n          value = result?.status ?? value;\n      }\n      if (errors.status?.hasError) {\n          runValidationTasks(\"status\", value);\n      }\n      setStatus(value);\n      }} \n      onBlur={() => runValidationTasks(\"status\", status)}\n      errorMessage={errors.status?.errorMessage} \n      hasError={errors.status?.hasError} \n      {...getOverrideProps(overrides, \"status\")}\n    >\n      <option children=\"Not started\" value=\"Not started\" {...getOverrideProps(overrides, \"statusOption0\")}></option>\n      <option children=\"In progress\" value=\"In progress\" {...getOverrideProps(overrides, \"statusOption1\")}></option>\n      <option children=\"Done\" value=\"Done\" {...getOverrideProps(overrides, \"statusOption2\")}></option>\n  </SelectField>\nConfigure form spacings (paddings and gaps)\n\nAdd spacing to your form and between inputs. Spacing values can either be a CSS length value (px, rem, em, %) or a reference to your theme object's spacing value (xss, medium, large).\n\nimport TodoCreateForm from '@/ui-components/TodoCreateForm'\n\n\n<TodoCreateForm overrides={{\nCopy\nhighlighted code example\n  TodoCreateForm: {\n    rowGap: 'xl',    // horizontal gap between inputs\n    columnGap: 'xs', // vertical gap between inputs\n    padding: 'xl',   // padding around form\n  },\n}} />\nCustomize label for Submit and Clear buttons\n\nYou can customize action button labels to better describe your form's use case, such as changing Submit to Create Todo.\n\nimport TodoCreateForm from '@/ui-components/TodoCreateForm'\n\n\n<TodoCreateForm overrides={{\nCopy\nhighlighted code example\n  ClearButton: {\n    children: 'Close'\n  },\n  SubmitButton: {\n    children: 'Save todo'\n  }\n}} />\nToggle visibility for Submit and Clear buttons\n\nYou can customize the visibility of action buttons to better accommodate your form's use case.\n\nimport TodoCreateForm from '@/ui-components/TodoCreateForm'\n\n\n<TodoCreateForm overrides={{\nCopy\nhighlighted code example\n  ClearButton: {\n    display: 'none'\n  },\n  SubmitButton: {\n    display: 'none'\n  }\n}} />\n\nIf you hide all form action buttons, you can still leverage the onChange event handler to self-manage the form lifecycle. This is useful for a form that updates data in real-time without explicit user confirmation.\n\nimport TodoCreateForm from '@/ui-components/TodoCreateForm'\n\n\n<TodoCreateForm\nCopy\nhighlighted code example\n  onChange={(fields) => {\n    console.log({ fields })\n    // make sure you return fields!\n    return fields\n  }}\n/>\nNEXT\nConfigure special inputs"
  },
  {
    "title": "Connected forms - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-ui/formbuilder/",
    "html": "Next.js\n/\nBuild UI\n/\nConnected forms\nConnected forms\n\nConnected Forms are bound to a model in your app's data schema. Whenever a connected form is submitted, a record is automatically created or updated in the bound data model, with some or all of the form's input fields mapping to fields in the data model. Connected forms automatically work with any Amplify GraphQL API, and no onSubmit handling is required.\n\nGenerate forms\n\nFirst, install the Amplify UI library.\n\nTerminal\nCopy\nTerminal code example\nnpm add @aws-amplify/ui-react\n\nTo use connected forms, you first need to deploy a data model from your sandbox environment. We will use the same example as in the getting started tutorial. To get started run the following command from your project root:\n\nTerminal\nCopy\nTerminal code example\nnpx ampx generate forms\n\nThis will generate create and update forms for each model defined in your schema in a folder called ui-components.\n\nTerminal\nCopy\nTerminal code example\nFile written: ui-components/graphql/subscriptions.ts\nFile written: ui-components/graphql/mutations.ts\nFile written: ui-components/graphql/queries.ts\nFile written: ui-components/TodoCreateForm.jsx\nFile written: ui-components/TodoCreateForm.d.ts\nFile written: ui-components/TodoUpdateForm.jsx\nFile written: ui-components/TodoUpdateForm.d.ts\nFile written: ui-components/utils.js\nFile written: ui-components/index.js\nRe-generating forms\n\nIn Gen 2, we automatically generate the form UI for you, which you can then customize and manage. If you decide to update your data model and need to regenerate the forms, please ensure you back up the original ui-components folder before executing the npx ampx generate forms command again.\n\nRender React form in your app\nIn your application's entrypoint file (e.g. src/index.js for create-react-app or src/main.jsx for Vite), add the following imports and configuration\nCopy\nhighlighted code example\nimport '@aws-amplify/ui-react/styles.css';\nimport { ThemeProvider } from '@aws-amplify/ui-react';\nimport { Amplify } from 'aws-amplify';\n\n\nimport outputs from './amplify_outputs.json';\n\n\nAmplify.configure(outputs);\nIn your application's entrypoint file (e.g. src/main.jsx for Vite), wrap the <App /> component with the following:\nCopy\ncode example\n<ThemeProvider>\n  <App />\n</ThemeProvider>\nImport your form by name. For a form named TodoCreateForm, you would use the following code:\nCopy\ncode example\nimport { TodoCreateForm } from './ui-components';\nPlace your form in code. For a form named ProductCreateForm in a React project, you could use the following App code:\nCopy\ncode example\nfunction App() {\n  return <TodoCreateForm />;\n}\n\n\nexport default App;\nTypes of forms\n\nAll connected and unconnected forms are either a Create form or an Update form.\n\nCreate forms\n\nCreate forms render a form with empty inputs. If a create form is connected to a data model, will always generate a new record upon submission.\n\nUpdate forms\n\nUpdate forms expect an input value in order to pre-populate the form.\n\nFor update forms that are connected to a data model, you can use the id prop, or the model prop:\n\nid prop: id string of the record you want to update. For example:\nCopy\ncode example\n<AuthorUpdateForm id=\"ac74af5c-3aab-4274-8f41-23e1e6576af5\" />\nModel prop: if your form is bound to a data model named Author, your form will have a prop named author as well, which can receive a record. For example:\nCopy\ncode example\n<AuthorUpdateForm author={authorRecord}>"
  },
  {
    "title": "Build UI - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-ui/",
    "html": "Next.js\n/\nBuild UI\nBuild UI\n\nAmplify offers a UI Library that makes it easy to build web app user interfaces that are connected to the backend. Amplify UI offers:\n\nConnected components that are designed to work seamlessly with AWS Amplify backend services, allowing you to quickly add common UX patterns for authentication, storage etc. without having to build them from scratch.\nTooling that generates React forms over data, and React components from Figma designs.\nConnected forms\nGenerate React forms for creating and updating data in your Amplify data backend.\nFigma-to-React\nGenerate React code directly inside Figma using Amplify UI.\nAuthenticator\nThe Authenticator is a connected component that adds complete authentication flows to your application with minimal boilerplate.\nStorage Image\nStorage Image is a connected component that simplifies the process of displaying images stored in an Amazon S3 bucket.\nStorage Manager\nStorage Manager is a connected component that facilitates operations such as uploading, downloading, listing, and deleting files from an Amazon S3 bucket.\nAccount Settings\nAccount Settings components are a set of standalone components that add user management flows to your application with minimal boilerplate. . .\nFace Liveness\nFaceLivenessDetector is a connected component that helps verify that only real users, not bad actors using spoofs, can access your services."
  },
  {
    "title": "Use Amazon Q Developer with Amplify - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/q-developer/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nUse Amazon Q Developer with Amplify\nUse Amazon Q Developer with Amplify\n\nAmazon Q Developer is a generative artificial intelligence (AI) powered conversational assistant that can help you understand, build, extend, and operate AWS applications. You can ask questions about AWS architecture, your AWS resources, best practices, documentation, support, and more. Amazon Q is constantly updating its capabilities so your questions get the most contextually relevant and actionable answers. When used in an integrated development environment (IDE), Amazon Q provides software development assistance. Amazon Q can chat about code, provide inline code completions, generate net new code, scan your code for security vulnerabilities, and make code upgrades and improvements, such as language updates, debugging, and optimizations.\n\nQ Developer in the IDE provides inline code suggestions in real time. As you write code, Amazon Q automatically generates suggestions based on your existing code and comments. When you start typing out single lines of code or comments, Amazon Q makes suggestions based on your current and previous inputs. Inline suggestions are automatically enabled when you download the Amazon Q extension.\n\nSetting up Q Developer\n\nAmazon Q is available as an extension in Visual Studio Code and a plugin in JetBrains. Amazon Q is also available in the AWS Toolkit for Visual Studio. To get started, please visit Install Amazon Q Developer.\n\nUse Q Developer - Inline code suggestions in your Amplify project\n\nAmplify generates two folders in your backend directory, auth and data, which contain TypeScript AWS CDK definitions for each of these resources. We’ll build out the schema for our API through the help of Amazon Q Developer's inline code suggestion capabilities.\n\nStep 1: Open amplify/data/resource.ts and comment out the default schema for Todo provided.\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\nimport { type ClientSchema, a, defineData } from \"@aws-amplify/backend\";\n\n\n// ...\n\n\n// const schema = a.schema({\n//   Todo: a\n//     .model({\n//       content: a.string(),\n//     })\n//     .authorization(allow => [allow.publicApiKey()]),\n// });\n\n\n// ...\n\nStep 2: In a new line below the commented schema, enter a comment to generate the schema using natural language. For example, generate a restaurant model with the following fields: id, name, description, address, image, rating, style. Rating can be a float value. Authorization should allow public. Press Enter for a new line and wait for Amazon Q Developer to generate inline code suggestion for your schema.\n\namplify/data/resource.ts\nimport { type ClientSchema, a, defineData } from \"@aws-amplify/backend\";\n\n\n// ...\n\n\n// const schema = a.schema({\n//   Todo: a\n//     .model({\n//       content: a.string(),\n//     })\n//     .authorization(allow => [allow.publicApiKey()]),\n// });\n\n\nCopy\nhighlighted code example\n// generate a restaurant model with the following fields: id, name, description, address, image, rating, style. Rating can be a float value. Authorization should allow public.\n\n\n// ...\n\nStep 3: Select the inline code suggestion generated by Amazon Q developer. The inline code suggestion feature assists you in defining the schema and hover over the output to select from other options.\n\nNote: You can also trigger inline code suggestion feature by invoking Amazon Q Developer manually using Option+C keyboard shortcut in VS Code. For more commands, please refer to the Commands tab in the Amazon Q extension.\n\nStep 4: Make any required changes to the schema and save the amplify/data/resource.ts file. This will trigger a sandbox deployment and your new data model will be deployed"
  },
  {
    "title": "Troubleshoot \"Cannot find module $amplify/env/<function-name>\" - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/troubleshooting/cannot-find-module-amplify-env/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nTroubleshooting\n/\nTroubleshoot \"Cannot find module $amplify/env/<function-name>\"\nTroubleshoot \"Cannot find module $amplify/env/<function-name>\"\n\nWhen deploying a Amplify Gen 2 app, you may encounter the error message Cannot find module $amplify/env/<function-name> in your frontend build on Amplify Console. This error occurs when your framework tsconfig.json configuration picks up the amplify directory and tries to resolve it as a module. This module is a placeholder for environment variables that are injected at build time by Amplify. To resolve this error, you need to exclude the amplify directory.\n\nTo exclude the amplify directory in your tsconfig.json, add the following lines to the exclude section:\n\ntsconfig.json\nCopy\ntsconfig.json code example\n{\n  \"exclude\": [\"amplify/**/*\"]\n}\n\nAmplify will perform type-checking on sandbox and pipeline-deploy using the tsconfig local to the Amplify backend amplify/tsconfig.json. If you'd like to extend your base configuration you can add it to the localized tsconfig.\n\nAlternatively, if you work within a monorepo you can move your backend to its own package and export the Schema and outputs for ease of sharing with your other apps. For example, in your backend package's package.json\n\npackage.json\nCopy\npackage.json code example\n{\n  \"name\": \"my-backend\",\n  \"private\": true,\n  \"exports\": {\n    \"./schema\": \"./amplify/data/resource.ts\",\n    \"./outputs\": \"./amplify_outputs.json\"\n  }\n}"
  },
  {
    "title": "Troubleshoot configuration errors - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/troubleshooting/library-not-configured/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nTroubleshooting\n/\nTroubleshoot configuration errors\nTroubleshoot configuration errors\n\nIf you are running into a missing configuration or NoCredentials error message and have called Amplify.configure in your project, your Amplify API is most likely being called before Amplify.configure. This can happen in a few different ways. Below are three possibilities you can check to troubleshoot this issue.\n\nCheck 1: Validate that Amplify.configure is called in the root of your project\n\nMake sure you are calling Amplify.configure in the root file of your project. The root file of your app may be different depending on your frontend framework. The current default for some common frameworks are listed below (if you are not using TypeScript the ts and tsx extensions would be js and jsx):\n\nVue.js: src/main.ts\nReact: src/main.tsx\nAngular: src/main.ts\nNext.js Page Router: pages/_app.tsx or src/pages/_app.tsx\nNuxt: app.vue (Or in a plugins file, as recommended here.)\n\nIf you are using the Next.js App Router, you can follow the suggestions in our Next.js documentation for root-level configuration. Keep in mind that if you are calling any APIs at the module-level (i.e. at the top of your file) in any of the Child components, you may still run into this issue. Continue on the Check 2 if this is the case.\n\nCheck 2: Move module-level Amplify API invocations\n\nWhen Amplify APIs are used outside of your application lifecycle, there is a risk that a JavaScript bundler may place that API call before Amplify.configure. Module-level function calls (calls at the top-level of a file), are generally evaluated in the order that they are imported.\n\nBelow is an example of code that will likely result in a missing configuration or NoCredentials error message:\n\nindex.ts\nCopy\nindex.ts code example\nimport { Amplify } from 'aws-amplify';\nimport ComponentX from 'module-fetch-auth';\n\n\n// fetchAuthSession() in ComponentX executed on import\n\n\nAmplify.configure();\n\n\nexport default function App() {\n  return (\n    <div>\n        <ComponentX />\n    </div>\n  );\n}\nmodule-fetch-auth.tsx\nCopy\nmodule-fetch-auth.tsx code example\nimport { fetchAuthSession } from 'aws-amplify/auth';\n\n\nfetchAuthSession(); // Will throw \"AuthUserPoolException: Auth UserPool not configured.\"\n\n\nexport default function ComponentX() {\n  return (\n    <div className=\"box\">\n      ...\n    </div>\n  );\n}\n\nThis error can also happen when using Next.js Layouts and calling Amplify APIs in child components at the module-level (at the top of your file/module). See below for an example of this issue:\n\nlayout.tsx\nCopy\nlayout.tsx code example\nimport ConfigureAmplifyClientSide from '@/ConfigureAmplifyClientSide';\n\n\nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode;\n}) {\n  return (\n    <html lang=\"en\">\n      <body className=\"container py-6\">\n        <>\n          <ConfigureAmplifyClientSide />\n          {children}\n        </>\n      </body>\n    </html>\n  );\n}\nConfigureAmplifyClientSide.tsx\nCopy\nConfigureAmplifyClientSide.tsx code example\nimport { Amplify } from \"aws-amplify\";\n\n\nAmplify.configure(config, { ssr: true });\n\n\nexport default function ConfigureAmplifyClientSide() {\n  return null;\n}\npage.tsx\nCopy\npage.tsx code example\nimport { fetchAuthSession } from \"aws-amplify/auth\";\n\n\n// The layout calls configure, but fetchAuthSession ends up executing first\n// Will throw \"AuthUserPoolException: Auth UserPool not configured.\"\nfetchAuthSession().then((session) => {\n  console.log(session);\n});\n\n\nexport default function HomePage() {\n  return (\n    <div className=\"box\">\n      ...\n    </div>\n  );\n}\n\nTo fix this, we suggest moving all Amplify API calls to within the application lifecycle. For instance, if you are using React, you can use the useEffect hook for functions that should run before the app is loaded:\n\nindex.ts\nCopy\nindex.ts code example\nimport { Amplify } from 'aws-amplify';\nimport ComponentX from 'module-fetch-auth';\n\n\nAmplify.configure();\n\n\nexport default function App() {\n  return (\n    <div>\n        <ComponentX />\n    </div>\n  );\n}\nmodule-fetch-auth.tsx\nCopy\nmodule-fetch-auth.tsx code example\nimport { type AuthSession, fetchAuthSession } from 'aws-amplify/auth';\nimport { useEffect, useState } from 'react';\n\n\nexport default function ComponentX() {\n  const [session, setSession] = useState<AuthSession|undefined>();\n\n\n  const getSession = async () => {\n    try {\n      const currentSession = await fetchAuthSession();\n      setSession(currentSession);\n    } catch (error: unknown) {\n      console.log(error);\n    }\n  };\n\n\n  useEffect(() => {\n    getSession();\n  }, []);\n\n\n  return (\n    <div className=\"box\">\n      ...\n    </div>\n  );\n}\nCheck 3: Configure Amplify on each page of a multi-page app\n\nIf you are working in a multi-page app, you need to call Amplify.configure() for each page/route of your application. We recommend calling Amplify.configure in a common source file and importing it into each page."
  },
  {
    "title": "Troubleshoot \"Stack CDKToolkit already exists\" - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/troubleshooting/stack-cdktoolkit-already-exists/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nTroubleshooting\n/\nTroubleshoot \"Stack CDKToolkit already exists\"\nTroubleshoot \"Stack CDKToolkit already exists\"\n\nIf you are deploying an Amplify Gen 2 app for the first time and have previously bootstrapped your AWS account to work with the AWS Cloud Development Kit (AWS CDK), and you encounter the following error in the Amplify Console:\n\nAmplify Console\nBuild error!\nStack [CDKToolkit] already exists\n\nYou can mitigate by manually updating your CDKToolkit stack using the browser-based AWS CloudShell:\n\nAWS CloudShell\nCopy\nAWS CloudShell code example\ncdk bootstrap aws://$(aws sts get-caller-identity --query Account --output text)/$AWS_REGION\n\nOr by running bootstrap using the AWS CDK CLI from your terminal:\n\nTerminal\nCopy\nTerminal code example\nnpx aws-cdk@latest bootstrap aws://<your-aws-account-id>/<your-aws-region>\n\nIf you continue to experience this issue after applying the workaround noted above, please file an issue in the GitHub repository for Amplify Backend."
  },
  {
    "title": "Troubleshooting - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/troubleshooting/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nTroubleshooting\nTroubleshooting\nTroubleshoot configuration errors\nAddressing missing configuration or NoCredentials error messages\nTroubleshoot \"Stack CDKToolkit already exists\"\nAddressing issues with upgrading CDKToolkit stacks\nTroubleshoot \"Cannot find module $amplify/env/<function-name>\"\nAddressing \"Cannot find module $amplify/env/<function-name>\" error message"
  },
  {
    "title": "Overriding resources - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/overriding-resources/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nOverriding resources\nOverriding resources\n\nBy using overrides, you may create a backend that the Amplify libraries or client config is unable to interpret properly. Always test changes in a staging environment.\n\nWhen defining resources, you can access some underlying AWS Cloud Development Kit (CDK) construct properties to modify resource configurations. This allows you to customize backend resources beyond what is offered through the define* functions.\n\nOverrides are defined in the amplify/backend.ts file after the defineBackend call has been made.\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource';\nimport { data } from './data/resource';\n\n\nconst backend = defineBackend({\n  auth,\n  data\n});\n\n\n// overrides go here\n\nThe backend object exposes a resources property with objects for each of the components passed into the defineBackend function. Each of these resource objects exposes underlying L1 and L2 AWS CDK constructs that you can modify.\n\nFor example, here is how you can access the Cognito user pool that is created by defineAuth and set a custom removal policy on the resource.\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource';\nimport { UserPool } from 'aws-cdk-lib/aws-cognito';\nimport { RemovalPolicy } from 'aws-cdk-lib';\n\n\nconst backend = defineBackend({\n  auth\n});\n\n\nconst userPool = backend.auth.resources.userPool as UserPool;\nuserPool.applyRemovalPolicy(RemovalPolicy.RETAIN_ON_UPDATE_OR_DELETE);\n\nMost L1 and L2 AWS CDK constructs that are used by the define* functions are accessible in this way.\n\nExample - Grant access permissions between resources\n\nConsider the case that we want to grant a function created by defineFunction access to call the Cognito user pool created by defineAuth. This can be accomplished with the following overrides.\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource';\nimport { data } from './data/resource';\nimport { demoFunction } from './functions/demo-function/resource';\nimport { UserPool } from 'aws-cdk-lib/aws-cognito';\nimport { Function } from 'aws-cdk-lib/aws-lambda';\n\n\nconst backend = defineBackend({\n  auth,\n  data,\n  demoFunction\n});\n\n\nconst userPool = backend.auth.resources.userPool as UserPool;\nconst lambdaFunction = backend.demoFunction.resources.lambda as Function;\n\n\n// grant the lambdaFunction read access to users\nuserPool.grant(lambdaFunction, 'cognito:GetUser', 'cognito:ListUsers');\n\n\n// pass the Lambda the UserPool ID so that the Lambda can use it to make SDK calls\nlambdaFunction.addEnvironment('USER_POOL_ID', userPool.userPoolId);\nExample - Mutate synthesized CloudFormation\n\nIt's possible to reach all the way down to the raw CloudFormation to mutate properties using addPropertyOverride on an AWS CDK construct. To edit the password policies of the Cognito user pool in defineAuth, you can use the following code.\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource';\n\n\nconst backend = defineBackend({\n  auth\n});\n\n\n// override user pool password policies\nbackend.auth.resources.cfnResources.cfnUserPool.addPropertyOverride(\n  'Policies',\n  {\n    PasswordPolicy: {\n      MinimumLength: 10,\n      RequireLowercase: true,\n      RequireNumbers: true,\n      RequireSymbols: true,\n      RequireUppercase: true,\n      TemporaryPasswordValidityDays: 20\n    }\n  }\n);\n\nNote the usage of auth.resources.cfnResources. This property exposes L1 CDK constructs that map one-to-one with the underlying CloudFormation properties.\n\nThe auth.resources.cfnResources.cfnUserPool property in the above example directly maps to the AWS::Cognito::UserPool CloudFormation resource.\n\nThis is different from auth.resources.userPool in the first example, which is an L2 CDK construct. These are constructs that provide a convenient interface around several related L1 constructs.\n\nExample - Add tags to resources\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource';\nimport { data } from './data/resource';\n\n\nconst backend = defineBackend({\n  auth,\n  data\n});\n\n\nbackend.data.resources.cfnResources.cfnGraphqlApi.addPropertyOverride('Tags', [\n  {\n    Key: 'graphqlapi-tag-1',\n    Value: 'graphql-tag-value-1'\n  },\n  {\n    Key: 'graphqlapi-tag-2',\n    Value: 'graphql-tag-value-2'\n  }\n]);\n\nFor situations where you need even more customization of your app backend, see the documentation on custom resources.\n\nPREVIOUS\nCustom resources"
  },
  {
    "title": "Custom resources - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/custom-resources/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nCustom resources\nCustom resources\n\nCustom resources allow you to integrate any AWS service into an Amplify backend. You are responsible for ensuring that your custom resources are secure, adhere to best practices, and work with the resources that Amplify creates for your app.\n\nWith Amplify Gen 2, you can add custom AWS resources to an Amplify app using the AWS Cloud Development Kit (AWS CDK), which is installed by default as part of the create-amplify workflow. The AWS CDK is an open source software development framework that defines your cloud application resources using familiar programming languages, such as TypeScript.\n\nThe AWS CDK can be used within an Amplify app to add custom resources and configurations beyond what Amplify supports out of the box. For example, a developer could use CDK to hook up a Redis cache, implement custom security rules, deploy containers on AWS Fargate, or use any other AWS service.\n\nThe infrastructure defined through the AWS CDK code is deployed along with the Amplify app backend. This provides the simplicity of Amplify combined with the flexibility of CDK for situations where you need more customization.\n\nAWS CDK apps are composed of building blocks known as constructs, which are composed together to form stacks and apps. You can learn more in the Concepts section of the AWS Cloud Development Kit (AWS CDK) v2 Developer Guide.\n\nWith the Amplify code-first DX, you can add existing or custom CDK constructs to the backend of your Amplify app.\n\nAdding an existing CDK construct\n\nThe AWS CDK comes with many existing constructs that can be directly added to your Amplify backend. For example, to add an Amazon Simple Queue Service (Amazon SQS) queue and an Amazon Simple Notification Service (Amazon SNS) topic to your backend, you can add the following to your amplify/backend.ts file.\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport * as sns from 'aws-cdk-lib/aws-sns';\nimport * as sqs from 'aws-cdk-lib/aws-sqs';\nimport { defineBackend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource';\nimport { data } from './data/resource';\n\n\nconst backend = defineBackend({\n  auth,\n  data\n});\n\n\nconst customResourceStack = backend.createStack('MyCustomResources');\n\n\nnew sqs.Queue(customResourceStack, 'CustomQueue');\nnew sns.Topic(customResourceStack, 'CustomTopic');\n\nNote the use of backend.createStack(). This method instructs the backend to create a new CloudFormation Stack for your custom resources to live in. You can create multiple custom stacks and you can place multiple resources in any given stack.\n\nDefining a CDK construct\n\nConstructs are the basic building blocks of AWS CDK apps. A construct represents a \"cloud component\" and encapsulates everything AWS CloudFormation needs to create the component. Read more.\n\nAs shown above, you can use the existing AWS CDK constructs directly in an Amplify backend. However, you may find yourself repeating some patterns of common constructs. Custom constructs allow you to encapsulate common patterns into reusable components. This helps you implement best practices, accelerate development, and maintain consistency across applications.\n\nA common use case is creating a custom notification construct that combines a Lambda function with Amazon SNS and Amazon Simple Email Service (Amazon SES).\n\nThis AWS CDK construct implements a decoupled notification system using Amazon SNS and Lambda. It allows publishing notification messages to an SNS topic from one Lambda function, and processing those messages asynchronously using a separate Lambda subscribed to the topic.\n\nThe key components are:\n\nAn Amazon SNS topic to receive notification messages\nA Lambda function to publish messages to the Amazon SNS topic\nA second Lambda subscribed to the topic that processes the messages and sends emails through Amazon SES\n\nThe publisher Lambda allows publishing a message containing the email subject, body text, and recipient address. The emailer Lambda retrieves messages from the SNS topic and handles sending the actual emails.\n\nThe CustomNotifications custom CDK construct can be defined as follows:\n\namplify/custom/CustomNotifications/resource.ts\nCopy\namplify/custom/CustomNotifications/resource.ts code example\nimport * as url from 'node:url';\nimport { Runtime } from 'aws-cdk-lib/aws-lambda';\nimport * as lambda from 'aws-cdk-lib/aws-lambda-nodejs';\nimport * as sns from 'aws-cdk-lib/aws-sns';\nimport * as subscriptions from 'aws-cdk-lib/aws-sns-subscriptions';\nimport { Construct } from 'constructs';\n\n\n// message to publish\nexport type Message = {\n  subject: string;\n  body: string;\n  recipient: string;\n};\n\n\ntype CustomNotificationsProps = {\n  /**\n   * The source email address to use for sending emails\n   */\n  sourceAddress: string;\n};\n\n\nexport class CustomNotifications extends Construct {\n  public readonly topic: sns.Topic;\n  constructor(scope: Construct, id: string, props: CustomNotificationsProps) {\n    super(scope, id);\n\n\n    const { sourceAddress } = props;\n\n\n    // Create SNS topic\n    this.topic = new sns.Topic(this, 'NotificationTopic');\n\n\n    // Create Lambda to publish messages to SNS topic\n    const publisher = new lambda.NodejsFunction(this, 'Publisher', {\n      entry: url.fileURLToPath(new URL('publisher.ts', import.meta.url)),\n      environment: {\n        SNS_TOPIC_ARN: this.topic.topicArn\n      },\n      runtime: Runtime.NODEJS_18_X\n    });\n\n\n    // Create Lambda to process messages from SNS topic\n    const emailer = new lambda.NodejsFunction(this, 'Emailer', {\n      entry: url.fileURLToPath(new URL('emailer.ts', import.meta.url)),\n      environment: {\n        SOURCE_ADDRESS: sourceAddress\n      },\n      runtime: Runtime.NODEJS_18_X\n    });\n\n\n    // Subscribe emailer Lambda to SNS topic\n    this.topic.addSubscription(new subscriptions.LambdaSubscription(emailer));\n\n\n    // Allow publisher to publish to SNS topic\n    this.topic.grantPublish(publisher);\n  }\n}\n\nThe Lambda function code for the Publisher is:\n\namplify/custom/CustomNotifications/publisher.ts\nCopy\namplify/custom/CustomNotifications/publisher.ts code example\n// amplify/custom/CustomNotifications/publisher.ts\nimport { PublishCommand, SNSClient } from '@aws-sdk/client-sns';\nimport type { Handler } from 'aws-lambda';\nimport type { Message } from './resource';\n\n\nconst client = new SNSClient({ region: process.env.AWS_REGION });\n\n\n// define the handler that will publish messages to the SNS Topic\nexport const handler: Handler<Message, void> = async (event) => {\n  const { subject, body, recipient } = event;\n  const command = new PublishCommand({\n    TopicArn: process.env.TOPIC_ARN,\n    Message: JSON.stringify({\n      subject,\n      body,\n      recipient\n    })\n  });\n  try {\n    const response = await client.send(command);\n    console.log('published', response);\n  } catch (error) {\n    console.log('failed to publish message', error);\n    throw new Error('Failed to publish message', { cause: error });\n  }\n};\n\nThe Lambda function code for the Emailer is:\n\namplify/custom/CustomNotifications/emailer.ts\nCopy\namplify/custom/CustomNotifications/emailer.ts code example\n// amplify/custom/CustomNotifications/emailer.ts\nimport { SESClient, SendEmailCommand } from '@aws-sdk/client-ses';\nimport type { SNSHandler } from 'aws-lambda';\nimport type { Message } from './resource';\n\n\nconst sesClient = new SESClient({ region: process.env.AWS_REGION });\n\n\n// define the handler to process messages from the SNS topic and send via SES\nexport const handler: SNSHandler = async (event) => {\n  for (const record of event.Records) {\n    const message: Message = JSON.parse(record.Sns.Message);\n\n\n    // send the message via email\n    await sendEmail(message);\n  }\n};\n\n\nconst sendEmail = async (message: Message) => {\n  const { recipient, subject, body } = message;\n\n\n  const command = new SendEmailCommand({\n    Source: process.env.SOURCE_ADDRESS,\n    Destination: {\n      ToAddresses: [recipient]\n    },\n    Message: {\n      Body: {\n        Text: { Data: body }\n      },\n      Subject: { Data: subject }\n    }\n  });\n\n\n  try {\n    const result = await sesClient.send(command);\n    console.log(`Email sent to ${recipient}: ${result.MessageId}`);\n  } catch (error) {\n    console.error(`Error sending email to ${recipient}: ${error}`);\n    throw new Error(`Failed to send email to ${recipient}`, { cause: error });\n  }\n};\n\nThe CustomNotifications CDK construct can then be added to the Amplify backend one or more times, with different properties for each instance.\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\n// amplify/backend.ts\nimport { defineBackend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource';\nimport { data } from './data/resource';\nimport { CustomNotifications } from './custom/CustomNotifications/resource';\n\n\nconst backend = defineBackend({\n  auth,\n  data\n});\n\n\nconst customNotifications = new CustomNotifications(\n  backend.createStack('CustomNotifications'),\n  'CustomNotifications',\n  { sourceAddress: 'sender@example.com' }\n);\n\n\nbackend.addOutput({\n  custom: {\n    topicArn: customNotifications.topic.topicArn,\n    topicName: customNotifications.topic.topicName,\n  },\n});\nCommunity CDK resources\n\nThe Construct Hub is a community-driven catalog of reusable infrastructure components. It is a place for developers to discover and share reusable patterns for AWS CDK, maintained by AWS.\n\nIn addition, the example projects using the AWS CDK repository contains a number of examples of reusable CDK constructs.\n\nYou can use these resources to create custom CDK constructs that can be used in your Amplify app.\n\nPREVIOUS\nDeletion protection and Backup resources\nNEXT\nOverriding resources"
  },
  {
    "title": "Deletion protection and Backup resources - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/deletion-backup-resources/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nDeletion protection and Backup resources\nDeletion protection and Backup resources\n\nDeleting a Amplify sandbox with a resource enabled with deletion protection, the deploy process will fail and the resource will need to be manually deleted on the AWS console.\n\nUsing the AWS Cloud Development Kit (CDK) we can configure Amplify generated resource to enable deletion protection and backups on supported resources. For example, you can use AWS CDK to enable Point-in-time recovery for DynamoDB tables, or use AWS Backup as a advanced backup option.\n\nUsing underlying CDK construct properties you can modify resource configurations. This allows you to customize backend resources beyond what is offered via the define* functions.\n\nEnabling deletion protection on a Auth resource\n\nFor example, if you would like to enable deletion protection on a Cognito user pool resource created by Amplify Auth.\n\namplify/backend.ts\nimport { defineBackend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource';\nimport { data } from './data/resource';\n\n\nconst backend = defineBackend({\n  auth,\n  data\n});\n\n\nCopy\nhighlighted code example\nconst { cfnUserPool } = backend.auth.resources.cfnResources\ncfnUserPool.deletionProtection = \"ACTIVE\";\nEnabling Deletion protection on a Data resource\n\nFor example, if you would like to enable Deletion protection on all DynamoDB tables created by GraphQL API.\n\namplify/backend.ts\nimport { defineBackend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource';\nimport { data } from './data/resource';\n\n\nconst backend = defineBackend({\n  auth,\n  data\n});\n\n\nCopy\nhighlighted code example\nconst { amplifyDynamoDbTables } = backend.data.resources.cfnResources;\nfor (const table of Object.values(amplifyDynamoDbTables)) {\n  table.deletionProtectionEnabled = true;\n}\nEnabling Point-in-time recovery for DynamoDB tables\n\nFor example, enabling Point-in-time recovery for all the DynamoDB tables created by GraphQL API. By default Point-in-Time recovery retains backups for 35 days.\n\namplify/backend.ts\nimport { defineBackend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource';\nimport { data } from './data/resource';\n\n\nconst backend = defineBackend({\n  auth,\n  data\n});\n\n\nCopy\nhighlighted code example\nconst { amplifyDynamoDbTables } = backend.data.resources.cfnResources;\nfor (const table of Object.values(amplifyDynamoDbTables)) {\n  table.pointInTimeRecoveryEnabled = true;\n}\nEnabling Backups for DynamoDB tables\n\nFor example, if your DynamoDB tables requires backups that extend the default 35 days point-in-time recovery, AWS Backup service can be utilized to centralize and automate backups for DynamoDB tables. The example below outlines a backup plan configured to run daily at midnight, for all DynamoDB tables.\n\namplify/backend.ts\nimport { defineBackend } from \"@aws-amplify/backend\";\nCopy\nhighlighted code example\nimport {\n  BackupPlan,\n  BackupPlanRule,\n  BackupResource,\n  BackupVault,\n} from \"aws-cdk-lib/aws-backup\";\nimport { Schedule } from \"aws-cdk-lib/aws-events\";\nimport { Duration } from \"aws-cdk-lib/core\";\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\n\n\nconst backend = defineBackend({\n  auth,\n  data,\n});\n\n\nCopy\nhighlighted code example\nconst backupStack = backend.createStack(\"backup-stack\");\nconst myTables = Object.values(backend.data.resources.tables);\n\n\nconst vault = new BackupVault(backupStack, \"BackupVault\", {\n  backupVaultName: \"backup-vault\",\n});\n\n\nconst plan = new BackupPlan(backupStack, \"BackupPlan\", {\n  backupPlanName: \"backup-plan\",\n  backupVault: vault,\n});\n\n\nplan.addRule(\n  new BackupPlanRule({\n    deleteAfter: Duration.days(60),\n    ruleName: \"backup-plan-rule\",\n    scheduleExpression: Schedule.cron({\n      minute: \"0\",\n      hour: \"0\",\n      day: \"*\",\n      month: \"*\",\n      year: \"*\",\n    }),\n  })\n);\n\n\nplan.addSelection(\"BackupPlanSelection\", {\n  resources: myTables.map((table) => BackupResource.fromDynamoDbTable(table)),\n  allowRestores: true,\n});\nPREVIOUS\nPubSub\nNEXT\nCustom resources"
  },
  {
    "title": "Set up Amplify PubSub - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/pubsub/set-up-pubsub/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nPubSub\n/\nSet up Amplify PubSub\nSet up Amplify PubSub\n\nThe AWS Amplify PubSub category provides connectivity with cloud-based message-oriented middleware. You can use PubSub to pass messages between your app instances and your app's backend creating real-time interactive experiences.\n\nPubSub is available with AWS IoT and Generic MQTT Over WebSocket Providers.\n\nWith AWS IoT, AWS Amplify's PubSub automatically signs your HTTP requests when sending your messages.\n\nAWS IoT\n\nThe default export for PubSub will sign requests according to Signature Version 4.\n\nMake sure that the @aws-amplify/pubsub package has the same version number as the aws-amplify package in your package.json file.\n\nTo use in your app, import PubSub from the root export path:\n\nCopy\ncode example\nimport { Amplify} from 'aws-amplify';\nimport { PubSub } from '@aws-amplify/pubsub';\n\nCreate a new instance for your endpoint and region in your configuration:\n\nCopy\ncode example\n// Apply plugin with configuration\nconst pubsub = new PubSub({\n  region: '<YOUR-IOT-REGION>',\n  endpoint:\n    'wss://xxxxxxxxxxxxx.iot.<YOUR-IOT-REGION>.amazonaws.com/mqtt'\n});\n\nFind your aws_pubsub_endpoint by logging onto your AWS Console, choosing IoT Core from the list of services and then choosing Settings from the left navigation pane.\n\nStep 1: Create IAM policies for AWS IoT\n\nTo use PubSub with AWS IoT, you will need to create the necessary IAM policies in the AWS IoT Console, and attach them to your Amazon Cognito Identity.\n\nGo to IoT Core and choose Security from the left navigation pane, and then Policies from the dropdown menu. Next, click Create. The following myIoTPolicy policy will allow full access to all the topics.\n\nStep 2: Attach your policy to your Amazon Cognito Identity\n\nThe next step is attaching the policy to your Cognito Identity.\n\nYou can retrieve the Cognito Identity Id of a logged in user with Auth Module:\n\nCopy\ncode example\nimport { fetchAuthSession } from 'aws-amplify/auth';\nfetchAuthSession().then((info) => {\n  const cognitoIdentityId = info.identityId;\n});\n\nThen, you need to send your Cognito Identity Id to the AWS backend and attach myIoTPolicy. You can do this with the following AWS CLI command:\n\nCopy\ncode example\naws iot attach-policy --policy-name 'myIoTPolicy' --target '<YOUR_COGNITO_IDENTITY_ID>'\nStep 3: Allow the Amazon Cognito Authenticated Role to access IoT Services\n\nFor your Cognito Authenticated Role to be able to interact with AWS IoT it may be necessary to update its permissions, if you haven't done this before.\nOne way of doing this is to log to your AWS Console, select CloudFormation from the available services. Locate the parent stack of your solution: it is usually named <SERVICE-NAME>-<CREATION_TIMESTAMP>.\nSelect the Resources tab and tap on AuthRole Physical ID.\nThe IAM console will be opened in a new tab. Once there, tap on the button Attach Policies, then search AWSIoTDataAccess and AWSIoTConfigAccess, select them and tap on Attach policy.\n\nIf you are using Cognito Groups, the IAM role associated with that group also need the AWSIoTDataAccess and AWSIoTConfigAccess policies attached to it.\n\nFailing to grant IoT related permissions to the Cognito Authenticated Role will result in errors similar to the following in your browser console: errorCode: 8, errorMessage: AMQJS0008I Socket closed.\n\nKeeping track of your pubsub instances\n\nIn a real-world application, the code that sets up a pubsub instance (const pubsub = new PubSub(...)) will be used in multiple places. This means that the configuration will be separate from where your application publishes (pubsub.publish(...)) or subscribes (pubsub.subscribe(...)).\n\nIf you already know all the connections when deploying your application, you can export singleton instances for other parts of your application to easily import and use.\n\nExample\n\n./src/utils/pubsub.ts:\n\nCopy\ncode example\nimport { PubSub } from '@aws-amplify/pubsub';\nexport const pubsub = new PubSub({...});\n\n./src/components/LatestMessage.tsx:\n\nCopy\ncode example\nimport { useState, useEffect } from 'react';\nimport { pubsub } from '../utils/pubsub';\n\n\nexport function LatestMessage() {\n  const [message, setMessage] = useState<string>(\"\");\n  useEffect(() => {\n    pubsub.subscribe({topics: ['messages']}).subscribe({\n        next: (data) => {\n          setMessage(data.msg);\n        }\n    });\n  }, [])\n  return <>{message}</>\n}\n\nThis means you will maintain a single connection to the target endpoint without needing to pass the pubsub instance as a property through layers of components.\n\nThird Party MQTT Providers\n\nImport PubSub from the mqtt specific export path\n\nCopy\ncode example\nimport { PubSub } from '@aws-amplify/pubsub/mqtt';\n\nCreate a new instance for your endpoint and region in your configuration:\n\nCopy\ncode example\n// Apply plugin with configuration\nconst pubsub = new PubSub({\n  endpoint: 'wss://iot.eclipse.org:443/mqtt'\n});\n\nYou can integrate any MQTT Over WebSocket provider with your app. Click here to learn more about MQTT Over WebSocket.\n\nOnly JSON serializable message payloads are currently supported for MQTT providers within PubSub. If you are attempting to use message payloads that are non-JSON serializable, consider transforming the payload into a format that aligns with the input type expected by MQTT.\n\nPREVIOUS\nPublish\nNEXT\nSubscribe and unsubscribe"
  },
  {
    "title": "Subscribe and unsubscribe - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/pubsub/subscribe/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nPubSub\n/\nSubscribe and unsubscribe\nSubscribe and unsubscribe\nSubscribe\nSubscribe to a topic\n\nIn order to start receiving messages from your provider, you need to subscribe to a topic as follows;\n\nCopy\ncode example\npubsub.subscribe({ topics: 'myTopic' }).subscribe({\n  next: (data) => console.log('Message received', data),\n  error: (error) => console.error(error),\n  complete: () => console.log('Done')\n});\n\nFollowing events will be triggered with subscribe()\n\nEvent\tDescription\nnext\tTriggered every time a message is successfully received for the topic\nerror\tTriggered when subscription attempt fails\ncomplete\tTriggered when you unsubscribe from the topic\nSubscribe to multiple topics\n\nTo subscribe for multiple topics, just pass a String array including the topic names:\n\nCopy\ncode example\npubsub.subscribe({ topics: ['myTopic1', 'myTopic1'] }).subscribe({\n  //...\n});\nUnsubscribe\n\nTo stop receiving messages from a topic, you can use unsubscribe() method:\n\nCopy\ncode example\nconst sub1 = pubsub.subscribe({ topics: 'myTopicA' }).subscribe({\n  next: (data) => console.log('Message received', data),\n  error: (error) => console.error(error),\n  complete: () => console.log('Done')\n});\n\n\nsub1.unsubscribe();\n// You will no longer get messages for 'myTopicA'\nSubscription connection status updates\n\nNow that your application is setup and using pubsub subscriptions, you may want to know when the subscription is finally established, or reflect to your users when the subscription isn't healthy. You can monitor the connection state for changes via Hub.\n\nCopy\ncode example\nimport { CONNECTION_STATE_CHANGE, ConnectionState } from '@aws-amplify/pubsub';\nimport { Hub } from 'aws-amplify/utils';\n\n\nHub.listen('pubsub', (data: any) => {\n  const { payload } = data;\n  if (payload.event === CONNECTION_STATE_CHANGE) {\n    const connectionState = payload.data.connectionState as ConnectionState;\n    console.log(connectionState);\n  }\n});\nConnection states\nConnected - Connected and working with no issues.\nConnectedPendingDisconnect - The connection has no active subscriptions and is disconnecting.\nConnectedPendingKeepAlive - The connection is open, but has missed expected keep alive messages.\nConnectedPendingNetwork - The connection is open, but the network connection has been disrupted. When the network recovers, the connection will continue serving traffic.\nConnecting - Attempting to connect.\nConnectionDisrupted - The connection is disrupted and the network is available.\nConnectionDisruptedPendingNetwork - The connection is disrupted and the network connection is unavailable.\nDisconnected - Connection has no active subscriptions and is disconnecting.\nConnection issues and automated reconnection\n\nYour application can lose connectivity for any number of reasons such as network outages or when the device is put to sleep. Your subscriptions will automatically reconnect when it becomes possible to do so.\n\nWhile offline, your application will miss messages and will not automatically catch up when reconnection happens. Depending on your usecase, you may want take action to catch up when your app comes back online.\n\nCopy\ncode example\nconst fetchRecentData = () => {\n  // Retrieve recent data from some sort of data storage service\n}\n\n\nlet priorConnectionState: ConnectionState;\n\n\nHub.listen(\"pubsub\", (data: any) => {\n  const { payload } = data;\n  if (\n    payload.event === CONNECTION_STATE_CHANGE\n  ) {\n\n\n    if (priorConnectionState === ConnectionState.Connecting && payload.data.connectionState === ConnectionState.Connected) {\n      fetchRecentData();\n    }\n    priorConnectionState = payload.data.connectionState;\n  }\n});\n\n\npubsub.subscribe('myTopic').subscribe({\n  next: data => // Process incoming messages\n})\nPREVIOUS\nSet up Amplify PubSub"
  },
  {
    "title": "Publish - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/pubsub/publish/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nPubSub\n/\nPublish\nPublish\n\nTo send a message to a topic, use publish() method with your topic name and the message:\n\nCopy\ncode example\nawait pubsub.publish({ topics: 'myTopic1', message: { msg: 'Hello to all subscribers!' } });\n\nIf multiple providers are defined in your app you can pass the message to a specific provider:\n\nCopy\ncode example\nawait pubsub.publish({ \n  topics: 'myTopic1',\n  message: { msg: 'Hello to all subscribers!' },\n  options: { provider: 'AWSIoTProvider' }\n});\n\nYou can also publish a message to multiple topics:\n\nCopy\ncode example\nawait pubsub.publish({ topics: ['myTopic1','myTopic2'], message: { msg: 'Hello to all subscribers!' } });\nNEXT\nSet up Amplify PubSub"
  },
  {
    "title": "PubSub - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/pubsub/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nPubSub\nPubSub\nSet up Amplify PubSub\nLearn more about how you can use PubSub to pass messages between your app instances and your app’s backend creating real-time interactive experiences.\nSubscribe and unsubscribe\nLearn more about how to subscribe to and unsubscribe from topics using Amplify's PubSub category\nPublish\nLearn more about how to publish a message using the PubSub category in Amplify"
  },
  {
    "title": "Interact with bots - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/interactions/chatbot/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nInteractions\n/\nInteract with bots\nInteract with bots\nSend messages to bot\n\nYou can send a text message to chatbot backend with send() command. The method returns a promise that includes the chatbot response.\n\nsrc/App.tsx\nCopy\nsrc/App.tsx code example\nimport { Interactions } from '@aws-amplify/interactions';\n\n\nconst userInput = \"I want to reserve a hotel for tonight\";\n\n\n// Provide a bot name and user input\nconst response = await Interactions.send({\n  botName: \"TheBotName\",\n  message: userInput\n});\n\n\n// Log chatbot response\nconsole.log(response.message);\nDisplay end of chat message\n\nYou can use onComplete() method to register a function to catch errors or chatbot confirmations when the session successfully ends.\n\nsrc/App.tsx\nCopy\nsrc/App.tsx code example\nimport { Interactions } from '@aws-amplify/interactions';\n\n\nInteractions.onComplete({\n  botName: \"TheBotName\",\n  callback: (error?: Error, completion?: {[key: string]: any}) => {\n     if (error) {\n        alert('bot conversation failed');\n     } else if (completion) {\n        console.debug('done: ' + JSON.stringify(completion, null, 2));\n        alert('Trip booked. Thank you! What would you like to do next?');\n     }\n  }\n});\nPREVIOUS\nSet up Amplify Interactions"
  },
  {
    "title": "Set up Amplify Interactions - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/interactions/set-up-interactions/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nInteractions\n/\nSet up Amplify Interactions\nSet up Amplify Interactions\n\nAWS Amplify Interactions enables AI-powered chatbots in your web or mobile apps. You can use Interactions to configure your backend chatbot provider and to integrate a chatbot UI into your app with just a single line of code.\n\nInteractions with AWS\n\nAWS Amplify supports Amazon Lex as the default chatbots service. Amazon Lex supports creating conversational bots with the same deep learning technologies that power Amazon Alexa.\n\nSetup AWS LexV2 bot\n\nYou can create an Amazon Lex V2 chatbot in Amazon Lex console. To create your bot, follow the steps shown in Amazon Lex V2 Developer Guide.\n\nUpdate your IAM Policy\n\nAmazon Lex service requires an IAM policy in order to use the interactions APIs (remember to replace the template with real value):\n\nCopy\ncode example\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\"lex:RecognizeText\", \"lex:RecognizeUtterance\"],\n      \"Resource\": \"arn:aws:lex:<your-app-region>:<your-account-id>:bot-alias/<your-bot-id>/<your-bot-alias-id>\"\n    }\n  ]\n}\nConfigure your frontend\n\nAdd the aws-amplify and interactions package to your project:\n\nTerminal\nCopy\nTerminal code example\nnpm add --save @aws-amplify/interactions aws-amplify\n\nMake sure that the @aws-amplify/interactions package has the same version number as the aws-amplify package in your package.json file.\n\nConfigure Amplify\n\nImport and load the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point. For example, App.js (Expo) or index.js (React Native CLI).\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { Amplify } from 'aws-amplify';\nimport outputs from '../amplify_outputs.json';\n\n\nAmplify.configure(outputs);\nAmplify.configure({\n  ...Amplify.getConfig(),\n  Interactions: {\n    LexV2: {\n      '<your-bot-name>': {\n        aliasId: '<your-bot-alias-id>',\n        botId: '<your-bot-id>',\n        localeId: '<your-bot-locale-id>',\n        region: '<your-bot-region>'\n      }\n    }\n  }\n});\n\nMake sure you call Amplify.configure as early as possible in your application’s life-cycle. A missing configuration or NoCredentials error is thrown if Amplify.configure has not been called before other Amplify JavaScript APIs. Review the Library Not Configured Troubleshooting guide for possible causes of this issue.\n\nNEXT\nInteract with bots"
  },
  {
    "title": "Interactions - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/interactions/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nInteractions\nInteractions\nSet up Amplify Interactions\nAWS Amplify Interactions category enables AI-powered chatbots in your web or mobile apps. You can use Interactions to configure your backend chatbot provider and to integrate a chatbot UI into your app with just a single line of code.\nInteract with bots\nLearn more about how to integrate chat bot interactions into your application using Amplify."
  },
  {
    "title": "Interpret sentiment - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/predictions/interpret-sentiment/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAI/ML Predictions\n/\nInterpret sentiment\nInterpret sentiment\n\nNote: Make sure to complete the getting started section first, where you will set up the IAM roles with the right policy actions\n\nWorking with the API\n\nAnalyze text to find key phrases, sentiment (positive, negative, neutral), or the syntax (pronouns, verbs, etc.). You can also find entities in the text such as names or places, or perform language detection.\n\nCopy\ncode example\nimport { Predictions } from '@aws-amplify/predictions';\n\n\nconst result = await Predictions.interpret({\n  text: {\n    source: {\n      text: textToInterpret,\n    },\n    type: 'ALL'\n  }\n})\nPREVIOUS\nLabel objects in an image"
  },
  {
    "title": "Label objects in an image - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/predictions/label-image/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAI/ML Predictions\n/\nLabel objects in an image\nLabel objects in an image\n\nNote: Make sure to complete the getting started section first, where you will set up the IAM roles with the right policy actions\n\nWorking with the API\n\nDetect labels, such if an image has a desk or a chair in it\n\nCopy\ncode example\nimport { Predictions } from '@aws-amplify/predictions';\n\n\nPredictions.identify({\n  labels: {\n    source: {\n      file\n    },\n    type: 'LABELS'\n  }\n})\n  .then((response) => {\n    const { labels } = response;\n    labels.forEach((object) => {\n      const { name, boundingBoxes } = object;\n    });\n  })\n  .catch((err) => console.log({ err }));\n\nDetect unsafe content in an image\n\nCopy\ncode example\nimport { Predictions } from '@aws-amplify/predictions';\n\n\nconst { unsafe } = await Predictions.identify({\n  labels: {\n    source: {\n      file\n    },\n    type: 'UNSAFE'\n  }\n})\n\nFor both labels and unsafe content\n\nCopy\ncode example\nimport { Predictions } from '@aws-amplify/predictions';\n\n\nconst { labels, unsafe } = await Predictions.identify({\n  labels: {\n    source: {\n      file\n    },\n    type: 'ALL'\n  }\n})\nPREVIOUS\nIdentify entities from images\nNEXT\nInterpret sentiment"
  },
  {
    "title": "Identify text - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/predictions/identify-text/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAI/ML Predictions\n/\nIdentify text\nIdentify text\n\nNote: Make sure to complete the getting started section first, where you will set up the IAM roles with the right policy actions\n\nWorking with the API\n\nDetect text in an input image. Input can be sent directly from the browser or an Amazon S3 key from project bucket.\n\nCopy\ncode example\nimport { Predictions } from '@aws-amplify/predictions';\n\n\nconst response = await Predictions.identify({\n  text: {\n    source: {\n      file\n    }\n  }\n});\nIdentify image stored in Amazon S3\nCopy\ncode example\nimport { Predictions } from '@aws-amplify/predictions';\n\n\nconst response = await Predictions.identify({\n  text: {\n    source: {\n      key: pathToPhoto,\n    }\n  }\n})\n\nThe following options are independent of which source is specified. For demonstration purposes we will reference a file but it can be an S3 Key as well. Predictions.identify({text : {...}}) can detect unstructured text PLAIN, structured text from tables TABLE or text from forms FORM.\n\nIdentify plain text\n\nFor detecting plain text, you can see the whole detected text, the lines detected, the position of each line of text, and each word.\n\nCopy\ncode example\nimport { Predictions } from '@aws-amplify/predictions';\n\n\nconst response = await Predictions.identify({\n  text: {\n    source: {\n      file\n    },\n    format: 'PLAIN'\n  }\n});\n\n\nconst {\n  text: {\n    fullText, // String\n    lines, // Array of String ordered from top to bottom\n    linesDetailed /* Array of objects that contains\n        text, // String\n        boundingBox: {\n          width, // ratio of overall image width\n          height, // ratio of overall image height\n          left, // left coordinate as a ratio of overall image width\n          top // top coordinate as a ratio of overall image height\n        },\n        polygon // Array of { x, y } coordinates as a ratio of overall image width and height\n        */,\n    words // Array of objects that contains { text, boundingBox, polygon}\n  }\n} = response;\nIdentify structured forms\n\nFor detecting structured forms (documents, tables, etc.) from an image, keyValues will return a string of the entity found in the image as well as metadata such as selected checkboxes or the relative location in the image using a boundingBox.\n\nCopy\ncode example\nimport { Predictions } from '@aws-amplify/predictions';\n\n\nconst response = await Predictions.identify({\n  text: {\n    source: {\n      file\n    },\n    format: 'FORM'\n  }\n});\n\n\nconst {\n  text: {\n    // same as PLAIN +\n    keyValues // Array of { key: string, value: { text: string, selected: boolean}, polygon, boundingBox }\n  }\n} = response;\n\nFor example the below image would return keyValues with \"Test\" or \"Checked\" as a key, and true since they are selected. The location of these elements would be returned in the boundingBox value.\n\nIdentify structured tables\n\nFor detecting structured tables from an image\n\nCopy\ncode example\nimport { Predictions } from '@aws-amplify/predictions';\n\n\nconst response = await Predictions.identify({\n  text: {\n    source: {\n      file\n    },\n    format: 'TABLE'\n  }\n});\n\n\nconst {\n  text: {\n    // same as PLAIN +\n    tables: [\n      {\n        size: { rows, columns },\n        table // Matrix Array[ Array ] of size rows\n        // each element of the array contains { text, boundingBox, polygon, selected, rowSpan, columnSpan}\n      }\n    ]\n  }\n} = response;\n\nFor detecting tables and forms on the image just select format \"ALL\"\n\nCopy\ncode example\nimport { Predictions } from '@aws-amplify/predictions';\n\n\nconst { text } = await Predictions.identify({\n  text: {\n    source: {\n      file\n    },\n    format: 'ALL'\n  }\n});\nPREVIOUS\nTranslate language\nNEXT\nIdentify entities from images"
  },
  {
    "title": "Identify entities from images - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/predictions/identify-entity/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAI/ML Predictions\n/\nIdentify entities from images\nIdentify entities from images\n\nNote: Make sure to complete the getting started section first, where you will set up the IAM roles with the right policy actions\n\nWorking with the API\n\nPredictions.identify({entities: {...}}) => Promise<> Detects entities from an image and potentially related information such as position, faces, and landmarks. Can also identify celebrities and entities that were previously added. This function returns a Promise that returns an object with the entities that was identified.\n\nInput can be sent directly from the browser (using File object or ArrayBuffer object) or an Amazon S3 key from project bucket.\n\nDetect entities directly from image uploaded from the browser. (File object)\n\nCopy\ncode example\nimport { Predictions } from '@aws-amplify/predictions';\n\n\nconst response = await Predictions.identify({\n  entities: {\n    source: {\n      file,\n    },\n  }\n});\n\nDetect entities directly from image binary from the browser. (ArrayBuffer object) This technique is useful when you have base64 encoded binary image data, for example, from a webcam source.\n\nCopy\ncode example\nimport { Predictions } from '@aws-amplify/predictions';\n\n\nconst response = await Predictions.identify({\n  entities: {\n    source: {\n      bytes: imageArrayBuffer,\n    },\n  }\n});\n\nFrom Amazon S3 key\n\nCopy\ncode example\nimport { Predictions } from '@aws-amplify/predictions';\n\n\nconst response = await Predictions.identify({\n  entities: {\n    source: {\n      key: pathToPhoto,\n      level: 'guest' | 'private' | 'protected', //optional, default is the configured on Storage category\n    },\n  }\n});\n\nThe following options are independent of which source is specified. For demonstration purposes it will be used file but it can be used S3 Key as well.\n\nDetecting bounding box of faces from an image with its landmarks (eyes, mouth, nose).\n\nCopy\ncode example\nimport { Predictions } from '@aws-amplify/predictions';\n\n\nconst { entities } = await Predictions.identify({\n  entities: {\n    source: {\n      file,\n    },\n  }\n})\nfor (const { boundingBox, landmarks } of entities) {\n  const { \n    width, // ratio of overall image width\n    height, // ratio of overall image height\n    left, // left coordinate as a ratio of overall image width\n    top // top coordinate as a ratio of overall image height\n  } = boundingBox;\n  \n  for (const landmark of landmarks) {\n    const {\n      type, // string \"eyeLeft\", \"eyeRight\", \"mouthLeft\", \"mouthRight\", \"nose\"\n      x, // ratio of overall image width\n      y // ratio of overall image height\n    } = landmark;\n  }\n}\n\nDetecting celebrities on an image. It will return only celebrities the name and urls with related information.\n\nCopy\ncode example\nimport { Predictions } from '@aws-amplify/predictions';\n\n\nconst { entities } = await Predictions.identify({\n  entities: {\n    source: {\n      file,\n    },\n    celebrityDetection: true // boolean. It will only show detected celebrities \n  }\n})\n\n\nfor (const { boundingBox, landmarks, metadata } of entities) {\n  const { \n    name,\n    urls \n  } = metadata; // celebrity info\n  \n  // ...\n}\n.catch(err => console.log({ err }));\n\nDetecting entities from previously uploaded images (e.g. Advanced Configuration for Identify Entities)\n\nCopy\ncode example\nimport { Predictions } from '@aws-amplify/predictions';\n\n\nconst { entities } = await Predictions.identify({\n  entities: {\n    source: {\n      file,\n    },\n    collection: true\n  }\n})\n\n\nfor (const { boundingBox, metadata } of entities) {\n  const {\n    width, // ratio of overall image width\n    height, // ratio of overall image height\n    left, // left coordinate as a ratio of overall image width\n    top // top coordinate as a ratio of overall image height\n  } = boundingBox;\n  const { externalImageId } = metadata; // this is the object key on S3 from the original image\n}\nPREVIOUS\nIdentify text\nNEXT\nLabel objects in an image"
  },
  {
    "title": "Set up Predictions - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/predictions/set-up-predictions/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAI/ML Predictions\n/\nSet up Predictions\nSet up Predictions\nSet up the backend\n\nTo enable Predictions we need to set up the appropriate IAM policy for Roles in your Cognito Identity Pool in order to use an appropriate feature. Additionally, we need to use the addOutput method to patch the custom Predictions resource to the expected output configuration.\n\nNote: In the following example, we configure the policy to enable all supported ML capabilities. Ensure to include only the actions & resources relevant to your specific use cases. To learn more, check the docs of Amazon Translate, Amazon Polly, Amazon Transcribe, Amazon Rekognition, Amazon Textract, and Amazon Comprehend.\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { auth } from \"./auth/resource\";\nimport { Stack } from \"aws-cdk-lib\";\nimport { PolicyStatement } from \"aws-cdk-lib/aws-iam\";\n\n\nconst backend = defineBackend({\n  auth,\n});\n\n\n// Configure a policy for the required use case.\n// The actions included below cover all supported ML capabilities\nbackend.auth.resources.unauthenticatedUserIamRole.addToPrincipalPolicy(\n  new PolicyStatement({\n    actions: [\n      \"translate:TranslateText\",\n      \"polly:SynthesizeSpeech\",\n      \"transcribe:StartStreamTranscriptionWebSocket\",\n      \"comprehend:DetectSentiment\",\n      \"comprehend:DetectEntities\",\n      \"comprehend:DetectDominantLanguage\",\n      \"comprehend:DetectSyntax\",\n      \"comprehend:DetectKeyPhrases\",\n      \"rekognition:DetectFaces\",\n      \"rekognition:RecognizeCelebrities\",\n      \"rekognition:DetectLabels\",\n      \"rekognition:DetectModerationLabels\",\n      \"rekognition:DetectText\",\n      \"rekognition:DetectLabel\",\n      \"rekognition:SearchFacesByImage\",      \n      \"textract:AnalyzeDocument\",\n      \"textract:DetectDocumentText\",\n      \"textract:GetDocumentAnalysis\",\n      \"textract:StartDocumentAnalysis\",\n      \"textract:StartDocumentTextDetection\",\n    ],\n    resources: [\"*\"],\n  })\n);\n\n\nbackend.addOutput({\n  custom: {\n    Predictions: {\n      convert: {\n        translateText: {\n          defaults: {\n            sourceLanguage: \"en\",\n            targetLanguage: \"es\",\n          },\n          proxy: false,\n          region: Stack.of(backend.auth.resources.unauthenticatedUserIamRole)\n            .region,\n        },\n        speechGenerator: {\n          defaults: {\n            voiceId: \"Ivy\",\n          },\n          proxy: false,\n          region: Stack.of(backend.auth.resources.unauthenticatedUserIamRole)\n            .region,\n        },\n        transcription: {\n          defaults: {\n            language: \"en-US\",\n          },\n          proxy: false,\n          region: Stack.of(backend.auth.resources.unauthenticatedUserIamRole)\n            .region,\n        },\n      },\n      identify: {\n        identifyEntities: {\n          defaults: {\n            collectionId: \"default\",\n            maxEntities: 10,\n          },\n          celebrityDetectionEnabled: true,\n          proxy: false,\n          region: Stack.of(backend.auth.resources.unauthenticatedUserIamRole)\n            .region,\n        },\n        identifyLabels: {\n          defaults: {\n            type: \"ALL\",\n          },\n          proxy: false,\n          region: Stack.of(backend.auth.resources.unauthenticatedUserIamRole)\n            .region,\n        },\n        identifyText: {\n          defaults: {\n            format: \"ALL\",\n          },\n          proxy: false,\n          region: Stack.of(backend.auth.resources.unauthenticatedUserIamRole)\n            .region,\n        },\n      },\n      interpret: {\n        interpretText: {\n          defaults: {\n            type: \"ALL\",\n          },\n          proxy: false,\n          region: Stack.of(backend.auth.resources.unauthenticatedUserIamRole)\n            .region,\n        },\n      },\n    },\n  },\n});\nInstall Amplify Libraries\n\nTo install the Amplify library to use predictions features, run the following commands in your project's root folder:\n\nTerminal\nCopy\nTerminal code example\nnpm add aws-amplify\nConfigure the frontend\n\nImport and load the configuration file in your app. It is recommended you add the Amplify configuration step to your app's root entry point. For example main.ts in React and Angular.\n\nsrc/main.ts\nCopy\nsrc/main.ts code example\nimport { Predictions } from \"aws-amplify/predictions\";\nimport outputs from \"./amplify_outputs.json\";\n\n\nAmplify.configure(outputs);\n\n\nAmplify.configure({\n  ...Amplify.getConfig(),\n  Predictions: config.custom.Predictions,\n});\nNEXT\nText to speech"
  },
  {
    "title": "Translate language - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/predictions/translate/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAI/ML Predictions\n/\nTranslate language\nTranslate language\n\nNote: Make sure to complete the getting started section first, where you will set up the IAM roles with the right policy actions\n\nWorking with the API\n\nTranslate text from one source language to a destination language.\n\nCopy\ncode example\nimport { Predictions } from '@aws-amplify/predictions';\n\n\nconst result = await Predictions.convert({\n  translateText: {\n    source: {\n      text: textToTranslate,\n      language : \"es\"\n    },\n    targetLanguage: \"en\"\n  }\n})\n\nTo view the complete list of supported languages refer to Supported languages and language codes.\n\nPREVIOUS\nTranscribe audio to text\nNEXT\nIdentify text"
  },
  {
    "title": "Transcribe audio to text - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/predictions/transcribe-audio/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAI/ML Predictions\n/\nTranscribe audio to text\nTranscribe audio to text\n\nNote: Make sure to complete the getting started section first, where you will set up the IAM roles with the right policy actions\n\nWorking with the API\n\nYou can transcribe a PCM Audio byte buffer to Text, such as a recording from microphone.\n\nCopy\ncode example\nimport { Predictions } from '@aws-amplify/predictions';\n\n\nconst { transcription } = await Predictions.convert({\n  transcription: {\n    source: {\n      bytes\n    }\n  }\n})\n\nTo view the complete list of all the supported languages and language specific features refer to the supported languages list. The language data input type has to support streaming for it to work with Amplify Predictions.\n\nPREVIOUS\nText to speech\nNEXT\nTranslate language"
  },
  {
    "title": "Text to speech - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/predictions/text-to-speech/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAI/ML Predictions\n/\nText to speech\nText to speech\n\nNote: Make sure to complete the getting started section first, where you will set up the IAM roles with the right policy actions\n\nWorking with the API\n\nGenerate an audio buffer for playback from a text input.\n\nCopy\ncode example\nimport { Predictions } from '@aws-amplify/predictions';\n\n\nconst result = await Predictions.convert({\n  textToSpeech: {\n    source: {\n      text: textToGenerateSpeech\n    },\n    voiceId: \"Amy\" \n  }\n})\n\nTo view the complete list of voiceId options refer to Voices in Amazon Polly.\n\nPREVIOUS\nSet up Predictions\nNEXT\nTranscribe audio to text"
  },
  {
    "title": "AI/ML Predictions - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/predictions/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAI/ML Predictions\nAI/ML Predictions\n\nAmplify provides provides a solution for using AI and ML cloud services to enhance your application. Some supported use cases:\n\nConvert text to speech\nTranscribe audio to text\nTranslate text from one language to another\nIdentify text from an image\nIdentify entities from an image\nIdentify real world objects from an image\nInterpret text\n\nPredictions is broadly organized into 3 key use cases - Identify, Convert, and Interpret - which are available in the client API as well as CLI workflows.\n\nIdentify will find text (words, tables, pages from a book), entities (faces and/or celebrities) from images. You can also identify real world landmarks or objects such as chairs, desks, etc. which are referred to as “labels” from images.\nConvert allows you to translate text from one source language to a target language. You can also generate speech audio from text input. Lastly, you can take an audio input and transcribe it using a websocket stream.\nInterpret allows you to analyze text for language, entities (places, people), key phrases, sentiment (positive, neutral, negative), and syntax (pronouns, verbs, adjectives).\n\nSome common use cases are listed below, as well as an advanced workflow which allows you to perform dynamic image indexing from a connected s3 bucket.\n\nPredictions comes with built-in support for Amazon Translate, Amazon Polly, Amazon Transcribe, Amazon Rekognition, Amazon Textract, and Amazon Comprehend.\n\nSet up Predictions\nGet started with integrating ML capabilities into your application using Amplify\nText to speech\nLearn how to integrate text-to-speech capabilities into your application using Amplify.\nTranscribe audio to text\nLearn more about how to transcribe audio to text (also known as speech-to-text) for your application using Amplify\nTranslate language\nLearn more about how to integrate translation capabilities for your application using Amplify\nIdentify text\nLearn how to identify text from images and documents in your application using AWS Amplify.\nIdentify entities from images\nLearn how to identify entities from an image using Amplify.\nLabel objects in an image\nLearn more about how to detect labels in an image using Amplify. For example you can detect if an image has objects such as chairs, desks etc.\nInterpret sentiment\nLearn how to determine key phrases, sentiment, language, syntax, and entities from text using Amplify."
  },
  {
    "title": "Use existing AWS resources - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/rest-api/existing-resources/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAPI (REST)\n/\nUse existing AWS resources\nUse existing AWS resources\n\nExisting Amazon API Gateway resources can be used with the Amplify Libraries by calling Amplify.configure() with the API Gateway API name and options. Note, you will need to supply the full resource configuration and library options objects when calling Amplify.configure(). The following example shows how to configure additional API Gateway resources to an existing Amplify application:\n\nCopy\ncode example\nimport { Amplify } from 'aws-amplify';\nimport outputs from '../amplify_outputs.json';\nAmplify.configure(outputs):\n\n\nconst existingConfig = Amplify.getConfig();\n\n\n// Add existing resource to the existing configuration.\nAmplify.configure({\n  ...existingConfig,\n  API: {\n    ...existingConfig.API,\n    REST: {\n      ...existingConfig.API?.REST,\n      YourAPIName: {\n        endpoint:\n          'https://abcdefghij1234567890.execute-api.us-east-1.amazonaws.com/stageName',\n        region: 'us-east-1' // Optional\n      }\n    }\n  }\n});\nYourAPIName: Friendly name for the API\nendpoint: The HTTPS endpoint of the API\nregion: AWS Region where the resources are provisioned. If not specified, the region will be inferred from the endpoint.\n\nNote that before you can add an AWS resource to your application, the application must have the Amplify libraries installed. If you need to perform this step, see Install Amplify Libraries.\n\nPREVIOUS\nTest the REST API"
  },
  {
    "title": "Test the REST API - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/rest-api/test-api/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAPI (REST)\n/\nTest the REST API\nTest the REST API\nTest the API from the terminal\n\nIf unauthenticated guest users have access to your REST API you can test it from the terminal using curl. curl is a command-line tool that lets you transfer data to and from a server using various protocols.\n\nCurl is available in many distributions including Mac, Windows and Linux. Follow the install instructions in the docs.\n\nMac and Linux\nWindows\nGET method example\nTerminal\nCopy\nTerminal code example\ncurl <your-api-endpoint>/<your-api-stage>/items\nPOST method example\nTerminal\nCopy\nTerminal code example\ncurl -H \"Content-Type: application/json\" -d '{\"name\":\"item-1\"}' <your-api-endpoint>/<your-api-stage>/items\nTest the API with API Gateway console\n\nLet's test your new REST API using the route below with HTTP Method GET and path /items?limit=10 which includes a limit query string parameter.\n\nTerminal\nGET /items?limit=10\nSign in to the API Gateway console\nChoose the myRestApi REST API\nIn the Resources pane, choose the method you want to test. Select GET right under /items.\nTerminal\n/                        \n|_ /items               Main resource. Eg: /items  \n  GET                   Methods  \n  DELETE  \n  PUT  \n  POST  \n  OPTIONS               Allow pre-flight requests in CORS by browser  \n    |_ /{proxy+}         Proxy resource. Eg: /items/, /items/id, items/object/{id}  \n    ANY                  Includes methods: DELETE, GET, HEAD, OPTIONS, PATCH, POST, PUT  \n    OPTIONS              Allow pre-flight requests in CORS by browser\nIn the Method Execution pane, select TEST. Choose the GET method and add limit=10 to the query string {items} field.\nChoose Test to run the test for GET /items?limit=10. The following information will be displayed: request, status, latency, response body, response headers and logs.\nTerminal\nRequest\n/items\nLatency\n111\nStatus\n200\nResponse body\n\"Hello from myFunction!\"\nResponse headers\n{\n  \"Access-Control-Allow-Headers\": \"*\",\n  \"Access-Control-Allow-Origin\": \"*\",\n  \"X-Amzn-Trace-Id\": \"Root=1-661eee4b-f400fbebc6cfe65c3dadebcd;Parent=189f175e8de8d3a7;Sampled=0;lineage=c22c6ce1:0\"\n}\nLog\nExecution log for request 9bd9d8dc-95e2-494b-be1b-716393f83c49\nTue Apr 16 21:31:55 UTC 2024 : Starting execution for request: 9bd9d8dc-95e2-494b-be1b-716393f83c49\nTue Apr 16 21:31:55 UTC 2024 : HTTP Method: GET, Resource Path: /items\nTue Apr 16 21:31:55 UTC 2024 : Method request path: {}\nTue Apr 16 21:31:55 UTC 2024 : Method request query string: {}\nTue Apr 16 21:31:55 UTC 2024 : Method request headers: {}\nTue Apr 16 21:31:55 UTC 2024 : Method request body before transformations: \nTue Apr 16 21:31:55 UTC 2024 : Endpoint request URI: https://lambda.us-east-1.amazonaws.com/2015-03-31/functions/arn:aws:lambda:us-east-1:[TRUNCATED:function:amplify-nextamplifygen2-y-testfunctionlambdaC407E8-zttuHxtL6x0V/invocations\nTue Apr 16 21:31:55 UTC 2024 : Endpoint request headers: {X-Amz-Date=20240416T213155Z, x-amzn-apigateway-api-id=bnyiitr69a, Accept=application/json, User-Agent=AmazonAPIGateway_bnyiitr69a, Host=lambda.us-east-1.amazonaws.com, X-Amz-Content-Sha256=246bd274ab578bc88286bd20a7371b0f08a1ec8cc2c8cacffb41e60430254c82, X-Amzn-Trace-Id=Root=1-661eee4b-f400fbebc6cfe65c3dadebcd, x-amzn-lambda-integration-tag=9bd9d8dc-95e2-494b-be1b-716393f83c49, Authorization=*********************************************************************************************************************************************************************************************************************************************************************************************************************************************bc00f2, X-Amz-Source-Arn=arn:aws:execute-api:us-east-1:[TRUNCATED]:bnyiitr69a/test-invoke-stage/GET/items, X-Amz-Security-Token= [TRUNCATED]\nTue Apr 16 21:31:55 UTC 2024 : Endpoint request body after transformations: {\"resource\":\"/items\",\"path\":\"/items\",\"httpMethod\":\"GET\",\"headers\":null,\"multiValueHeaders\":null,\"queryStringParameters\":null,\"multiValueQueryStringParameters\":null,\"pathParameters\":null,\"stageVariables\":null,\"requestContext\":{\"resourceId\":\"1m3yhu\",\"resourcePath\":\"/items\",\"httpMethod\":\"GET\",\"extendedRequestId\":\"WVorzEQzoAMFubg=\",\"requestTime\":\"16/Apr/2024:21:31:55 +0000\",\"path\":\"/items\",\"accountId\":\"[TRUNCATED]\n\",\"protocol\":\"HTTP/1.1\",\"stage\":\"test-invoke-stage\",\"domainPrefix\":\"testPrefix\",\"requestTimeEpoch\":1713303115234,\"requestId\":\"9bd9d8dc-95e2-494b-be1b-716393f83c49\",\"identity\":{\"cognitoIdentityPoolId\":null,\"cognitoIdentityId\":null,\"apiKey\":\"test-invoke-api-key\",\"principalOrgId\":null,\"cognitoAuthenticationType\":null,\"userArn\":\"arn:aws:iam::[TRUNCATED]:user/ykethan\",\"apiKeyId\":\"test-invoke-api-key-id\",\"userAgent\":\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\",\"accountId\":\"05364941472 [TRUNCATED]\nTue Apr 16 21:31:55 UTC 2024 : Sending request to https://lambda.us-east-1.amazonaws.com/2015-03-31/functions/arn:aws:lambda:us-east-1:[TRUNCATED]\n:function:amplify-nextamplifygen2-y-testfunctionlambdaC407E8-zttuHxtL6x0V/invocations\nTue Apr 16 21:31:55 UTC 2024 : Received response. Status: 200, Integration latency: 108 ms\nTue Apr 16 21:31:55 UTC 2024 : Endpoint response headers: {Date=Tue, 16 Apr 2024 21:31:55 GMT, Content-Type=application/json, Content-Length=135, Connection=keep-alive, x-amzn-RequestId=67cfbdff-46cf-4355-8475-50a22e1f3234, x-amzn-Remapped-Content-Length=0, X-Amz-Executed-Version=$LATEST, X-Amzn-Trace-Id=root=1-661eee4b-f400fbebc6cfe65c3dadebcd;parent=189f175e8de8d3a7;sampled=0;lineage=c22c6ce1:0}\nTue Apr 16 21:31:55 UTC 2024 : Endpoint response body before transformations: {\"statusCode\":200,\"headers\":{\"Access-Control-Allow-Origin\":\"*\",\"Access-Control-Allow-Headers\":\"*\"},\"body\":\"\\\"Hello from myFunction!\\\"\"}\nTue Apr 16 21:31:55 UTC 2024 : Method response body after transformations: \"Hello from myFunction!\"\nTue Apr 16 21:31:55 UTC 2024 : Method response headers: {Access-Control-Allow-Origin=*, Access-Control-Allow-Headers=*, X-Amzn-Trace-Id=Root=1-661eee4b-f400fbebc6cfe65c3dadebcd;Parent=189f175e8de8d3a7;Sampled=0;lineage=c22c6ce1:0}\nTue Apr 16 21:31:55 UTC 2024 : Successfully completed execution\nTue Apr 16 21:31:55 UTC 2024 : Method completed with status: 200\nPREVIOUS\nDelete data\nNEXT\nUse existing AWS resources"
  },
  {
    "title": "Update data - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/rest-api/update-data/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAPI (REST)\n/\nUpdate data\nUpdate data\nPUT requests\n\nTo create or update a item via the API endpoint:\n\nCopy\ncode example\nimport { put } from 'aws-amplify/api';\n\n\nasync function updateItems() {\n  try {\n    const Item = { name: 'My first Item', message: 'Hello world!' };\n    const restOperation = put({\n      apiName: 'myRestApi',\n      path: 'items/1',\n      options: {\n        body: Item\n      }\n    });\n    const response = await restOperation.response;\n    console.log('PUT call succeeded: ', response);\n  } catch (error) {\n    console.log('PUT call failed: ', JSON.parse(error.response.body));\n  }\n}\nPREVIOUS\nPost data\nNEXT\nDelete data"
  },
  {
    "title": "Delete data - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/rest-api/delete-data/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAPI (REST)\n/\nDelete data\nDelete data\nDELETE requests\n\nTo delete an item via the API endpoint:\n\nCopy\ncode example\nimport { del } from 'aws-amplify/api';\n\n\nasync function deleteItem() {\n  try {\n    const restOperation = del({\n      apiName: 'myRestApi',\n      path: 'items/1'\n    });\n    await restOperation.response;\n    console.log('DELETE call succeeded');\n  } catch (e) {\n    console.log('DELETE call failed: ', JSON.parse(e.response.body));\n  }\n}\nPREVIOUS\nUpdate data\nNEXT\nTest the REST API"
  },
  {
    "title": "Post data - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/rest-api/post-data/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAPI (REST)\n/\nPost data\nPost data\nPOST Requests\n\nSend a POST request with a JSON body.\n\nCopy\ncode example\nimport { post } from 'aws-amplify/api';\n\n\nasync function postItem() {\n  try {\n    const restOperation = post({\n      apiName: 'myRestApi',\n      path: 'items',\n      options: {\n        body: {\n          message: 'Mow the lawn'\n        }\n      }\n    });\n\n\n    const { body } = await restOperation.response;\n    const response = await body.json();\n\n\n    console.log('POST call succeeded');\n    console.log(response);\n  } catch (error) {\n    console.log('POST call failed: ', JSON.parse(error.response.body));\n  }\n}\nPREVIOUS\nFetch data\nNEXT\nUpdate data"
  },
  {
    "title": "Fetch data - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/rest-api/fetch-data/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAPI (REST)\n/\nFetch data\nFetch data\n\nTo invoke an endpoint, you need to set input object with required apiName option and optional headers, queryParams, and body options. API status code response > 299 are thrown as an ApiError instance. The error instance provides name and message properties parsed from the response.\n\nGET requests\nCopy\ncode example\nimport { get } from 'aws-amplify/api';\n\n\nasync function getItem() {\n  try {\n    const restOperation = get({ \n      apiName: 'myRestApi',\n      path: 'items' \n    });\n    const response = await restOperation.response;\n    console.log('GET call succeeded: ', response);\n  } catch (error) {\n    console.log('GET call failed: ', JSON.parse(error.response.body));\n  }\n}\nAccessing response payload\n\nYou can consume the response payload by accessing the body property of the response object. Depending on the use case and the content type of the body, you can consume they payload in string, blob, or JSON.\n\nCopy\ncode example\n// ...\nconst { body } = await restOperation.response;\n// consume as a string:\nconst str = await body.text();\n// OR consume as a blob:\nconst blob = await body.blob();\n// OR consume as a JSON:\nconst json = await body.json();\n\nYou can not consume the response payload more than once.\n\nAccess HTTP response from errors\n\nThe REST API handler may throw an ApiError error instance. If the error is caused by an HTTP response with a non-2xx status code, the error instance will provide a response property. The response property contains following properties:\n\nstatusCode: HTTP status code\nheaders: HTTP response headers\nbody: HTTP response body as a string\n\nThe following example shows how to access the HTTP response from an ApiError instance, so that you can handle the error response from your REST API endpoint:\n\nCopy\ncode example\nimport { ApiError, get } from 'aws-amplify/api';\n\n\ntry {\n  const restOperation = get({ \n    apiName: 'myRestApi',\n    path: 'items' \n  });\n  await restOperation.response;\n} catch (error) {\n  if (error instanceof ApiError) {\n    if (error.response) {\n      const { \n        statusCode, \n        headers, \n        body \n      } = error.response;\n      console.error(`Received ${statusCode} error response with payload: ${body}`);\n    }\n    // Handle API errors not caused by HTTP response.\n  }\n  // Handle other errors.\n}\nPREVIOUS\nDefine authorization rules\nNEXT\nPost data"
  },
  {
    "title": "Set up Amplify HTTP API - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/rest-api/set-up-http-api/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAPI (REST)\n/\nSet up Amplify HTTP API\nSet up Amplify HTTP API\n\nUsing the AWS Cloud Development Kit (AWS CDK), you can configure Amplify Functions as resolvers for routes of an HTTP API powered by Amazon API Gateway.\n\nSet up HTTP API with Lambda Function\n\nTo get started, create a new directory and a resource file, amplify/functions/api-function/resource.ts. Then, define the function with defineFunction:\n\namplify/functions/api-function/resource.ts\nCopy\namplify/functions/api-function/resource.ts code example\nimport { defineFunction } from \"@aws-amplify/backend\";\n\n\nexport const myApiFunction = defineFunction({\n  name: \"api-function\",\n});\n\nThen, create the corresponding handler file, amplify/functions/api-function/handler.ts, file with the following contents:\n\namplify/functions/api-function/handler.ts\nCopy\namplify/functions/api-function/handler.ts code example\nimport type { APIGatewayProxyHandlerV2 } from \"aws-lambda\";\n\n\nexport const handler: APIGatewayProxyHandlerV2 = async (event) => {\n  console.log(\"event\", event);\n  return {\n    statusCode: 200,\n    // Modify the CORS settings below to match your specific requirements\n    headers: {\n      \"Access-Control-Allow-Origin\": \"*\", // Restrict this to domains you trust\n      \"Access-Control-Allow-Headers\": \"*\", // Specify only the headers you need to allow\n    },\n    body: JSON.stringify(\"Hello from api-function!\"),\n  };\n};\n\nNext, using the AWS CDK, create an HTTP API in your backend file:\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { Stack } from \"aws-cdk-lib\";\nimport {\n  CorsHttpMethod,\n  HttpApi,\n  HttpMethod,\n} from \"aws-cdk-lib/aws-apigatewayv2\";\nimport {\n  HttpIamAuthorizer,\n  HttpUserPoolAuthorizer,\n} from \"aws-cdk-lib/aws-apigatewayv2-authorizers\";\nimport { HttpLambdaIntegration } from \"aws-cdk-lib/aws-apigatewayv2-integrations\";\nimport { Policy, PolicyStatement } from \"aws-cdk-lib/aws-iam\";\nimport { myApiFunction } from \"./functions/api-function/resource\";\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\n\n\nconst backend = defineBackend({\n  auth,\n  data,\n  myApiFunction,\n});\n\n\n// create a new API stack\nconst apiStack = backend.createStack(\"api-stack\");\n\n\n// create a IAM authorizer\nconst iamAuthorizer = new HttpIamAuthorizer();\n\n\n// create a User Pool authorizer\nconst userPoolAuthorizer = new HttpUserPoolAuthorizer(\n  \"userPoolAuth\",\n  backend.auth.resources.userPool,\n  {\n    userPoolClients: [backend.auth.resources.userPoolClient],\n  }\n);\n\n\n// create a new HTTP Lambda integration\nconst httpLambdaIntegration = new HttpLambdaIntegration(\n  \"LambdaIntegration\",\n  backend.myApiFunction.resources.lambda\n);\n\n\n// create a new HTTP API with IAM as default authorizer\nconst httpApi = new HttpApi(apiStack, \"HttpApi\", {\n  apiName: \"myHttpApi\",\n  corsPreflight: {\n    // Modify the CORS settings below to match your specific requirements\n    allowMethods: [\n      CorsHttpMethod.GET,\n      CorsHttpMethod.POST,\n      CorsHttpMethod.PUT,\n      CorsHttpMethod.DELETE,\n    ],\n    // Restrict this to domains you trust\n    allowOrigins: [\"*\"],\n    // Specify only the headers you need to allow\n    allowHeaders: [\"*\"],\n  },\n  createDefaultStage: true,\n});\n\n\n// add routes to the API with a IAM authorizer and different methods\nhttpApi.addRoutes({\n  path: \"/items\",\n  methods: [HttpMethod.GET, HttpMethod.PUT, HttpMethod.POST, HttpMethod.DELETE],\n  integration: httpLambdaIntegration,\n  authorizer: iamAuthorizer,\n});\n\n\n// add a proxy resource path to the API\nhttpApi.addRoutes({\n  path: \"/items/{proxy+}\",\n  methods: [HttpMethod.ANY],\n  integration: httpLambdaIntegration,\n  authorizer: iamAuthorizer,\n});\n\n\n// add the options method to the route\nhttpApi.addRoutes({\n  path: \"/items/{proxy+}\",\n  methods: [HttpMethod.OPTIONS],\n  integration: httpLambdaIntegration,\n});\n\n\n// add route to the API with a User Pool authorizer\nhttpApi.addRoutes({\n  path: \"/cognito-auth-path\",\n  methods: [HttpMethod.GET],\n  integration: httpLambdaIntegration,\n  authorizer: userPoolAuthorizer,\n});\n\n\n// create a new IAM policy to allow Invoke access to the API\nconst apiPolicy = new Policy(apiStack, \"ApiPolicy\", {\n  statements: [\n    new PolicyStatement({\n      actions: [\"execute-api:Invoke\"],\n      resources: [\n        `${httpApi.arnForExecuteApi(\"*\", \"/items\")}`,\n        `${httpApi.arnForExecuteApi(\"*\", \"/items/*\")}`,\n        `${httpApi.arnForExecuteApi(\"*\", \"/cognito-auth-path\")}`,\n      ],\n    }),\n  ],\n});\n\n\n// attach the policy to the authenticated and unauthenticated IAM roles\nbackend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(apiPolicy);\nbackend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(apiPolicy);\n\n\n// add outputs to the configuration file\nbackend.addOutput({\n  custom: {\n    API: {\n      [httpApi.httpApiName!]: {\n        endpoint: httpApi.url,\n        region: Stack.of(httpApi).region,\n        apiName: httpApi.httpApiName,\n      },\n    },\n  },\n});\nInstall Amplify Libraries\n\nUse the package manager of your choice to install the Amplify JavaScript library. For example, with npm:\n\nTerminal\nCopy\nTerminal code example\nnpm add aws-amplify\nInitialize Amplify API\n\nTo initialize the Amplify API category you need to configure Amplify with Amplify.configure().\n\nImport and load the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point. For example src/main.ts:\n\npages/_app.tsx\nCopy\npages/_app.tsx code example\nimport { Amplify } from 'aws-amplify';\nimport outputs from '@/amplify_outputs.json';\n\n\nAmplify.configure(outputs);\nconst existingConfig = Amplify.getConfig();\nAmplify.configure({\n  ...existingConfig,\n  API: {\n    ...existingConfig.API,\n    REST: outputs.custom.API,\n  },\n});\n\nMake sure you call Amplify.configure as early as possible in your application’s life-cycle. A missing configuration or NoCredentials error is thrown if Amplify.configure has not been called before other Amplify JavaScript APIs. Review the Library Not Configured Troubleshooting guide for possible causes of this issue.\n\nPREVIOUS\nSet up Amplify REST API\nNEXT\nDefine authorization rules"
  },
  {
    "title": "Set up Amplify REST API - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/rest-api/set-up-rest-api/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAPI (REST)\n/\nSet up Amplify REST API\nSet up Amplify REST API\n\nUsing the AWS Cloud Development Kit (AWS CDK), you can configure Amplify Functions as resolvers for routes of a REST API powered by Amazon API Gateway.\n\nSet up REST API with Lambda Function\n\nCreate a new directory and a resource file, amplify/functions/api-function/resource.ts. Then, define the function with defineFunction:\n\namplify/functions/api-function/resource.ts\nCopy\namplify/functions/api-function/resource.ts code example\nimport { defineFunction } from \"@aws-amplify/backend\";\n\n\nexport const myApiFunction = defineFunction({\n  name: \"api-function\",\n});\n\nCreate the corresponding handler file, amplify/functions/api-function/handler.ts, file with the following contents:\n\namplify/functions/api-function/handler.ts\nCopy\namplify/functions/api-function/handler.ts code example\nimport type { APIGatewayProxyHandler } from \"aws-lambda\";\n\n\nexport const handler: APIGatewayProxyHandler = async (event) => {\n  console.log(\"event\", event);\n  return {\n    statusCode: 200,\n    // Modify the CORS settings below to match your specific requirements\n    headers: {\n      \"Access-Control-Allow-Origin\": \"*\", // Restrict this to domains you trust\n      \"Access-Control-Allow-Headers\": \"*\", // Specify only the headers you need to allow\n    },\n    body: JSON.stringify(\"Hello from myFunction!\"),\n  };\n};\n\nUse the AWS CDK to create an REST API resource powered by Amazon API Gateway.\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { Stack } from \"aws-cdk-lib\";\nimport {\n  AuthorizationType,\n  CognitoUserPoolsAuthorizer,\n  Cors,\n  LambdaIntegration,\n  RestApi,\n} from \"aws-cdk-lib/aws-apigateway\";\nimport { Policy, PolicyStatement } from \"aws-cdk-lib/aws-iam\";\nimport { myApiFunction } from \"./functions/api-function/resource\";\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\n\n\nconst backend = defineBackend({\n  auth,\n  data,\n  myApiFunction,\n});\n\n\n// create a new API stack\nconst apiStack = backend.createStack(\"api-stack\");\n\n\n// create a new REST API\nconst myRestApi = new RestApi(apiStack, \"RestApi\", {\n  restApiName: \"myRestApi\",\n  deploy: true,\n  deployOptions: {\n    stageName: \"dev\",\n  },\n  defaultCorsPreflightOptions: {\n    allowOrigins: Cors.ALL_ORIGINS, // Restrict this to domains you trust\n    allowMethods: Cors.ALL_METHODS, // Specify only the methods you need to allow\n    allowHeaders: Cors.DEFAULT_HEADERS, // Specify only the headers you need to allow\n  },\n});\n\n\n// create a new Lambda integration\nconst lambdaIntegration = new LambdaIntegration(\n  backend.myApiFunction.resources.lambda\n);\n\n\n// create a new resource path with IAM authorization\nconst itemsPath = myRestApi.root.addResource(\"items\", {\n  defaultMethodOptions: {\n    authorizationType: AuthorizationType.IAM,\n  },\n});\n\n\n// add methods you would like to create to the resource path\nitemsPath.addMethod(\"GET\", lambdaIntegration);\nitemsPath.addMethod(\"POST\", lambdaIntegration);\nitemsPath.addMethod(\"DELETE\", lambdaIntegration);\nitemsPath.addMethod(\"PUT\", lambdaIntegration);\n\n\n// add a proxy resource path to the API\nitemsPath.addProxy({\n  anyMethod: true,\n  defaultIntegration: lambdaIntegration,\n});\n\n\n// create a new Cognito User Pools authorizer\nconst cognitoAuth = new CognitoUserPoolsAuthorizer(apiStack, \"CognitoAuth\", {\n  cognitoUserPools: [backend.auth.resources.userPool],\n});\n\n\n// create a new resource path with Cognito authorization\nconst booksPath = myRestApi.root.addResource(\"cognito-auth-path\");\nbooksPath.addMethod(\"GET\", lambdaIntegration, {\n  authorizationType: AuthorizationType.COGNITO,\n  authorizer: cognitoAuth,\n});\n\n\n// create a new IAM policy to allow Invoke access to the API\nconst apiRestPolicy = new Policy(apiStack, \"RestApiPolicy\", {\n  statements: [\n    new PolicyStatement({\n      actions: [\"execute-api:Invoke\"],\n      resources: [\n        `${myRestApi.arnForExecuteApi(\"*\", \"/items\", \"dev\")}`,\n        `${myRestApi.arnForExecuteApi(\"*\", \"/items/*\", \"dev\")}`,\n        `${myRestApi.arnForExecuteApi(\"*\", \"/cognito-auth-path\", \"dev\")}`,\n      ],\n    }),\n  ],\n});\n\n\n// attach the policy to the authenticated and unauthenticated IAM roles\nbackend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(\n  apiRestPolicy\n);\nbackend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(\n  apiRestPolicy\n);\n\n\n// add outputs to the configuration file\nbackend.addOutput({\n  custom: {\n    API: {\n      [myRestApi.restApiName]: {\n        endpoint: myRestApi.url,\n        region: Stack.of(myRestApi).region,\n        apiName: myRestApi.restApiName,\n      },\n    },\n  },\n});\nInstall Amplify Libraries\n\nUse the package manager of your choice to install the Amplify JavaScript library. For example, with npm:\n\nTerminal\nCopy\nTerminal code example\nnpm add aws-amplify\nInitialize Amplify API\n\nTo initialize the Amplify API category you need to configure Amplify with Amplify.configure().\n\nImport and load the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point. For example index.js in React or main.ts in Angular.\n\npages/_app.tsx\nCopy\npages/_app.tsx code example\nimport { Amplify } from 'aws-amplify';\nimport outputs from '@/amplify_outputs.json';\n\n\nAmplify.configure(outputs);\nconst existingConfig = Amplify.getConfig();\nAmplify.configure({\n  ...existingConfig,\n  API: {\n    ...existingConfig.API,\n    REST: outputs.custom.API,\n  },\n});\n\nMake sure you call Amplify.configure as early as possible in your application’s life-cycle. A missing configuration or NoCredentials error is thrown if Amplify.configure has not been called before other Amplify JavaScript APIs. Review the Library Not Configured Troubleshooting guide for possible causes of this issue.\n\nNEXT\nSet up Amplify HTTP API"
  },
  {
    "title": "Define authorization rules - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/rest-api/customize-authz/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAPI (REST)\n/\nDefine authorization rules\nDefine authorization rules\n\nWhen determining the authorization mode for your REST endpoint, there are a few customizations you can do.\n\nIAM Authorization\n\nBy default, the API will be using IAM authorization and the requests will be signed for you automatically. IAM authorization has two modes: one using an unauthenticated role, and one using an authenticated role. When the user has not signed in, the unauthenticated role is used by default. Once the user has signed in, the authenticate role is used, instead.\n\nAPI Key\n\nIf you want to configure a public REST API, you can set an API key in Amazon API Gateway or create one using the CDK construct. Then, you can set the API key header in the API configuration which will be applied to all requests.\n\nCopy\ncode example\nAmplify.configure(outputs, {\n  API: {\n    REST: {\n      headers: async () => {\n        return { 'X-Api-Key': apiKey };\n      }\n    }\n  }\n});\nCognito User Pool Authorization\n\nYou can use the access token from configured Cognito User Pool to authenticate against REST endpoint. The JWT token can be retrieved from the Auth category.\n\nCopy\ncode example\nimport { fetchAuthSession } from 'aws-amplify/auth'\n\n\nconst session = await fetchAuthSession();\nconst token = session.tokens?.idToken\n\nThen you need to set the Authorization header in the API category configuration. The following example shows how to set the Authorization header for all requests.\n\nCopy\ncode example\nAmplify.configure(outputs, {\n  API: {\n    REST: {\n      headers: async () => {\n        return { Authorization: authToken };\n      }\n    }\n  }\n});\n\nFor more details on how to configure the API Gateway with the custom authorization, see this\n\nNote related to use of Access Token or ID Token\n\nThe ID Token contains claims about the identity of the authenticated user such as name, email, and phone_number. On the Amplify Authentication category you can retrieve the Id Token using:\n\nCopy\ncode example\nconst session = await fetchAuthSession();\nconst token = session.tokens?.idToken\n\nThe Access Token contains scopes and groups and is used to grant access to authorized resources. This is a tutorial for enabling custom scopes. You can retrieve the Access Token using\n\nCopy\ncode example\nconst session = await fetchAuthSession();\nconst token = session.tokens?.accessToken\nCustom Authorization Token\n\nIf you want to use a custom authorization token, you can set the token in the API category configuration. The custom authorization token will be applied to all requests.\n\nCopy\ncode example\nAmplify.configure(outputs, {\n  API: {\n    REST: {\n      headers: async () => {\n        return { Authorization: customAuthToken };\n      }\n    }\n  }\n});\nSetting Authorization Headers per Request\n\nAlternatively, you can set the authorization headers per request. For example, if you want to use a custom header named Authorization for a specific REST request, you can set the following configuration:\n\nCopy\ncode example\nasync function updateItem() {\n  await del({\n    apiName: 'myRestApi',\n    path: 'items/1',\n    options: {\n      headers: {\n        Authorization: authToken\n      }\n    }\n  }).response;\n}\nPREVIOUS\nSet up Amplify HTTP API\nNEXT\nFetch data"
  },
  {
    "title": "Create an in-app messaging campaign on AWS Console - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/in-app-messaging/create-campaign/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nIn-App Messaging\n/\nCreate an in-app messaging campaign on AWS Console\nCreate an in-app messaging campaign on AWS Console\n\nAs an alternative to writing AWS Cloud Development Kit (CDK) code, you can use the AWS console to create a campaign that sends messages through any single channel that is supported by Amazon Pinpoint: Mobile Push, In-App, Email, SMS or Custom channels. Learn how to create a campaign using Amazon Pinpoint to continue integrating in-app messages in your app with Amplify.\n\nLogin to the AWS Console, and Search for Pinpoint.\n\nClick on your project from the list of available project. Your project name would be the name you provided when you created the pinpoint project using CDK.\n\nClick on Campaigns from the left navigation menu, and then click on Create a campaign\n\nAdd a name to your campaign, and keep the following options as follows and then click Next:\n\nCampaign type: Standard campaign\nChannel: In-App messaging\nset prioritization: Fairly important\n\nClick on the Create a segment radio button, add a name for your segment, and then click Next.\n\nYou can add as many segments as needed to the campaign. For this quickstart, you can use Include any audiences under the Segment group 1 section.\nYou can add a criteria to your segments to ensure that audiences that satisfy that criteria can receive the in-app message.\nIf you see an error message titled Segment might include multiple channels, click I understand to proceed.\n\nClick on the Create a new in-app message radio button.\n\nYou have the ability to customize the following attributes of the in-app message:\n\nLayout: Which includes all of the different messaging layout options.\nHeader: Title of the in-app message, including the text color/alignment.\nMessage: The body of the Message, including the text color/alignment.\nBackground: Control the background color of the in-app message.\nImage URL: Add an image to be displayed as part of the in-app message body.\nPrimary button: Allows the addition of a button to add functionality to the in-app message.\nSecondary button: Allows the addition of an extra button for additional functionality.\nCustom Data: Allows the in-app message to pass additional data to the frontend app once it is triggered by an event.\n\nFor this tutorial you can create a simple message as shown below. Customers in your application will see the same message once the event is triggered.\n\nOnce you have finished customizing your in-app message, click on Next.\nUnder Trigger events, add the name of the analytics trigger that will be sent from your frontend app.\nYou have the ability to customize the trigger to allow only certain attributes or metrics that are passed with the analytics event to trigger the in-app message. (Optional)\n\nBy default, the number of messages shown per session is 1. You can update this threshold during campaign setup.\n\nReview your campaign, and then click on Launch campaign.\n\nYour campaign is now setup, and you are ready to start integrating the In-App Messaging functionality into your app.\n\nNote: Campaign start time must be at least 15 minutes in future. In-app messages can only be synced to local device once the campaign becomes active (status should be \"In Progress\" in the campaigns screen of the Pinpoint console).\n\nPREVIOUS\nResolve conflicts"
  },
  {
    "title": "API (REST) - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/rest-api/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAPI (REST)\nAPI (REST)\nSet up Amplify REST API\nThe API category provides a solution for making HTTP requests to REST API endpoints. The API library can be used for creating signed requests against Amazon API Gateway when the API Gateway Authorization is set to AWS_IAM or Cognito User Pools.\nSet up Amplify HTTP API\nThe API category provides a solution for making HTTP requests to HTTP API endpoints. The API library can be used for creating signed requests against Amazon API Gateway when the API Gateway Authorization is set to AWS_IAM or Cognito User Pools.\nDefine authorization rules\nLearn more about how to define authorization rules for Amplify's REST API capabilities\nFetch data\nUsing the GET API REST in Amplify\nPost data\nUsing Post, Put, etc. in Amplify\nUpdate data\nUsing Post, Put, etc. in Amplify\nDelete data\nUsing the Delete API REST in Amplify\nTest the REST API\nLearn how you can test the REST API from the terminal, with Amplify Mock, or with the API Gateway console.\nUse existing AWS resources\nConfigure the Amplify Libraries to use existing Amazon API Gateway resources by referencing them in your configuration."
  },
  {
    "title": "Resolve conflicts - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/in-app-messaging/resolve-conflicts/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nIn-App Messaging\n/\nResolve conflicts\nResolve conflicts\n\nIn the rare case where an event is sent and meets the criteria set forth by multiple in-app messages, the library needs to decide which message to return. If such a conflict should arise, In-App Messaging will choose a message by:\n\nSorting the messages in order of campaign expiration\nReturning the top message sorted (the closest message to expiry)\n\nHowever, this may not be how you wish to resolve such conflicts so you may want to set your own conflict handler.\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { setConflictHandler } from 'aws-amplify/in-app-messaging';\n\n\n/**\n * Regardless of your conflict resolution strategy the handler must always accept\n * an array of in-app messages and return a single in-app message.\n */\nconst myConflictHandler = (messages) => {\n  // Return a random message\n  const randomIndex = Math.floor(Math.random() * messages.length);\n  return messages[randomIndex];\n};\n\n\nsetConflictHandler(myConflictHandler);\nPREVIOUS\nRespond to interaction events\nNEXT\nCreate an in-app messaging campaign on AWS Console"
  },
  {
    "title": "Respond to interaction events - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/in-app-messaging/respond-interaction-events/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nIn-App Messaging\n/\nRespond to interaction events\nRespond to interaction events\n\nYour code can respond with additional behavior to your users interacting with in-app messages by adding interaction event listeners.\n\nMessage received\n\nAdd onMessageReceived listeners to respond to an in-app message being received from the library as the result of an event matching the criteria of a synced in-app message. This is required if you are implementing a custom UI so that your UI can respond to event-triggered campaign messages but you may also find it helpful to listen for these messages for any other reason your application requires.\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { onMessageReceived } from 'aws-amplify/in-app-messaging';\n\n\nconst myMessageReceivedHandler = (message) => {\n  // Do something with the received message\n};\n\n\nconst listener = onMessageReceived(myMessageReceivedHandler);\n\n\nlistener.remove(); // Remember to remove the listener when it is no longer needed\nMessage displayed\n\nAdd onMessageDisplayed listeners to respond to an in-app message being displayed to your user.\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { onMessageDisplayed } from 'aws-amplify/in-app-messaging';\n\n\nconst myMessageDisplayedHandler = (message) => {\n  // Do something with the displayed message\n};\n\n\nconst listener = onMessageDisplayed(myMessageDisplayedHandler);\n\n\nlistener.remove(); // Remember to remove the listener when it is no longer needed\nMessage dismissed\n\nAdd onMessageDismissed listeners to respond to an in-app message being dismissed by your user.\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { onMessageDismissed } from 'aws-amplify/in-app-messaging';\n\n\nconst myMessageDismissedHandler = (message) => {\n  // Do something with the dismissed message\n};\n\n\nconst listener = onMessageDismissed(myMessageDismissedHandler);\n\n\nlistener.remove(); // Remember to remove the listener when it is no longer needed\nMessage action taken\n\nAdd onMessageActionTaken listeners to respond to an action being taken on an in-app message. Typically, this means that the user has tapped or clicked a button on an in-app message.\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { onMessageActionTaken } from 'aws-amplify/in-app-messaging';\n\n\nconst myMessageActionTakenHandler = (message) => {\n  // Do something with the message action was taken against\n};\n\n\nconst listener = onMessageActionTaken(myMessageActionTakenHandler);\n\n\nlistener.remove(); // Remember to remove the listener when it is no longer needed\nNotifying listeners\n\nIf you are using the Amplify In-App Messaging UI, interaction events notifications are already wired up for you. However, if you are implementing your own UI, it is highly recommended to notify listeners of interaction events through your UI code so that the library can take further actions prescribed by the installed provider (for example, automatically recording corresponding Analytics events).\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { notifyMessageInteraction } from 'aws-amplify/in-app-messaging';\n\n\nconst message = {\n  // In-app message that you want to record an interaction on\n}\n\n\n/**\n * Interaction events that can be notified correspond to their respective listeners:\n *    'messageReceived'\n *    'messageDisplayed'\n *    'messageDismissed'\n *    'messageActionTaken'\n */\nnotifyMessageInteraction({ message, type: 'messageDisplayed' });\nPREVIOUS\nIdentify a user\nNEXT\nResolve conflicts"
  },
  {
    "title": "Identify a user - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/in-app-messaging/identify-user/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nIn-App Messaging\n/\nIdentify a user\nIdentify a user\n\nTo fully harness the potential of In-App Messaging, you must segment and target your In-App Messaging campaigns to specific user subsets. By identifying users with additional information, including their device demographics, location and any attributes of your choosing, you will be able to display intelligent, targeted in-app messages to the right users.\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { identifyUser } from 'aws-amplify/in-app-messaging';\n\n\nawait identifyUser({\n  userId: '', // E.g. user-id\n  userProfile: {\n    email: '', // E.g. example@service.com\n    name: '', // E.g. name-of-the-user\n    plan: '' // E.g. plan-they-subscribe-to\n    customProperties: {\n      // E.g. hobbies: ['cooking', 'knitting'],\n    },\n    demographic: {\n      appVersion: '',\n      locale: '', // E.g. en_US\n      make: '', // E.g. Apple\n      model: '', // E.g. iPhone\n      modelVersion: '', // E.g. 13\n      platform: '', // E.g. iOS\n      platformVersion: '', // E.g. 15\n      timezone: '' // E.g. Americas/Los_Angeles\n    },\n    location: {\n      city: '', // E.g. Seattle\n      country: '', // E.g. US,\n      postalCode: '', // E.g. 98121\n      region: '', // E.g. WA\n      latitude: 0.0,\n      longitude: 0.0\n    },\n    metrics: {\n      // E.g. logins: 157\n    },\n  },\n});\nIdentify a user with Amazon Pinpoint\n\nWhen using identifyUser with Amazon Pinpoint, in addition to the other user info properties you can configure the address, optOut, and userAttributes properties under options.\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { identifyUser } from 'aws-amplify/in-app-messaging';\n\n\nawait identifyUser({\n  userId: '', // E.g. user-id\n  options: {\n    address: '' // E.g. A device token or email address\n    optOut: ''  // Either ALL or NONE\n    userAttributes: {\n      // E.g. interests: ['soccer', 'shoes'],\n    }\n  },\n});\nPREVIOUS\nClear messages\nNEXT\nRespond to interaction events"
  },
  {
    "title": "Clear messages - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/in-app-messaging/clear-messages/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nIn-App Messaging\n/\nClear messages\nClear messages\n\nOnce messages have been synced to your user's device, clearMessages() can be used to clear the synced messages.\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { clearMessages } from 'aws-amplify/in-app-messaging';\n\n\nawait clearMessages();\n\nNote: If your app has authentication implemented, we recommend calling clearMessages() in between user log-ins to remove messages targeted for specific user segments. This is especially important if you anticipate your application will be used in shared device scenarios.\n\nPREVIOUS\nDisplay messages\nNEXT\nIdentify a user"
  },
  {
    "title": "Display messages - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/in-app-messaging/display-messages/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nIn-App Messaging\n/\nDisplay messages\nDisplay messages\n\nIn-app messages are displayed when an In-App Messaging or analytics event is sent and matches the criteria defined by your active In-App Messaging campaigns.\n\nAnalytics event\n\nNow that messages have been synced to your users' devices, Amplify In-App Messaging will allow you to start displaying them with Amplify Analytics events with no additional integration steps. Any events you record or are already recording using the Analytics' record API are automatically picked up and processed by In-App Messaging. If the event matches the attributes and criteria defined in an in-app message, that message will be displayed.\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { record } from 'aws-amplify/analytics';\n\n\nrecord({\n  name: 'first_event',\n  attributes: { color: 'red' },\n  metrics: { quantity: 10 }\n});\n\nIf the event name, attributes, and metrics match those set forth by one of your In-App Messaging campaigns, you should see the in-app message displayed in your app.\n\nIn-App Messaging events\n\nIn addition to or instead of Amplify Analytics events, you can also dispatch In-App Messaging events to trigger an in-app message display programmatically.\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { dispatchEvent } from 'aws-amplify/in-app-messaging';\n\n\ndispatchEvent({\n  name: 'first_event',\n  attributes: { color: 'red' },\n  metrics: { quantity: 10 }\n});\n\nIf the event name, attributes, and metrics match those set forth by one of your In-App Messaging campaigns, you should see the in-app message displayed in your app.\n\nPREVIOUS\nSync messages\nNEXT\nClear messages"
  },
  {
    "title": "Sync messages - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/in-app-messaging/sync-messages/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nIn-App Messaging\n/\nSync messages\nSync messages\n\nTo trigger messages, you must sync them from your In-App Messaging campaigns to your users' devices. These messages are then triggered with an analytics or In-App Messaging event. You can control when and how often this sync is performed.\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { syncMessages } from 'aws-amplify/in-app-messaging';\n\n\nawait syncMessages();\n\nNote: Syncing messages will always overwrite existing messages currently on the user's device so that they are always up to date when the sync is performed.\n\nPREVIOUS\nIntegrate your application\nNEXT\nDisplay messages"
  },
  {
    "title": "Set up in-app messaging - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/in-app-messaging/set-up-in-app-messaging/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nIn-App Messaging\n/\nSet up in-app messaging\nSet up in-app messaging\n\nAmplify allows interacting with In-App Messaging APIs, enabling you to send messages to your app users. In-App Messaging is a powerful tool to engage with your users and provide them with relevant information. A campaign is a messaging initiative that engages a specific audience segment. A campaign sends tailored messages according to a schedule that you define. You can use the AWS Cloud Development Kit (AWS CDK) to create a campaign that sends messages through any single channel that is supported by Amazon Pinpoint: Mobile Push, In-App, Email, SMS or Custom channels.\n\nThe following is an example utilizing the AWS CDK to create the In-App Messaging resource powered by Amazon Pinpoint. Note: there are no official hand-written (L2) constructs for this service yet.\n\nNote: Campaign start time must be at least 15 minutes in future. In-app messages can only be synced to local device once the campaign becomes active (Status should be \"In Progress\" in the campaigns screen of the Pinpoint console).\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\nimport {\n  CfnApp,\n  CfnCampaign,\n  CfnSegment,\n} from \"aws-cdk-lib/aws-pinpoint\";\nimport { Policy, PolicyStatement } from \"aws-cdk-lib/aws-iam\";\nimport { Stack } from \"aws-cdk-lib/core\";\n\n\n\n\nconst backend = defineBackend({\n  auth, \n  data,\n  // additional resources \n});\n\n\nconst inAppMessagingStack = backend.createStack(\"inAppMessaging-stack\");\n\n\n// create a Pinpoint app\nconst pinpoint = new CfnApp(inAppMessagingStack, \"Pinpoint\", {\n  name: \"myPinpointApp\",\n});\n\n\n// create a segment \nconst mySegment = new CfnSegment(inAppMessagingStack, \"Segment\", {\n  applicationId: pinpoint.ref,\n  name: \"mySegment\",\n});\n\n\n// create a campaign with event and in-app message template\nnew CfnCampaign(inAppMessagingStack, \"Campaign\", {\n  applicationId: pinpoint.ref,\n  name: \"MyCampaign\",\n  segmentId: mySegment.attrSegmentId,\n  schedule: {\n    // ensure the start and end time are in the future\n    startTime: \"2024-02-23T14:39:34Z\", \n    endTime: \"2024-02-29T14:32:40Z\",\n    frequency: \"IN_APP_EVENT\",\n    eventFilter: {\n      dimensions: {\n        eventType: {\n          dimensionType: \"INCLUSIVE\",\n          values: [\"my_first_event\"],\n        },\n      },\n      filterType: \"ENDPOINT\",\n    },\n  },\n\n\n  messageConfiguration: {\n    inAppMessage: {\n      layout: \"TOP_BANNER\",\n      content: [\n        {\n          // define the content of the in-app message\n          bodyConfig: {\n            alignment: \"CENTER\",\n            body: \"This is an example in-app message.\",\n            textColor: \"#FFFFFF\",\n          },\n          backgroundColor: \"#000000\",\n          headerConfig: {\n            alignment: \"CENTER\",\n            header: \"Welcome!\",\n            textColor: \"#FFFFFF\",\n          },\n          // optionally, define buttons, images, etc.\n        },\n      ],\n    },\n  },\n});\n\n\n//create an IAM policy to allow interacting with Pinpoint in-app messaging\nconst pinpointPolicy = new Policy(inAppMessagingStack, \"PinpointPolicy\", {\n  policyName: \"PinpointPolicy\",\n  statements: [\n    new PolicyStatement({\n      actions: [\n        \"mobiletargeting:GetInAppMessages\",\n        \"mobiletargeting:UpdateEndpoint\",\n        \"mobiletargeting:PutEvents\",\n      ],\n      resources: [pinpoint.attrArn + \"/*\", pinpoint.attrArn],\n    }),\n  ],\n});\n\n\n// apply the policy to the authenticated and unauthenticated roles\nbackend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(pinpointPolicy);\nbackend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(pinpointPolicy);\n\n\n// patch the custom Pinpoint resource to the expected output configuration\nbackend.addOutput({\n  notifications: {\n    amazon_pinpoint_app_id: pinpoint.ref,\n    aws_region: Stack.of(pinpoint).region,\n    channels: [\"IN_APP_MESSAGING\"],\n  },\n});\nInstall Amplify Libraries\n\nFirst, install the aws-amplify library:\n\nTerminal\nCopy\nTerminal code example\nnpm add aws-amplify\nInitialize In-App Messaging\n\nTo finish setting up your application with Amplify, you need to configure it using the configure API. Next, to interact with In-App Messaging APIs, you need to first initialize In-App Messaging by calling the initializeInAppMessaging API directly imported from the in-app-messaging sub-path. This is required to be called as early as possible in the app lifecycle.\n\nindex.tsx\nCopy\nindex.tsx code example\nimport { Amplify } from 'aws-amplify';\nimport { initializeInAppMessaging } from 'aws-amplify/in-app-messaging';\nimport outputs from '@/amplify_outputs.json';\n\n\nAmplify.configure(outputs);\ninitializeInAppMessaging();\n\nMake sure you call Amplify.configure as early as possible in your application’s life-cycle. A missing configuration or NoCredentials error is thrown if Amplify.configure has not been called before other Amplify JavaScript APIs.\n\nReferences\n\nAmazon Pinpoint Construct Library\n\nNEXT\nIntegrate your application"
  },
  {
    "title": "Integrate your application - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/in-app-messaging/integrate-application/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nIn-App Messaging\n/\nIntegrate your application\nIntegrate your application\nInstall Amplify UI for React\n\nAlthough Amplify In-App Messaging can be used as a standalone JavaScript library, this guide will show you how to use it together with Amplify UI, which currently supports integration with React and React Native, to get started quickly.\n\nLearn more about Amplify In-App Messaging UI and how to fully unlock its capabilities here: Amplify UI for In-App Messaging\n\nTerminal\nCopy\nTerminal code example\nnpm add @aws-amplify/ui-react @aws-amplify/ui-react-notifications\nIntegrate Amplify UI\n\nAmplify UI provides a Higher-Order Component for ease of integrating the In-App Messaging UI with your application. Simply wrap your application root component in, for example, App.js.\n\nsrc/App.js\nCopy\nsrc/App.js code example\nimport { withInAppMessaging } from '@aws-amplify/ui-react-notifications';\n\n\nimport '@aws-amplify/ui-react/styles.css';\n\n\nconst App = () => (\n  {/* Your application code */}\n);\n\n\nexport default withInAppMessaging(App);\n\nBelow is an example of what your entry file should look like:\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport React, { useEffect } from 'react';\nimport {\n  initializeInAppMessaging,\n  syncMessages,\n  dispatchEvent\n} from 'aws-amplify/in-app-messaging';\nimport { Button, View } from '@aws-amplify/ui-react';\nimport { withInAppMessaging } from '@aws-amplify/ui-react-notifications';\nimport { record } from 'aws-amplify/analytics';\nimport '@aws-amplify/ui-react/styles.css';\nimport outputs from '../amplify_outputs.json';\n\n\nAmplify.configure(outputs);\ninitializeInAppMessaging();\n\n\n// To display your in-app message, make sure this event name matches one you created\n// in an In-App Messaging campaign!\nconst myFirstEvent = { name: 'my_first_event' };\n\n\nconst App = () => {\n  useEffect(() => {\n    // Messages from your campaigns need to be synced from the backend before they\n    // can be displayed. You can trigger this anywhere in your app. Here you are\n    // syncing just once when this component (your app) renders for the first time.\n    syncMessages();\n  }, []);\n\n\n  return (\n    <View>\n      {/* This button has an example of an analytics event triggering the in-app message. */}\n      <Button\n        onClick={() => {\n          record(myFirstEvent);\n        }}\n      >\n        Record Analytics Event\n      </Button>\n\n\n      {/* This button has an example of an In-app Messaging event triggering the in-app message.*/}\n      <Button\n        onClick={() => {\n          dispatchEvent(myFirstEvent);\n        }}\n      >\n        Send In-App Messaging Event\n      </Button>\n    </View>\n  );\n};\n\n\nexport default withInAppMessaging(App);\n\nYou can now build and run your app in your terminal. If you click on one of the buttons shown in the above example, the in-app message you defined in the Pinpoint console should be displayed in your app.\n\nPREVIOUS\nSet up in-app messaging\nNEXT\nSync messages"
  },
  {
    "title": "Use Amazon Location Service SDK - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/geo/amazon-location-sdk/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nGeo\n/\nUse Amazon Location Service SDK\nUse Amazon Location Service SDK\n\nAmplify Geo provides solutions for common use cases with Amazon Location Service but for any functionality that is not currently supported by Amplify Geo you can access the Amazon Location Service SDK directly.\n\nFollow this guide to get started with the aws-sdk for Amazon Location Service using Amplify Auth credentials.\n\nOverview\n\nIn this tutorial, we’ll go over the following:\n\nSetting up the AWS SDK JavaScript v3 package for the Amazon Location Service SDK calls with Amplify auth.\nCode examples using the Amazon Location Service SDK.\nInstalling SDK dependencies\n\nThe first step to using the SDKs in the client is to install the necessary dependencies with the following command:\n\nTerminal\nCopy\nTerminal code example\nnpm add @aws-sdk/client-location\nConnecting your app to Amazon Location Service\n\nIn the following procedure, you’ll connect your app to the Amazon Location Service APIs.\n\nTo connect your app to the Amazon Location Service\n\nIn your React App, open src/App.js file, and call the following function to initialize the Amazon Location Service client:\n\nCopy\ncode example\nimport { Amplify } from 'aws-amplify';\nimport { fetchAuthSession } from 'aws-amplify/auth';\nimport {\n  LocationClient,\n  AssociateTrackerConsumerCommand\n} from '@aws-sdk/client-location';\nimport outputs from '../amplify_outputs.json';\nAmplify.configure(outputs);\n\n\nconst createClient = async () => {\n  const session = await fetchAuthSession();\n  const client = new LocationClient({\n    credentials: session.credentials,\n    region: amplifyconfig.aws_project_region\n  });\n  return client;\n};\n\nYou’ve now successfully connected your app to the Amazon Location Service.\n\nUsing the Amazon Location Service APIs\n\nIn order to access Amazon Location Service APIs, ensure you've provisioned resources and configured your app using the instructions in either Amplify Geo Maps docs or the Amazon Location Service console.\n\nYou can check out the Amazon Location API Reference documentation for a complete list of supported features.\n\nExample: Getting Device Position\n\nThis example requires you to have first provisioned a Tracker resource using the Amazon Location Service console.\n\nThe following code details how to use the Amazon Location Service APIs to update a device position and get a device position using the tracker you just created:\n\nCopy\ncode example\n// UpdateDevicePosition API\nconst params = {\n  TrackerName: 'trackerId',\n  Updates: [\n    {\n      DeviceId: 'deviceId',\n      Position: [-122.431297, 37.773972],\n      SampleTime: new Date()\n    }\n  ]\n};\nconst command = new BatchUpdateDevicePositionCommand(params);\nclient.send(command, (err, data) => {\n  if (err) console.error(err);\n  if (data) console.log(data);\n});\n\n\n// GetDevicePosition API\nconst client = await createClient();\nconst params = {\n  TrackerName: 'trackerId',\n  DeviceId: 'deviceId'\n};\nconst command = new GetDevicePositionCommand(params);\nclient.send(command, (err, data) => {\n  if (err) console.error(err);\n  if (data) console.log(data);\n});\nPREVIOUS\nMigrate from Google Maps"
  },
  {
    "title": "In-App Messaging - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/in-app-messaging/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nIn-App Messaging\nIn-App Messaging\nSet up in-app messaging\nLearn how to get started with in-app messaging.\nIntegrate your application\nLearn how to integrate your application with In-app Messaging.\nSync messages\nLearn how to sync in-app messages to your user's local device. Synced messages will be displayed when a matching event is triggered.\nDisplay messages\nLearn how in-app messages are displayed when an In-App Messaging or analytics event is sent and matches the criteria set forth by your active In-App Messaging campaigns.\nClear messages\nLearn more about how to clear synced in-app messages from the user's device.\nIdentify a user\nLearn how to segment and target your In-App Messaging campaigns to specific user subsets.\nRespond to interaction events\nLearn how to respond with additional behavior to your users interacting with in-app messages by adding interaction event listeners.\nResolve conflicts\nLearn how to resolve conflicts when an event is sent and meets the criteria set forth by multiple in-app messages.\nCreate an in-app messaging campaign on AWS Console\nCreate a new Pinpoint campaign and configure it to be used with your Amplify project."
  },
  {
    "title": "Migrate from Google Maps - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/geo/google-migration/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nGeo\n/\nMigrate from Google Maps\nMigrate from Google Maps\n\nAre you using Google Maps or another similar Map Provider and would like to switch over to using Amplify Geo or Amazon Location Service? This tutorial will show you how to take your existing Google Maps APIs and switch over to using Amplify Geo.\n\nGetting Started\n\nAmplify Geo provides APIs for using location based functionality. Under the hood Amplify uses Amazon Location Service and is designed to work with open source mapping library MapLibre.\n\nThis guide assumes that you are already familiar with the Google Maps JavaScript API and with front-end web development concepts including HTML, CSS, and JavaScript.\n\nTo complete this tutorial, you will need:\n\nAmplify Geo\nA text editor\nKey differences between Amplify Geo and Google Maps\nCoordinates Conventions\n\nA key difference to notice between using Amplify Geo and Google Maps is with Google Maps Platform their convention for specifying coordinates is [lat, lng]. When migrating over to Amplify Geo the order is swapped to be [lng, lat]. This was done to match the geojson spec which is also used by MapLibre.\n\nAuthorization\n\nWhen using Google Maps Platform or other similar services like Mapbox you will first be prompted to go to the Google Cloud Console to set up APIs and create an API key where you will then use the API key when requesting the Google Maps JS API. With Amplify Geo you will instead setup Amplify Auth and the MapView component will read the auth configuration from the amplify_outputs.json file. Behind the scenes Amplify Auth uses Amazon Cognito to set up client credentials with access to Location Service and Geo will use those credentials when making any location related API calls. More information on setting Amplify Auth and Geo can be found below in the Setting Up Amplify section.\n\nCreate a webpage\nOpen your text editor and create a new file called index.html.\nPaste the following code into the file to set up the framework for a webpage with a map.\nCopy\ncode example\n<!DOCTYPE html>\n<html>\n\n\n<head>\n    <meta charset=\"utf-8\">\n    <title>Display a map on a webpage</title>\n    <meta name=\"viewport\" content=\"initial-scale=1,maximum-scale=1,user-scalable=no\">\n    <!-- Import MapLibre  -->\n    <script src=\"https://cdn.amplify.aws/packages/maplibre-gl/1.15.2/maplibre-gl.js\"\n        integrity=\"sha384-rwYfkmAOpciZS2bDuwZ/Xa/Gog6jXem8D/whm3wnsZSVFemDDlprcUXHnDDUcrNU\" crossorigin=\"anonymous\"\n        referrerpolicy=\"no-referrer\"></script>\n    <link href=\"https://cdn.amplify.aws/packages/maplibre-gl/1.15.2/maplibre-gl.css\" rel=\"stylesheet\"\n        integrity=\"sha384-DrPVD9GufrxGb7kWwRv0CywpXTmfvbKOZ5i5pN7urmIThew0zXKTME+gutUgtpeD\" crossorigin=\"anonymous\"\n        referrerpolicy=\"no-referrer\">\n    </link>\n    <!-- Import Amplify  -->\n    <script src=\"https://cdn.amplify.aws/packages/core/5.0.5/aws-amplify-core.min.js\" \n        integrity=\"sha384-eM2urkpomL9SRm/kuPHZG3XPEItAiUAAyotT/AqlhSus8iAqs/EfHaYy1Jn5ih7K\" crossorigin=\"anonymous\"\n        referrerpolicy=\"no-referrer\"></script>\n    <script src=\"https://cdn.amplify.aws/packages/auth/5.0.5/aws-amplify-auth.min.js\"\n        integrity=\"sha384-H25CFLYd7YHa1Oib73fs3kJN36VhaHHkLjo4AhGrhJ4HuKam05pg2/0t2MR6epun\" crossorigin=\"anonymous\"\n        referrerpolicy=\"no-referrer\"></script>\n    <script src=\"https://cdn.amplify.aws/packages/geo/2.0.5/aws-amplify-geo.min.js\"\n        integrity=\"sha384-Esc9xx0X7ckb/yeYHuYsZGqBB4FwYr98NFHS3BRXLeRE/eB0uVrad2w+G6cGxYb5\" crossorigin=\"anonymous\"\n        referrerpolicy=\"no-referrer\"></script>\n    <script src=\"https://cdn.amplify.aws/packages/maplibre-gl-js-amplify/1.5.0/maplibre-gl-js-amplify.umd.min.js\"\n        integrity=\"sha384-9kJyZavd3Jk6QzHeaLpugVonfZmZZZdixek6uglOwzKtZvDS9K3W4dshw1uswmlV\" crossorigin=\"anonymous\"\n        referrerpolicy=\"no-referrer\"></script>\n    </link>\n\n\n    <style>\n        body {\n            margin: 0;\n            padding: 0;\n        }\n\n\n        #map {\n            position: absolute;\n            top: 0;\n            bottom: 0;\n            width: 100%;\n        }\n    </style>\n</head>\n\n\n<body>\n    <div id=\"map\"></div>\n    <script type=\"module\">\n        import outputs from \"../amplify_outputs.json\" assert { type: \"json\" };\n        const { Amplify } = aws_amplify_core;\n        const { createMap } = AmplifyMapLibre;\n        Amplify.configure(outputs);\n\n\n        // Add code from below steps here\n    </script>\n</body>\n\n\n</html>\n\nThis code imports the MapLibre GL JS library and CSS, one of the popular options for map rendering we recommend for use with Amplify Geo. In the HTML body you create a <div> element with an id of 'map' that will be the map's container. Finally in the script section you'll setup some Amplify configuration that is required for Amplify Geo to understand what Amplify AWS resources have been created.\n\nSetting up Amplify\nYou will need to setup a Geo Map resources. Follow instructions for creating a map.\nOnce the workflow has completed you should have an amplify_outputs.json file in the same directory as your index.html file.\nSave your index.html file.\nDisplay a map\n\nIn this step we will show you how to add code to display a map in your application.\n\nAmplify\nGoogle Maps\n\nWith Amplify Geo and MapLibre you can add the following code to your index.html file inside the <script> tags, after the Amplify.configure command:\n\nCopy\ncode example\nconst map = await createMap({\n  container: document.getElementById('map'), // div ID\n  center: [-122.4783, 37.8199], // initial coordinates [long, lat]\n  zoom: 13 // initial zoom level, high number being more zoomed in\n});\n\nSave your HTML file and open it in a web browser to see your rendered map.\n\nDisplay a marker\n\nHere you will add a marker to your map\n\nAmplify\nGoogle Maps\n\nWith Amplify Geo and MapLibre you can do the following.\n\nCopy\ncode example\nconst marker = new maplibregl.Marker().setLngLat([-122.4783, 37.8199]).addTo(map);\n\nSave your changes and refresh your page and you should see a default blue marker icon on your map.\n\nThis example uses MapLibre's marker component to create a marker. To see more examples with markers on from MapLibre check the examples here.\n\nAdd a Popup\n\nNow you can add a popup that displays information when a user clicks on a marker.\n\nAmplify\nGoogle Maps\n\nWith Amplify Geo and MapLibre you can do the following.\n\nCopy\ncode example\nconst popup = new maplibregl.Popup().setHTML(\n  `<h3>Golden Gate Bridge</h3><p>The hex code for the bridge's color is: #c0362c</p>`\n);\n\n\nconst marker = new maplibregl.Marker()\n  .setLngLat([-122.4783, 37.8199])\n  .setPopup(popup)\n  .addTo(map);\n\nSave your changes and refresh your page and now when you click on the icon a popup should appear on the screen.\n\nThis example uses MapLibre's popup component to create a marker popup. To see more examples with popups on from MapLibre check the examples here.\n\nAdd a search component\n\nNow we can try adding a search bar to your map which can return results and place markers on a map based on those results.\n\nAmplify\nGoogle Maps\n\nWith Amplify Geo and MapLibre you can do the following.\n\nCopy\ncode example\nconst { createMap, createAmplifyGeocoder } = AmplifyMapLibre; // import from above updated to include createAmplifyGeocoder\n\n\nconst geocoder = createAmplifyGeocoder();\nmap.addControl(geocoder);\n\nSave your changes and refresh your page and now when you should see a maplibre-gl-geocoder control in the top right corner of your map.\n\nThis example uses the MapLibre's geocoder component to create a search component. To see more options for our createAmplifyGeocoder utility function check out the docs here.\n\nAdd a stand alone search component\n\nNow we can try adding a search bar without adding it to a map which can return results that you can use.\n\nAmplify\nGoogle Maps\n\nWith Amplify Geo and MapLibre you can do the following.\n\nCopy\ncode example\n// Create a div to hold the search component\nconst el = document.createElement(\"div\");\nel.setAttribute(\"id\", \"search\");\ndocument.body.appendChild(el);\n\n\n// Create the geocoder component and append it to the div you created earlier\nconst geocoder = createAmplifyGeocoder();\ndocument.getElementById(\"search\").appendChild(geocoder.onAdd());\n\nSave your changes and refresh your page and now when you should see a maplibre-gl-geocoder control in the div you created.\n\nThis example uses the MapLibre's geocoder component to create a search component. To see more options for our createAmplifyGeocoder utility function check out the docs here.\n\nPREVIOUS\nUse existing Amazon Location resources\nNEXT\nUse Amazon Location Service SDK"
  },
  {
    "title": "Use existing Amazon Location resources - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/geo/existing-resources/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nGeo\n/\nUse existing Amazon Location resources\nUse existing Amazon Location resources\n\nTo use existing Amazon Location Services resources with your Amplify backend or frontend application, use the addOutput method to surface backend resource outputs to the amplify_outputs.json file:\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from \"@aws-amplify/backend\"\n\n\nconst backend = defineBackend({})\n\n\nbackend.addOutput({\n  geo: {\n    aws_region: \"<your-aws-region>\",\n    maps: {\n      items: {\n        \"<your-friendly-map-name>\": {\n          name: \"<your-map-name>\",\n          style: \"<your-map-style>\",\n        },\n      },\n      default: \"<your-friendly-map-name>\",\n    },\n  },\n})\nAuthorization permissions\n\nTo use your existing Amazon Location Service resources (i.e. maps and place indices) with Amplify Geo, you need to ensure your role has the right authorization permissions through Cognito.\n\nNote: Here is a guide on Creating an Amazon Cognito identity pool for use with Amazon Location Service\n\nThere are two roles created by Cognito: an \"authenticated role\" that grants signed-in-user-level access and an \"unauthenticated role\" that allows unauthenticated access to resources. Attach the following policies for the appropriate resources and roles (Auth and/or Unauth). Replace {region}, {account-id}, and {enter Map/PlaceIndex name} with the correct items. Note that certain actions cannot be performed with unauthenticated access. The list of actions allowed for the Unauth role is in the Granting access to Amazon Location Service guide.\n\nCopy\ncode example\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"GetTiles\",\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"geo:GetMapTile\",\n        \"geo:GetMapSprites\",\n        \"geo:GetMapGlyphs\",\n        \"geo:GetMapStyleDescriptor\"\n      ],\n      \"Resource\": \"arn:aws:geo:<your-geo-region>:<your-account-id>:map/<your-map-name>\"\n    },\n    {\n      \"Sid\": \"Search\",\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"geo:SearchPlaceIndexForPosition\",\n        \"geo:SearchPlaceIndexForText\"\n      ],\n      \"Resource\": \"arn:aws:geo:<your-geo-region>:<your-account-id>:place-index/<your-index-name>\"\n    },\n    {\n      \"Sid\": \"Geofence\",\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"geo:GetGeofence\",\n        \"geo:PutGeofence\",\n        \"geo:BatchPutGeofence\",\n        \"geo:BatchDeleteGeofence\",\n        \"geo:ListGeofences\",\n      ],\n      \"Resource\": \"arn:aws:geo:<your-geo-region>:<your-account-id>:geofence-collection/<your-collection-name>\"\n    }\n  ]\n}\nConfigure client library directly\n\nYou can first import and configure the generated amplify_outputs.json. You can then manually configure Amplify Geo like this:\n\nCopy\ncode example\nimport { Amplify } from 'aws-amplify';\nimport outputs from '../amplify_outputs.json';\n\n\nAmplify.configure(outputs);\nAmplify.configure({\n  ...Amplify.getConfig(),\n  Geo: {\n    LocationService: {\n      maps: {\n        items: {\n          <your-map-name>: {\n            // REQUIRED - Amazon Location Service Map resource name\n            style: 'VectorEsriStreets' // REQUIRED - String representing the style of map resource\n          }\n        },\n        default: '<your-preferred-default-map>' // REQUIRED - Amazon Location Service Map resource name to set as default\n      },\n      search_indices: {\n        items: ['<your-geo-index>'], // REQUIRED - Amazon Location Service Place Index name\n        default: '<your-default-index>' // REQUIRED - Amazon Location Service Place Index name to set as default\n      },\n      geofenceCollections: {\n        items: ['<your-geo-collection>'], // REQUIRED - Amazon Location Service Geofence Collection name\n        default: '<your-default-collection>' // REQUIRED - Amazon Location Service Geofence Collection name to set as default\n      },\n      region: '<your-geo-region>' // REQUIRED - Amazon Location Service Region\n    }\n  }\n});\n\nNow you can proceed to displaying a map or adding location search to your app.\n\nPREVIOUS\nWork with geofences\nNEXT\nMigrate from Google Maps"
  },
  {
    "title": "Work with geofences - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/geo/geofences/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nGeo\n/\nWork with geofences\nWork with geofences\nProvisioning geofence resources\n\nFirst, make sure you've provisioned a geofence collection resource and configured your app using the instructions in either Configure a geofence collection or Use existing Amazon Location Service resources and you have already setup displaying a map in your application.\n\nManage Geofences in Your Application\n\nTo add a geofence management component to your map, you can use the amplify-geofence-control.\n\nInstall the necessary dependencies with the following command:\n\nTerminal\nCopy\nTerminal code example\nnpm add aws-amplify \\\n  @aws-amplify/geo \\\n  @aws-amplify/ui-react \\\n  @aws-amplify/ui-react-geo\n\nNote: Make sure that aws-amplify @aws-amplify/geo version 6.0.0 or above are installed.\n\nFirst, create a map onto which you want to add the geofence management component. See the guide on creating and displaying maps.\n\nThen, import AmplifyGeofenceControl from \"maplibre-gl-js-amplify\", create a new instance of this control and add it to your MapLibre map instance.\n\nNotes: To use Geofence Controls the user will need to be authenticated with the administrative Cognito user associated with the Geofence Collection you created. Below is an example using React and the Amplify Authenticator.\n\nJavascript\nReact\n\nNote: When using the existing maps implementation you can add the Geofence control to an existing map\n\nCopy\ncode example\nimport { useEffect, useRef } from \"react\";\n- import { createMap } from \"maplibre-gl-js-amplify\";\n+ import { createMap, AmplifyGeofenceControl } from \"maplibre-gl-js-amplify\";\n+ import { withAuthenticator } from \"@aws-amplify/ui-react\";\n+ import \"@aws-amplify/ui-react/styles.css\";\n+ import \"maplibre-gl-js-amplify/dist/public/amplify-ctrl-geofence.css\";\nimport \"maplibre-gl/dist/maplibre-gl.css\";\n\n\nfunction Map() {\n  const mapRef = useRef(null); // Reference to the map DOM element\n  // Wrapping your code in a useEffect allows us to run initializeMap after the div has been rendered into the DOM\n  useEffect(() => {\n    let map;\n    async function initializeMap() {\n      // You only want to initialize the underlying maplibre map after the div has been rendered\n      if (mapRef.current != null) {\n        map = await createMap({\n          container: mapRef.current,\n          center: [-122.431297, 37.773972],\n          zoom: 11,\n        });\n      }\n+     const control = new AmplifyGeofenceControl()\n+     map.addControl(control);\n  }\n  initializeMap();\n    // Cleans up and maplibre DOM elements and other resources - https://maplibre.org/maplibre-gl-js/docs/API/classes/Map/#remove\n    return function cleanup() {\n      if (map != null) map.remove();\n    };\n  }, []);\n return (\n   <div className=\"App\">\n     <div ref={mapRef} id=\"map\" />\n   </div>\n );\n}\n\n\nexport default withAuthenticator(Map);\n\nNote: Ensure that your package bundler (webpack, rollup, etc) is configured to handle css files. Check out the webpack documentation here.\n\nGeofence API\n\nIf you are using a different mapping library or need a programmatic approach to managing geofences, the @aws-amplify/geo package provides methods for managing geofences, but not geofence collections.\n\nFirst, you need to import Geo from the @aws-amplify/geo package.\n\nCopy\ncode example\nimport { Geo } from '@aws-amplify/geo';\nsaveGeofences\n\nsaveGeofences is used to save geofences to your collection. It can take a single geofence or an array of geofences.\n\nAPI\nCopy\ncode example\nGeo.saveGeofences(geofences, options) => Promise<SaveGeofenceResults>;\nParameters\ngeofences - can be a single geofence object, or an array of geofence objects to save to a collection.\noptions - optional options object for saving geofences\ncollectionName - the name of the collection to save geofences to.\nDefaults to the default collection listed in your amplify_outputs.json file after provisioning a geofence collection resource.\n\nGeofence objects must have the following properties:\n\ngeofenceId - a opaque and unique identifier for the geofence.\ngeometry - a geometry object that defines the geofence.\npolygon - an array of arrays with [Longitude, Latitude] coordinates.\n\nNOTE: Polygon arrays have a few requirements:\n\nmust have at least 4 vertices (i.e. 4 coordinate points)\nthe first and last point must be the same in order to complete the polygonal loop\nvertices must be in counter-clockwise order\nReturn\n\nThe return from saveGeofences is a Promise that resolves to SaveGeofenceResults which contains both successes and errors for geofences that were successfully created or failed.\n\nEach success object has the following properties:\n\ngeofenceId - the geofenceId of the geofence that was saved.\ncreateTime - the time the geofence was created.\nupdateTime - the time the geofence was last updated.\n\nEach error object has the following properties:\n\ngeofenceId - the geofenceId of the geofence that failed to be saved.\nerror - an error object\ncode - the error code\nmessage - the error message\nExample\nCopy\ncode example\nlet saveGeofenceResults;\ntry {\n  saveGeofenceResults = await Geo.saveGeofences({\n    geofenceId: 'my-geofence',\n    geometry: {\n      polygon: [\n        [-123.14695358276366, 49.290090146520434],\n        [-123.1358814239502, 49.294960279811974],\n        [-123.15021514892577, 49.29300108863353],\n        [-123.14909934997559, 49.29132171993048],\n        [-123.14695358276366, 49.290090146520434]\n      ]\n    }\n  });\n} catch (error) {\n  // errors thrown by input validations of `saveGeofences`\n  throw error;\n}\n\n\nif (saveGeofenceResults.errors.length > 0) {\n  // error handling that are from the underlying API calls\n  console.log(`Success count: ${saveGeofenceResults.successes.length}`);\n  console.log(`Error count: ${saveGeofenceResults.errors.length}`);\n}\ngetGeofence\n\ngeoGeofence is used to get a single geofence from a collection.\n\nAPI\nCopy\ncode example\nGeo.getGeofence(geofenceId, options) => Promise<Geofence>;\nParameters\ngeofenceId - the id of the geofence to get.\noptions - optional options object for getting a geofence\ncollectionName - the name of the collection to get geofence from.\nDefaults to the default collection listed in your amplify_outputs.json file after provisioning a geofence collection resource.\nReturn\n\nThe return from getGeofence is a Promise that resolves to a geofence object.\n\nExample\nCopy\ncode example\nlet responses;\ntry {\n  response = await Geo.getGeofence('geofenceId');\n} catch (error) {\n  throw error;\n}\nlistGeofences\n\nlistGeofences is used to get a list of geofences from a collection. It has pagination built in and will return 100 geofences per page.\n\nAPI\nCopy\ncode example\nGeo.listGeofences(options) => Promise<ListGeofenceResults>;\nParameters\noptions - optional options object for saving geofences\nnextToken - the pagination token for the next page of geofences.\nif no token is given, it will return the first page of geofences.\ncollectionName - the name of the collection to save geofences to.\nDefaults to the default collection listed in your amplify_outputs.json file after provisioning a geofence collection resource.\nReturn\n\nReturns a Promise that resolves to an object with the following properties:\n\nentries - an array of geofences\nnextToken - the pagination token for the next page of geofences\nExample\nCopy\ncode example\nlet response;\ntry {\n  response = await Geo.listGeofences();\n  response.entries.forEach((geofence) => console.log(geofence.geofenceId));\n} catch (error) {\n  throw error;\n}\ndeleteGeofences\n\ndeleteGeofences is used to delete a geofences from a collection. It can delete a single or multiple geofences at once.\n\nAPI\nCopy\ncode example\nGeo.deleteGeofences(geofenceIds, options) => Promise<DeleteGeofencesResults>;\nParameters\ngeofenceIds - a single geofenceId or array of geofenceIds to delete\noptions - optional options object for saving geofences\ncollectionName - the name of the collection to save geofences to.\nDefaults to the default collection listed in your amplify_outputs.json file after provisioning a geofence collection resource.\nReturn\n\nThe return from deleteGeofences is a Promise that resolves to an object with both successes and errors for geofences that were successfully deleted or not.\n\nThe success object is an array of geofenceIds that were successfully deleted.\nThe error object is an array of error objects that include the following properties:\ngeofenceId - the geofenceId of the geofence that failed to be deleted.\nerror - an error object\ncode - the error code\nmessage - the error\nExample\nCopy\ncode example\nlet response;\ntry {\n  response = await Geo.deleteGeofences(\n    [\n      \"geofence1\",\n      \"geofence2\",\n      \"geofence3\",\n    ]\n  )\ncatch (error) {\n  // error handling from logic and validation issues within `deleteGeofences`\n  throw error;\n}\n\n\nif(response.errors.length > 0){\n  // error handling that are from the underlying API calls\n  console.log(`Success count: ${response.successes.length}`);\n  console.log(`Error count: ${response.errors.length}`);\n}\nPREVIOUS\nConfigure a geofence collection\nNEXT\nUse existing Amazon Location resources"
  },
  {
    "title": "Configure a geofence collection - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/geo/configure-geofencing/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nGeo\n/\nConfigure a geofence collection\nConfigure a geofence collection\n\nA Geofence is a virtual perimeter for a real-world geographic area. A Geofence contains points or vertices that form a closed boundary, defining an area of interest. Geofence collections store one or multiple Geofences.\n\nSetup a new Geofence Collection\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { Policy, PolicyStatement } from \"aws-cdk-lib/aws-iam\";\nimport { CfnGeofenceCollection } from \"aws-cdk-lib/aws-location\";\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\n\n\nconst backend = defineBackend({\n  auth,\n  data,\n  // additional resources\n});\n\n\nconst geoStack = backend.createStack(\"geo-stack\");\n\n\n// create a location services geofence collection\nconst myGeofenceCollection = new CfnGeofenceCollection(\n  geoStack,\n  \"GeofenceCollection\",\n  {\n    collectionName: \"myGeofenceCollection\",\n    pricingPlan: \"RequestBasedUsage\",\n    tags: [\n      {\n        key: \"name\",\n        value: \"myGeofenceCollection\",\n      },\n    ],\n  }\n);\n\n\n// create an IAM policy to allow interacting with geofence collection resource\nconst myGeofenceCollectionPolicy = new Policy(\n  geoStack,\n  \"GeofenceCollectionPolicy\",\n  {\n    policyName: \"myGeofenceCollectionPolicy\",\n    statements: [\n      new PolicyStatement({\n        actions: [\n          \"geo:GetGeofence\",\n          \"geo:PutGeofence\",\n          \"geo:BatchPutGeofence\",\n          \"geo:BatchDeleteGeofence\",\n          \"geo:ListGeofences\",\n        ],\n        resources: [myGeofenceCollection.attrArn],\n      }),\n    ],\n  }\n);\n\n\n// apply the policy to the authenticated and unauthenticated roles\nbackend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(myGeofenceCollectionPolicy);\nbackend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(myGeofenceCollectionPolicy);\n\n\n// patch the geofence collection resource to the expected output configuration\nbackend.addOutput({\n  geo: {\n    geofence_collections: {\n      default: myGeofenceCollection.collectionName,\n      items: [myGeofenceCollection.collectionName],\n    },\n  },\n});\nGeofence Collection Pricing Plan\n\nThe pricing plan for the Geofence Collection will be set to RequestBasedUsage. We advice you to go through the location service pricing along with the location service terms (82.5 section) to learn more about the pricing plan.\n\nGroup access\n\nTo scope access permissions based on Cognito User Groups\n\nCreate a Cognito User Pool Group\namplify/auth/resource.ts\nCopy\namplify/auth/resource.ts code example\nimport { defineAuth } from '@aws-amplify/backend';\n\n\nexport const auth = defineAuth({\n  loginWith: {\n    email: true,\n  },\n  groups: [\"User\"],\n});\nAdd permissions to the Cognito User Pool Group role\namplify/backend.ts\nCopy\namplify/backend.ts code example\nconst myGeofenceCollectionPolicy = new Policy(\n  geoStack,\n  \"GeofenceCollectionPolicy\",\n  {\n    policyName: \"myGeofenceCollectionPolicy\",\n    statements: [\n      new PolicyStatement({\n        actions: [\n          \"geo:GetGeofence\",\n          \"geo:PutGeofence\",\n          \"geo:BatchPutGeofence\",\n          \"geo:BatchDeleteGeofence\",\n          \"geo:ListGeofences\",\n        ],\n        resources: [myGeofenceCollection.attrArn],\n      }),\n    ],\n  }\n);\n\n\nbackend.auth.resources.groups[\"User\"].role.attachInlinePolicy(myGeofenceCollectionPolicy);\n\nNote: If you combine Auth/Guest user access and Individual Group access, users who are members of a group will only be granted the permissions of the group, and not the authenticated user permissions. The permissions apply to ALL Geofences in a collection. For example, If you add Read permission such as ListGeofences and GetGeofence to User Cognito group, ALL users added to that group will be able to read the properties of ALL Geofences in that Geofence collection.\n\nUsing the AWS SDK for Javascript\n\nAlternatively, if you want to add users to an existing Cognito user pool group programmatically, you can use the AWS SDK for Javascript. Refer to the API documentation.\n\nNote: After you have provisioned the Geofence Collection, depending on your application's use-case, you can also add Geofences to the provisioned Geofence Collection programmatically. Refer this API documentation for more information.\n\nPREVIOUS\nWork with location search\nNEXT\nWork with geofences"
  },
  {
    "title": "Work with maps - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/geo/maps/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nGeo\n/\nWork with maps\nWork with maps\nDisplay a map\n\nFirst, ensure you've provisioned an Amazon Location Service Map resource and configured your app using the instructions in either Set up map or Use existing resources guide.\n\nNote: For React, you can use the Amplify React MapView component\n\nTo render a map, the MapLibre GL and the maplibre-gl-js-amplify libraries are required. MapLibre GL is an open source map rendering library and maplibre-gl-js-amplify library makes it easy to integrate MapLibre with Amplify Geo and handles Authentication.\n\nAdd the dependencies to your app:\n\nTerminal\nCopy\nTerminal code example\nnpm add maplibre-gl maplibre-gl-js-amplify\n\nVerify the following:\n\nmaplibre-gl-js-amplify version 4.0.0 or above is installed\nAny package bundlers (webpack, rollup, etc) are\b configured to handle css files. Check out the webpack documentation here.\n\nImport the library into your application:\n\nCopy\ncode example\nimport { createMap } from 'maplibre-gl-js-amplify';\nimport 'maplibre-gl/dist/maplibre-gl.css';\n\nNext, create and render the Map with the help of createMap.\n\nNote: There must be a div with an id=\"map\" on the DOM before making the call to createMap in this way.\n\nCopy\ncode example\nasync function initializeMap() {\n  const map = await createMap({\n    container: 'map', // An HTML Element or HTML element ID to render the map in https://maplibre.org/maplibre-gl-js/docs/API/classes/Map/\n    center: [-123.1187, 49.2819], // [Longitude, Latitude]\n    zoom: 11\n  });\n}\n\n\ninitializeMap();\n\nTo render a map using a className or something other than the ID you can pass in a reference to the HTML Element itself.\n\nCopy\ncode example\nconst element = document.getElementsByClassName(\"class\")[0];\n\n\nconst map = await createMap({\n    container: element,\n    ...\n})\n\nThe MapLibre canvas requires a defined height to display properly, otherwise you may end up with a blank screen where the map is supposed to be.\n\nThe amplify-map.css file has a few commonly used methods for setting the height of the map component. You can add some of the examples listed to your own styles or directly import amplify-map.css like so:\n\nCopy\ncode example\nimport \"maplibre-gl-js-amplify/dist/public/amplify-map.css\";\n\nTo render a map using percentage based height you need to ensure that all ancestor elements to the map container have a height:\n\nCopy\ncode example\nhtml,\nbody,\n#root {\n  /* The ancestors of the map element */\n  height: 100%;\n}\n\n\n#map {\n  height: 50%;\n}\n\nDisplay markers on map\n\nTo display markers on a map, use the drawPoints function. drawPoints expects:\n\nsourceName - specifies the layer on which the markers are rendered on. You can edit existing markers by passing the same sourceName\ncoordinate data - (longitude, latitude) the coordinate data of the markers to be displayed\na maplibre-gl-js Map - the map object on which to render the markers\n\nFirst, import the drawPoints method in your app. Your import section should include look like this\n\nCopy\ncode example\nimport { drawPoints } from 'maplibre-gl-js-amplify';\n\nThe drawPoints method returns ids of the source and layers used to display the markers on the map. These ids can be used for further customization through maplibre-gl-js source, paint, and layer options.\n\nFor more information about the parameters and options that can be used with drawPoints check the documentation here.\n\nNext, use the following code snippet when you want to display the markers on the map. Add it to the initializeMap() function if you want the markers to show up on map load.\n\nCopy\ncode example\nmap.on('load', function () {\n  drawPoints(\n    'mySourceName', // Arbitrary source name\n    [\n      {\n        coordinates: [-122.483696, 37.833818], // [Longitude, Latitude]\n        title: 'Golden Gate Bridge',\n        address: 'A suspension bridge spanning the Golden Gate'\n      },\n      {\n        coordinates: [-122.477, 37.8105] // [Longitude, Latitude]\n      }\n    ], // An array of coordinate data, an array of Feature data, or an array of [NamedLocations](https://github.com/aws-amplify/maplibre-gl-js-amplify/blob/main/src/types.ts#L8)\n    map,\n    {\n      showCluster: true,\n      unclusteredOptions: {\n        showMarkerPopup: true\n      },\n      clusterOptions: {\n        showCount: true\n      }\n    }\n  );\n});\n\nDisplay different map styles\n\nThe getAvailableMaps API fetches information for all maps that are available to be displayed.\n\nThis is useful if you would like to give your users a variety of maps styles to choose from.\n\nCopy\ncode example\nimport { Geo } from '@aws-amplify/geo';\n\n\nGeo.getAvailableMaps();\n\nThe available maps are returned as an array with the following contents:\n\nCopy\ncode example\n//returns\n[\n  {\n    mapName: 'myAmplifyGeoEsriStreetMap',\n    style: 'VectorEsriStreets'\n  },\n  {\n    mapName: 'myAmplifyGeoEsriTopographicMap',\n    style: 'VectorEsriTopographic'\n  }\n];\n\nYou can resize and customize a map with the resize and setStyle functions:\n\nCopy\ncode example\nmap.setStyle('myAmplifyGeoEsriTopographicMap'); // map name received from getAvailableMaps()\nmap.resize(); // forces the map to re-render\nRemoving a map from the DOM\n\nWhen it's time to remove the map from the DOM, you can use the .remove method of the generated map. This will clean up and release all resources associated with the map (DOM elements, event bindings, web workers, and WebGL resources).\n\nCopy\ncode example\nmap.remove();\n\nAfter calling .remove(), you must not call any other methods on the map.\n\nFor React users:\n\nNot removing the map on component unmount can cause memory leaks in your application. It's recommended to call .remove() in either the return function of a React useEffect hook or the componentWillUnmount lifecycle hook of a class component.\n\nAdd map to html website\n\nTo display a map on your html website, add the following scripts to your html webpage.\n\nCopy\ncode example\n<link href=\"https://cdn.amplify.aws/packages/maplibre-gl/1.15.2/maplibre-gl.css\" rel=\"stylesheet\" integrity=\"sha384-DrPVD9GufrxGb7kWwRv0CywpXTmfvbKOZ5i5pN7urmIThew0zXKTME+gutUgtpeD\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></link>\n<script src=\"https://cdn.amplify.aws/packages/maplibre-gl/1.15.2/maplibre-gl.js\" integrity=\"sha384-rwYfkmAOpciZS2bDuwZ/Xa/Gog6jXem8D/whm3wnsZSVFemDDlprcUXHnDDUcrNU\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></script>\n<script src=\"https://cdn.amplify.aws/packages/core/4.3.0/aws-amplify-core.min.js\" integrity=\"sha384-7Oh+5w0l7XGyYvSqbKi2Q7SA5K640V5nyW2/LEbevDQEV1HMJqJLA1A00z2hu8fJ\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></script>\n<script src=\"https://cdn.amplify.aws/packages/auth/4.3.8/aws-amplify-auth.min.js\" integrity=\"sha384-jfkXCEfYyVmDXYKlgWNwv54xRaZgk14m7sjeb2jLVBtUXCD2p+WU8YZ2mPZ9Xbdw\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></script>\n<script src=\"https://cdn.amplify.aws/packages/geo/1.1.0/aws-amplify-geo.min.js\" integrity=\"sha384-TFMTyWuCbiptXTzvOgzJbV8TPUupG1rA1AVrznAhCSpXTIdGw82bGd8RTk5rr3nP\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></script>\n<script src=\"https://cdn.amplify.aws/packages/maplibre-gl-js-amplify/1.1.0/maplibre-gl-js-amplify.umd.min.js\" integrity=\"sha384-7/RxWonKW1nM9zCKiwU9x6bkQTjldosg0D1vZYm0Zj+K/vUSnA3sOMhlRRWAtHPi\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></script>\n\nNext, add a div element with id map anywhere in your webpage where you want to render the map. Include the following code snippet to configure Amplify (update the amplify_outputs.json file path accordingly) and instantiate the map.\n\nCopy\ncode example\n<script type=\"module\">\n  import outputs from './amplify_outputs.json' assert { type: 'json' };\n  const { Amplify } = aws_amplify_core;\n  const { createMap } = AmplifyMapLibre;\n  Amplify.configure(outputs);\n  createMap({\n    container: 'map',\n    center: [-123.1187, 49.2819], // [Longitude, Latitude]\n    zoom: 13\n  });\n</script>\nSample application\nCopy\ncode example\n<!DOCTYPE html>\n<html>\n    <head>\n        <meta charset=\"utf-8\">\n        <title>Display a map on a webpage</title>\n        <meta name=\"viewport\" content=\"initial-scale=1,maximum-scale=1,user-scalable=no\">\n        <link href=\"https://cdn.amplify.aws/packages/maplibre-gl/1.15.2/maplibre-gl.css\" rel=\"stylesheet\" integrity=\"sha384-DrPVD9GufrxGb7kWwRv0CywpXTmfvbKOZ5i5pN7urmIThew0zXKTME+gutUgtpeD\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></link>\n        <script src=\"https://cdn.amplify.aws/packages/maplibre-gl/1.15.2/maplibre-gl.js\" integrity=\"sha384-rwYfkmAOpciZS2bDuwZ/Xa/Gog6jXem8D/whm3wnsZSVFemDDlprcUXHnDDUcrNU\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></script>\n        <script src=\"https://cdn.amplify.aws/packages/core/5.0.5/aws-amplify-core.min.js\" integrity=\"sha384-eM2urkpomL9SRm/kuPHZG3XPEItAiUAAyotT/AqlhSus8iAqs/EfHaYy1Jn5ih7K\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></script>\n        <script src=\"https://cdn.amplify.aws/packages/auth/5.0.5/aws-amplify-auth.min.js\" integrity=\"sha384-H25CFLYd7YHa1Oib73fs3kJN36VhaHHkLjo4AhGrhJ4HuKam05pg2/0t2MR6epun\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></script>\n        <script src=\"https://cdn.amplify.aws/packages/geo/2.0.5/aws-amplify-geo.min.js\" integrity=\"sha384-Esc9xx0X7ckb/yeYHuYsZGqBB4FwYr98NFHS3BRXLeRE/eB0uVrad2w+G6cGxYb5\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></script>\n        <script src=\"https://cdn.amplify.aws/packages/maplibre-gl-js-amplify/1.5.0/maplibre-gl-js-amplify.umd.min.js\" integrity=\"sha384-9kJyZavd3Jk6QzHeaLpugVonfZmZZZdixek6uglOwzKtZvDS9K3W4dshw1uswmlV\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></script>\n        <style>\n            body { margin: 0; padding: 0; }\n            #map { position: absolute; top: 0; bottom: 0; width: 100%; }\n        </style>\n    </head>\n    <body>\n        <div id=\"map\"></div>\n        <script type=\"module\">\n            import outputs from \"./amplify_outputs.json\" assert { type: \"json\" };\n            const { Amplify } = aws_amplify_core;\n            const { createMap } = AmplifyMapLibre;\n            Amplify.configure(outputs);\n            createMap({\n                container: \"map\",\n                center: [-123.1187, 49.2819], // [Longitude, Latitude]\n                zoom: 13,\n            });\n        </script>\n    </body>\n</html>\nMap API's\n\nIf you want more information about the maps you currently have configured or want a way to switch between maps programmatically, the @aws-amplify/geo package provides API's that return more information about your currently provisioned maps.\n\nFirst, you need to import Geo from the @aws-amplify/geo package.\n\nCopy\ncode example\nimport { Geo } from '@aws-amplify/geo';\ngetAvailableMaps\n\ngetAvailableMaps will return the map resources you currently have provisioned in your Amplify project. You can switch between any of these different maps and display their different map styles.\n\nAPI\nCopy\ncode example\nGeo.getAvailableMaps() => Promise<AmazonLocationServiceMapStyle[]>;\nParameters\nN/A\nReturn\n\nThe return from getAvailableMaps is a Promise that resolves to AmazonLocationServiceMapStyle[] which is an array of mapName, style, and region.\n\nEach object has the following properties:\n\nmapName - name of the map you created.\nstyle - the Amazon Location Service style used to create the map.\nregion - the AWS region the map is hosted in.\n\nNote: When changing a map with Amplify and MapLibre the setStyle function should be called with the name of the Location Service map NOT the style. This is because the transformRequest function uses the Location Service map name to make a new request for map tile data.\n\nExample\nCopy\ncode example\nconst availableMaps = await Geo.getAvailableMaps();\n\n\nmap.setStyle(availableMaps[0].mapName);\ngetDefaultMap\n\ngetDefaultMap is used to get a the default map object.\n\nAPI\nCopy\ncode example\nGeo.getDefaultMap() => Promise<AmazonLocationServiceMapStyle>;\nParameters\nN/A\nReturn\n\nThe return from getDefaultMap is a Promise that resolves to a AmazonLocationServiceMapStyle object.\n\nThe object has the following properties:\n\nmapName - name of the map you created.\nstyle - the Amazon Location Service style used to create the map.\nregion - the AWS region the map is hosted in.\nExample\nCopy\ncode example\nconst defaultMap = await Geo.getDefaultMap();\nPREVIOUS\nSet up Amplify Geo\nNEXT\nConfigure location search"
  },
  {
    "title": "Work with location search - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/geo/location-search/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nGeo\n/\nWork with location search\nWork with location search\nAdd location search functionality on a map\n\nFirst, make sure you've provisioned a search index resource and configured your app using the instructions in either Configure Location Search or Use existing Amazon Location Service resources and you have already setup displaying a map in your application.\n\nNote: For React, you can use the Amplify UI Location Search component to generate and display the search results.\n\nTo add a location search UI component to your map, you can use the maplibre-gl-geocoder library. maplibre-gl-js-amplify package makes it easy to integrate maplibre-gl-geocoder with Amplify Geo by exporting a utility function createAmplifyGeocoder() that returns an instance of maplibre-gl-geocoder with some pre-defined settings and supports all the options for customizing the UI component\n\nInstall the necessary dependencies with the following command:\n\nTerminal\nCopy\nTerminal code example\nnpm add @maplibre/maplibre-gl-geocoder maplibre-gl@1 maplibre-gl-js-amplify\n\nNote: Make sure that maplibre-gl-js-amplify version 4.0.0 or above is installed.\n\nFirst, create a map onto which you want to add the location search UI component. See the guide on creating and displaying maps.\n\nThen, use createAmplifyGeocoder() to get a new instance of MaplibreGeocoder and add the location search UI component to the map.\n\nNote: Ensure that your package bundler (webpack, rollup, etc) is configured to handle css files. Check out the webpack documentation here.\n\nCopy\ncode example\nimport { createMap, createAmplifyGeocoder } from \"maplibre-gl-js-amplify\";\nimport maplibregl from \"maplibre-gl\";\nimport \"maplibre-gl/dist/maplibre-gl.css\";\nimport \"@maplibre/maplibre-gl-geocoder/dist/maplibre-gl-geocoder.css\";\nimport \"maplibre-gl-js-amplify/dist/public/amplify-geocoder.css\"; // Optional CSS for Amplify recommended styling\n\n\nasync function initializeMap() {\n    const el = document.createElement(\"div\");\n    el.setAttribute(\"id\", \"map\");\n    document.body.appendChild(el);\n\n\n    const map = await createMap({\n        container: \"map\",\n        center: [-123.1187, 49.2819], // [Longitude, Latitude]\n        zoom: 11,\n    })\n\n\n    map.addControl(createAmplifyGeocoder());\n}\n\n\ninitializeMap();\n\nDisplay the location search box outside the map\n\nYou can also use maplibre-gl-geocoder to display the location search UI component anywhere in your application, even outside the map.\n\nTo do so, extract the html element using function onAdd() and attach it anywhere in your DOM instead of adding it via the map's addControl() function.\n\nCopy\ncode example\nconst geocoder = createAmplifyGeocoder();\ndocument.getElementById(\"search\").appendChild(geocoder.onAdd());\n\nCustomize Search Icons\n\nYou can customize the search icons used by the maplibre-gl-geocoder to use any image of your choosing. MapLibre markers require an HTMLElement when passing in custom images.\n\nThe following example puts an existing SVG icon into an HTMLElement before being passed to createAmplifyGeocoder which creates a maplibre-gl-geocoder.\n\nCopy\ncode example\nimport myIcon from \"./myIcon.svg\" // relative path to your custom icon\n\n\nconst icon = new Image(100, 100);\nicon.src = myIcon;\n\n\nconst geocoder = createAmplifyGeocoder({ showResultMarkers: { element: icon } });\nmap.addControl(geocoder);\n\nLocation-based search capabilities\n\nAmplify Geo enables you to search for locations by text, addresses, or geo-coordinates.\n\nSearch by text, address, business name, city, and more\n\nThe Geo.searchByText() API enables you to search for places or points of interest by free-form text, such as an address, name, city, or region.\n\nCopy\ncode example\nimport { Geo } from \"@aws-amplify/geo\"\n\n\nGeo.searchByText(\"Amazon Go Store\")\n\nCustomize your search results further by providing:\n\ncountries - to limit the search results to given countries (specified in ISO Alpha-3 country codes)\nmaxResults - to limit the maximum result set\nbiasPosition - to act as the search origination location\nsearchAreaConstraints - to limit the area to search inside of\nsearchIndexName - to use a different Location Service search index resource than the default\n\nNote: Providing both biasPosition and searchAreaConstraints parameters simultaneously returns an error.\n\nCopy\ncode example\nconst searchOptionsWithBiasPosition = {\n  countries: string[], // Alpha-3 country codes\n  maxResults: number, // 50 is the max and the default\n  biasPosition: [\n    longitude // number\n    latitude // number,\n  ], // Coordinates point to act as the center of the search\n  searchIndexName: string, // the string name of the search index\n}\n\n\nconst searchOptionsWithSearchAreaConstraints = {\n  countries: [\"USA\"], // Alpha-3 country codes\n  maxResults: 25, // 50 is the max and the default\n  searchAreaConstraints: [SWLongitude, SWLatitude, NELongitude, NELatitude], // Bounding box to search inside of\n  searchIndexName: string, // the string name of the search index\n}\n\n\nGeo.searchByText('Amazon Go Stores', searchOptionsWithBiasPosition)\n\nThis returns places and their coordinates that match the search constraints. A place can also have additional metadata as shown in the example below.\n\nCopy\ncode example\n// returns\n[\n  {\n    geometry: {\n      point:\n        [\n          -122.34014899999994, // Longitude point\n          47.61609000000004 // Latitude point\n        ],\n    },\n    addressNumber: \"2131\" // optional string for the address number alone\n    country: \"USA\" // optional Alpha-3 country code\n    label: \"Amazon Go, 2131 7th Ave, Seattle, WA, 98121, USA\" // Optional string\n    municipality: \"Seattle\" // Optional string\n    neighborhood: undefined // Optional string\n    postalCode: \"98121\" // Optional string\n    region: \"Washington\" // Optional string\n    street: \"7th Ave\" // Optional string\n    subRegion: \"King County\" // Optional string\n  }\n]\nSearch by coordinates\n\nThe Geo.searchByCoordinates() API is a reverse Geocoder that takes a coordinate point and returns information about what it finds at that point on the map. The returned object is the same shape as searchByText() API above.\n\nCopy\ncode example\nimport { Geo } from \"@aws-amplify/geo\";\n\n\nGeo.searchByCoordinates([longitudePoint, latitudePoint])\n\nYou can optionally limit your result set with the maxResults parameter or override the default search index with the searchIndexName parameter.\n\nCopy\ncode example\nconst searchOptionsWithBiasPosition = {\n  maxResults: number, // 50 is the max and the default\n  searchIndexName: string, // the string name of the search index\n}\n\n\nGeo.searchByCoordinates([-122.3399573, 47.616179], searchOptionsWithBiasPosition)\nSearch for suggestions\n\nThe Geo.searchForSuggestions() API enables you to search for suggestions by free-form text, such as a place, address, city, or region.\n\nCopy\ncode example\nimport { Geo } from \"@aws-amplify/geo\";\n\n\nGeo.searchForSuggestions(\"Amazon Go Store\")\n\nSimilar to Geo.searchByText() API, customize your search results further by providing:\n\ncountries - to limit the search results to given countries (specified in ISO Alpha-3 country codes)\nmaxResults - to limit the maximum result set\nbiasPosition - to act as the search origination location\nsearchAreaConstraints - to limit the area to search inside of\nsearchIndexName - to use a different Location Service search index resource than the default\n\nNote: Providing both biasPosition and searchAreaConstraints parameters simultaneously returns an error.\n\nCopy\ncode example\nconst searchOptionsWithBiasPosition = {\n  countries: string[], // Alpha-3 country codes\n  maxResults: number, // 50 is the max and the default\n  biasPosition: [\n    longitude // number\n    latitude // number,\n  ], // Coordinates point to act as the center of the search\n  searchIndexName: string, // the string name of the search index\n}\n\n\nconst searchOptionsWithSearchAreaConstraints = {\n  countries: [\"USA\"], // Alpha-3 country codes\n  maxResults: 25, // 50 is the max and the default\n  searchAreaConstraints: [SWLongitude, SWLatitude, NELongitude, NELatitude], // Bounding box to search inside of\n  searchIndexName: string, // the string name of the search index\n}\n\n\nGeo.searchForSuggestions('Amazon Go', searchOptionsWithBiasPosition)\n\nThis returns a list of suggestions (places and their respective placeId if available) that match the search constraints.\n\nCopy\ncode example\n// returns\n[\n  {\n    text: \"Amazon Go, 2131 7th Ave, Seattle, WA, 98121, USA\",\n    placeId: \"8fd9d4c6-2527-4190-a7df-0dae352c9dc6\"\n  },\n  {\n    text: \"Amazon Go, 1906 Terry Ave, Seattle, WA, 98101, USA\",\n    placeId: \"5d04d071-dea2-4d86-bfce-86bd6a8f4787\"\n  }\n]\n\nIn cases where placeId is not available on the list of suggestions as below, use searchByText to search for the selected place by text.\n\nCopy\ncode example\nGeo.searchForSuggestions(\"Amazon\", { MaxResults: 5 })\n\n\n// returns\n[\n  {\n    text: \"Amazon Go\",\n  },\n  {\n    text: \"Amazon 4-star\",\n  }\n]\n\n\nGeo.searchByText('Amazon Go', { MaxResults: 5 })\n\nThis returns places and their coordinates that match the search text.\n\nSearch by PlaceId\n\nThe Geo.searchByPlaceId() API enables you to search for a place by a placeId, which is a unique opaque token for a place returned by the provider.\n\nCopy\ncode example\nimport { Geo } from \"@aws-amplify/geo\";\n\n\nGeo.searchByPlaceId(placeId)\n\nYou can optionally override the default search index with the searchIndexName parameter.\n\nCopy\ncode example\nconst searchByPlaceIdOptions = {\n  searchIndexName: string, // the string name of the search index\n}\n\n\nGeo.searchByPlaceId(\"8fd9d4c6-2527-4190-a7df-0dae352c9dc6\", searchByPlaceIdOptions)\n\nThis returns a place with metadata as shown in the example below.\n\nCopy\ncode example\n// returns\n{\n  geometry: {\n    point:\n      [\n        -122.34014899999994, // Longitude point\n        47.61609000000004 // Latitude point\n      ],\n  },\n  addressNumber: \"2131\" // optional string for the address number alone\n  country: \"USA\" // optional Alpha-3 country code\n  label: \"Amazon Go, 2131 7th Ave, Seattle, WA, 98121, USA\" // Optional string\n  municipality: \"Seattle\" // Optional string\n  neighborhood: undefined // Optional string\n  postalCode: \"98121\" // Optional string\n  region: \"Washington\" // Optional string\n  street: \"7th Ave\" // Optional string\n  subRegion: \"King County\" // Optional string\n}\nPREVIOUS\nConfigure location search\nNEXT\nConfigure a geofence collection"
  },
  {
    "title": "Configure location search - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/geo/configure-location-search/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nGeo\n/\nConfigure location search\nConfigure location search\n\nAmplify's geo category enables you to search by places, addresses, and coordinates in your app with \"place index\" resources.\n\nSetup a new Location Search Index\namplify/backend.ts\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { Policy, PolicyStatement } from \"aws-cdk-lib/aws-iam\";\nCopy\nhighlighted code example\nimport { CfnMap, CfnPlaceIndex } from \"aws-cdk-lib/aws-location\";\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\n\n\nconst backend = defineBackend({\n  auth,\n  data,\n  // additional resources\n});\n\n\nconst geoStack = backend.createStack(\"geo-stack\");\n\n\n// create a location services map\nconst map = new CfnMap(geoStack, \"Map\", {\n  mapName: \"myMap\",\n  description: \"Map\",\n  configuration: {\n    style: \"VectorEsriNavigation\",\n  },\n  pricingPlan: \"RequestBasedUsage\",\n  tags: [\n    {\n      key: \"name\",\n      value: \"myMap\",\n    },\n  ],\n});\n\n\n\n\n// create an IAM policy to allow interacting with geo resource\nconst myGeoPolicy = new Policy(geoStack, \"GeoPolicy\", {\n  policyName: \"myGeoPolicy\",\n  statements: [\n    new PolicyStatement({\n      actions: [\n        \"geo:GetMapTile\",\n        \"geo:GetMapSprites\",\n        \"geo:GetMapGlyphs\",\n        \"geo:GetMapStyleDescriptor\",\n      ],\n      resources: [map.attrArn],\n    }),\n  ],\n});\n\n\n// apply the policy to the authenticated and unauthenticated roles\nbackend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(myGeoPolicy);\nbackend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(myGeoPolicy);\n\n\nCopy\nhighlighted code example\n// create a location services place index\nconst myIndex = new CfnPlaceIndex(geoStack, \"PlaceIndex\", {\n  dataSource: \"Here\",\n  dataSourceConfiguration: {\n    intendedUse: \"SingleUse\",\n  },\n  indexName: \"myPlaceIndex\",\n  pricingPlan: \"RequestBasedUsage\",\n  tags: [\n    {\n      key: \"name\",\n      value: \"myPlaceIndex\",\n    },\n  ],\n});\n\n\n// create a policy to allow access to the place index\nconst myIndexPolicy = new Policy(geoStack, \"IndexPolicy\", {\n  policyName: \"myIndexPolicy\",\n  statements: [\n    new PolicyStatement({\n      actions: [\n        \"geo:SearchPlaceIndexForPosition\",\n        \"geo:SearchPlaceIndexForText\",\n        \"geo:SearchPlaceIndexForSuggestions\",\n        \"geo:GetPlace\",\n      ],\n      resources: [myIndex.attrArn],\n    }),\n  ],\n});\n\n\n// attach the policy to the authenticated and unauthenticated IAM roles\nbackend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(myIndexPolicy);\nbackend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(myIndexPolicy);\n\n\n// patch the place index resource to the expected output configuration\nbackend.addOutput({\n  geo: {\n    aws_region: geoStack.region,\n    maps: {\n      items: {\n        [map.mapName]: {\n          style: \"VectorEsriNavigation\",\n        },\n      },\n      default: map.mapName,\n    },\nCopy\nhighlighted code example\n    search_indices: {\n      default: myIndex.indexName,\n      items: [myIndex.indexName],\n    },\n  },\n});\nLocation Search Index Pricing Plan\n\nThe pricing plan for Search Index will be set to RequestBasedUsage. We advice you to go through the location service pricing along with the location service terms (82.5 section) to learn more about the pricing plan.\n\nAdvanced Settings\n\nYou can optionally configure the data provider and result storage location for your location search index.\n\nLocation Search data provider\n\nYou can select a data provider as the source for geocoding, reverse geocoding and searches. Each provider gathers and curates their data using different means. They may also have varying expertise in different regions of the world. The available data providers of geospatial data are shown. To learn more about data providers, please refer this location service documentation.\n\nHere – For additional information about HERE Technologies, see Here guide.\nEsri – For additional information about Esri, see Esri guide.\n\nNote: If your application is tracking or routing assets you use in your business (such as delivery vehicles or employees), you may only use HERE as your geolocation provider. See section 82 of the AWS service terms for more details.\n\nLocation Search result storage location\n\nYou can specify how the results of a search operation will be stored by the caller.\n\nSingleUse - specifies that the results won't be stored.\nStorage - specifies that the result can be cached or stored in a database.\n\nRefer this location service doc for more information.\n\nPREVIOUS\nWork with maps\nNEXT\nWork with location search"
  },
  {
    "title": "Set up Amplify Geo - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/geo/set-up-geo/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nGeo\n/\nSet up Amplify Geo\nSet up Amplify Geo\n\nAmplify provides APIs and map UI components for maps and location search for your web apps.You can add maps and location search functionality to your app in just a few lines of code. The following is an example utilizing the AWS Cloud Development Kit (AWS CDK) to create a Geo resource powered by Amazon Location Services. But do note there are no official hand-written (L2) constructs for this service yet.\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { Policy, PolicyStatement } from \"aws-cdk-lib/aws-iam\";\nimport { CfnMap } from \"aws-cdk-lib/aws-location\";\nimport { Stack } from \"aws-cdk-lib/core\";\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\n\n\nconst backend = defineBackend({\n  auth,\n  data,\n  // additional resources\n});\n\n\nconst geoStack = backend.createStack(\"geo-stack\");\n\n\n// create a location services map\nconst map = new CfnMap(geoStack, \"Map\", {\n  mapName: \"myMap\",\n  description: \"Map\",\n  configuration: {\n    style: \"VectorEsriNavigation\",\n  },\n  pricingPlan: \"RequestBasedUsage\",\n  tags: [\n    {\n      key: \"name\",\n      value: \"myMap\",\n    },\n  ],\n});\n\n\n// create an IAM policy to allow interacting with geo resource\nconst myGeoPolicy = new Policy(geoStack, \"GeoPolicy\", {\n  policyName: \"myGeoPolicy\",\n  statements: [\n    new PolicyStatement({\n      actions: [\n        \"geo:GetMapTile\",\n        \"geo:GetMapSprites\",\n        \"geo:GetMapGlyphs\",\n        \"geo:GetMapStyleDescriptor\",\n      ],\n      resources: [map.attrArn],\n    }),\n  ],\n});\n\n\n// apply the policy to the authenticated and unauthenticated roles\nbackend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(myGeoPolicy);\nbackend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(myGeoPolicy);\n\n\n// patch the map resource to the expected output configuration\nbackend.addOutput({\n  geo: {\n    aws_region: geoStack.region,\n    maps: {\n      items: {\n        [map.mapName]: {\n          style: \"VectorEsriNavigation\",\n        },\n      },\n      default: map.mapName,\n    },\n  },\n});\nConfigure your application\n\nTo display a map in your application, you can use the Amplify React MapView component or the MapLibre GL with maplibre-gl-js-amplify libraries are required.\n\nInstall the necessary dependencies by running the following command:\n\nTerminal\nCopy\nTerminal code example\nnpm add aws-amplify @aws-amplify/geo\n\nNote: Make sure that version 6.0.0 or above is installed.\n\nImport and load the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point.\n\npages/_app.js\nCopy\npages/_app.js code example\nimport { Amplify } from 'aws-amplify';\nimport outputs from '@/amplify_outputs.json';\nAmplify.configure(outputs);\n\nMake sure you call Amplify.configure as early as possible in your application’s life-cycle. A missing configuration or NoCredentials error is thrown if Amplify.configure has not been called before other Amplify JavaScript APIs.\n\nNotes:\n\nIf you want to use existing Amazon Location Service resources follow this guide instead.\nIf you want to use Amazon Location Service APIs not directly supported by Geo, use the escape hatch to access the Amazon Location Service SDK.\nReferences\n\nLocation Construct Library\n\nMap Pricing Plan\n\nThe pricing plan for the Map example is set to RequestBasedUsage. We advice you to go through the location service pricing along with the location service terms (82.5 section) to learn more about the pricing plan.\n\nNEXT\nWork with maps"
  },
  {
    "title": "Geo - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/geo/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nGeo\nGeo\nSet up Amplify Geo\nAWS Amplify Geo module provides a simple way to get map data, search for places, and reverse geocoding.\nWork with maps\nWorking with map displays, APIs, and more.\nConfigure location search\nCreate and manage location search indices or place indices that are used to search for places in your application.\nWork with location search\nUse Amplify Geo to add location search and location-based search capabilities.\nConfigure a geofence collection\nCreate and manage collections of Geofences\nWork with geofences\nProvision and manage geofences in your application with Amplify Geo.\nUse existing Amazon Location resources\nConfigure Amplify Geo to use existing Amazon Location Service resources by referencing them in your configuration.\nMigrate from Google Maps\nMigrate applications from Google Maps to Amplify Geo\nUse Amazon Location Service SDK\nFor specialized use cases where Amplify does not provide the functionality, you can use the escape hatch to access a low-level client instance for Amazon Location Service."
  },
  {
    "title": "Use existing AWS resources - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/analytics/existing-resources/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAnalytics\n/\nUse existing AWS resources\nUse existing AWS resources\n\nTo use existing Amazon Pinpoint resources with your Amplify backend or frontend application, use the addOutput method to surface backend resource outputs to the amplify_outputs.json file:\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from \"@aws-amplify/backend\"\n\n\nconst backend = defineBackend({})\n\n\nbackend.addOutput({\n  analytics: {\n    amazon_pinpoint: {\n      aws_region: \"<your-aws-region>\",\n      app_id: \"<your-pinpoint-app-id>\",\n    },\n  },\n})\nConfiguring client library directly\n\nAlternatively, you can configure the client library directly using Amplify.configure(). This manual setup enables you to use your existing Amazon Pinpoint resource in your app.\n\nsrc/main.ts\nCopy\nsrc/main.ts code example\nimport { Amplify } from 'aws-amplify';\n\n\nAmplify.configure({\n  ...Amplify.getConfig(),\n  Analytics: {\n    ...Amplify.getConfig().Analytics,\n    Pinpoint: {\n      // REQUIRED -  Amazon Pinpoint App Client ID\n      appId: 'XXXXXXXXXXabcdefghij1234567890ab',\n\n\n      // REQUIRED -  Amazon service region\n      region: 'us-east-1',\n\n\n      // OPTIONAL - How many events can be buffered at once.\n      bufferSize: 1000,\n\n\n      // OPTIONAL - How many events will be flushed from the buffer per batch.\n      flushSize: 100,\n\n\n      // OPTIONAL - The interval in milliseconds to perform a buffer check and flush if necessary.\n      flushInterval: 5000, // 5s\n\n\n      // OPTIONAL - The limit for failed recording retries.\n      resendLimit: 5\n    }\n  }\n});\nUpdate your IAM Policy\n\nAmazon Pinpoint requires an AWS Identity and Access Management (IAM) policy in order to use the record and identifyUser APIs:\n\nCopy\ncode example\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\"mobiletargeting:UpdateEndpoint\", \"mobiletargeting:PutEvents\"],\n      \"Resource\": [\"arn:aws:mobiletargeting:*:<your-account-id>:apps/<your-pinpoint-app-id>*\"]\n    }\n  ]\n}\nPREVIOUS\nPersonalized recommendations"
  },
  {
    "title": "Personalized recommendations - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/analytics/personalize-recommendations/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAnalytics\n/\nPersonalized recommendations\nPersonalized recommendations\n\nAmazon Personalize can create recommendations by using event data, historical data, or a combination of both. The event data can then be used to create recommendations.\n\nTo record event data, you need the following:\n\nA dataset group\nAn event tracker.\n\nFor more information, see Record Events.\n\nInstallation and Configuration\n\nAfter creating the Amazon Personalize dataset group, you need to add the personalize:PutEvents permission to your AWS Identity and Access Management (IAM) user roles.\n\nAn example IAM policy:\n\nCopy\ncode example\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [{\n    \"Effect\": \"Allow\",\n    \"Action\": \"personalize:PutEvents\",\n    \"Resource\": \"arn:aws:personalize:<your-aws-region>:<your-account-id>:event-tracker/<your-resource-name>\"\n  }]\n}\n\nYou need the tracking ID of your event tracker. For more information, see Get a Tracking ID.\n\nConfigure Amazon Personalize:\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { Amplify } from 'aws-amplify';\nAmplify.configure({\n  ...Amplify.getConfig(),\n  Analytics: {\n    Personalize: {\n      // REQUIRED - The trackingId to track the events\n      trackingId: '<tracking-id>',\n      // REQUIRED -  Amazon Personalize service region\n      region: 'us-east-1',\n      // OPTIONAL - The number of events to be deleted from the buffer when flushed.\n      flushSize: 10,\n      // OPTIONAL - The interval in milliseconds to perform a buffer check and flush if necessary.\n      flushInterval: 5000 // 5s\n    }\n  }\n});\nWorking with the API\n\nYou can use the Identify event type to track a user identity. This lets you connect a user to their actions and record traits about them. To identify a user, specify a unique identifier for the userId property. Consider the following user interactions when choosing when and how often to call record with the Identify eventType:\n\nAfter a user registers.\nAfter a user logs in.\nWhen a user updates their information (For example, changing or adding a new address).\nUpon loading any pages that are accessible by a logged-in user (optional).\nCopy\ncode example\nimport { record } from 'aws-amplify/analytics/personalize';\n\n\nrecord({\n  eventType: 'Identify',\n  properties: {\n    userId: '<user-id>'\n  }\n});\n\nYou can send events to Amazon Personalize by calling the record operation. If you already use Identify to track end-user data, you can skip the userId, the SDK will fetch the userId based on current browser session. For information about the properties field, see Put Events.\n\nCopy\ncode example\nimport { record } from 'aws-amplify/analytics/personalize';\n\n\nrecord({\n  eventType: '<event-type>',\n  userId: '<user-id>', // optional\n  properties: {\n    itemId: '<item-id>',\n    eventValue: '<event-value>'\n  }\n});\n\nYou can track iframe and HTML5 media types by using the MediaAutoTrack event type. MediaAutoTrack tracks all media events of the media DOM element that you bind to. MediaAutoTracker will automatically track Play, Pause, Ended, TimeWatched, and Resume in eventType. The duration of the event compared to the total length of the media is stored as a percentage value in eventValue.\n\nCopy\ncode example\nimport { record } from 'aws-amplify/analytics/personalize';\n\n\nrecord({\n  eventType: 'MediaAutoTrack',\n  userId: '<user-id>', // (optional)\n  properties: {\n    domElementId: 'media-dom-element-id',\n    itemId: '<item-d>'\n  }\n});\nFlush events\n\nThe recorded events are saved in a buffer and sent to the remote server periodically (You can tune it with the flushInterval option). If needed, you have the option to manually clear all the events from the buffer by using the 'flushEvents' API.\n\nCopy\ncode example\nimport { flushEvents } from 'aws-amplify/analytics/personalize';\n\n\nflushEvents();\nPREVIOUS\nStoring analytics data\nNEXT\nUse existing AWS resources"
  },
  {
    "title": "Storing analytics data - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/analytics/storing-data/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAnalytics\n/\nStoring analytics data\nStoring analytics data\n\nThe Amazon Data Firehose analytics provider allows you to send analytics data to an Amazon Data Firehose stream for reliably storing data.\n\nSetup Firehose stream\n\nThe following is an example utilizing the AWS Cloud Development Kit (AWS CDK) to create the Analytics resource powered by Amazon Data Firehose.\n\nLet's create a storage bucket to store the data from the Firehose stream.\n\namplify/storage/resource.ts\nCopy\namplify/storage/resource.ts code example\nimport { defineStorage } from \"@aws-amplify/backend\";\n\n\n// Define the S3 bucket resource\nexport const storage = defineStorage({\n  name: \"FirehoseDestinationBucket\",\n});\n\nnext, let's create the Firehose resource.\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\nimport { storage } from \"./storage/resource\";\nimport { CfnDeliveryStream } from \"aws-cdk-lib/aws-kinesisfirehose\";\nimport { Stack } from \"aws-cdk-lib/core\";\nimport {\n  Policy,\n  PolicyStatement,\n  Role,\n  ServicePrincipal,\n} from \"aws-cdk-lib/aws-iam\";\n\n\nconst backend = defineBackend({\n  auth, \n  data,\n  storage,\n  // additional resources \n});\n\n\n// Create a new stack for the Firehose resources\nconst firehoseStack = backend.createStack(\"firehose-stack\");\n\n\n// Access the S3 bucket resource\nconst s3Bucket = backend.storage.resources.bucket;\n\n\n// Create a new IAM role for the Firehose\nconst firehoseRole = new Role(firehoseStack, \"FirehoseRole\", {\n  assumedBy: new ServicePrincipal(\"firehose.amazonaws.com\"),\n});\n\n\n// Grant the Firehose role read/write permissions to the S3 bucket\ns3Bucket.grantReadWrite(firehoseRole);\n\n\n// Create a new Firehose delivery stream\nconst myFirehose = new CfnDeliveryStream(firehoseStack, \"MyFirehose\", {\n  deliveryStreamType: \"DirectPut\",\n  s3DestinationConfiguration: {\n    bucketArn: s3Bucket.bucketArn,\n    roleArn: firehoseRole.roleArn,\n  },\n  deliveryStreamName: \"myFirehose\",\n});\n\n\n// Create a new IAM policy to allow users to write to the Firehose\nconst firehosePolicy = new Policy(firehoseStack, \"FirehosePolicy\", {\n  statements: [\n    new PolicyStatement({\n      actions: [\"firehose:PutRecordBatch\"],\n      resources: [myFirehose.attrArn],\n    }),\n  ],\n});\n\n\n// Attach the policy to the authenticated and unauthenticated IAM roles\nbackend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(firehosePolicy);\nbackend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(firehosePolicy);\nInstallation and Configuration\n\nEnsure you have setup IAM permissions for firehose:PutRecordBatch.\n\nExample IAM policy for Amazon Data Firehose:\n\nCopy\ncode example\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [{\n    \"Effect\": \"Allow\",\n    \"Action\": \"firehose:PutRecordBatch\",\n    // replace the template fields\n    \"Resource\": \"arn:aws:firehose:<your-aws-region>:<your-aws-account-id>:deliverystream/<your-stream-name>\"\n  }]\n}\n\nConfigure Firehose:\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { Amplify } from 'aws-amplify';\n\n\nAmplify.configure({\n  ...Amplify.getConfig(),\n  Analytics: {\n    KinesisFirehose: {\n      // REQUIRED -  Amazon Kinesis Firehose service region\n      region: 'us-east-1',\n\n\n      // OPTIONAL - The buffer size for events in number of items.\n      bufferSize: 1000,\n\n\n      // OPTIONAL - The number of events to be deleted from the buffer when flushed.\n      flushSize: 100,\n\n\n      // OPTIONAL - The interval in milliseconds to perform a buffer check and flush if necessary.\n      flushInterval: 5000, // 5s\n\n\n      // OPTIONAL - The limit for failed recording retries.\n      resendLimit: 5\n    }\n  }\n});\nStoring data\n\nYou can send a data to a Firehose stream with the standard record method. Any data is acceptable and streamName is required:\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { record } from 'aws-amplify/analytics/kinesis-firehose';\n\n\nrecord({\n  data: {\n    // The data blob to put into the record\n  },\n  streamName: 'myFirehose'\n});\nFlush events\n\nThe recorded events are saved in a buffer and sent to the remote server periodically (You can tune it with the flushInterval option). If needed, you have the option to manually clear all the events from the buffer by using the 'flushEvents' API.\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { flushEvents } from 'aws-amplify/analytics/kinesis-firehose';\n\n\nflushEvents();\nPREVIOUS\nStreaming analytics data\nNEXT\nPersonalized recommendations"
  },
  {
    "title": "Streaming analytics data - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/analytics/streaming-data/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAnalytics\n/\nStreaming analytics data\nStreaming analytics data\n\nThe Amazon Kinesis analytics provider allows you to send analytics data to an Kinesis stream for real-time processing.\n\nSetup Kinesis stream\n\nThe following is an example utilizing the AWS Cloud Development Kit (AWS CDK) to create the Analytics resource powered by Amazon Kinesis.\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\nimport { Policy, PolicyStatement } from \"aws-cdk-lib/aws-iam\";\nimport { Stream } from \"aws-cdk-lib/aws-kinesis\";\nimport { Stack } from \"aws-cdk-lib/core\";\n\n\nconst backend = defineBackend({\n  auth, \n  data,\n  // additional resources \n});\n\n\n// create a new stack for the Kinesis stream\nconst kinesisStack = backend.createStack(\"kinesis-stack\");\n\n\n// create a new Kinesis stream with one shard\nconst kinesisStream = new Stream(kinesisStack, \"KinesisStream\", {\n  streamName: \"myKinesisStream\",\n  shardCount: 1,\n});\n\n\n// create a new policy to allow PutRecords to the Kinesis stream\nconst kinesisPolicy = new Policy(kinesisStack, \"KinesisPolicy\", {\n  statements: [\n    new PolicyStatement({\n      actions: [\"kinesis:PutRecords\"],\n      resources: [kinesisStream.streamArn],\n    }),\n  ],\n});\n\n\n// apply the policy to the authenticated and unauthenticated roles\nbackend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(kinesisPolicy);\nbackend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(kinesisPolicy);\nInstallation and Configuration\n\nIf you did not use the CLI, ensure you have setup IAM permissions for kinesis:PutRecords.\n\nExample IAM policy for Amazon Kinesis:\n\nCopy\ncode example\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [{\n    \"Effect\": \"Allow\",\n    \"Action\": \"kinesis:PutRecords\",\n    \"Resource\": \"arn:aws:kinesis:<your-aws-region>:<your-aws-account-id>:stream/<your-stream-name>\" // replace the template fields\n  }]\n}\n\nFor more information visit the Amazon Kinesis Developer Documentation.\n\nConfigure Kinesis:\n\nsrc/index.js\nCopy\nsrc/index.js code example\n// Configure the plugin after adding it to the Analytics module\nimport { Amplify } from 'aws-amplify';\n\n\nAmplify.configure({\n  ...Amplify.getConfig(),\n  Analytics: {\n    Kinesis: {\n      // REQUIRED -  Amazon Kinesis service region\n      region: 'us-east-1',\n\n\n      // OPTIONAL - The buffer size for events in number of items.\n      bufferSize: 1000,\n\n\n      // OPTIONAL - The number of events to be deleted from the buffer when flushed.\n      flushSize: 100,\n\n\n      // OPTIONAL - The interval in milliseconds to perform a buffer check and flush if necessary.\n      flushInterval: 5000, // 5s\n\n\n      // OPTIONAL - The limit for failed recording retries.\n      resendLimit: 5\n    }\n  }\n});\nStream data\n\nYou can send a data to a Kinesis stream with the standard record() method:\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { record } from 'aws-amplify/analytics/kinesis';\n\n\nrecord({\n  data: {\n    // The data blob to put into the record\n  },\n  partitionKey: 'myPartitionKey',\n  streamName: 'myKinesisStream'\n});\nFlush events\n\nThe recorded events are saved in a buffer and sent to the remote server periodically (You can tune it with the flushInterval option). If needed, you have the option to manually clear all the events from the buffer by using the 'flushEvents' API.\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { flushEvents } from 'aws-amplify/analytics/kinesis';\n\n\nflushEvents();\nPREVIOUS\nEnable and disable analytics\nNEXT\nStoring analytics data"
  },
  {
    "title": "Automatically track sessions - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/analytics/auto-track-sessions/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAnalytics\n/\nAutomatically track sessions\nAutomatically track sessions\n\nAnalytics auto tracking helps you to automatically track user behaviors like sessions' start/stop, page view change and web events like clicking or mouseover.\n\nSession Tracking\n\nYou can track the session both in a web app or a React Native app by using Analytics. A web session can be defined in different ways. To keep it simple, we define a web session as being active when the page is not hidden and inactive when the page is hidden. A session in a React Native app is active when the app is in the foreground and inactive when the app is in the background.\n\nFor example:\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { configureAutoTrack } from 'aws-amplify/analytics';\n\n\nconfigureAutoTrack({\n  // REQUIRED, turn on/off the auto tracking\n  enable: true,\n  // REQUIRED, the event type, it's one of 'event', 'pageView' or 'session'\n  type: 'session',\n  // OPTIONAL, additional options for the tracked event.\n  options: {\n    // OPTIONAL, the attributes of the event\n    attributes: {\n      customizableField: 'attr'\n    }\n  }\n});\n\nBy default, when the page/app transitions to the foreground, the Analytics module will send an event to the Amazon Pinpoint Service.\n\nCopy\ncode example\n{\n  \"eventType\": \"_session_start\",\n  \"attributes\": {\n    \"customizableField\": \"attr\"\n  }\n}\n\nThis behavior can be disabled by calling configureAutoTrack:\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { configureAutoTrack } from 'aws-amplify/analytics';\n\n\nconfigureAutoTrack({\n  enable: false,\n  type: 'session'\n});\nPage View Tracking\n\nUse this feature to track the most frequently viewed page/url in your webapp. It automatically sends events containing url information when a page is visited.\n\nThis behavior can be enabled by calling configureAutoTrack:\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { configureAutoTrack } from 'aws-amplify/analytics';\n\n\nconfigureAutoTrack({\n  // REQUIRED, turn on/off the auto tracking\n  enable: true,\n  // REQUIRED, the event type, it's one of 'event', 'pageView' or 'session'\n  type: 'pageView',\n  // OPTIONAL, additional options for the tracked event.\n  options: {\n    // OPTIONAL, the attributes of the event\n    attributes: {\n      customizableField: 'attr'\n    },\n\n\n    // OPTIONAL, the event name. By default, this is 'pageView'\n    eventName: 'pageView',\n\n\n    // OPTIONAL, the type of app under tracking. By default, this is 'multiPageApp'.\n    // You will need to change it to 'singlePage' if your app is a single-page app like React\n    appType: 'multiPageApp',\n\n\n    // OPTIONAL, provide the URL for the event.\n    urlProvider:  () => {\n      // the default function\n      return window.location.origin + window.location.pathname;\n    }\n  }\n});\n\nThis behavior can be disabled by calling configureAutoTrack:\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { configureAutoTrack } from 'aws-amplify/analytics';\n\n\nconfigureAutoTrack({\n  enable: false,\n  type: 'pageView'\n});\nPage Event Tracking\n\nUse page event tracking to track user interactions with specific elements on a page. Attach the specified selectors to your DOM element and turn on the auto tracking.\n\nThis behavior can be enabled by calling configureAutoTrack:\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { configureAutoTrack } from 'aws-amplify/analytics';\n\n\nconfigureAutoTrack({\n  // REQUIRED, turn on/off the auto tracking\n  enable: true,\n  // REQUIRED, the event type, it's one of 'event', 'pageView' or 'session'\n  type: 'event',\n  // OPTIONAL, additional options for the tracked event.\n  options: {\n    // OPTIONAL, the attributes of the event\n    attributes: {\n      customizableField: 'attr'\n    },\n    // OPTIONAL, events you want to track. By default, this is 'click'\n    events: ['click'],\n\n\n    // OPTIONAL, the prefix of the selectors. By default, this is 'data-amplify-analytics-'\n    // Per https://www.w3schools.com/tags/att_global_data.asp, always start\n    // the prefix with 'data' to avoid collisions with the user agent\n    selectorPrefix: 'data-amplify-analytics-'\n  }\n});\n\nFor example:\n\nCopy\ncode example\n<!-- you want to track this button and send an event when it is clicked -->\n<button\n  data-amplify-analytics-on=\"click\"\n  data-amplify-analytics-name=\"click\"\n  data-amplify-analytics-attrs=\"attr1:attr1_value,attr2:attr2_value\"\n/>\n\nWhen the button above is clicked, an event will be sent automatically. This is equivalent to doing:\n\nCopy\ncode example\n<script>\n  import { record } from 'aws-amplify/analytics';\n  var sendEvent = function() {\n    record({\n      name: 'click',\n      attributes: {\n        attr: 'attr', // the default ones\n        attr1: attr1_value, // defined in the button component\n        attr2: attr2_value // defined in the button component\n      }\n    });\n  };\n</script>\n<button onclick=\"sendEvent()\" />\n\nThis behavior can be disabled by calling configureAutoTrack:\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { configureAutoTrack } from 'aws-amplify/analytics';\n\n\nconfigureAutoTrack({\n  enable: false,\n  type: 'event'\n});\n\nNote: Amplify doesn't capture location automatically. Instead, you can add the location information in the default config when you configure Analytics or while updating the end point.\n\nPREVIOUS\nIdentify user\nNEXT\nEnable and disable analytics"
  },
  {
    "title": "Enable and disable analytics - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/analytics/enable-disable/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAnalytics\n/\nEnable and disable analytics\nEnable and disable analytics\nDisable Analytics\n\nAnalytics are enabled by default when you configure it in your app. To disable Analytics in your app use the disable function:\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { disable } from 'aws-amplify/analytics';\n\n\ndisable();\nEnable Analytics\n\nTo enable analytics you can use the enable function in your app:\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { enable } from 'aws-amplify/analytics';\n\n\nenable();\nPREVIOUS\nAutomatically track sessions\nNEXT\nStreaming analytics data"
  },
  {
    "title": "Identify user - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/analytics/identify-user/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAnalytics\n/\nIdentify user\nIdentify user\n\nThis API sends information about the current user to Amazon Pinpoint.\n\nAdditional information such as the user's name, email, location, and device can be included by specifying the UserProfile. Custom attributes can also be included by setting UserProfile.customProperties.\n\nIf the user was signed in through signIn you can retrieve the current user's ID as shown below:\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { identifyUser } from 'aws-amplify/analytics';\nimport { getCurrentUser } from 'aws-amplify/auth';\n\n\nconst location = {\n  latitude: 47.606209,\n  longitude: -122.332069,\n  postalCode: '98122',\n  city: 'Seattle',\n  region: 'WA',\n  country: 'USA'\n};\n\n\nconst customProperties = {\n  plan: ['plan'],\n  phoneNumber: ['+11234567890'],\n  age: ['25']\n};\n\n\nconst userProfile = {\n  location,\n  name: 'username',\n  email: 'name@example.com',\n  customProperties\n};\n\n\nasync function sendUserData() {\n  const user = await getCurrentUser();\n\n\n  identifyUser({\n    userId: user.userId,\n    userProfile\n  });\n}\n\nSending user information allows you to associate a user to their user profile and activities or actions in your app. The user's actions and attributes can also tracked across devices and platforms by using the same userId.\n\nSome scenarios for identifying a user and their associated app activities are:\n\nWhen a user completes app sign up\nWhen a user completes sign in process\nWhen a user launches your app\nWhen a user modifies or updates their user profile\nPREVIOUS\nRecord events\nNEXT\nAutomatically track sessions"
  },
  {
    "title": "Set up Amplify Analytics - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/analytics/set-up-analytics/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAnalytics\n/\nSet up Amplify Analytics\nSet up Amplify Analytics\n\nAmplify enables you to collect analytics data for your app. In order to use Analytics, you will enable Amazon Kinesis or Amazon Pinpoint using the AWS Cloud Development Kit (AWS CDK). The Analytics category uses Amazon Cognito identity pools to identify users in your app. Cognito allows you to receive data from authenticated, and unauthenticated users in your app.\n\nSet up Analytics backend\n\nUse the AWS CDK to create an analytics resource powered by Amazon Pinpoint.\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from \"@aws-amplify/backend\"\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\nimport { Policy, PolicyStatement } from \"aws-cdk-lib/aws-iam\";\nimport { CfnApp } from \"aws-cdk-lib/aws-pinpoint\";\nimport { Stack } from \"aws-cdk-lib/core\";\n\n\nconst backend = defineBackend({\n  auth,\n  data,\n  // additional resources\n});\n\n\nconst analyticsStack = backend.createStack(\"analytics-stack\");\n\n\n// create a Pinpoint app\nconst pinpoint = new CfnApp(analyticsStack, \"Pinpoint\", {\n  name: \"myPinpointApp\",\n});\n\n\n// create an IAM policy to allow interacting with Pinpoint\nconst pinpointPolicy = new Policy(analyticsStack, \"PinpointPolicy\", {\n  policyName: \"PinpointPolicy\",\n  statements: [\n    new PolicyStatement({\n      actions: [\"mobiletargeting:UpdateEndpoint\", \"mobiletargeting:PutEvents\"],\n      resources: [pinpoint.attrArn + \"/*\"],\n    }),\n  ],\n});\n\n\n// apply the policy to the authenticated and unauthenticated roles\nbackend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(pinpointPolicy);\nbackend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(pinpointPolicy);\n\n\n// patch the custom Pinpoint resource to the expected output configuration\nbackend.addOutput({\n  analytics: {\n    amazon_pinpoint: {\n      app_id: pinpoint.ref,\n      aws_region: Stack.of(pinpoint).region,\n    }\n  },\n});\nInstall Amplify Libraries\n\nFirst, install the aws-amplify library:\n\nTerminal\nCopy\nTerminal code example\nnpm add aws-amplify\nInitialize Amplify Analytics\n\nImport and load the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point.\n\npages/_app.tsx\nCopy\npages/_app.tsx code example\nimport { Amplify } from 'aws-amplify';\nimport { record } from 'aws-amplify/analytics';\nimport outputs from '@/amplify_outputs.json';\n\n\nAmplify.configure({\n  ...Amplify.getConfig(),\n  Analytics: amplifyconfig.Analytics,\n});\n\nNext Steps:\n\nCongratulations! Now that you have Analytics' backend provisioned and Analytics library installed. Check out the following links to see Amplify Analytics use cases:\n\nRecord Events\nTrack Sessions\nIdentify User\nReferences\n\nAmazon Pinpoint Construct Library\n\nNEXT\nRecord events"
  },
  {
    "title": "Record events - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/analytics/record-events/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAnalytics\n/\nRecord events\nRecord events\nRecording Custom Events\n\nTo record custom events call the record API:\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { record } from 'aws-amplify/analytics';\n\n\nrecord({\n  name: 'albumVisit',\n});\n\nAnalytics events are buffered in memory and periodically sent to the service and not saved locally between application sessions. If the session is ended before a buffered event is sent, it will be lost. Use the flushEvents API to manually send buffered events to the service.\n\nRecord a Custom Event with Attributes\n\nThe record API lets you add additional attributes to an event. For example, to record artist information with an albumVisit event:\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { record } from 'aws-amplify/analytics';\n\n\nrecord({\n  name: 'albumVisit',\n  attributes: { genre: '', artist: '' },\n});\n\nRecorded events will be buffered and periodically sent to Amazon Pinpoint.\n\nRecord Engagement Metrics\n\nMetrics can also be added to an event:\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { record } from 'aws-amplify/analytics';\n\n\nrecord({\n  name: 'albumVisit',\n  metrics: { minutesListened: 30 },\n});\n\nMetric values must be a Number type such as a float or integer.\n\nThe Amazon Pinpoint event count updates in minutes after recording your event.\n\nHowever, it can take upwards of 30 minutes for the event to display in the Filter section, and for its custom attributes to appear in Amazon Pinpoint.\n\nFlush events\n\nThe recorded events are saved in a buffer and sent to the remote server periodically. If needed, you have the option to manually clear all the events from the buffer by using the 'flushEvents' API.\n\nsrc/index.js\nCopy\nsrc/index.js code example\nimport { flushEvents } from 'aws-amplify/analytics';\n\n\nflushEvents();\nPREVIOUS\nSet up Amplify Analytics\nNEXT\nIdentify user"
  },
  {
    "title": "Next.js App Router (Server Components) - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/server-side-rendering/nextjs-app-router-server-components/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nServer-Side Rendering\n/\nNext.js App Router (Server Components)\nNext.js App Router (Server Components)\n\nThis Quickstart guide will walk you through how to build a task list application with TypeScript, Next.js App Router with Server Components, and React. If you are new to these technologies, we recommend you go through the official React, Next.js, and TypeScript tutorials first.\n\nPrerequisites\n\nBefore you get started, make sure you have the following installed:\n\nNode.js v18.17 or later\nnpm v9 or later\ngit v2.14.1 or later\n\nYou will also need to create an AWS account. Note that AWS Amplify is part of the AWS Free Tier.\n\nCreate a project\n\nFirst, you will need to create a new Next.js app. The following command will create a Next.js app in a directory called next-amplify-gen2 that uses the App Router.\n\nCopy\ncode example\nnpm create next-app@14 -- next-amplify-gen2 --typescript --eslint --app --no-src-dir --no-tailwind --import-alias '@/*'\ncd next-amplify-gen2\n\nThe easiest way to get started with AWS Amplify is through npm with create-amplify.\n\nCopy\ncode example\nnpm create amplify@latest\n? Where should we create your project? (.) # press enter\n\nRunning this command will scaffold a lightweight Amplify project in your current project with the following files:\n\nCopy\ncode example\n├── amplify/\n│   ├── auth/\n│   │   └── resource.ts\n│   ├── data/\n│   │   └── resource.ts\n│   ├── backend.ts\n│   └── package.json\n├── node_modules/\n├── .gitignore\n├── package-lock.json\n├── package.json\n└── tsconfig.json\nStart local dev server\n\nLet's start a local dev server for your app development. For the frontend, run npm run dev to spin up a localhost dev server with the default Next.js template.\n\nCopy\ncode example\nnpm run dev\n\nNow configure your AWS account to use Amplify. Note: If you already have an AWS profile with credentials on your local machine, and you have configured the corresponding AWS profile with the AmplifyBackendDeployFullAccess permission policy, you can skip this step.\n\nFor the backend, we're going to start a cloud sandbox environment. Amplify gives every developer a personal cloud sandbox environment that provides isolated development spaces to rapidly build, test, and iterate. When you're working with a team, each developer will have their own personal cloud sandbox. In a new terminal window, run the following command:\n\nCopy\ncode example\nnpx ampx sandbox\nDo not use cloud sandbox environments in production.\n\nYou should now have these two commands running concurrently in different terminal windows.\n\nBuild a backend\n\nNext, we will add data and auth capabilities to the app. In Amplify Gen 2, the resource.ts files are where you define the corresponding backend resource and details about it.\n\nAdd data\n\ncreate-amplify provides the scaffolding of a amplify/data/resource.ts file, which is ready to deploy.\n\nSee the complete amplify/data/resources.ts\n\nStep 1: Open amplify/data/resource.ts and update it to add a done field of type boolean and a priority field of enum with a value of ['low', 'medium', 'high']. We've removed the default comments to shorten the code below for the next few examples.\n\namplify/data/resource.ts\nimport { type ClientSchema, a, defineData } from '@aws-amplify/backend';\n\n\n// ...\n\n\nconst schema = a.schema({\n  Todo: a\n    .model({\n      content: a.string(),\nCopy\nhighlighted code example\n      done: a.boolean(),\n      priority: a.enum(['low', 'medium', 'high'])\n    })\n    .authorization(allow => [allow.owner(), allow.publicApiKey().to(['read'])]),\n});\n\n\n// ...\n\nOnce you save your changes to the data model, they will be deployed in seconds to your cloud sandbox.\n\nThe Todo data model is defined with authorization rules to allow the person who creates the Todo instance (the owner) to perform all actions on the data they own. We are also allowing all page viewers, including unauthenticated users, to read data.\n\nNote: These authorization rules can be modified using a chain of methods as defined by default. For example, we could remove the .to(['read']) and allow all visitors to perform all actions on data or add permissions for signed-in users or users who belong to user groups such as Admin. You can learn more about all options for authorization in the Customize your auth rules section of the docs.\n\nStep 2: Remove public access by deleting the allow.publicApiKey().to(['read']) authorization rule. Your authorization rule will look like the code below:\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\n// ...\n\n\n.authorization(allow => [allow.owner()]),\n\n\n// ...\n\nBelow the schema declaration, you will see the defineData function, which receives our schema and authorization configuration as arguments. The default configuration is for an apiKey to enable public access.\n\nStep 3: Update the defaultAuthorizationMode to userPool so that the default is to use user authentication.\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\n// ...\n\n\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    defaultAuthorizationMode: 'userPool'\n  }\n});\nAdd authentication\n\nNow let's work on our authentication configuration. Similar to the data/resource.ts we just worked on, the auth/resource.ts file has code to define our authentication configuration. In this case, we are setting the authentication method to log in with email.\n\nSee the complete amplify/auth/resources.ts\n\nLet's customize the subject of the verification email sent to users after they sign up for our app. There is only one step to complete.\n\nOpen amplify/auth/resource.ts and update it to add a subject line by defining an object with email authentication properties referencing the code below:\n\namplify/auth/resource.ts\n// amplify/auth/resource.ts\nimport { defineAuth } from '@aws-amplify/backend';\n\n\nexport const auth = defineAuth({\n  loginWith: {\nCopy\nhighlighted code example\n   email: {\n     verificationEmailSubject: 'Welcome! Verify your email!'\n   },\n  }\n});\nThe Data and Auth resource files are imported into the amplify/backend.ts file which serves as the entry point to the Amplify backend for all resources used in this app. It is shown below, but there are no modifications needed to complete this quickstart.\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource';\nimport { data } from './data/resource';\n\n\ndefineBackend({\n  auth,\n  data\n});\nBuild UI\n\nLet's add UI that connects to the backend data and auth resources.\n\nConfigure Amplify Client Side\n\nFirst, install the Amplify UI component library:\n\nCopy\ncode example\nnpm add @aws-amplify/ui-react\n\nNext, create a components folder in the root of your project and copy the contents below to a file called ConfigureAmplify.tsx.\n\ncomponents/ConfigureAmplify.tsx\nCopy\ncomponents/ConfigureAmplify.tsx code example\n// components/ConfigureAmplify.tsx\n\"use client\";\n\n\nimport { Amplify } from \"aws-amplify\";\n\n\nimport outputs from \"@/amplify_outputs.json\";\n\n\nAmplify.configure(outputs, { ssr: true });\n\n\nexport default function ConfigureAmplifyClientSide() {\n  return null;\n}\n\nUpdate app/layout.tsx to import and render <ConfigureAmplifyClientSide />. This client component will configure Amplify for client pages in our application.\n\napp/layout.tsx\nCopy\napp/layout.tsx code example\n// app/layout.tsx\nimport \"@aws-amplify/ui-react/styles.css\";\nimport type { Metadata } from \"next\";\nimport { Inter } from \"next/font/google\";\nimport \"./globals.css\";\n\n\nimport ConfigureAmplifyClientSide from \"@/components/ConfigureAmplify\";\n\n\nconst inter = Inter({ subsets: [\"latin\"] });\n\n\nexport const metadata: Metadata = {\n  title: \"Create Next App\",\n  description: \"Generated by create next app\",\n};\n\n\nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode;\n}) {\n  return (\n    <html lang=\"en\">\n      <body className={inter.className}>\n        <ConfigureAmplifyClientSide />\n        {children}\n      </body>\n    </html>\n  );\n}\nConfigure Amplify Server Side\n\nFirst, install the Amplify Next.js adapter:\n\nCopy\ncode example\nnpm add @aws-amplify/adapter-nextjs\n\nNext, create a utils/amplify-utils.ts file from the root of the project and paste the code below. runWithAmplifyServerContext, cookiesClient, and AuthGetCurrentUserServer are declared here and will be used to gain access to Amplify assets from the server.\n\nutils/amplify-utils.ts\nCopy\nutils/amplify-utils.ts code example\n// utils/amplify-utils.ts\nimport { cookies } from \"next/headers\";\n\n\nimport { createServerRunner } from \"@aws-amplify/adapter-nextjs\";\nimport { generateServerClientUsingCookies } from \"@aws-amplify/adapter-nextjs/api\";\nimport { getCurrentUser } from \"aws-amplify/auth/server\";\n\n\nimport { type Schema } from \"@/amplify/data/resource\";\nimport outputs from \"@/amplify_outputs.json\";\n\n\nexport const { runWithAmplifyServerContext } = createServerRunner({\n  config: outputs,\n});\n\n\nexport const cookiesClient = generateServerClientUsingCookies<Schema>({\n  config: outputs,\n  cookies,\n});\n\n\nexport async function AuthGetCurrentUserServer() {\n  try {\n    const currentUser = await runWithAmplifyServerContext({\n      nextServerContext: { cookies },\n      operation: (contextSpec) => getCurrentUser(contextSpec),\n    });\n    return currentUser;\n  } catch (error) {\n    console.error(error);\n  }\n}\nAdd server authentication routes\n\nFirst, create a client-side Login component in the components folder that will be wrapped in withAuthenticator. If the user is logged in, they will be redirected to the index route; otherwise, the Amplify UI Authenticator component will be rendered.\n\ncomponents/Login.tsx\nCopy\ncomponents/Login.tsx code example\n// components/Login.tsx\n\"use client\";\n\n\nimport { withAuthenticator } from \"@aws-amplify/ui-react\";\nimport { AuthUser } from \"aws-amplify/auth\";\nimport { redirect } from \"next/navigation\";\nimport { useEffect } from \"react\";\n\n\nfunction Login({ user }: { user?: AuthUser }) {\n  useEffect(() => {\n    if (user) {\n      redirect(\"/\");\n    }\n  }, [user]);\n  return null;\n}\n\n\nexport default withAuthenticator(Login);\n\nNext, create a new route under app/login/page.tsx to render the Login component.\n\napp/login/page.tsx\nCopy\napp/login/page.tsx code example\n// app/login/page.tsx\n\n\nimport Login from \"@/components/Login\";\n\n\nexport default function LoginPage() {\n  return <Login />;\n}\nCustom <Authenticator> example\n\nFinally, create a Logout component to be used later.\n\ncomponents/Logout.tsx\nCopy\ncomponents/Logout.tsx code example\n// components/Logout.tsx\n\n\n\"use client\";\n\n\nimport { signOut } from \"aws-amplify/auth\";\nimport { useRouter } from \"next/navigation\";\n\n\nexport default function Logout() {\n  const router = useRouter();\n\n\n  return (\n    <button\n      onClick={async () => {\n        await signOut();\n        router.push(\"/login\");\n      }}\n      className=\"px-2 bg-white text-black\"\n    >\n      Sign out\n    </button>\n  );\n}\n\nNote: If using Amplify UI Social Providers, set the callbackUrls for the /login route when configuring social sign-in for your Gen 2 backend, as shown below.\n\namplify/auth/resource.ts\nCopy\namplify/auth/resource.ts code example\nimport { defineAuth, secret } from '@aws-amplify/backend';\n\n\nexport const auth = defineAuth({\n  loginWith: {\n    externalProviders: {\n      // ...\n      callbackUrls: [\n        'http://localhost:3000/login',\n        'https://mywebsite.com/login'\n      ],\n      logoutUrls: ['http://localhost:3000/logout', 'https://mywebsite.com/logout']\n    }\n  }\n});\nAdd middleware for server-side redirect\n\nCreate middleware.ts in the root of the project with the contents below.\n\nThis middleware runs fetchAuthSession wrapped in runWithAmplifyServerContext and will redirect to /login when a user is not logged in.\n\nmiddleware.ts\nCopy\nmiddleware.ts code example\n// middleware.ts\nimport { NextRequest, NextResponse } from \"next/server\";\n\n\nimport { fetchAuthSession } from \"aws-amplify/auth/server\";\n\n\nimport { runWithAmplifyServerContext } from \"@/utils/amplify-utils\";\n\n\nexport async function middleware(request: NextRequest) {\n  const response = NextResponse.next();\n\n\n  const authenticated = await runWithAmplifyServerContext({\n    nextServerContext: { request, response },\n    operation: async (contextSpec) => {\n      try {\n        const session = await fetchAuthSession(contextSpec, {});\n        return session.tokens !== undefined;\n      } catch (error) {\n        console.log(error);\n        return false;\n      }\n    },\n  });\n\n\n  if (authenticated) {\n    return response;\n  }\n\n\n  return NextResponse.redirect(new URL(\"/login\", request.url));\n}\n\n\nexport const config = {\n  matcher: [\n    /*\n     * Match all request paths except for the ones starting with:\n     * - api (API routes)\n     * - _next/static (static files)\n     * - _next/image (image optimization files)\n     * - favicon.ico (favicon file)\n     * - login\n     */\n    \"/((?!api|_next/static|_next/image|favicon.ico|login).*)\",\n  ],\n};\n\nRun your application with npm run dev and navigate to http://localhost:3000. You should now see the authenticator, which is already configured and ready for your first sign-up! Create a new user account, confirm the account through email, and then sign in.\n\nView list of to-do items\n\nNow, let's display data on our app's frontend.\n\nThe code below uses the cookiesClient to provide access to the Todo model defined in the backend.\n\nModify your app's home page file, app/page.tsx, with the following code:\n\napp/page.tsx\nCopy\napp/page.tsx code example\n// app/page.tsx\n\n\nimport { cookiesClient } from \"@/utils/amplify-utils\";\n\n\nasync function App() {\n  const { data: todos } = await cookiesClient.models.Todo.list();\n\n\n  return (\n    <>\n      <h1>Hello, Amplify 👋</h1>\n      <ul>\n        {todos && todos.map((todo) => <li key={todo.id}>{todo.content}</li>)}\n      </ul>\n    </>\n  );\n}\n\n\nexport default App;\n\nOnce you save the file and navigate back to http://localhost:3000, you should see \"Hello, Amplify\" with a blank page for now because you have only an empty list of to-dos.\n\nCreate a new to-do item\n\nLet's update the component to have a form for prompting the user for the title for creating a new to-do list item and run the addTodo method on form submission. In a production app, the additional fields of the Todo model would be added to the form.\n\nAfter creating a to-do, revalidatePath is run to clear the Next.js cache for this route to instantly update the results from the server without a full page reload.\n\napp/page.tsx\nCopy\napp/page.tsx code example\n// app/page.tsx\n\n\nimport { revalidatePath } from \"next/cache\";\n\n\nimport { AuthGetCurrentUserServer, cookiesClient } from \"@/utils/amplify-utils\";\n\n\nimport Logout from \"@/components/Logout\";\n\n\nasync function App() {\n  const user = await AuthGetCurrentUserServer();\n  const { data: todos } = await cookiesClient.models.Todo.list();\n\n\n  async function addTodo(data: FormData) {\n    \"use server\";\n    const title = data.get(\"title\") as string;\n    await cookiesClient.models.Todo.create({\n      content: title,\n      done: false,\n      priority: \"medium\",\n    });\n    revalidatePath(\"/\");\n  }\n\n\n  return (\n    <>\n      <h1>Hello, Amplify 👋</h1>\n      {user && <Logout />}\n      <form action={addTodo}>\n        <input type=\"text\" name=\"title\" />\n        <button type=\"submit\">Add Todo</button>\n      </form>\n\n\n      <ul>\n        {todos && todos.map((todo) => <li key={todo.id}>{todo.content}</li>)}\n      </ul>\n    </>\n  );\n}\n\n\nexport default App;\nTerminate dev server\n\nGo to localhost in the browser to make sure you can now log in and create and list to-dos. You can end your development session by shutting down the frontend dev server and cloud sandbox. The sandbox prompts you to delete your backend resources. While you can retain your backend, we recommend deleting all resources so you can start clean again next time.\n\nDeploy and host a fullstack branch\n\nNow that your app is working, let's deploy it to a shared fullstack branch so you can share the project with your team. Amplify offers a fully managed hosting service with CI/CD built in, making it easy to set up production and staging environments with Git branches. In Gen 2, every Git branch in your repository maps 1:1 to a fullstack branch in Amplify.\n\nCreate remote Git repository\n\nIf you already have your project remotely hosted in a Git repository, you can skip this step. Otherwise, navigate to your preferred Git provider, and add your project to a new repository. Amplify supports GitHub, AWS CodeCommit, GitLab, and Bitbucket.\n\nConnect branch in the Amplify console\nTo get started with Gen 2, log in to the Amplify console and navigate to your preferred AWS Region. (The Amplify console is available in 19 AWS Regions).\nFrom the Public Preview banner, choose Try Amplify Gen 2.\n\nIn the Git provider screen, choose Option 2: Start with an existing app. Connect the repository you just deployed and pick a branch.\n\nReview all of your settings to ensure everything is set up correctly. Choose Save and deploy to deploy your web app.\n\nManage fullstack branch\n\nThe new Amplify console gives you a central place to manage your branches, hosting settings, CI/CD builds, and backend resources. Even though you can access backend resources directly from AWS service consoles, the Amplify console offers built-in user and data administration."
  },
  {
    "title": "Server-Side Rendering - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/server-side-rendering/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nServer-Side Rendering\nServer-Side Rendering\n\nThis guide walks through how to use Amplify Auth and Data APIs from Next.js server-side runtimes.\n\nBefore you begin:\n\nFollow the Next.js App Router tutorial\nInstall the Amplify Next.js adapter\n\nTo use Amplify APIs server-side, you need to install the Amplify Next.js adapter in addition to the Amplify libraries:\n\nTerminal\nCopy\nTerminal code example\nnpm add aws-amplify @aws-amplify/adapter-nextjs\nConfigure Amplify APIs for server-side usage\n\nYou will need to create a runWithAmplifyServerContextRunner function to use Amplify APIs on the server-side of your Next.js app.\n\nYou can create an amplifyServerUtils.ts file under a utils folder in your codebase. In this file, you will import the Amplify backend outputs from the amplify_outputs.json file that is generated by the Amplify CLI, and use the createServerRunner function to create the runWithAmplifyServerContextRunner function.\n\nFor example, the utils/amplifyServerUtils.ts file may contain the following content:\n\nCopy\ncode example\nimport { createServerRunner } from '@aws-amplify/adapter-nextjs';\nimport outputs from '@/amplify_outputs.json';\n\n\nexport const { runWithAmplifyServerContext } = createServerRunner({\n  config: outputs\n});\n\nYou can use the exported runWithAmplifyServerContext function to call Amplify APIs within isolated request contexts. You can review examples under the Calling Amplify category APIs on the server side section.\n\nTIP: You only need to call the createServerRunner function once and reuse the runWithAmplifyServerContext function throughout.\n\nConfigure Amplify library for client-side usage\n\nWhen you use the Amplify library on the client-side of your Next.js app, you will need to configure Amplify by calling the Amplify.configure as you would to use Amplify in a single-page application.\n\nNOTE: To use the Amplify library on the client side in a Next.js app, you will need to set ssr to true when calling Amplify.configure. This instructs the Amplify library to store tokens in the cookie store of a browser. Cookies will be sent along with requests to your Next.js server for authentication.\n\nCopy\ncode example\n'use client';\n\n\nimport outputs from '@/amplify_outputs.json';\nimport { Amplify } from 'aws-amplify';\n\n\nAmplify.configure(outputs, {\n  ssr: true // required when using Amplify with Next.js\n});\n\n\nexport default function RootLayoutThatConfiguresAmplifyOnTheClient({\n  children\n}: {\n  children: React.ReactNode;\n}) {\n  return children;\n}\n\nTo avoid repetitive calls to Amplify.configure, you can call it once in a top-level client-side rendered layout component.\n\nLearn more\nConfigure Amplify in a Next.js App Router application\nAuthentication with Next.js server-side runtime\n\nYou can use the Amplify Auth category APIs to sign up and sign in your end users on the client side. When you set ssr: true when calling Amplify.configure, the Amplify library uses cookies to store tokens which will be sent along with HTTP requests to your Next.js app server.\n\nManage Auth session with the Next.js Middleware\n\nYou can use the fetchAuthSession API to check the auth sessions that are attached to the incoming requests in the middleware of your Next.js app to protect your routes. For example:\n\nCopy\ncode example\nimport { fetchAuthSession } from 'aws-amplify/auth/server';\nimport { NextRequest, NextResponse } from 'next/server';\nimport { runWithAmplifyServerContext } from '@/utils/amplifyServerUtils';\n\n\nexport async function middleware(request: NextRequest) {\n  const response = NextResponse.next();\n\n\n  const authenticated = await runWithAmplifyServerContext({\n    nextServerContext: { request, response },\n    operation: async (contextSpec) => {\n      try {\n        const session = await fetchAuthSession(contextSpec);\n        return (\n          session.tokens?.accessToken !== undefined &&\n          session.tokens?.idToken !== undefined\n        );\n      } catch (error) {\n        console.log(error);\n        return false;\n      }\n    }\n  });\n\n\n  if (authenticated) {\n    return response;\n  }\n\n\n  return NextResponse.redirect(new URL('/sign-in', request.url));\n}\n\n\nexport const config = {\n  matcher: [\n    /*\n     * Match all request paths except for the ones starting with:\n     * - api (API routes)\n     * - _next/static (static files)\n     * - _next/image (image optimization files)\n     * - favicon.ico (favicon file)\n     */\n    '/((?!api|_next/static|_next/image|favicon.ico|sign-in).*)'\n  ]\n};\n\nIn this example, if the incoming request is not associated with a valid user session the request will be redirected to the /sign-in route.\n\nNOTE: When calling fetchAuthSession with a response context, it will send the refreshed tokens (if any) back to the client via the Set-Cookie header in the response.\n\nCalling Amplify category APIs on the server side\n\nFor the Auth categories to use Amplify APIs on the server in your Next.js app, you will need to:\n\nImport the API from the /server sub path.\nUse the runWithAmplifyServerContext helper function created by calling the createServerRunner function exported from @aws-amplify/adapter-nextjs to call the Amplify API in an isolated server context.\n\nFor the GraphQL API category, review Connect to data from Server-side Runtimes.\n\nNOTE: A subset of Amplify APIs can now be called on the server side of a Next.js app. These APIs are exported from the /server sub paths. See the full list of supported APIs.\n\nNote: If you use the Amplify server-side APIs in a server action and encounter the following error running next build:\n\n./node_modules/@aws-amplify/core/node_modules/@aws-crypto/sha256-js/build/module/index.js + 12 modules\n\nCannot get final name for export 'fromUtf8' of ./node_modules/@smithy/util-utf8/dist-es/index.js\n\nYou can add the following to your next.config.js:\n\nnext.config.js\n/** @type {import('next').NextConfig} */\nconst nextConfig = {\nCopy\nhighlighted code example\n  experimental: {\n    serverComponentsExternalPackages: ['@aws-crypto'],\n  },\n};\n\nSee Next.js documentation on serverComponentsExternalPackages for more details.\n\nWith Next.js App Router\nDynamic rendering in React server component\n\nDynamic rendering is based on a user session extracted from an incoming request.\n\nCopy\ncode example\nimport { cookies } from 'next/headers';\nimport { getCurrentUser } from 'aws-amplify/auth/server';\nimport { runWithAmplifyServerContext } from '@/utils/amplifyServerUtils';\n\n\n// This page always dynamically renders per request\nexport const dynamic = 'force-dynamic';\n\n\nexport default async function AuthGetCurrentUserServer() {\n  try {\n    const currentUser = await runWithAmplifyServerContext({\n      nextServerContext: { cookies },\n      operation: (contextSpec) => getCurrentUser(contextSpec)\n    });\n\n\n    return (\n      <AuthFetchResult\n        description=\"The API is called on the server side.\"\n        data={currentUser}\n      />\n    );\n  } catch (error) {\n    console.error(error);\n    return <p>Something went wrong...</p>;\n  }\n}\nStatic rendering in React server component\n\nStatic rendering does not require a user session, so you can specify the nextServerContext parameter as null. This is useful for some use cases; for example, when you are using the Storage API with guest access (if you have enabled it in your backend).\n\nCopy\ncode example\nimport { getUrl } from 'aws-amplify/storage/server';\nimport Image from 'next/image';\nimport { runWithAmplifyServerContext } from '@/utils/amplifyServerUtils';\n\n\n// Re-render this page every 60 minutes\nexport const revalidate = 60 * 60; // in seconds\n\n\nexport default async function StaticallyRenderedPage() {\n  try {\n    const splashUrl = await runWithAmplifyServerContext({\n      nextServerContext: null,\n      operation: (contextSpec) =>\n        getUrl(contextSpec, {\n          key: 'splash.png'\n        })\n    });\n\n\n    return (\n      <Image\n        src={splashUrl.url.toString()}\n        alt=\"Splash Image\"\n        width={500}\n        height={500}\n      />\n    );\n  } catch (error) {\n    console.error(error);\n    return <p>Something went wrong...</p>;\n  }\n}\n\nNOTE: The URL returned by the getUrl API expires in the above example. You may want to specify the revalidate parameter to rerender the page as required to ensure the URL gets regenerated.\n\nIn Route Handlers\n\nIn route handlers require implementing an API route that enables GET /apis/get-current-user.\n\nCopy\ncode example\nimport { getCurrentUser } from 'aws-amplify/auth/server';\nimport { cookies } from 'next/headers';\nimport { NextResponse } from 'next/server';\nimport { runWithAmplifyServerContext } from '@/utils/amplifyServerUtils';\n\n\nexport async function GET() {\n  const user = await runWithAmplifyServerContext({\n    nextServerContext: { cookies },\n    operation: (contextSpec) => getCurrentUser(contextSpec)\n  });\n\n\n  return NextResponse.json({ user });\n}\n\nWhen you call fetch('/apis/get-current-user') it returns a payload that contains the user data for the current signed-in user.\n\nWith Next.js Pages Router\nIn getServerSideProps\n\nThe following example extracts current user data from the request and provides them to a page react component via its props.\n\nCopy\ncode example\nexport const getServerSideProps: GetServerSideProps = async ({ req, res }) => {\n  const currentUser = await runWithAmplifyServerContext({\n    nextServerContext: { request: req, response: res },\n    operation: (contextSpec) => getCurrentUser(contextSpec)\n  });\n\n\n  return { props: { currentUser } };\n};\nIn getStaticProps\n\nSimilar to static rendering with the App Router, you can pass null as the value of the nextServerContext parameter to use the Amplify Storage API with guest access.\n\nCopy\ncode example\nexport async function getStaticProps() {\n  const splashUrl = await runWithAmplifyServerContext({\n    nextServerContext: null,\n    operation: (contextSpec) => getUrl(contextSpec, { key: 'splash.png' })\n  });\n\n\n  return {\n    props: { imageUrl: splashUrl.url.toString() },\n    revalidate: (splashUrl.expiresAt.getTime() - Date.now()) / 1000 // in seconds\n  };\n}\nSupported APIs for Next.js server-side usage\n\nAll APIs that support use on the server are exported from the aws-amplify/<category>/server sub paths. You must use these APIs for any server-side use cases.\n\nCategory\tAPIs\tServer (Node.js) Amplify Hosting/Vercel\tVercel Edge Runtime (middleware)\nAuth\tfetchAuthSession\t✅\t✅\nAuth\tfetchUserAttributes\t✅\t✅\nAuth\tgetCurrentUser\t✅\t✅\nData\tgenerateServerClientUsingCookies\t✅\t\nData\tgenerateServerClientUsingReqRes\t✅\t\nStorage\tgetUrl\t✅\t\nStorage\tgetProperties\t✅\t\nStorage\tlist\t✅\t\nStorage\tremove\t✅\t\nStorage\tcopy\t✅\t"
  },
  {
    "title": "Analytics - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/analytics/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\n/\nAnalytics\nAnalytics\nSet up Amplify Analytics\nThe Analytics category enables you to collect analytics data for your app. The Analytics category comes with built-in support for Amazon Pinpoint and Amazon Kinesis (Kinesis support is currently only available in the Amplify JavaScript library). The Analytics category uses Amazon Cognito Identity pools to identify users in your App. Cognito allows you to receive data from authenticated, and unauthenticated users in your App.\nRecord events\nLearn how to record analytics events using Amplify.\nIdentify user\nUse the Amplify analytics plugin to inform Pinpoint about your users.\nAutomatically track sessions\nThe Amplify analytics plugin records when an application opens and closes. This session information can be viewed either from your local computer’s terminal or the AWS Console for Pinpoint.\nEnable and disable analytics\nLearn how to enable/disable analytics using Amplify.\nStreaming analytics data\nThe Amazon Kinesis analytics provider allows you to send analytics data to an Amazon Kinesis stream for real-time processing.\nStoring analytics data\nThe Amazon Data Firehose analytics provider allows you to send analytics data to an Amazon Data Firehose stream for reliably storing data.\nPersonalized recommendations\nAmazon Personalize can create recommendations by using event data, historical data, or a combination of both. The event data can then be used to create recommendations.\nUse existing AWS resources\nConfigure the Amplify Libraries to use existing Amazon Pinpoint resources by referencing them in your configuration."
  },
  {
    "title": "Add any AWS service - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAdd any AWS service\nAdd any AWS service\nAnalytics\nLearn how to set Analytics resource powered by Pinpoint\nGeo\nModern, interactive maps with location markers and location search.\nIn-App Messaging\nLearn how to set up In-App Messaging resource powered by Pinpoint\nAPI (REST)\nA straightforward and secure solution for making HTTP requests using REST APIs\nAI/ML Predictions\nLearn how to set up AI/ML Predictions\nInteractions\nAutomate customer workflows by enlisting the help of conversational chatbots powered by deep learning technologies\nPubSub\nThe AWS Amplify PubSub category provides connectivity with cloud-based message-oriented middleware. You can use PubSub to pass messages between your app instances and its backend creating real-time interactive experiences.\nDeletion protection and Backup resources\nLearn how to enable deletion protection and backup on resources.\nCustom resources\nLearn how to write custom resources with the AWS CDK.\nOverriding resources\nLearn how to override resources."
  },
  {
    "title": "Modify Amplify-generated Lambda resources with CDK - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/functions/modify-resources-with-cdk/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nFunctions\n/\nModify Amplify-generated Lambda resources with CDK\nModify Amplify-generated Lambda resources with CDK\n\nAmplify Functions utilize the NodejsFunction construct from the AWS Cloud Development Kit (CDK). The underlying resources can be modified, overridden, or extended using CDK after setting the resource on your backend.\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from '@aws-amplify/backend';\nimport { myFunction } from './functions/my-function';\n\n\nconst backend = defineBackend({\n  myFunction\n})\n\n\n// CDK constructs can be accessed via\nbackend.myFunction.resources\n\n\n// where the Lambda function can be found on\nbackend.myFunction.resources.lambda\n\nThe Lambda resource available is a representation of IFunction.\n\nAdding IAM Policies\n\nTo learn how to add IAM policies to a Function's execution role, visit the documentation for granting access to other resources.\n\nPREVIOUS\nExamples"
  },
  {
    "title": "S3 Upload confirmation - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/functions/examples/s3-upload-confirmation/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nFunctions\n/\nExamples\n/\nS3 Upload confirmation\nS3 Upload confirmation\n\nYou can use defineStorage and defineFunction to create a function trigger to confirm uploading a file.\n\nTo get started, install the @types/aws-lambda package, which contains types for different kinds of Lambda handlers, events, and responses.\n\nTerminal\nCopy\nTerminal code example\nnpm add --save @types/aws-lambda\n\nUpdate your storage definition to define the onUpload trigger as below:\n\namplify/storage/resource.ts\nCopy\namplify/storage/resource.ts code example\nimport { defineFunction, defineStorage } from \"@aws-amplify/backend\";\n\n\nexport const storage = defineStorage({\n  name: 'myProjectFiles',\n  triggers: {\n    onUpload: defineFunction({\n      entry: './on-upload-handler.ts'\n    })\n  }\n});\n\nNext, create a file named amplify/storage/on-upload-handler.ts and use the following code to log the object keys whenever an object is uploaded to the bucket. You can add your custom logic to this function as needed.\n\namplify/storage/on-upload-handler.ts\nCopy\namplify/storage/on-upload-handler.ts code example\nimport type { S3Handler } from 'aws-lambda';\n\n\nexport const handler: S3Handler = async (event) => {\n  const objectKeys = event.Records.map((record) => record.s3.object.key);\n  console.log(`Upload handler invoked for objects [${objectKeys.join(', ')}]`);\n};\n\nNow, when you deploy your backend, this function will be invoked whenever an object is uploaded to the bucket.\n\nPREVIOUS\nDynamoDB Streams"
  },
  {
    "title": "DynamoDB Streams - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/functions/examples/dynamo-db-stream/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nFunctions\n/\nExamples\n/\nDynamoDB Streams\nDynamoDB Streams\n\nWith AWS Lambda, you can seamlessly integrate various event sources, such as Amazon DynamoDB, Amazon SQS, and others, to trigger Lambda functions in response to real-time events. This feature enables you to build responsive, event-driven applications that react to changes in data or system state without the need for polling services.\n\nIn this guide, lets configure a Lambda function with an Amazon DynamoDB stream as an event source. The Lambda function is automatically triggered whenever an item is added, updated, or deleted from the table, enabling you to build real-time applications that react to changes in your data. In this example, we will use a Todo table created by a data model on the GraphQL API.\n\nTo get started, install the AWS Lambda Powertools Logger, which provides structured logging capabilities for your Lambda function, and the aws-lambda package, which is used to define the handler type.\n\nTerminal\nCopy\nTerminal code example\nnpm add --save-dev @aws-lambda-powertools/logger @types/aws-lambda\n\nSecond, create a new directory and a resource file, amplify/functions/dynamoDB-function/resource.ts. Then, define the function with defineFunction:\n\namplify/functions/dynamoDB-function/resource.ts\nCopy\namplify/functions/dynamoDB-function/resource.ts code example\nimport { defineFunction } from \"@aws-amplify/backend\";\n\n\nexport const myDynamoDBFunction = defineFunction({\n  name: \"dynamoDB-function\",\n});\n\nThird, create the corresponding handler file, amplify/functions/dynamoDB-function/handler.ts, file with the following contents:\n\namplify/functions/dynamoDB-function/handler.ts\nCopy\namplify/functions/dynamoDB-function/handler.ts code example\nimport type { DynamoDBStreamHandler } from \"aws-lambda\";\nimport { Logger } from \"@aws-lambda-powertools/logger\";\n\n\nconst logger = new Logger({\n  logLevel: \"INFO\",\n  serviceName: \"dynamodb-stream-handler\",\n});\n\n\nexport const handler: DynamoDBStreamHandler = async (event) => {\n  for (const record of event.Records) {\n    logger.info(`Processing record: ${record.eventID}`);\n    logger.info(`Event Type: ${record.eventName}`);\n\n\n    if (record.eventName === \"INSERT\") {\n      // business logic to process new records\n      logger.info(`New Image: ${JSON.stringify(record.dynamodb?.NewImage)}`);\n    }\n  }\n  logger.info(`Successfully processed ${event.Records.length} records.`);\n  \n  return {\n    batchItemFailures: [],\n  };\n};\n\nLastly, create DynamoDB table as event source in the amplify/backend.ts file:\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { StartingPosition } from \"aws-cdk-lib/aws-lambda\";\nimport { DynamoEventSource } from \"aws-cdk-lib/aws-lambda-event-sources\";\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\nimport { myDynamoDBFunction } from \"./functions/kinesis-function/resource\";\n\n\nconst backend = defineBackend({\n  auth,\n  data,\n  myDynamoDBFunction,\n});\n\n\nconst eventSource = new DynamoEventSource(backend.data.resources.tables[\"Todo\"], {\n  startingPosition: StartingPosition.LATEST,\n});\n\n\nbackend.myDynamoDBFunction.resources.lambda.addEventSource(eventSource);\nPREVIOUS\nAmazon Kinesis Data Streams\nNEXT\nS3 Upload confirmation"
  },
  {
    "title": "Custom message - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/functions/examples/custom-message/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nFunctions\n/\nExamples\n/\nCustom message\nCustom message\n\nYou can use defineAuth and defineFunction to create an Amazon Cognito custom message AWS Lambda trigger thats sends an custom email or phone verification message, or a multi-factor authentication (MFA) code.\n\nTo get started, install @types/aws-lambda package that will be used to define the type of the handler:\n\nTerminal\nCopy\nTerminal code example\nnpm add --save-dev @types/aws-lambda\n\nNext, create a new directory and a resource file, amplify/auth/custom-message/resource.ts. Then, define the function with defineFunction:\n\namplify/auth/custom-message/resource.ts\nCopy\namplify/auth/custom-message/resource.ts code example\nimport { defineFunction } from '@aws-amplify/backend';\n\n\nexport const customMessage = defineFunction({\n  name: \"custom-message\",\n});\n\nNext, create the corresponding handler file, amplify/auth/custom-message/handler.ts, file with the following contents:\n\namplify/auth/custom-message/handler.ts\nCopy\namplify/auth/custom-message/handler.ts code example\nimport type { CustomMessageTriggerHandler } from \"aws-lambda\";\n\n\nexport const handler: CustomMessageTriggerHandler = async (event) => {\n  if (event.triggerSource === \"CustomMessage_ForgotPassword\") {\n    const locale = event.request.userAttributes[\"locale\"];\n    if (locale === \"en\") {\n      event.response.emailMessage = `Your new one-time code is ${event.request.codeParameter}`;\n      event.response.emailSubject = \"Reset my password\";\n    } else if (locale === \"es\") {\n      event.response.emailMessage = `Tu nuevo código de un solo uso es ${event.request.codeParameter}`;\n      event.response.emailSubject = \"Restablecer mi contraseña\";\n    }\n  }\n\n\n  return event;\n};\n\nLastly, set the newly created function resource on your auth resource:\n\namplify/auth/resource.ts\nCopy\namplify/auth/resource.ts code example\nimport { defineAuth } from '@aws-amplify/backend';\nimport { customMessage } from \"./custom-message/resource\";\n\n\nexport const auth = defineAuth({\n  // ...\n  triggers: {\n    customMessage,\n  }\n});\n\nAfter deploying the changes, whenever a user with user attribute locale set to es attempts to reset a password they will receive an email with a one-time code in Spanish.\n\nPREVIOUS\nUser attribute validation\nNEXT\nGoogle reCAPTCHA challenge"
  },
  {
    "title": "Google reCAPTCHA challenge - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/functions/examples/google-recaptcha-challenge/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nFunctions\n/\nExamples\n/\nGoogle reCAPTCHA challenge\nGoogle reCAPTCHA challenge\n\nYou can use defineAuth and defineFunction to create an auth experience that requires a reCAPTCHA v3 token. This can be accomplished by leveraging Amazon Cognito's feature to define a custom auth challenge and 3 triggers:\n\nCreate auth challenge\nDefine auth challenge\nVerify auth challenge response\nCreate auth challenge trigger\n\nTo get started, create the first of the three triggers, create-auth-challenge. This is the trigger responsible for creating the reCAPTCHA challenge after a password is verified.\n\namplify/auth/create-auth-challenge/resource.ts\nCopy\namplify/auth/create-auth-challenge/resource.ts code example\nimport { defineFunction } from \"@aws-amplify/backend\"\n\n\nexport const createAuthChallenge = defineFunction({\n  name: \"create-auth-challenge\",\n})\n\nAfter creating the resource file, create the handler with the following contents:\n\namplify/auth/create-auth-challenge/handler.ts\nCopy\namplify/auth/create-auth-challenge/handler.ts code example\nimport type { CreateAuthChallengeTriggerHandler } from \"aws-lambda\"\n\n\nexport const handler: CreateAuthChallengeTriggerHandler = async (event) => {\n  const { request, response } = event\n\n\n  if (\n    // session will contain 3 \"steps\": SRP, password verification, custom challenge\n    request.session.length === 2 &&\n    request.challengeName === \"CUSTOM_CHALLENGE\"\n  ) {\n    response.publicChallengeParameters = { trigger: \"true\" }\n    response.privateChallengeParameters = { answer: \"\" }\n    // optionally set challenge metadata\n    response.challengeMetadata = \"CAPTCHA_CHALLENGE\"\n  }\n\n\n  return event\n}\nDefine auth challenge trigger\n\nNext, you will want to create the trigger responsible for defining the auth challenge flow, define-auth-challenge.\n\namplify/auth/define-auth-challenge/resource.ts\nCopy\namplify/auth/define-auth-challenge/resource.ts code example\nimport { defineFunction } from \"@aws-amplify/backend\"\n\n\nexport const defineAuthChallenge = defineFunction({\n  name: \"define-auth-challenge\",\n})\n\nAfter creating the resource file, create the handler with the following contents:\n\namplify/auth/define-auth-challenge/handler.ts\nCopy\namplify/auth/define-auth-challenge/handler.ts code example\nimport type { DefineAuthChallengeTriggerHandler } from \"aws-lambda\"\n\n\nexport const handler: DefineAuthChallengeTriggerHandler = async (event) => {\n  const { response } = event\n  const [srp, password, captcha] = event.request.session\n\n\n  // deny by default\n  response.issueTokens = false\n  response.failAuthentication = true\n\n\n  if (srp?.challengeName === \"SRP_A\") {\n    response.failAuthentication = false\n    response.challengeName = \"PASSWORD_VERIFIER\"\n  }\n\n\n  if (\n    password?.challengeName === \"PASSWORD_VERIFIER\" &&\n    password.challengeResult === true\n  ) {\n    response.failAuthentication = false\n    response.challengeName = \"CUSTOM_CHALLENGE\"\n  }\n\n\n  if (\n    captcha?.challengeName === \"CUSTOM_CHALLENGE\" &&\n    // check for the challenge metadata set in \"create-auth-challenge\"\n    captcha?.challengeMetadata === \"CAPTCHA_CHALLENGE\" &&\n    captcha.challengeResult === true\n  ) {\n    response.issueTokens = true\n    response.failAuthentication = false\n  }\n\n\n  return event\n}\nVerify auth challenge response trigger\n\nLastly, create the trigger responsible for verifying the challenge response, which in this case is the reCAPTCHA token verification.\n\nIf you have not done so already, you will need to register your application and retrieve a reCAPTCHA secret key. This can then be configured for use with your cloud sandbox using:\n\nTerminal\nCopy\nTerminal code example\nnpx ampx sandbox secret set GOOGLE_RECAPTCHA_SECRET_KEY\namplify/auth/verify-auth-challenge-response/resource.ts\nCopy\namplify/auth/verify-auth-challenge-response/resource.ts code example\nimport { defineFunction, secret } from \"@aws-amplify/backend\"\n\n\nexport const verifyAuthChallengeResponse = defineFunction({\n  name: \"verify-auth-challenge-response\",\n  environment: {\n    GOOGLE_RECAPTCHA_SECRET_KEY: secret(\"GOOGLE_RECAPTCHA_SECRET_KEY\"),\n  },\n})\n\nAfter creating the resource file, create the handler with the following contents:\n\namplify/auth/verify-auth-challenge-response/handler.ts\nCopy\namplify/auth/verify-auth-challenge-response/handler.ts code example\nimport type { VerifyAuthChallengeResponseTriggerHandler } from \"aws-lambda\"\nimport { env } from \"$amplify/env/verify-auth-challenge-response\"\n\n\n/**\n * Google ReCAPTCHA verification response\n * @see https://developers.google.com/recaptcha/docs/v3#site_verify_response\n */\ntype GoogleRecaptchaVerifyResponse = {\n  // whether this request was a valid reCAPTCHA token for your site\n  success: boolean\n  // the score for this request (0.0 - 1.0)\n  score: number\n  // the action name for this request (important to verify)\n  action: string\n  // timestamp of the challenge load (ISO format yyyy-MM-dd'T'HH:mm:ssZZ)\n  challenge_ts: string\n  // the hostname of the site where the reCAPTCHA was solved\n  hostname: string\n  // optional error codes\n  \"error-codes\"?: unknown[]\n}\n\n\nexport const handler: VerifyAuthChallengeResponseTriggerHandler = async (\n  event\n) => {\n  if (!event.request.challengeAnswer) {\n    throw new Error(\"Missing challenge answer\")\n  }\n\n\n  // https://developers.google.com/recaptcha/docs/verify#api_request\n  const url = new URL(\"https://www.google.com/recaptcha/api/siteverify\")\n  const params = new URLSearchParams({\n    secret: env.GOOGLE_RECAPTCHA_SECRET_KEY,\n    response: event.request.challengeAnswer,\n  })\n  url.search = params.toString()\n\n\n  const request = new Request(url, {\n    method: \"POST\",\n  })\n\n\n  const response = await fetch(request)\n  const result = (await response.json()) as GoogleRecaptchaVerifyResponse\n\n\n  if (!result.success) {\n    throw new Error(\"Verification failed\", { cause: result[\"error-codes\"] })\n  }\n\n\n  // indicate whether the answer is correct\n  event.response.answerCorrect = result.success\n\n\n  return event\n}\nConfigure auth resource\n\nFinally, import and set the three triggers on your auth resource:\n\namplify/auth/resource.ts\nCopy\namplify/auth/resource.ts code example\nimport { defineAuth } from \"@aws-amplify/backend\"\nimport { createAuthChallenge } from \"./create-auth-challenge/resource\"\nimport { defineAuthChallenge } from \"./define-auth-challenge/resource\"\nimport { verifyAuthChallengeResponse } from \"./verify-auth-challenge-response/resource\"\n\n\n/**\n * Define and configure your auth resource\n * @see https://docs.amplify.aws/gen2/build-a-backend/auth\n */\nexport const auth = defineAuth({\n  loginWith: {\n    email: true,\n  },\n  triggers: {\n    createAuthChallenge,\n    defineAuthChallenge,\n    verifyAuthChallengeResponse,\n  },\n})\nPREVIOUS\nCustom message\nNEXT\nAmazon Kinesis Data Streams"
  },
  {
    "title": "Amazon Kinesis Data Streams - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/functions/examples/kinesis-stream/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nFunctions\n/\nExamples\n/\nAmazon Kinesis Data Streams\nAmazon Kinesis Data Streams\n\nWith AWS Lambda, you can seamlessly integrate various event sources, such as Amazon Kinesis, Amazon SQS, and others, to trigger Lambda functions in response to real-time events. This feature enables you to build responsive, event-driven applications that react to changes in data or system state without the need for polling services.\n\nIn this guide, let us configure a Lambda function with a Kinesis data stream as an event source. The Lambda function is automatically triggered whenever new data is published to the stream - whether you're processing streaming data, reacting to application events, or automating workflows.\n\nTo get started, install the AWS Lambda Powertools Logger, which provides structured logging capabilities for your Lambda function, and the aws-lambda package, which is used to define the handler type.\n\nTerminal\nCopy\nTerminal code example\nnpm add @aws-lambda-powertools/logger @types/aws-lambda\n\nSecond, create a new directory and a resource file, amplify/functions/kinesis-function/resource.ts. Then, define the function with defineFunction:\n\namplify/functions/kinesis-function/resource.ts\nCopy\namplify/functions/kinesis-function/resource.ts code example\nimport { defineFunction } from \"@aws-amplify/backend\";\n\n\nexport const myKinesisFunction = defineFunction({\n  name: \"kinesis-function\",\n});\n\nThird, create the corresponding handler file, amplify/functions/kinesis-function/handler.ts, file with the following contents:\n\namplify/functions/kinesis-function/handler.ts\nCopy\namplify/functions/kinesis-function/handler.ts code example\nimport type {\n  KinesisStreamBatchResponse,\n  KinesisStreamHandler,\n  KinesisStreamRecordPayload,\n} from \"aws-lambda\";\nimport { Buffer } from \"node:buffer\";\nimport { Logger } from \"@aws-lambda-powertools/logger\";\n\n\nconst logger = new Logger({\n  logLevel: \"INFO\",\n  serviceName: \"kinesis-stream-handler\",\n});\n\n\nexport const handler: KinesisStreamHandler = async (\n  event,\n  context\n): Promise<KinesisStreamBatchResponse> => {\n  for (const record of event.Records) {\n    try {\n      logger.info(`Processed Kinesis Event - EventID: ${record.eventID}`);\n      const recordData = await getRecordDataAsync(record.kinesis);\n      logger.info(`Record Data: ${recordData}`);\n    } catch (err) {\n      logger.error(`An error occurred ${err}`);\n      /*\n      When processing stream data, if any item fails, returning the failed item's position immediately\n      prompts Lambda to retry from this item forward, ensuring continuous processing without skipping data.\n      */\n      return {\n        batchItemFailures: [{ itemIdentifier: record.kinesis.sequenceNumber }],\n      };\n    }\n  }\n  logger.info(`Successfully processed ${event.Records.length} records.`);\n  return { batchItemFailures: [] };\n};\n\n\nasync function getRecordDataAsync(\n  payload: KinesisStreamRecordPayload\n): Promise<string> {\n  const data = Buffer.from(payload.data, \"base64\").toString(\"utf-8\");\n  await Promise.resolve(1); // Placeholder for an async process\n  return data;\n}\n\nLastly, create the Kinesis stream and add it as a event source in the amplify/backend.ts file:\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { Stream } from \"aws-cdk-lib/aws-kinesis\";\nimport { StartingPosition } from \"aws-cdk-lib/aws-lambda\";\nimport { KinesisEventSource } from \"aws-cdk-lib/aws-lambda-event-sources\";\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\nimport { myKinesisFunction } from \"./functions/kinesis-function/resource\";\n\n\nconst backend = defineBackend({\n  auth,\n  data,\n  myKinesisFunction,\n});\n\n\nconst kinesisStack = backend.createStack(\"kinesis-stack\");\n\n\nconst kinesisStream = new Stream(kinesisStack, \"KinesisStream\", {\n  streamName: \"myKinesisStream\",\n  shardCount: 1,\n});\n\n\nconst eventSource = new KinesisEventSource(kinesisStream, {\n  startingPosition: StartingPosition.LATEST,\n  reportBatchItemFailures: true,\n});\n\n\nbackend.myKinesisFunction.resources.lambda.addEventSource(eventSource);\n\nFor examples on streaming analytics data to the Kinesis stream from your frontend, see the Streaming analytics data documentation.\n\nPREVIOUS\nGoogle reCAPTCHA challenge\nNEXT\nDynamoDB Streams"
  },
  {
    "title": "User attribute validation - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/functions/examples/user-attribute-validation/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nFunctions\n/\nExamples\n/\nUser attribute validation\nUser attribute validation\n\nYou can use defineAuth and defineFunction to create a Cognito pre sign-up Lambda trigger that extends the behavior of sign-up to validate attribute values.\n\nTo get started, create a new directory and a resource file, amplify/auth/pre-sign-up/resource.ts. Then, define the function with defineFunction:\n\namplify/auth/pre-sign-up/resource.ts\nCopy\namplify/auth/pre-sign-up/resource.ts code example\nimport { defineFunction } from '@aws-amplify/backend';\n\n\nexport const preSignUp = defineFunction({\n  name: \"pre-sign-up\"\n});\n\nNext, create the corresponding handler file, amplify/auth/pre-sign-up/handler.ts, file with the following contents:\n\namplify/auth/pre-sign-up/handler.ts\nCopy\namplify/auth/pre-sign-up/handler.ts code example\nimport type { PreSignUpTriggerHandler } from \"aws-lambda\"\n\n\nfunction isOlderThan(date: Date, age: number) {\n  const comparison = new Date()\n  comparison.setFullYear(comparison.getFullYear() - age)\n  return date.getTime() > comparison.getTime()\n}\n\n\nexport const handler: PreSignUpTriggerHandler = async (event) => {\n  const birthdate = new Date(event.request.userAttributes[\"birthdate\"])\n\n\n  // you must be 13 years or older\n  if (!isOlderThan(birthdate, 13)) {\n    throw new Error(\"You must be 13 years or older to use this site\")\n  }\n\n\n  return event\n}\n\nLastly, set the newly created function resource on your auth resource:\n\namplify/auth/resource.ts\nCopy\namplify/auth/resource.ts code example\nimport { defineAuth } from '@aws-amplify/backend';\nimport { preSignUp } from './pre-sign-up/resource';\n\n\nexport const auth = defineAuth({\n  // ...\n  triggers: {\n    preSignUp\n  }\n});\n\nAfter deploying the changes, whenever a user attempts to sign up this handler will verify the submitter's age is above 13 years.\n\nPREVIOUS\nOverride ID token claims\nNEXT\nCustom message"
  },
  {
    "title": "Override ID token claims - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/functions/examples/override-token/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nFunctions\n/\nExamples\n/\nOverride ID token claims\nOverride ID token claims\n\nYou can use defineAuth and defineFunction to create an Amazon Cognito Pre token generation AWS Lambda trigger to override the token by adding a new claim or modifying the user's group membership.\n\nTo get started, install the aws-lambda package, which is used to define the handler type.\n\nTerminal\nCopy\nTerminal code example\nnpm add --save-dev @types/aws-lambda\n\nCreate a new directory and a resource file, amplify/auth/pre-token-generation/resource.ts. Then, define the function with defineFunction:\n\namplify/auth/pre-token-generation/resource.ts\nCopy\namplify/auth/pre-token-generation/resource.ts code example\nimport { defineFunction } from '@aws-amplify/backend';\n\n\nexport const preTokenGeneration = defineFunction({\n  name: 'pre-token-generation',\n});\n\nThen, create the corresponding handler file, amplify/auth/post-confirmation/pre-token-generation/handler.ts, file with the following contents:\n\namplify/auth/pre-token-generation/handler.ts\nCopy\namplify/auth/pre-token-generation/handler.ts code example\nimport type { PreTokenGenerationTriggerHandler } from \"aws-lambda\";\n\n\nexport const handler: PreTokenGenerationTriggerHandler = async (event) => {\n  event.response = {\n    claimsOverrideDetails: {\n      groupOverrideDetails: {\n        // This will add the user to the cognito group \"amplify_group_1\" \n        groupsToOverride: [\"amplify_group_1\"],\n      },\n      claimsToAddOrOverride: {\n        // This will add the custom claim \"amplfy_attribute\" to the id token\n        amplfy_attribute: \"amplify_gen_2\",\n      },\n    },\n  };\n  return event;\n};\n\nLastly, set the newly created function resource on your auth resource:\n\namplify/auth/resource.ts\nCopy\namplify/auth/resource.ts code example\nimport { defineAuth } from '@aws-amplify/backend';\nimport { preTokenGeneration } from './pre-token-generation/resource';\n\n\nexport const auth = defineAuth({\n  loginWith: {\n    email: true,\n  },\n  triggers: {\n    preTokenGeneration\n  }\n});\n\nAfter deploying the changes, The idToken of the user will be modified as per the trigger above.\n\nCopy\ncode example\n{\n  \"cognito:groups\": [\n    \"amplify_group_1\"\n  ],\n  \"email_verified\": true,\n  \"iss\": \"...\",\n  \"cognito:username\": \"...\",\n  \"origin_jti\": \"...\",\n  \"amplfy_attribute\": \"amplify_gen_2\",\n  \"aud\": \"...\",\n}\nPREVIOUS\nCreate a user profile record\nNEXT\nUser attribute validation"
  },
  {
    "title": "Create a user profile record - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/functions/examples/create-user-profile-record/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nFunctions\n/\nExamples\n/\nCreate a user profile record\nCreate a user profile record\n\nYou can use defineAuth and defineFunction to create a Cognito post confirmation Lambda trigger to create a profile record when a user is confirmed.\n\nA user is \"confirmed\" when they verify their account. Typically this happens when the user confirms their email via the verification email. The post confirmation handler will not be triggered for federated sign-ins (i.e. social sign-in).\n\nTo get started, install the aws-lambda package, which is used to define the handler type.\n\nTerminal\nCopy\nTerminal code example\nnpm add --save-dev @types/aws-lambda\n\nUpdate the amplify/data/resource.ts file to define a data model for the user's profile:\n\nMake sure to configure the authorization rule to allow the postConfirmation resource as highlighted below. Granting access to resources creates environment variables for your Function such as the GraphQL API endpoint. To learn more visit the environment variables and secrets documentation for Functions.\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\nimport { type ClientSchema, a, defineData } from \"@aws-amplify/backend\";\nimport { postConfirmation } from \"../auth/post-confirmation/resource\";\n\n\nconst schema = a\n  .schema({\n    UserProfile: a\n      .model({\n        email: a.string(),\n        profileOwner: a.string(),\n      })\n      .authorization((allow) => [\n        allow.ownerDefinedIn(\"profileOwner\"),\n      ]),\n  })\n  .authorization((allow) => [allow.resource(postConfirmation)]);\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    defaultAuthorizationMode: \"apiKey\",\n    apiKeyAuthorizationMode: {\n      expiresInDays: 30,\n    },\n  },\n});\n\nCreate a new directory and a resource file, amplify/auth/post-confirmation/resource.ts. Then, define the Function with defineFunction:\n\namplify/auth/post-confirmation/resource.ts\nCopy\namplify/auth/post-confirmation/resource.ts code example\nimport { defineFunction } from '@aws-amplify/backend';\n\n\nexport const postConfirmation = defineFunction({\n  name: 'post-confirmation',\n});\n\nRun the command npx ampx sandbox to create the backend, then use the command below to generate GraphQL client code to call your data backend.\n\nNote: We are working on bringing the end-to-end typed experience to connect to your data from within function resources without needing this step. If you'd like to provide feedback on the experience or want to have early access, join our Discord community.\n\nTerminal\nCopy\nTerminal code example\nnpx ampx generate graphql-client-code --out <path-to-post-confirmation-handler-dir>/graphql\n\nThen, create the corresponding handler file, amplify/auth/post-confirmation/handler.ts, file with the following contents:\n\namplify/auth/post-confirmation/handler.ts\nCopy\namplify/auth/post-confirmation/handler.ts code example\nimport type { PostConfirmationTriggerHandler } from \"aws-lambda\";\nimport { type Schema } from \"../../data/resource\";\nimport { Amplify } from \"aws-amplify\";\nimport { generateClient } from \"aws-amplify/data\";\nimport { env } from \"$amplify/env/post-confirmation\";\nimport { createUserProfile } from \"./graphql/mutations\";\n\n\nAmplify.configure(\n  {\n    API: {\n      GraphQL: {\n        endpoint: env.AMPLIFY_DATA_GRAPHQL_ENDPOINT,\n        region: env.AWS_REGION,\n        defaultAuthMode: \"iam\",\n      },\n    },\n  },\n  {\n    Auth: {\n      credentialsProvider: {\n        getCredentialsAndIdentityId: async () => ({\n          credentials: {\n            accessKeyId: env.AWS_ACCESS_KEY_ID,\n            secretAccessKey: env.AWS_SECRET_ACCESS_KEY,\n            sessionToken: env.AWS_SESSION_TOKEN,\n          },\n        }),\n        clearCredentialsAndIdentityId: () => {\n          /* noop */\n        },\n      },\n    },\n  }\n);\n\n\nconst client = generateClient<Schema>({\n  authMode: \"iam\",\n});\n\n\nexport const handler: PostConfirmationTriggerHandler = async (event) => {\n  await client.graphql({\n    query: createUserProfile,\n    variables: {\n      input: {\n        email: event.request.userAttributes.email,\n        profileOwner: `${event.request.userAttributes.sub}::${event.userName}`,\n      },\n    },\n  });\n\n\n  return event;\n};\n\nLastly, set the newly created Function resource on your auth resource:\n\namplify/auth/resource.ts\nCopy\namplify/auth/resource.ts code example\nimport { defineAuth } from '@aws-amplify/backend';\nimport { postConfirmation } from './post-confirmation/resource';\n\n\nexport const auth = defineAuth({\n  loginWith: {\n    email: true,\n  },\n  triggers: {\n    postConfirmation\n  }\n});\n\nAfter deploying the changes, whenever a user signs up and verifies their account a profile record is automatically created.\n\nPREVIOUS\nAdd user to group\nNEXT\nOverride ID token claims"
  },
  {
    "title": "Add user to group - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/functions/examples/add-user-to-group/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nFunctions\n/\nExamples\n/\nAdd user to group\nAdd user to group\n\nYou can use defineAuth and defineFunction to create a Cognito post confirmation Lambda trigger that extends the behavior to perform some action when a user is confirmed.\n\nA user is \"confirmed\" when they verify their account. Typically this happens when the user confirms their email via the verification email. The post confirmation handler will not be triggered for federated sign-ins (i.e. social sign-in).\n\nTo get started, install the AWS SDK v3 package, which will be used to perform actions against your auth resource, and the @types/aws-lambda package, which is used to define the handler type:\n\nTerminal\nCopy\nTerminal code example\nnpm add --save-dev @aws-sdk/client-cognito-identity-provider @types/aws-lambda\n\nNext, create a new directory and a resource file, amplify/auth/post-confirmation/resource.ts. Then, define the Function with defineFunction:\n\namplify/auth/post-confirmation/resource.ts\nCopy\namplify/auth/post-confirmation/resource.ts code example\nimport { defineFunction } from '@aws-amplify/backend';\n\n\nexport const postConfirmation = defineFunction({\n  name: 'post-confirmation',\n  // optionally define an environment variable for your group name\n  environment: {\n    GROUP_NAME: 'EVERYONE'\n  }\n});\n\nAfter creating the Function definition you will need to:\n\ncreate the EVERYONE group\ngrant access to your auth resource to ensure it can perform the addUserToGroup action\nset the Function as the post confirmation trigger\namplify/auth/resource.ts\nCopy\namplify/auth/resource.ts code example\nimport { defineAuth } from \"@aws-amplify/backend\";\nimport { postConfirmation } from \"./post-confirmation/resource\"\n\n\nexport const auth = defineAuth({\n  loginWith: {\n    email: true,\n  },\n  groups: [\"EVERYONE\"],\n  triggers: {\n    postConfirmation,\n  },\n  access: (allow) => [\n    allow.resource(postConfirmation).to([\"addUserToGroup\"]),\n  ],\n})\n\nThen create the Function's corresponding handler file, amplify/auth/post-confirmation/handler.ts, file with the following contents:\n\namplify/auth/post-confirmation/handler.ts\nCopy\namplify/auth/post-confirmation/handler.ts code example\nimport type { PostConfirmationTriggerHandler } from 'aws-lambda';\nimport {\n  CognitoIdentityProviderClient,\n  AdminAddUserToGroupCommand\n} from '@aws-sdk/client-cognito-identity-provider';\nimport { env } from '$amplify/env/post-confirmation';\n\n\nconst client = new CognitoIdentityProviderClient();\n\n\n// add user to group\nexport const handler: PostConfirmationTriggerHandler = async (event) => {\n  const command = new AdminAddUserToGroupCommand({\n    GroupName: env.GROUP_NAME,\n    Username: event.userName,\n    UserPoolId: event.userPoolId\n  });\n  const response = await client.send(command);\n  console.log('processed', response.$metadata.requestId);\n  return event;\n};\n\nAfter deploying the changes, whenever a user signs up and verifies their account they are automatically added to the group named \"EVERYONE\".\n\nPREVIOUS\nEmail domain filtering\nNEXT\nCreate a user profile record"
  },
  {
    "title": "Email domain filtering - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/functions/examples/email-domain-filtering/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nFunctions\n/\nExamples\n/\nEmail domain filtering\nEmail domain filtering\n\nYou can use defineAuth and defineFunction to create a Cognito pre sign-up Lambda trigger that performs filtering based on the user's email address. This can allow or deny user signups based on their email address.\n\nTo get started, install the aws-lambda package, which is used to define the handler type.\n\nTerminal\nCopy\nTerminal code example\nnpm add --save-dev @types/aws-lambda\n\nNext, create a new directory and a resource file, amplify/auth/pre-sign-up/resource.ts. Then, define the Function with defineFunction:\n\namplify/auth/pre-sign-up/resource.ts\nCopy\namplify/auth/pre-sign-up/resource.ts code example\nimport { defineFunction } from '@aws-amplify/backend';\n\n\nexport const preSignUp = defineFunction({\n  name: 'pre-sign-up',\n  // optionally define an environment variable for your filter\n  environment: {\n    ALLOW_DOMAIN: 'amazon.com'\n  }\n});\n\nNext, create the corresponding handler file, amplify/auth/pre-sign-up/handler.ts, file with the following contents:\n\namplify/auth/pre-sign-up/handler.ts\nCopy\namplify/auth/pre-sign-up/handler.ts code example\nimport type { PreSignUpTriggerHandler } from 'aws-lambda';\nimport { env } from '$amplify/env/pre-sign-up';\n\n\nexport const handler: PreSignUpTriggerHandler = async (event) => {\n  const email = event.request.userAttributes['email'];\n\n\n  if (!email.endsWith(env.ALLOW_DOMAIN)) {\n    throw new Error('Invalid email domain');\n  }\n\n\n  return event;\n};\n\nLastly, set the newly created Function resource on your auth resource:\n\namplify/auth/resource.ts\nCopy\namplify/auth/resource.ts code example\nimport { defineAuth } from '@aws-amplify/backend';\nimport { preSignUp } from './pre-sign-up/resource';\n\n\nexport const auth = defineAuth({\n  // ...\n  triggers: {\n    preSignUp\n  }\n});\n\nAfter deploying the changes, whenever a user attempts to sign up without an amazon.com email address they will receive an error.\n\nNEXT\nAdd user to group"
  },
  {
    "title": "Grant access to other resources - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/functions/grant-access-to-other-resources/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nFunctions\n/\nGrant access to other resources\nGrant access to other resources\n\nIn order for Amplify Functions to interact with other resources they must be given access. There are two ways to grant Amplify Functions access to other resources:\n\nUsing the access property\nUsing the AWS Cloud Development Kit (CDK)\nUsing the access property\n\nThe access property is a property found in each of the define* functions for defining Amplify resources. It allows you specify the necessary actions using common language.\n\nWhen you grant a function access to another resource in your Amplify backend (such as granting access to storage), it will configure environment variables for that function to make SDK calls to the AWS services it has access to. Those environment variables are typed and available as part of the env object.\n\nSay you have a function that generates reports each month from your Data resource and needs to store the generated reports in Storage:\n\namplify/storage/resource.ts\nCopy\namplify/storage/resource.ts code example\nimport { defineStorage } from '@aws-amplify/backend';\nimport { generateMonthlyReports } from '../functions/generate-monthly-reports/resource';\n\n\nexport const storage = defineStorage({\n  name: 'myReports',\n  access: (allow) => ({\n    'reports/*': [\n      allow.resource(generateMonthlyReports).to(['read', 'write', 'delete'])\n    ]\n  })\n});\n\nThis access definition will add the environment variable myReports_BUCKET_NAME to the function. This environment variable can be accessed on the env object.\n\nHere's an example of how it can be used to upload some content to S3.\n\namplify/functions/generate-monthly-reports/handler.ts\nCopy\namplify/functions/generate-monthly-reports/handler.ts code example\nimport { S3Client, PutObjectCommand } from '@aws-sdk/client-s3';\nimport { env } from '$amplify/env/generate-monthly-reports';\n\n\nconst s3Client = new S3Client();\n\n\nexport const handler = async () => {\n  const command = new PutObjectCommand({\n    Bucket: env.myReports_BUCKET_NAME,\n    Key: `reports/${new Date().toISOString()}.csv`,\n    Body: new Blob([''], { type: 'text/csv;charset=utf-8;' })\n  });\n\n\n  await s3Client.send(command);\n};\nUsing CDK\n\nWhen permissions are needed to access resources beyond the capabilities of the access property, you must use CDK.\n\nFunctions are created with an execution role, which is an IAM role that contains policies that dictate what resources your Function can interact with when it executes. This role can be extended using the addToRolePolicy() method:\n\namplify/backend.ts\nimport { defineBackend } from \"@aws-amplify/backend\"\nimport * as iam from \"aws-cdk-lib/aws-iam\"\nimport * as sns from \"aws-cdk-lib/aws-sns\"\nimport { weeklyDigest } from \"./functions/weekly-digest/resource\"\n\n\nconst backend = defineBackend({\n  weeklyDigest,\n})\n\n\nconst weeklyDigestLambda = backend.weeklyDigest.resources.lambda\n\n\nconst topicStack = backend.createStack(\"WeeklyDigest\")\nconst topic = new sns.Topic(topicStack, \"Topic\", {\n  displayName: \"digest\",\n})\n\n\nCopy\nhighlighted code example\nconst statement = new iam.PolicyStatement({\n  sid: \"AllowPublishToDigest\",\n  actions: [\"sns:Publish\"],\n  resources: [topic.topicArn],\n})\n\n\nweeklyDigestLambda.addToRolePolicy(statement)\n\nHowever some constructs provide a grant* method to grant access to common policy actions. Revisiting the example above you can grant the same access with grantPublish:\n\namplify/backend.ts\nimport { defineBackend } from \"@aws-amplify/backend\"\nimport * as iam from \"aws-cdk-lib/aws-iam\"\nimport * as sns from \"aws-cdk-lib/aws-sns\"\nimport { weeklyDigest } from \"./functions/weekly-digest/resource\"\n\n\nconst backend = defineBackend({\n  weeklyDigest,\n})\n\n\nconst weeklyDigestLambda = backend.weeklyDigest.resources.lambda\n\n\nconst topicStack = backend.createStack(\"WeeklyDigest\")\nconst topic = new sns.Topic(topicStack, \"Topic\", {\n  displayName: \"digest\"\n})\n\n\nCopy\nhighlighted code example\ntopic.grantPublish(weeklyDigestLambda)\nPREVIOUS\nStreaming logs\nNEXT\nExamples"
  },
  {
    "title": "Examples - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/functions/examples/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nFunctions\n/\nExamples\nExamples\nEmail domain filtering\nUse an Auth Pre Signup trigger to allow or deny sign-ups based on email domains\nAdd user to group\nUse an Auth Post Authentication trigger to automatically add new users to a group\nCreate a user profile record\nUse an Auth Post Authentication trigger to automatically a user profile record\nOverride ID token claims\nUse an Auth Pre token generation trigger to override ID token claims\nUser attribute validation\nValidate user attributes with an Auth trigger\nCustom message\nUse an Auth custom message authentication trigger to customize the message sent to users\nGoogle reCAPTCHA challenge\nLeverage Google reCAPTCHA to protect against spam\nAmazon Kinesis Data Streams\nCreate a Lambda event source for a Amazon Kinesis Data Stream to trigger Lambda functions in response to real-time events\nDynamoDB Streams\nCreate a Lambda event source using Amazon DynamoDB Streams to trigger a Lambda function in response to real-time events.\nS3 Upload confirmation\nUse a trigger to confirm uploading files"
  },
  {
    "title": "Streaming logs - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/functions/streaming-logs/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nFunctions\n/\nStreaming logs\nStreaming logs\n\nAmplify enables you to stream logs from your Function directly to your terminal while running ampx sandbox. To get started, specify the --stream-function-logs option when starting sandbox:\n\nTerminal\nCopy\nTerminal code example\nnpx ampx sandbox --stream-function-logs\n\nNote: this feature is only available for Sandbox\n\nStreaming Function logs directly to your terminal enable faster debug iterations, and greater insight into your Functions' executions.\n\nFiltering\n\nBy default, Amplify will stream all of your Functions' logs. If you wish to only stream a subset of Functions you can specify a filter by Function name or a regular expression for Function names. For example, if you have a collection of Auth triggers where the Function names include \"auth\"\n\nTerminal\nCopy\nTerminal code example\nnpx ampx sandbox --stream-function-logs --logs-filter auth\n\nAfter you successfully deploy your personal cloud sandbox, start your frontend application, and sign up for the first time, you will see logs from your triggers' executions printed to the terminal where sandbox is running.\n\nTerminal\n> npx ampx sandbox --stream-function-logs --logs-filter auth\n...\n\n\n✨  Total time: 158.44s\n\n\n[Sandbox] Watching for file changes...\nFile written: amplify_outputs.json\n[auth-pre-sign-up] 3:36:34 PM INIT_START Runtime Version: nodejs:18.v30\tRuntime Version ARN: arn:aws:lambda:us-east-1::runtime:f89c264158db39a1cfcbb5f9b3741413df1cfce4d550c9a475a67d923e19e2f4\n[auth-pre-sign-up] 3:36:34 PM START RequestId: 685be2bd-5df1-4dd5-9eb1-24f5f6337f91 Version: $LATEST\n[auth-pre-sign-up] 3:36:34 PM END RequestId: 685be2bd-5df1-4dd5-9eb1-24f5f6337f91\n[auth-pre-sign-up] 3:36:34 PM REPORT RequestId: 685be2bd-5df1-4dd5-9eb1-24f5f6337f91\tDuration: 4.12 ms\tBilled Duration: 5 ms\tMemory Size: 512 MB\tMax Memory Used: 67 MB\tInit Duration: 173.67 ms\n[auth-post-confirmation] 3:38:40 PM INIT_START Runtime Version: nodejs:18.v30\tRuntime Version ARN: arn:aws:lambda:us-east-1::runtime:f89c264158db39a1cfcbb5f9b3741413df1cfce4d550c9a475a67d923e19e2f4\n[auth-post-confirmation] 3:38:40 PM START RequestId: fce69b9f-b257-4af8-8a6e-821f84a39ce7 Version: $LATEST\n[auth-post-confirmation] 3:38:41 PM 2024-07-19T22:38:41.209Z\tfce69b9f-b257-4af8-8a6e-821f84a39ce7\tINFO\tprocessed 412f8911-acfa-41c7-9605-fa0c40891ea9\n[auth-post-confirmation] 3:38:41 PM END RequestId: fce69b9f-b257-4af8-8a6e-821f84a39ce7\n[auth-post-confirmation] 3:38:41 PM REPORT RequestId: fce69b9f-b257-4af8-8a6e-821f84a39ce7\tDuration: 264.38 ms\tBilled Duration: 265 ms\tMemory Size: 512 MB\tMax Memory Used: 93 MB\tInit Duration: 562.19 ms\n[auth-pre-authentication] 3:38:41 PM INIT_START Runtime Version: nodejs:18.v30\tRuntime Version ARN: arn:aws:lambda:us-east-1::runtime:f89c264158db39a1cfcbb5f9b3741413df1cfce4d550c9a475a67d923e19e2f4\n[auth-pre-authentication] 3:38:41 PM START RequestId: 9210ca3a-1351-4826-8544-123684765710 Version: $LATEST\n[auth-pre-authentication] 3:38:41 PM END RequestId: 9210ca3a-1351-4826-8544-123684765710\n[auth-pre-authentication] 3:38:41 PM REPORT RequestId: 9210ca3a-1351-4826-8544-123684765710\tDuration: 3.47 ms\tBilled Duration: 4 ms\tMemory Size: 512 MB\tMax Memory Used: 67 MB\tInit Duration: 180.24 ms\n[auth-post-authentication] 3:38:42 PM INIT_START Runtime Version: nodejs:18.v30\tRuntime Version ARN: arn:aws:lambda:us-east-1::runtime:f89c264158db39a1cfcbb5f9b3741413df1cfce4d550c9a475a67d923e19e2f4\n[auth-post-authentication] 3:38:42 PM START RequestId: 60c1d680-ea24-4a8b-93de-02d085859140 Version: $LATEST\n[auth-post-authentication] 3:38:42 PM END RequestId: 60c1d680-ea24-4a8b-93de-02d085859140\n[auth-post-authentication] 3:38:42 PM REPORT RequestId: 60c1d680-ea24-4a8b-93de-02d085859140\tDuration: 4.61 ms\tBilled Duration: 5 ms\tMemory Size: 512 MB\tMax Memory Used: 68 MB\tInit Duration: 172.66 ms\nWriting to a file\n\nBy default, Amplify will print logs to the terminal where sandbox is running, however you can alternatively write logs to a file by specifying --logs-out-file:\n\nTerminal\nCopy\nTerminal code example\nnpx ampx sandbox --stream-function-logs --logs-out-file sandbox.log\n\nThis can be combined with --logs-filter to create a log file of just your Auth-related Functions, for example:\n\nTerminal\nCopy\nTerminal code example\nnpx ampx sandbox --stream-function-logs --logs-filter auth --logs-out-file sandbox-auth.log\n\nHowever it cannot be combined multiple times to write logs to multiple files.\n\nPREVIOUS\nScheduling Functions\nNEXT\nGrant access to other resources"
  },
  {
    "title": "Scheduling Functions - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/functions/scheduling-functions/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nFunctions\n/\nScheduling Functions\nScheduling Functions\n\nAmplify offers the ability to schedule Functions to run on specific intervals using natural language or cron expressions. To get started, specify the schedule property in defineFunction:\n\namplify/jobs/weekly-digest/resource.ts\nCopy\namplify/jobs/weekly-digest/resource.ts code example\nimport { defineFunction } from \"@aws-amplify/backend\";\n\n\nexport const weeklyDigest = defineFunction({\n  name: \"weekly-digest\",\n  schedule: \"every week\",\n});\n\nFunction schedules are powered by Amazon EventBridge rules, and can be leveraged to address use cases such as:\n\ngenerating a \"front page\" of top-performing posts\ngenerating a weekly digest of top-performing posts\ngenerating a monthly report of warehouse inventory\n\nTheir handlers can be typed using the EventBridgeHandler type:\n\namplify/jobs/weekly-digest/handler.ts\nCopy\namplify/jobs/weekly-digest/handler.ts code example\nimport type { EventBridgeHandler } from \"aws-lambda\";\n\n\nexport const handler: EventBridgeHandler = async (event) => {\n  console.log(\"event\", JSON.stringify(event, null, 2))\n}\n\nNote: AWS Lambda types can be installed with\n\nTerminal\nCopy\nTerminal code example\nnpm install --save-dev @types/aws-lambda\n\nSchedules can either be a single interval, or multiple intervals:\n\namplify/jobs/generate-report/resource.ts\nCopy\namplify/jobs/generate-report/resource.ts code example\nimport { defineFunction } from \"@aws-amplify/backend\";\n\n\nexport const generateReport = defineFunction({\n  name: \"generate-report\",\n  schedule: [\"every week\", \"every month\", \"every year\"],\n});\n\nSchedules can also be defined to execute using minutes or hours with a shorthand syntax:\n\namplify/jobs/drink-some-water/resource.ts\nCopy\namplify/jobs/drink-some-water/resource.ts code example\nimport { defineFunction } from \"@aws-amplify/backend\";\n\n\nexport const drinkSomeWater = defineFunction({\n  name: \"drink-some-water\",\n  schedule: \"every 1h\"\n})\n\nOr combined to create complex schedules:\n\namplify/jobs/remind-me/resource.ts\nCopy\namplify/jobs/remind-me/resource.ts code example\nimport { defineFunction } from \"@aws-amplify/backend\";\n\n\nexport const remindMe = defineFunction({\n  name: \"remind-me\",\n  schedule: [\n    // every sunday at midnight\n    \"every week\",\n    // every tuesday at 5pm\n    \"0 17 * * 2\",\n    // every wednesday at 5pm\n    \"0 17 * * 3\",\n    // every thursday at 5pm\n    \"0 17 * * 4\",\n    // every friday at 5pm\n    \"0 17 * * 5\",\n  ]\n})\nUsing natural language\n\nSchedules can be written using natural language, using terms you use every day. Amplify supports the following time periods:\n\nday will always start at midnight\nweek will always start on Sunday at midnight\nmonth will always start on the first of the month at midnight\nyear will always start on the first of the year at midnight\nm for minutes\nh for hours\n\nNatural language expressions are prefixed with \"every\":\n\namplify/jobs/drink-some-water/resource.ts\nCopy\namplify/jobs/drink-some-water/resource.ts code example\nimport { defineFunction } from \"@aws-amplify/backend\";\n\n\nexport const drinkSomeWater = defineFunction({\n  name: \"drink-some-water\",\n  schedule: \"every 1h\"\n})\nUsing cron expressions\n\nSchedules can be written using cron expressions.\n\namplify/jobs/remind-me/resource.ts\nCopy\namplify/jobs/remind-me/resource.ts code example\nimport { defineFunction } from \"@aws-amplify/backend\";\n\n\nexport const remindMe = defineFunction({\n  name: \"remind-me-to-take-the-trash-out\",\n  schedule: [\n    // every tuesday at 9am\n    \"0 9 * * 2\",\n    // every friday at 9am\n    \"0 9 * * 5\",\n  ]\n})\nPREVIOUS\nConfigure Functions\nNEXT\nStreaming logs"
  },
  {
    "title": "Configure Functions - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/functions/configure-functions/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nFunctions\n/\nConfigure Functions\nConfigure Functions\n\ndefineFunction comes out-of-the-box with sensible but minimal defaults. The following options are provided to tweak the function configuration.\n\nname\n\nBy default, functions are named based on the directory the defineFunction call is placed in. In the above example, defining the function in amplify/functions/my-demo-function/resource.ts will cause the function to be named my-demo-function by default.\n\nIf an entry is specified, then the name defaults to the basename of the entry path. For example, an entry of ./signup-trigger-handler.ts would cause the function name to default to signup-trigger-handler.\n\nThis optional property can be used to explicitly set the name of the function.\n\namplify/functions/my-demo-function/resource.ts\nCopy\namplify/functions/my-demo-function/resource.ts code example\nexport const myDemoFunction = defineFunction({\n  entry: './demo-function-handler.ts',\n  name: 'overrideName' // explicitly set the name to override the default naming behavior\n});\ntimeoutSeconds\n\nBy default, functions will time out after 3 seconds. This can be configured to any whole number of seconds up to 15 minutes.\n\namplify/functions/my-demo-function/resource.ts\nexport const myDemoFunction = defineFunction({\nCopy\nhighlighted code example\n  timeoutSeconds: 60 // 1 minute timeout\n});\nmemoryMB\n\nBy default, functions have 512 MB of memory allocated to them. This can be configured from 128 MB up to 10240 MB. Note that this can increase the cost of function invocation. For more pricing information see here.\n\namplify/functions/my-demo-function/resource.ts\nexport const myDemoFunction = defineFunction({\nCopy\nhighlighted code example\n  memoryMB: 256 // allocate 256 MB of memory to the function.\n});\nruntime\n\nCurrently, only Node runtimes are supported by defineFunction. However, you can change the Node version that is used by the function. The default is the oldest Node LTS version that is supported by AWS Lambda (currently Node 18).\n\nIf you wish to use an older version of Node, keep an eye on the Lambda Node version deprecation schedule. As Lambda removes support for old Node versions, you will have to update to newer supported versions.\n\namplify/functions/my-demo-function/resource.ts\nCopy\namplify/functions/my-demo-function/resource.ts code example\nexport const myDemoFunction = defineFunction({\n  runtime: 20 // use Node 20\n});\nentry\n\nBy default, Amplify will look for your function handler in a file called handler.ts in the same directory as the file where defineFunction is called. To point to a different handler location, specify an entry value.\n\namplify/functions/my-demo-function/resource.ts\nCopy\namplify/functions/my-demo-function/resource.ts code example\nexport const myDemoFunction = defineFunction({\n  entry: './path/to/handler.ts' // this path should either be absolute or relative to the current file\n});\nPREVIOUS\nEnvironment variables and secrets\nNEXT\nScheduling Functions"
  },
  {
    "title": "Environment variables and secrets - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/functions/environment-variables-and-secrets/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nFunctions\n/\nEnvironment variables and secrets\nEnvironment variables and secrets\n\nAmplify Functions support setting environment variables and secrets on the environment property of defineFunction.\n\nNote: do not store secret values in environment variables. Environment variables values are rendered in plaintext to the build artifacts located at .amplify/artifacts and may be emitted to CloudFormation stack event messages. To store secrets skip to the secrets section\n\nEnvironment variables\n\nEnvironment variables can be configured in defineFunction using the environment property.\n\namplify/functions/say-hello/resource.ts\nCopy\namplify/functions/say-hello/resource.ts code example\nimport { defineFunction } from '@aws-amplify/backend';\n\n\nexport const sayHello = defineFunction({\n  environment: {\n    NAME: 'World'\n  }\n});\n\nAny environment variables specified here will be available to the function at runtime.\n\nSome environment variables are constant across all branches and deployments. But many environment values differ between deployment environments. Branch-specific environment variables can be configured for Amplify hosting deployments.\n\nSuppose you created a branch-specific environment variable in hosting called \"API_ENDPOINT\" which had a different value for your \"staging\" vs \"prod\" branch. If you wanted that value to be available to your function you can pass it to the function using\n\namplify/functions/say-hello/resource.ts\nCopy\namplify/functions/say-hello/resource.ts code example\nexport const sayHello = defineFunction({\n  environment: {\n    NAME: \"World\",\n    API_ENDPOINT: process.env.API_ENDPOINT\n  }\n});\nAccessing environment variables\n\nWithin your function handler, you can access environment variables using the normal process.env global object provided by the Node runtime. However, this does not make it easy to discover what environment variables will be available at runtime. Amplify generates an env symbol that can be used in your function handler and provides typings for all variables that will be available at runtime. Copy the following code to use it.\n\namplify/functions/say-hello/handler.ts\nCopy\nhighlighted code example\nimport { env } from '$amplify/env/say-hello'; // the import is '$amplify/env/<function name>'\n\n\nexport const handler = async (event) => {\n  // the env object has intellisense for all environment variables that are available to the function\n  return `Hello, ${env.NAME}!`;\n};\nLearn more\nUnderstanding the \"env\" symbol and how to manually configure your Amplify project to use it\nSecrets\n\nSometimes it is necessary to provide a secret value to a function. For example, it may need a database password or an API key to perform some business use case. Environment variables should NOT be used for this because environment variable values are included in plaintext in the function configuration. Instead, secret access can be used.\n\nBefore using a secret in a function, you need to define a secret. After you have defined a secret, you can reference it in your function config.\n\namplify/functions/say-hello/resource.ts\nCopy\namplify/functions/say-hello/resource.ts code example\nimport { defineFunction, secret } from '@aws-amplify/backend';\n\n\nexport const sayHello = defineFunction({\n  environment: {\n    NAME: \"World\",\n    API_ENDPOINT: process.env.API_ENDPOINT,\n    API_KEY: secret('MY_API_KEY') // this assumes you created a secret named \"MY_API_KEY\"\n  }\n});\n\nYou can use this secret value at runtime in your function the same as any other environment variable. However, you will notice that the value of the environment variable is not stored as part of the function configuration. Instead, the value is fetched when your function runs and is provided in memory.\n\namplify/functions/say-hello/handler.ts\nCopy\namplify/functions/say-hello/handler.ts code example\nimport { env } from '$amplify/env/say-hello';\n\n\nexport const handler = async (event) => {\n  const request = new Request(env.API_ENDPOINT, {\n    headers: {\n      // this is the value of secret named \"MY_API_KEY\"\n      Authorization: `Bearer ${env.API_KEY}`\n    }\n  })\n  // ...\n  return `Hello, ${env.NAME}!`;\n};\nPREVIOUS\nSet up a Function\nNEXT\nConfigure Functions"
  },
  {
    "title": "Set up a Function - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/functions/set-up-function/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nFunctions\n/\nSet up a Function\nSet up a Function\n\nAmplify Functions are powered by AWS Lambda, and allow you to perform a wide variety of customization through self-contained functions. Functions can respond to events from other resources, execute some logic in-between events like an authentication flow, or act as standalone jobs. They are used in a variety of settings and use cases:\n\nAuthentication flow customizations (e.g. attribute validations, allowlisting email domains)\nResolvers for GraphQL APIs\nHandlers for individual REST API routes, or to host an entire API\nScheduled jobs\n\nTo get started, create a new directory and a resource file, amplify/functions/say-hello/resource.ts. Then, define the Function with defineFunction:\n\namplify/functions/say-hello/resource.ts\nCopy\namplify/functions/say-hello/resource.ts code example\nimport { defineFunction } from '@aws-amplify/backend';\n\n\nexport const sayHello = defineFunction({\n  // optionally specify a name for the Function (defaults to directory name)\n  name: 'say-hello',\n  // optionally specify a path to your handler (defaults to \"./handler.ts\")\n  entry: './handler.ts'\n});\n\nNext, create the corresponding handler file at amplify/functions/say-hello/handler.ts. This is where your function code will go.\n\namplify/functions/say-hello/handler.ts\nCopy\namplify/functions/say-hello/handler.ts code example\nimport type { Handler } from 'aws-lambda';\n\n\nexport const handler: Handler = async (event, context) => {\n  // your function code goes here\n  return 'Hello, World!';\n};\n\nThe handler file must export a function named \"handler\". This is the entry point to your function. For more information on writing functions, refer to the AWS documentation for Lambda function handlers using Node.js.\n\nLastly, this function needs to be added to your backend.\n\namplify/backend.ts\nimport { defineBackend } from '@aws-amplify/backend';\nCopy\nhighlighted code example\nimport { sayHello } from './functions/say-hello/resource';\n\n\ndefineBackend({\nCopy\nhighlighted code example\n  sayHello\n});\n\nNow when you run npx ampx sandbox or deploy your app on Amplify, it will include your Function.\n\nTo invoke your Function, we recommend adding your Function as a handler for a custom query with your Amplify Data resource. This will enable you to strongly type Function arguments and the return statement, and use this to author your Function's business logic. To get started, open your amplify/data/resource.ts file and specify a new query in your schema:\n\namplify/data/resource.ts\nimport { type ClientSchema, a, defineData } from \"@aws-amplify/backend\"\nimport { sayHello } from \"../functions/say-hello/resource\"\n\n\nconst schema = a.schema({\nCopy\nhighlighted code example\n  sayHello: a\n    .query()\n    .arguments({\n      name: a.string().default(\"World\"),\n    })\n    .returns(a.string())\n    .handler(a.handler.function(sayHello)),\n})\n\n\nexport type Schema = ClientSchema<typeof schema>\n\n\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    defaultAuthorizationMode: \"iam\",\n  },\n})\n\nNow you can use this query from the Schema export to strongly type your Function handler:\n\namplify/functions/say-hello/handler.ts\nCopy\namplify/functions/say-hello/handler.ts code example\nimport type { Schema } from \"../../data/resource\"\n\n\nexport const handler: Schema[\"sayHello\"][\"functionHandler\"] = async (event) => {\n  // arguments typed from `.arguments()`\n  const { name } = event.arguments\n  // return typed from `.returns()`\n  return `Hello, ${name}!`\n}\n\nFinally, use the data client to invoke your Function by calling its associated query.\n\nsrc/main.ts\nimport type { Schema } from \"./amplify/data/resource\"\nimport { Amplify } from \"aws-amplify\"\nimport { generateClient } from \"aws-amplify/api\"\nimport outputs from \"./amplify_outputs.json\"\n\n\nAmplify.configure(outputs)\n\n\nconst client = generateClient<Schema>()\n\n\nCopy\nhighlighted code example\nclient.queries.sayHello({\n  name: \"Amplify\",\n})\nNext steps\n\nNow that you have completed setting up your first Function, you may also want to add some additional features or modify a few settings. We recommend you learn more about:\n\nEnvironment variables and secrets\nGrant access to other resources\nExplore example use cases\nModifying underlying resources with CDK\nNEXT\nEnvironment variables and secrets"
  },
  {
    "title": "Functions - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/functions/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nFunctions\nFunctions\nSet up a Function\nUse AWS Lambda functions to perform tasks and customize workflows.\nEnvironment variables and secrets\nLearn how to configure and consume environment variables and secrets\nConfigure Functions\nLearn how to configure functions\nScheduling Functions\nLearn how to schedule functions to run at specific intervals\nStreaming logs\nStream execution logs directly to your terminal while Sandbox is running\nGrant access to other resources\nExtend the capabilities of your Function by granting access to other resources\nExamples\nExample use cases for Amplify Functions\nModify Amplify-generated Lambda resources with CDK\nLearn how to extend the underlying Function resources"
  },
  {
    "title": "Manage files with Amplify console - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/storage/manage-with-amplify-console/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nStorage\n/\nManage files with Amplify console\nManage files with Amplify console\n\nThe File storage page in the Amplify console provides a user-friendly interface for managing your application's backend file storage. It allows for efficient testing and management of your files.\n\nIf you have not yet created a storage resource, visit the Storage setup guide.\n\nAccess File storage\n\nAfter you've deployed your storage resource, you can access the manager on Amplify Console.\n\nLog in to the Amplify console and choose your app.\nSelect the branch you would like to access.\nSelect Storage from the left navigation bar.\nTo upload a file\nOn the Storage page, select the Upload button\nSelect the file you would like to upload and then select Done\n\nAlternatively, you can Drag and drop a file onto the Storage page.\n\nTo delete a file\nOn the Storage page, select the file you want to delete.\nSelect the Actions dropdown and then select Delete.\nTo copy a file\nOn the Storage page, select the file you want to copy.\nSelect the Actions dropdown and then select Copy to.\nSelect or create the folder you want a copy of your file to be saved to.\nSelect Copy to copy your file to the selected folder.\nTo move a file\nOn the Storage page, select the file you want to move.\nSelect the Actions dropdown and then select Move to.\nSelect or create the folder you want to move your file to.\nSelect Move to move your file to the selected folder.\nPREVIOUS\nUse Amplify Storage with any S3 bucket"
  },
  {
    "title": "Use Amplify Storage with any S3 bucket - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/storage/use-with-custom-s3/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nStorage\n/\nUse Amplify Storage with any S3 bucket\nUse Amplify Storage with any S3 bucket\n\nWith Amplify Storage APIs, you can use your own S3 buckets instead of the Amplify-created ones.\n\nImportant: To utilize the storage APIs with an S3 bucket outside of Amplify, you must have Amplify Auth configured in your project.\n\nStep 1 - Add necessary permissions to the S3 bucket\n\nFor the specific Amazon S3 bucket that you want to use with these APIs, you need to make sure that the associated IAM role has the necessary permissions to read and write data to that bucket.\n\nTo do this, go to Amazon S3 console > Select the S3 bucket > Permissions > Edit Bucket Policy.\n\nThe policy will look something like this\n\nCopy\ncode example\n{\n\t\"Version\": \"2012-10-17\",\n\t\"Statement\": [\n\t\t{\n\t\t\t\"Sid\": \"Statement1\",\n\t\t\t\"Principal\": { \"AWS\": \"arn:aws:iam::<AWS-account-ID>:role/<role-name>\" },\n\t\t\t\"Effect\": \"Allow\",\n\t\t\t\"Action\": [\n\t\t\t\t\"s3:PutObject\",\n\t\t\t\t\"s3:GetObject\",\n\t\t\t\t\"s3:DeleteObject\",\n\t\t\t\t\"s3:ListBucket\"\n\t\t\t],\n\t\t\t\"Resource\": [\n\t\t\t\t\"arn:aws:s3:::<bucket-name>/*\"\n\t\t\t]\n\t\t}\n\t]\n}\n\nReplace <AWS-account-ID> with your AWS account ID and <role-name> with the IAM role associated with your Amplify Auth setup. Replace <bucket-name> with the S3 bucket name.\n\nYou can refer to Amazon S3's Policies and Permissions documentation for more ways to customize access to the bucket.\n\nStep 2 - Specify S3 bucket in Amplify's backend config\n\nNext, use the addOutput method from the backend definition object to define a custom s3 bucket by specifying the name and region of the bucket in your amplify/backend.ts file.\n\nImportant\n\nYou cannot use both a storage backend configured through Amplify and a custom S3 bucket at the same time.\n\nIf you specify a custom S3 bucket, no sandbox storage resource will be created. The provided custom S3 bucket will be used, even in the sandbox environment.\n\nCopy\ncode example\nimport { defineBackend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource';\nimport { data } from './data/resource';\n\n\nconst backend = defineBackend({\n  auth,\n  data,\n});\n\n\nCopy\nhighlighted code example\nbackend.addOutput({\n  storage: {\n    aws_region: \"<region>\",\n    bucket_name: \"<bucket-name>\"\n  },\n});\nStep 3 - Import latest amplify_outputs.json file\n\nTo ensure the local amplify_outputs.json file is up-to-date, you can run the npx ampx generate outputs command or download the latest amplify_outputs.json from the Amplify console as shown below.\n\nNow that you've configured the necessary permissions, you can start using the storage APIs with your chosen S3 bucket.\n\nPREVIOUS\nExtend S3 resources\nNEXT\nManage files with Amplify console"
  },
  {
    "title": "Extend S3 resources - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/storage/extend-s3-resources/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nStorage\n/\nExtend S3 resources\nExtend S3 resources\nFor Amplify-generated S3 resources\n\nAmplify Storage generates Amazon S3 resources to offer storage features. You can access the underlying Amazon S3 resources to further customize your backend configuration by using the AWS Cloud Developer Kit (AWS CDK).\n\nExample - Enable Transfer Acceleration\n\nThe following is an example of how you would enable Transfer Acceleration on the bucket (CDK documentation). In order to enable Transfer Acceleration on the bucket, you will have to unwrap the L1 CDK construct from the L2 CDK construct like the following.\n\nCopy\nhighlighted code example\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport { defineBackend } from '@aws-amplify/backend';\nimport { storage } from './storage/resource';\n\n\nconst backend = defineBackend({\n  storage\n});\n\n\nCopy\nhighlighted code example\nconst s3Bucket = backend.storage.resources.bucket;\n\n\nconst cfnBucket = s3Bucket.node.defaultChild as s3.CfnBucket;\n\n\ncfnBucket.accelerateConfiguration = {\n  accelerationStatus: \"Enabled\" // 'Suspended' if you want to disable transfer acceleration\n}\n\nRead more about escape hatches in the CDK.\n\nFor Manually configured S3 resources\n\nTo make calls to your S3 bucket from your App, you need to set up a CORS Policy for your S3 bucket. This callout is only for manual configuration of your S3 bucket.\n\nThe following steps will set up your CORS Policy:\n\nGo to Amazon S3 console and click on your project's userfiles bucket, which is normally named as [Bucket Name][Id]-dev. \nClick on the Permissions tab for your bucket. \nClick the edit button in the Cross-origin resource sharing (CORS) section. \nMake the Changes and click on Save Changes. You can add required metadata to be exposed in ExposeHeaders with x-amz-meta-XXXX format. \nCopy\ncode example\n[\n  {\n    \"AllowedHeaders\": [\"*\"],\n    \"AllowedMethods\": [\"GET\", \"HEAD\", \"PUT\", \"POST\", \"DELETE\"],\n    \"AllowedOrigins\": [\"*\"],\n    \"ExposeHeaders\": [\n      \"x-amz-server-side-encryption\",\n      \"x-amz-request-id\",\n      \"x-amz-id-2\",\n      \"ETag\",\n      \"x-amz-meta-foo\"\n    ],\n    \"MaxAgeSeconds\": 3000\n  }\n]\n\nNote: You can restrict the access to your bucket by updating AllowedOrigin to include individual domains.\n\nPREVIOUS\nListen to storage events\nNEXT\nUse Amplify Storage with any S3 bucket"
  },
  {
    "title": "Listen to storage events - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/storage/lambda-triggers/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nStorage\n/\nListen to storage events\nListen to storage events\n\nFunction triggers can be configured to enable event-based workflows when files are uploaded or deleted. To add a function trigger, modify the defineStorage configuration.\n\nFirst, in your storage definition, add the following:\n\namplify/storage/resource.ts\nexport const storage = defineStorage({\n  name: 'myProjectFiles',\nCopy\nhighlighted code example\n  triggers: {\n    onUpload: defineFunction({\n      entry: './on-upload-handler.ts'\n    }),\n    onDelete: defineFunction({\n      entry: './on-delete-handler.ts'\n    })\n  }\n});\n\nThen create the function definitions at amplify/storage/on-upload-handler.ts and amplify/storage/on-delete-handler.ts.\n\namplify/storage/on-upload-handler.ts\nCopy\namplify/storage/on-upload-handler.ts code example\nimport type { S3Handler } from 'aws-lambda';\n\n\nexport const handler: S3Handler = async (event) => {\n  const objectKeys = event.Records.map((record) => record.s3.object.key);\n  console.log(`Upload handler invoked for objects [${objectKeys.join(', ')}]`);\n};\namplify/storage/on-delete-handler.ts\nCopy\namplify/storage/on-delete-handler.ts code example\nimport type { S3Handler } from 'aws-lambda';\n\n\nexport const handler: S3Handler = async (event) => {\n  const objectKeys = event.Records.map((record) => record.s3.object.key);\n  console.log(`Delete handler invoked for objects [${objectKeys.join(', ')}]`);\n};\n\nNote: The S3Handler type comes from the @types/aws-lambda npm package. This package contains types for different kinds of Lambda handlers, events, and responses.\n\nNow, when you deploy your backend, these functions will be invoked whenever an object is uploaded or deleted from the bucket.\n\nPREVIOUS\nCopy files\nNEXT\nExtend S3 resources"
  },
  {
    "title": "Copy files - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/storage/copy-files/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nStorage\n/\nCopy files\nCopy files\n\nNote: You can only copy files up to 5GB in a single operation\n\nYou can copy an existing file to a different path within the storage bucket using the copy API.\n\nThe copy method duplicates an existing file to a designated path and returns an object {path: 'destPath'} upon successful completion.\n\nCopy\ncode example\nimport { copy } from 'aws-amplify/storage';\n\n\nconst copyFile = async () => {\n  try {\n    const response = await copy({\n      source: {\n        path: 'album/2024/1.jpg',\n        // Alternatively, path: ({identityId}) => `album/{identityId}/1.jpg`\n      },\n      destination: {\n        path: 'shared/2024/1.jpg',\n        // Alternatively, path: ({identityId}) => `shared/{identityId}/1.jpg`\n      },\n    });\n  } catch (error) {\n    console.error('Error', err);\n  }\n};\n\nCross identity ID copying is only allowed if the destination path has the the right access rules to allow other authenticated users writing to it.\n\nMore copy options\nOption\tType\tDescription\tReference Links\nuseAccelerateEndpoint\tboolean\tWhether to use accelerate endpoint.\tTransfer Acceleration\nPREVIOUS\nRemove files\nNEXT\nListen to storage events"
  },
  {
    "title": "Remove files - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/storage/remove-files/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nStorage\n/\nRemove files\nRemove files\n\nFiles can be removed from a storage bucket using the 'remove' API. If a file is protected by an identity Id, only the user who owns the file will be able to remove it.\n\nCopy\ncode example\nimport { remove } from 'aws-amplify/storage';\n\n\ntry {\n  await remove({ \n    path: 'album/2024/1.jpg',\n    // Alternatively, path: ({identityId}) => `album/{identityId}/1.jpg`\n  });\n} catch (error) {\n  console.log('Error ', error);\n}\nPREVIOUS\nList file properties\nNEXT\nCopy files"
  },
  {
    "title": "List file properties - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/storage/list-files/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nStorage\n/\nList file properties\nList file properties\n\nYou can list files without having to download all the files. You can do this by using the list API from the Amplify Library for Storage. You can also get properties individually for a file using the getProperties API.\n\nList Files\nCopy\ncode example\nimport { list } from 'aws-amplify/storage';\n\n\nconst result = await list({\n\tpath: 'photos/',\n  // Alternatively, path: ({identityId}) => `album/{identityId}/photos/`\n});\n\nNote the trailing slash / - if you had requested list({ path : 'photos' }) it would also match against files like photos123.jpg alongside photos/123.jpg.\n\nThe format of the response will look similar to the below example:\n\nCopy\ncode example\n{\n  items: [\n    {\n      path: \"photos/123.jpg\",\n      eTag: \"30074401292215403a42b0739f3b5262\",\n      lastModified: \"Thu Oct 08 2020 23:59:31 GMT+0800 (Singapore Standard Time)\",\n      size: 138256\n    },\n    // ...\n  ],\n}\n\nManually created folders will show up as files with a size of 0, but you can also match keys against a regex like file.key.match(/\\.[0-9a-z]+$/i) to distinguish files from folders. Since \"folders\" are a virtual concept in Amazon S3, any file may declare any depth of folder just by having a / in its name.\n\nTo access the contents and subpaths of a \"folder\", you have two options:\n\nRequest the entire path and parse the contents.\nUse the subpathStrategy option to retrieve only the files within the specified path (i.e. exclude files under subpaths).\nGet all nested files within a path\n\nThis retrieves all files and folders under a given path. You may need to parse the result to get only the files within the specified path.\n\nCopy\ncode example\nfunction processStorageList(response) {\n  let files = [];\n  let folders = new Set();\n  response.items.forEach((res) => {\n    if (res.size) {\n      files.push(res);\n      // sometimes files declare a folder with a / within then\n      let possibleFolder = res.path.split('/').slice(0, -1).join('/');\n      if (possibleFolder) folders.add(possibleFolder);\n    } else {\n      folders.add(res.path);\n    }\n  });\n  return { files, folders };\n}\n\nIf you need the files and folders in terms of a nested object instead (for example, to build an explorer UI), you could parse it recursively:\n\nCopy\ncode example\nfunction processStorageList(response) {\n  const filesystem = {};\n  // https://stackoverflow.com/questions/44759750/how-can-i-create-a-nested-object-representation-of-a-folder-structure\n  const add = (source, target, item) => {\n    const elements = source.split('/');\n    const element = elements.shift();\n    if (!element) return; // blank\n    target[element] = target[element] || { __data: item }; // element;\n    if (elements.length) {\n      target[element] =\n        typeof target[element] === 'object' ? target[element] : {};\n      add(elements.join('/'), target[element], item);\n    }\n  };\n  response.items.forEach((item) => add(item.path, filesystem, item));\n  return filesystem;\n}\n\nThis places each item's data inside a special __data key.\n\nExcluding subpaths\n\nIn addition to using the list API to get all the contents of a path, you can also use it to get only the files within a path while excluding files under subpaths.\n\nFor example, given the following keys in your path you may want to return only the jpg object, and not the \"vacation\" subpath and its contents:\n\nCopy\ncode example\nphotos/photo1.jpg\nphotos/vacation/\n\nThis can be accomplished with the subpathStrategy option:\n\nsrc/main.ts\nCopy\nsrc/main.ts code example\nimport { list } from \"aws-amplify/storage\";\nconst result = await list({ \n  path: \"photos/\",\n  options:{\n    subpathStrategy: { strategy:'exclude' }\n  }\n});\n\nThe response will include only the objects within the photos/ path and will also communicate any excluded subpaths:\n\nCopy\ncode example\n{\n    excludedSubpaths: [\n      'photos/vacation/'\n    ],\n    items: [\n      {\n        path: \"photos/photo1.jpg\",\n        eTag: \"30074401292215403a42b0739f3b5262\",\n        lastModified: \"Thu Oct 08 2020 23:59:31 GMT+0800 (Singapore Standard Time)\",\n        size: 138256\n      },\n    ]\n}\n\nThe default delimiter character is '/', but this can be changed by supplying a custom delimiter:\n\nsrc/main.ts\nCopy\nsrc/main.ts code example\nconst result = await list({\n  // Path uses '-' character to organize files rather than '/'\n  path: 'photos-',\n  options: {\n    subpathStrategy: {\n      strategy: 'exclude',\n      delimiter: '-'\n    }\n  }\n});\nMore list options\nOption\tType\tDescription\nlistAll\tboolean\tSet to true to list all files within the specified path\npageSize\tnumber\tSets the maximum number of files to be return. The range is 0 - 1000\nnextToken\tstring\tIndicates whether the list is being continued on this bucket with a token\nuseAccelerateEndpoint\tboolean\tWhether to use accelerate endpoint.\n\nRead more at Transfer Acceleration\n\nIf the pageSize is set lower than the total file size, a single list call only returns a subset of all the files. To list all the files with multiple calls, users can use the nextToken flag:\n\nCopy\ncode example\nimport { list } from 'aws-amplify/storage';\n\n\nconst PAGE_SIZE = 20;\nlet nextToken = undefined;\n//...\nconst loadNextPage = async () => {\n  let response = await list({\n    path: 'photos/',\n    // Alternatively, path: ({ identityId }) => `album/{identityId}/photos/`\n    pageSize: PAGE_SIZE,\n    nextToken: nextToken\n    }\n  });\n  if (response.nextToken) {\n    nextToken = response.nextToken;\n  } else {\n    nextToken = undefined;\n  }\n  // render list items from response.items\n};\nGet File Properties\n\nYou can also view the properties of an individual file.\n\nCopy\ncode example\nimport { getProperties } from 'aws-amplify/storage';\n\n\ntry {\n  const result = await getProperties({\n    path: 'album/2024/1.jpg'\n    // Alternatively, path: ({ identityId }) => `album/{identityId}/1.jpg`\n  });\n  console.log('File Properties ', result);\n} catch (error) {\n  console.log('Error ', error);\n}\n\nThe properties and metadata will look similar to the below example\n\nCopy\ncode example\n{\n  path: \"album/2024/1.jpg\",\n  contentType: \"image/jpeg\",\n  contentLength: 6873,\n  eTag: \"\\\"56b32cf4779ff6ca3ba3f2d455fa56a7\\\"\",\n  lastModified: Wed Apr 19 2023 14:20:55 GMT-0700 (Pacific Daylight Time) {},\n  metadata: { owner: 'aws' }\n}\nMore getProperties options\nOption\tType\tDescription\nuseAccelerateEndpoint\tboolean\tWhether to use accelerate endpoint.\n\nTo get the metadata in result for all APIs you have to configure user defined metadata in CORS.\n\nLearn more about how to setup an appropriate CORS Policy.\n\nPREVIOUS\nDownload files\nNEXT\nRemove files"
  },
  {
    "title": "Download files - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/storage/download-files/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nStorage\n/\nDownload files\nDownload files\nStorage Image React UI Component\n\nYou can easily display images in your app by using the cloud-connected Storage Image React UI component. This component fetches images securely from your storage resource and displays it on the web page.\n\nTerminal\nCopy\nTerminal code example\nnpm add @aws-amplify/ui-react-storage aws-amplify\nCopy\ncode example\nimport { StorageImage } from '@aws-amplify/ui-react-storage';\n\n\nexport const DefaultStorageImageExample = () => {\n  return <StorageImage alt=\"cat\" path=\"your-path/cat.jpg\" />;\n};\n\nLearn more about how you can further customize the UI component by referring to the Storage Image documentation.\n\nTo further customize your in-app experience, you can use the getUrl or downloadData API from the Amplify Library for Storage.\n\nNote: Refer to the Transfer Acceleration documentation to learn how to enable transfer acceleration for storage APIs.\n\nGet or download file from a URL\n\nWith the getUrl API, you can get a presigned URL which is valid for 900 seconds or 15 minutes by default. You can use this URL to create a download link for users to click on. The expiresAt property is a Date object that represents the time at which the URL will expire.\n\nCopy\ncode example\nimport { getUrl } from 'aws-amplify/storage';\n\n\nconst linkToStorageFile = await getUrl({\n  path: \"album/2024/1.jpg\",\n  // Alternatively, path: ({identityId}) => `album/{identityId}/1.jpg`\n  options: {\n    validateObjectExistence?: false,  // defaults to false\n    expiresIn?: 20 // validity of the URL, in seconds. defaults to 900 (15 minutes) and maxes at 3600 (1 hour)\n    useAccelerateEndpoint: true; // Whether to use accelerate endpoint.\n  },\n});\nconsole.log('signed URL: ', linkToStorageFile.url);\nconsole.log('URL expires at: ', linkToStorageFile.expiresAt);\n\nInside your template or JSX code, you can use the url property to create a link to the file:\n\nCopy\ncode example\n<a href={linkToStorageFile.url.toString()} target=\"_blank\" rel=\"noreferrer\">\n  {fileName} \n</a>\n\nThis function does not check if the file exists by default. As result, the signed URL may fail if the file to be downloaded does not exist.\n\nMore getUrl options\nOption\tType\tDescription\nuseAccelerateEndpoint\tboolean\tWhether to use accelerate endpoint.\n\nRead more at Transfer Acceleration\nvalidateObjectExistence\tboolean\tWhether to head object to make sure the object existence before downloading. Defaults to false\nexpiresIn\tnumber\tNumber of seconds till the URL expires.\n\nThe expiration time of the presigned url is dependent on the session and will max out at 1 hour.\nDownload to a file\n\nUse the downloadData API to download the file locally.\n\nCopy\ncode example\nimport { downloadData } from 'aws-amplify/storage';\n\n\n// Downloads file content to memory\nconst { body, eTag } = await downloadData({\n  path: \"/album/2024/1.jpg\",\n  options: {\n    // optional progress callback\n    onProgress: (event) => {\n      console.log(event.transferredBytes);\n    }\n    // optional bytes range parameter to download a part of the file, the 2nd MB of the file in this example\n    bytesRange: {\n      start: 1024,\n      end: 2048\n    }\n  }\n}).result;\nGet the text value of downloaded File\n\nYou can get the value of file in any of the three formats: blob, json, or text. You can call the respective method on the body property to consume the set data in the respective format.\n\nCopy\ncode example\nimport { downloadData } from 'aws-amplify/storage';\n\n\ntry {\n  const downloadResult = await downloadData({\n    path: \"/album/2024/1.jpg\"\n  }).result;\n  const text = await downloadResult.body.text();\n  // Alternatively, you can use `downloadResult.body.blob()`\n  // or `downloadResult.body.json()` get read body in Blob or JSON format.\n  console.log('Succeed: ', text);\n} catch (error) {\n  console.log('Error : ', error);\n}\nMonitor download progress\nCopy\ncode example\nimport { downloadData } from 'aws-amplify/storage';\n\n\n// Download a file from S3 bucket\nconst { body, eTag } = await downloadData(\n  {\n    path: \"/album/2024/1.jpg\",\n    options: {\n      onProgress: (progress) {\n        console.log(`Download progress: ${(progress.transferredBytes/progress.totalBytes) * 100}%`);\n      }\n    }\n  }\n).result;\nCancel download\nCopy\ncode example\nimport { downloadData, isCancelError } from 'aws-amplify/storage';\n\n\nconst downloadTask = downloadData({ path: \"/album/2024/1.jpg\" });\ndownloadTask.cancel();\ntry {\n  await downloadTask.result;\n} catch (error) {\n  if (isCancelError(error)) {\n    // Handle error thrown by task cancellation.\n  }\n}\nMore download options\nOption\tType\tDescription\tReference Links\nuseAccelerateEndpoint\tboolean\tWhether to use accelerate endpoint.\tTransfer Acceleration\nbytesRange\t{ start: number; end:number; }\tbytes range parameter to download a part of the file.\t\nonProgress\tcallback\tCallback function tracking the upload/download progress.\t\nFrequently Asked Questions\ndownloadData is cached; if you have recently modified a file you may not get the latest version right away. You can pass in cacheControl: 'no-cache' to get the latest version.\ndownloadData only returns the latest cached version of the file; there is not yet an API to view prior versions.\nImage compression or CloudFront CDN caching for your S3 buckets is not yet possible.\nThere is no API for Cognito Group-based access to files.\nThere is currently no API for getting the identityId of other users; you have to retrieve this from elsewhere before calling Storage.get.\nPREVIOUS\nUpload files\nNEXT\nList file properties"
  },
  {
    "title": "Upload files - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/storage/upload-files/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nStorage\n/\nUpload files\nUpload files\n\nYou can implement upload functionality in your app by either using the Storage Manager UI component or further customizing the upload experience using the upload API.\n\nStorage Manager React UI Component\n\nUpload files from your app in minutes by using the cloud-connected Storage Manager UI Component.\n\nTerminal\nCopy\nTerminal code example\nnpm add @aws-amplify/ui-react-storage aws-amplify\n\nThen, use the component in your app.\n\nCopy\ncode example\nimport { StorageManager } from '@aws-amplify/ui-react-storage';\nimport '@aws-amplify/ui-react/styles.css';\n\n\nexport const DefaultStorageManagerExample = () => {\n  return (\n    <StorageManager\n      acceptedFileTypes={['image/*']}\n      path=\"public/\"\n      maxFileCount={1}\n      isResumable\n    />\n  );\n};\n\nLearn more about how you can further customize the UI component by referring to the Storage Manager documentation.\n\nImplement upload functionality\n\nNote: Refer to the Transfer Acceleration documentation to learn how to enable transfer acceleration for storage APIs.\n\nUpload from file\n\nThe following is an example of how you would upload a file from a file object, this could be retrieved from the local machine or a different source.\n\nCopy\ncode example\nimport { uploadData } from \"aws-amplify/storage\";\n\n\nconst file = document.getElementById(\"file\");\nconst upload = document.getElementById(\"upload\");\n\n\nupload.addEventListener(\"click\", () => {\n  const fileReader = new FileReader();\n  fileReader.readAsArrayBuffer(file.files[0]);\n\n\n  fileReader.onload = async (event) => {\n    console.log(\"Complete File read successfully!\", event.target.result);\n    try {\n      await uploadData({\n                data: event.target.result, \n                path: file.files[0].name \n            });\n    } catch (e) {\n      console.log(\"error\", e);\n    }\n  };\n});\nUpload from data\n\nYou can following this example if you have data saved in memory and would like to upload this data to the cloud.\n\nCopy\ncode example\nimport { uploadData } from 'aws-amplify/storage';\n\n\ntry {\n  const result = await uploadData({\n    path: \"album/2024/1.jpg\",\n    // Alternatively, path: ({identityId}) => `album/${identityId}/1.jpg`\n    data: file,\n    options: {\n      onProgress // Optional progress callback.\n    }\n  }).result;\n  console.log('Succeeded: ', result);\n} catch (error) {\n  console.log('Error : ', error);\n}\nMonitor upload progress\n\nMonitor progress of upload by using the onProgress options\n\nCopy\ncode example\nimport { uploadData } from 'aws-amplify/storage';\n\n\nconst monitorUpload = async () => {\n  try {\n    const result = await uploadData({\n      path: \"album/2024/1.jpg\",\n      // Alternatively, path: ({identityId}) => `album/${identityId}/1.jpg`\n      data: file,\n      options: {\n        onProgress: ({ transferredBytes, totalBytes }) => {\n          if (totalBytes) {\n            console.log(\n              `Upload progress ${Math.round(\n                (transferredBytes / totalBytes) * 100\n              )} %`\n            );\n          }\n        },\n      },\n    }).result;\n    console.log(\"Path from Response: \", result.path);\n  } catch (error) {\n    console.log(\"Error : \", error);\n  }\n}\nPause, resume, and cancel uploads\n\nWe have callback functions that support resuming, pausing, and cancelling uploadData requests.\n\nCopy\ncode example\nimport { uploadData, isCancelError } from 'aws-amplify/storage';\n\n\n// Pause, resume, and cancel a task\nconst uploadTask = uploadData({ path, data: file });\n//...\nuploadTask.pause();\n//...\nuploadTask.resume();\n//...\nuploadTask.cancel();\n//...\ntry {\n  await uploadTask.result;\n} catch (error) {\n  if (isCancelError(error)) {\n    // Handle error thrown by task cancellation\n  }\n}\nMore upload options\nOption\tType\tDescription\ncontentType\tString\tThe default content-type header value of the file when downloading it.\n\nRead more at Content-Type documentation\ncontentEncoding\tString\tThe default content-encoding header value of the file when downloading it.\n\nRead more at Content-Encoding documentation\ncontentDisposition\tString\tSpecifies presentational information for the object.\n\nRead more at Content-Disposition documentation\nmetadata\tmap<String>\tA map of metadata to store with the object in S3.\n\nRead more at S3 metadata documentation\nuseAccelerateEndpoint\tboolean\tWhether to use accelerate endpoint.\n\nRead more at Transfer Acceleration\n\nUploads that were initiated over one hour ago will be cancelled automatically. There are instances (e.g. device went offline, user logs out) where the incomplete file remains in your Amazon S3 account. It is recommended to setup a S3 lifecycle rule to automatically cleanup incomplete upload requests.\n\nMultiPart upload\n\nAmplify will automatically perform an Amazon S3 multipart upload for objects that are larger than 5MB. For more information about S3's multipart upload, see Uploading and copying objects using multipart upload\n\nPREVIOUS\nCustomize authorization rules\nNEXT\nDownload files"
  },
  {
    "title": "Customize authorization rules - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/storage/authorization/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nStorage\n/\nCustomize authorization rules\nCustomize authorization rules\n\nCustomize authorization for your storage bucket by defining access to file paths for guests, authenticated users, and user groups. Access can also be defined for functions that require access to the storage bucket.\n\nRefer to the following examples to understand how you can further customize authorization against different user types.\n\nAccess Types\n\nNote: Paths in access definitions cannot have a '/' at the beginning of the string.\n\nBy default, all paths are denied to all types of users unless explicitly granted within defineStorage using the access callback as shown below.\n\nAuthentication is required to continue using Amplify Storage, please make sure you set it up if you haven't already - documentation to set up Auth.\n\nGuest Users\nAuthenticated Users\nUser Groups\nOwners\nFunctions\n\nTo grant all guest (i.e. not signed in) users of your application read access to files under media/, use the following access values.\n\namplify/storage/resource.ts\nCopy\namplify/storage/resource.ts code example\nexport const storage = defineStorage({\n  name: 'myProjectFiles',\n  access: (allow) => ({\n    'media/*': [\n      allow.guest.to(['read']) // additional actions such as \"write\" and \"delete\" can be specified depending on your use case\n    ]\n  })\n});\nAccess definition rules\n\nThere are some rules for the types of paths that can be specified at the same time in the storage access definition.\n\nAll paths must end with /*.\nOnly one level of nesting is allowed. For example, you can define access controls on media/* and media/albums/* but not on media/albums/photos/* because there are two other definitions along the same path.\nWildcards cannot conflict with the {entity_id} token. For example, you cannot have both media/* and media/{entity_id}/* defined because the wildcard in the first path conflicts with the {entity_id} token in the second path.\nA path cannot be a prefix of another path with an {entity_id} token. For example media/* and media/albums/{entity_id}/* is not allowed.\n\nWhen one path is a subpath of another, the permissions on the subpath always override the permissions from the parent path. Permissions are not \"inherited\" from a parent path. Consider the following access definition example:\n\nCopy\ncode example\nexport const storage = defineStorage({\n  name: 'myProjectFiles',\n  access: (allow) => ({\n    'media/*': [allow.authenticated.to(['read', 'write', 'delete'])],\n    'media/profile-pictures/*': [allow.guest.to(['read'])],\n    'media/albums/*': [allow.authenticated.to(['read'])],\n    'other/*': [\n      allow.guest.to(['read']),\n      allow.authenticated.to(['read', 'write'])\n    ]\n  })\n});\n\nThe access control matrix for this configuration is\n\n\tmedia/*\tmedia/profile-pictures/*\tmedia/albums/*\tother/*\nAuthenticated Users\tread, write, delete\tNONE\tread\tread, write\nGuest users\tNONE\tread\tNONE\tread\n\nAuthenticated users have access to read, write, and delete everything under media/* EXCEPT media/profile-pictures/* and media/albums/*. For those subpaths, the scoped down access overrides the access granted on the parent media/*\n\nAvailable actions\n\nWhen you configure access to a particular path, you can scope the access to one or more CRUDL actions.\n\nAccess\tCorresponding Library APIs\nread\tgetUrl, downloadData, list, and getProperties\nget\tgetUrl and downloadData\nlist\tlist, and getProperties\nwrite\tuploadData, copy\ndelete\tremove\n\nNote: read is a combination of get and list access definitions and hence cannot be defined in the presence of get or list.\n\nFor Gen 1 public, protected, and private access pattern\n\nTo configure defineStorage in Amplify Gen 2 to behave the same way as the storage category in Gen 1, the following definition can be used.\n\namplify/storage/resource.ts\nCopy\namplify/storage/resource.ts code example\nexport const storage = defineStorage({\n  name: 'myProjectFiles',\n  access: (allow) => ({\n    'public/*': [\n      allow.guest.to(['read']),\n      allow.authenticated.to(['read', 'write', 'delete']),\n    ],\n    'protected/{entity_id}/*': [\n      allow.authenticated.to(['read']),\n      allow.entity('identity').to(['read', 'write', 'delete'])\n    ],\n    'private/{entity_id}/*': [\n      allow.entity('identity').to(['read', 'write', 'delete'])\n    ]\n  })\n});\nPREVIOUS\nSet up Storage\nNEXT\nUpload files"
  },
  {
    "title": "Set up Storage - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/storage/set-up-storage/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nStorage\n/\nSet up Storage\nSet up Storage\n\nIn this guide, you will learn how to set up storage in your Amplify app. You will set up your backend resources, and enable listing, uploading, and downloading files.\n\nIf you have not yet created an Amplify app, visit the quickstart guide.\n\nAmplify Storage seamlessly integrates file storage and management capabilities into frontend web and mobile apps, built on top of Amazon Simple Storage Service (Amazon S3). It provides intuitive APIs and UI components for core file operations, enabling developers to build scalable and secure file storage solutions without dealing with cloud service complexities.\n\nBuilding your storage backend\n\nFirst, create a file amplify/storage/resource.ts. This file will be the location where you configure your storage backend. Instantiate storage using the defineStorage function and providing a name for your storage bucket. This name is a friendly name to identify your bucket in your backend configuration. Amplify will generate a unique identifier for your app using a UUID, the name attribute is just for use in your app.\n\namplify/storage/resource.ts\nCopy\namplify/storage/resource.ts code example\nimport { defineStorage } from '@aws-amplify/backend';\n\n\nexport const storage = defineStorage({\n  name: 'amplifyTeamDrive'\n});\n\nImport your storage definition in your amplify/backend.ts file that contains your backend definition. Add storage to defineBackend.\n\namplify/backend.ts\nimport { defineBackend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource';\nCopy\nhighlighted code example\nimport { storage } from './storage/resource';\n\n\ndefineBackend({\n  auth,\nCopy\nhighlighted code example\n  storage\n});\n\nNow when you run npx ampx sandbox or deploy your app on Amplify, it will configure an Amazon S3 bucket where your files will be stored. Before files can be accessed in your application, you must configure storage access rules.\n\nTo deploy these changes, commit them to git and push the changes upstream. Amplify's CI/CD system will automatically pick up the changes and build and deploy the updates.\n\nTerminal\nCopy\nTerminal code example\ngit commit -am \"add storage backend\"\ngit push\nDefine File Path Access\n\nBy default, no users or other project resources have access to any files in the storage bucket. Access must be explicitly granted within defineStorage using the access callback.\n\nThe access callback returns an object where each key in the object is a file path and each value in the object is an array of access rules that apply to that path.\n\nThe following example shows you how you can set up your file storage structure for a generic photo sharing app. Here,\n\nGuests have access to see all profile pictures and only the users that uploaded the profile picture can replace or delete them. Users are identified by their Identity Pool ID in this case i.e. identityID.\nThere's also a general pool where all users can submit pictures.\n\nLearn more about customizing access to file path.\n\namplify/storage/resource.ts\nCopy\namplify/storage/resource.ts code example\nexport const storage = defineStorage({\n  name: 'amplifyTeamDrive',\n  access: (allow) => ({\n    'profile-pictures/{entity_id}/*': [\n      allow.guest.to(['read']),\n      allow.entity('identity').to(['read', 'write', 'delete'])\n    ],\n    'picture-submissions/*': [\n      allow.authenticated.to(['read','write']),\n      allow.guest.to(['read', 'write'])\n    ],\n  })\n});\nConnect your app code to the storage backend\n\nThe Amplify Storage library provides client APIs that connect to the backend resources you defined.\n\nConfigure Amplify in project\n\nImport and load the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point. For example index.js in React or main.ts in Angular.\n\nCopy\ncode example\nimport { Amplify } from 'aws-amplify';\nimport outputs from '../amplify_outputs.json';\n\n\nAmplify.configure(outputs);\n\nMake sure you call Amplify.configure as early as possible in your application’s life-cycle. A missing configuration or NoCredentials error is thrown if Amplify.configure has not been called before other Amplify JavaScript APIs.\n\nUpload your first file\n\nNext, let's a photo to the picture-submissions/ path.\n\nCopy\ncode example\nimport { uploadData } from \"aws-amplify/storage\";\n\n\nconst file = document.getElementById(\"file\");\nconst upload = document.getElementById(\"upload\");\n\n\nupload.addEventListener(\"click\", () => {\n  const fileReader = new FileReader();\n  fileReader.readAsArrayBuffer(file.files[0]);\n\n\n  fileReader.onload = async (event) => {\n    console.log(\"Complete File read successfully!\", event.target.result);\n    try {\n      await uploadData({\n        data: event.target.result,\n        path: `picture-submissions/${file.files[0].name}`\n      });\n    } catch (e) {\n      console.log(\"error\", e);\n    }\n  };\n});\nManage files in Amplify console\n\nAfter successfully publishing your storage backend and connecting your project with client APIs, you can manage files and folders in the Amplify console. You can perform on-demand actions like upload, download, copy, and more under the Storage tab in the console. Refer to Manage files in Amplify Console guide for additional information.\n\nConclusion\n\nCongratulations! You finished the Set up Amplify Storage guide. In this guide, you set up and connected to backend resources, customized your file paths and access definitions, and connected your application to the backend to implement features like file uploads and downloads.\n\nNext steps\n\nNow that you have completed setting up storage in your Amplify app, you can proceed to add file management features to your app. You can use the following guides to implement upload and download functionality, or you can access more capabilities from the side navigation.\n\nUpload Files\nDownload Files\nNEXT\nCustomize authorization rules"
  },
  {
    "title": "Nuxt.js server runtime - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/connect-from-server-runtime/nuxtjs-server-runtime/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nConnect to data from Server-side Runtimes\n/\nNuxt.js server runtime\nNuxt.js server runtime\n\nThis guide walks through how you can connect to Amplify Data from Nuxt.js Server-side Runtime (SSR). For Nuxt.js applications, Amplify provides first-class support for Routing (Pages) , API Routes , and Middleware.\n\nBefore you begin, you will need:\n\nA Nuxt.js application created\nDeployed Amplify Data resources, or directly using AWS AppSync\nConnect to Amplify Data from a Nuxt.js server runtime\n\nConnecting to Amplify Data will include setting up the AmplifyAPIs Plugin with the runWithAmplifyServerContext adapter, using the useNuxtApp() composable, setting up the Amplify server context utility and then using the runAmplifyApi function to call the API in an isolated server context.\n\nStep 1 - Set up the AmplifyAPIs Plugin\n\nNuxt 3 offers universal rendering by default, where your data fetching logic may be executed on both the client and server sides. Amplify offers APIs that are capable of running within a server context to support use cases such as server-side rendering (SSR) and static site generation (SSG), though Amplify's client-side APIs and server-side APIs of Amplify are slightly different. You can set up an AmplifyAPIs plugin to make your data fetching logic run smoothly across the client and server. To learn more about how to use Amplify categories APIs in server side rendering, refer to this documentation.\n\nCreate a plugins directory under the root of your Nuxt project.\nCreate two files 01.amplify-apis.client.ts and 01.amplify-apis.server.ts under the plugins directory.\n\nIn these files, you will register both client-specific and server-specific Amplify APIs that you will use in your Nuxt project as a plugin. You can then access these APIs via the useNuxtApp composable.\n\nNOTE: The leading number in the files name indicate the plugin loading order, for more details see https://nuxt.com/docs/guide/directory-structure/plugins#registration-order. The .client and .server indicate the runtime that the logic contained in the file will run on, client or server. For details see: https://nuxt.com/docs/guide/directory-structure/plugins\n\nModify the 01.amplify-apis.client.ts file, with the following code:\n\nExpand to view the code implementation\n\nNext, modify the 01.amplify-apis.server.ts file, with the following code:\n\nExpand to view the code implementation\nStep 2 - Use the useNuxtApp() composable\n\nUsing the GraphQL API in ~/app.vue:\n\nnuxt-amplify-gen2/app.vue\nCopy\nnuxt-amplify-gen2/app.vue code example\n<script setup lang=\"ts\">\nimport { Authenticator } from '@aws-amplify/ui-vue';\nimport '@aws-amplify/ui-vue/styles.css';\nimport { onMounted, ref } from 'vue';\nimport type { Schema } from '@/amplify/data/resource';\n\n\n// create a reactive reference to the array of todos\nconst todos = ref<Schema['Todo']['type'][]>([]);\n\n\nasync function listTodos() {\n try {\n    // `$Amplify` is generated by Nuxt according to the `provide` key in the plugins\n    // fetch all todos\n    const { data } = await useNuxtApp().$Amplify.GraphQL.client.models.Todo.list();\n    todos.value = data;\n\n\n  } catch (error) {\n     console.error('Error fetching todos', error);\n  }\n}\n\n\n// fetch todos when the component is mounted\nonMounted(() => {\n  listTodos();\n});\n</script>\n\n\n\n\n<template>\n  <Authenticator>\n    <template v-slot=\"{ user, signOut }\">\n      <h1>Hello, Amplify 👋</h1>\n        <ul>\n          <li v-for=\"todo in todos\" :key=\"todo.id\">{{ todo.content }}</li>\n        </ul>\n      <button @click=\"signOut\">Sign Out</button>\n    </template>\n  </Authenticator>\n</template>\n\nThe app.vue file can be rendered on both the client and server sides by default. The useNuxtApp().$Amplify composable will pick up the correct implementation of 01.amplify-apis.client.ts and 01.amplify-apis.server.ts to use, depending on the runtime.\n\nOnly a subset of Amplify APIs are usable on the server side, and as the libraries evolve, amplify-apis.client and amplify-apis.server may diverge further. You can guard your API calls to ensure an API is available in the context where you use it. E.g., you can use if (process.client) to ensure that a client-only API isn't executed on the server.\n\nStep 3 - Set up Amplify for API Routes\n\nFollowing the specification of Nuxt, your API route handlers will live under ~/server, which is a separate environment from other parts of your Nuxt app; hence, the plugins created in the previous step are not usable here, and extra work is required.\n\nSetup Amplify Server Context Utility\nCreate a utils directory under the server directory of your Nuxt project.\nCreate an amplifyUtils.ts file under the utils directory.\n\nIn this file, you will create a helper function to call Amplify APIs that are capable of running on the server side with context isolation. Modify the amplifyUtils.ts file, with the following code:\n\nExpand to view the code implementation\n\nNow, you can use the runAmplifyApi function to call Amplify APIs in an isolated server context. Create a new API route /api/current-user in the server directory and modify the current-user.ts file, with the following code:\n\nnuxt-amplify-gen2/server/api/current-user.ts\nCopy\nnuxt-amplify-gen2/server/api/current-user.ts code example\nimport { getCurrentUser } from \"aws-amplify/auth/server\";\nimport { runAmplifyApi } from \"~/server/utils/amplifyUtils\";\n\n\nexport default defineEventHandler(async (event) => {\n  const user = await runAmplifyApi(event, (contextSpec) =>\n    getCurrentUser(contextSpec)\n  );\n\n\n  return user;\n});\n\nYou can then fetch data from this API route, for example: fetch('http://localhost:3000/api/current-user')\n\nPREVIOUS\nNext.js server runtime"
  },
  {
    "title": "Storage - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/storage/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nStorage\nStorage\nSet up Storage\nSet up Amplify Storage for your project\nCustomize authorization rules\nDefine granular authorization rules for storage buckets\nUpload files\nUpload files using Amplify Storage\nDownload files\nDownload files using Amplify Storage\nList file properties\nGet list of files or file properties using Amplify Storage\nRemove files\nRemove files using Amplify Storage\nCopy files\nCopy files using Amplify Storage\nListen to storage events\nSet up triggers on Storage events\nExtend S3 resources\nExtend configuration for S3 resources\nUse Amplify Storage with any S3 bucket\nYou can use the Amplify Storage APIs against your own S3 bucket in your account.\nManage files with Amplify console\nManage your applications storage files with Amplify console"
  },
  {
    "title": "Optimistic UI - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/optimistic-ui/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nOptimistic UI\nOptimistic UI\n\nAmplify Data can be used with TanStack Query to implement optimistic UI, allowing CRUD operations to be rendered immediately on the UI before the request roundtrip has completed. Using Amplify Data with TanStack additionally makes it easy to render loading and error states, and allows you to rollback changes on the UI when API calls are unsuccessful.\n\nIn the following examples we'll create a list view that optimistically renders newly created items, and a detail view that optimistically renders updates and deletes.\n\nFor more details on TanStack Query, including requirements, supported browsers, and advanced usage, see the TanStack Query documentation. For complete guidance on how to implement optimistic updates with TanStack Query, see the TanStack Query Optimistic UI Documentation. For more on Amplify Data, see the API documentation.\n\nTo get started, run the following command in an existing Amplify project with a React frontend:\n\nTerminal\nCopy\nTerminal code example\n# Install TanStack Query\nnpm i @tanstack/react-query @tanstack/react-query-devtools\n\nModify your Data schema to use this \"Real Estate Property\" example:\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\nconst schema = a.schema({\n  RealEstateProperty: a.model({\n    name: a.string().required(),\n    address: a.string(),\n  }).authorization(allow => [allow.guest()])\n})\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    defaultAuthorizationMode: 'iam',\n  },\n});\n\nSave the file and run npx ampx sandbox to deploy the changes to your backend cloud sandbox. For the purposes of this guide, we'll build a Real Estate Property listing application.\n\nNext, at the root of your project, add the required TanStack Query imports, and create a client:\n\nsrc/main.tsx\nimport React from 'react'\nimport ReactDOM from 'react-dom/client'\nimport App from './App.tsx'\nimport './index.css'\nimport { Amplify } from 'aws-amplify'\nimport outputs from '../amplify_outputs.json'\nCopy\nhighlighted code example\nimport { QueryClient, QueryClientProvider } from \"@tanstack/react-query\";\nimport { ReactQueryDevtools } from \"@tanstack/react-query-devtools\";\n\n\nAmplify.configure(outputs)\n\n\nconst queryClient = new QueryClient()\n\n\nReactDOM.createRoot(document.getElementById('root')!).render(\n  <React.StrictMode>\nCopy\nhighlighted code example\n    <QueryClientProvider client={queryClient}>\n      <App />\n      <ReactQueryDevtools initialIsOpen={false} />\n    </QueryClientProvider>\n  </React.StrictMode>,\n)\n\nTanStack Query Devtools are not required, but are a useful resource for debugging and understanding how TanStack works under the hood. By default, React Query Devtools are only included in bundles when process.env.NODE_ENV === 'development', meaning that no additional configuration is required to exclude them from a production build. For more information on the TanStack Query Devtools, visit the TanStack Query Devtools docs\n\nFor the complete working example, including required imports and React component state management, see the Complete Example below.\n\nHow to use TanStack Query query keys with the Amplify Data API\n\nTanStack Query manages query caching based on the query keys you specify. A query key must be an array. The array can contain a single string or multiple strings and nested objects. The query key must be serializable, and unique to the query's data.\n\nWhen using TanStack to render optimistic UI with Amplify Data, you must use different query keys depending on the API operation. When retrieving a list of items, a single string is used (e.g. queryKey: [\"realEstateProperties\"]). This query key is also used to optimistically render a newly created item. When updating or deleting an item, the query key must also include the unique identifier for the record being deleted or updated (e.g. queryKey: [\"realEstateProperties\", newRealEstateProperty.id]).\n\nFor more detailed information on query keys, see the TanStack Query documentation.\n\nOptimistically rendering a list of records\n\nTo optimistically render a list of items returned from the Amplify Data API, use the TanStack useQuery hook, passing in the Data API query as the queryFn parameter. The following example creates a query to retrieve all records from the API. We'll use realEstateProperties as the query key, which will be the same key we use to optimistically render a newly created item.\n\nsrc/App.tsx\nCopy\nhighlighted code example\nimport type { Schema } from '../amplify/data/resource'\nimport { generateClient } from 'aws-amplify/data'\nimport { useQuery } from '@tanstack/react-query'\n\n\nconst client = generateClient<Schema>();\n\n\nfunction App() {\nCopy\nhighlighted code example\n  const {\n    data: realEstateProperties,\n    isLoading,\n    isSuccess,\n    isError: isErrorQuery,\n  } = useQuery({\n    queryKey: [\"realEstateProperties\"],\n    queryFn: async () => {\n      const response = await client.models.RealEstateProperty.list();\n\n\n      const allRealEstateProperties = response.data;\n\n\n      if (!allRealEstateProperties) return null;\n\n\n      return allRealEstateProperties;\n    },\n  });\n  // return ...\n}\nOptimistically rendering a newly created record\n\nTo optimistically render a newly created record returned from the Amplify Data API, use the TanStack useMutation hook, passing in the Amplify Data API mutation as the mutationFn parameter. We'll use the same query key used by the useQuery hook (realEstateProperties) as the query key to optimistically render a newly created item. We'll use the onMutate function to update the cache directly, as well as the onError function to rollback changes when a request fails.\n\nimport { generateClient } from 'aws-amplify/api'\nimport type { Schema } from '../amplify/data/resource'\nCopy\nhighlighted code example\nimport { useQueryClient, useMutation } from '@tanstack/react-query'\n\n\nconst client = generateClient<Schema>()\n\n\nfunction App() {\nCopy\nhighlighted code example\n  const queryClient = useQueryClient();\n\n\nCopy\nhighlighted code example\n  const createMutation = useMutation({\n    mutationFn: async (input: { name: string, address: string }) => {\n      const { data: newRealEstateProperty } = await client.models.RealEstateProperty.create(input)\n      return newRealEstateProperty;\n    },\n    // When mutate is called:\n    onMutate: async (newRealEstateProperty) => {\n      // Cancel any outgoing refetches\n      // (so they don't overwrite our optimistic update)\n      await queryClient.cancelQueries({ queryKey: [\"realEstateProperties\"] });\n\n\n      // Snapshot the previous value\n      const previousRealEstateProperties = queryClient.getQueryData([\n        \"realEstateProperties\",\n      ]);\n\n\n      // Optimistically update to the new value\n      if (previousRealEstateProperties) {\n        queryClient.setQueryData([\"realEstateProperties\"], (old: Schema[\"RealEstateProperty\"][\"type\"][]) => [\n          ...old,\n          newRealEstateProperty,\n        ]);\n      }\n\n\n      // Return a context object with the snapshotted value\n      return { previousRealEstateProperties };\n    },\n    // If the mutation fails,\n    // use the context returned from onMutate to rollback\n    onError: (err, newRealEstateProperty, context) => {\n      console.error(\"Error saving record:\", err, newRealEstateProperty);\n      if (context?.previousRealEstateProperties) {\n        queryClient.setQueryData(\n          [\"realEstateProperties\"],\n          context.previousRealEstateProperties\n        );\n      }\n    },\n    // Always refetch after error or success:\n    onSettled: () => {\n      queryClient.invalidateQueries({ queryKey: [\"realEstateProperties\"] });\n    },\n  });\n  // return ...\n}\nQuerying a single item with TanStack Query\n\nTo optimistically render updates on a single item, we'll first retrieve the item from the API. We'll use the useQuery hook, passing in the get query as the queryFn parameter. For the query key, we'll use a combination of realEstateProperties and the record's unique identifier.\n\nimport { generateClient } from 'aws-amplify/data'\nimport type { Schema } from '../amplify/data/resource'\nimport { useQuery } from '@tanstack/react-query'\n\n\nconst client = generateClient<Schema>()\n\n\nfunction App() {\n  const currentRealEstatePropertyId = \"SOME_ID\"\nCopy\nhighlighted code example\n  const {\n    data: realEstateProperty,\n    isLoading,\n    isSuccess,\n    isError: isErrorQuery,\n  } = useQuery({\n    queryKey: [\"realEstateProperties\", currentRealEstatePropertyId],\n    queryFn: async () => {\n      if (!currentRealEstatePropertyId) { return }\n\n\n      const { data: property } = await client.models.RealEstateProperty.get({\n        id: currentRealEstatePropertyId,\n      });\n      return property;\n    },\n  });\n}\nOptimistically render updates for a record\n\nTo optimistically render Amplify Data updates for a single record, use the TanStack useMutation hook, passing in the update mutation as the mutationFn parameter. We'll use the same query key combination used by the single record useQuery hook (realEstateProperties and the record's id) as the query key to optimistically render the updates. We'll use the onMutate function to update the cache directly, as well as the onError function to rollback changes when a request fails.\n\nWhen directly interacting with the cache via the onMutate function, the newRealEstateProperty parameter will only include fields that are being updated. When calling setQueryData, include the previous values for all fields in addition to the newly updated fields to avoid only rendering optimistic values for updated fields on the UI.\n\nsrc/App.tsx\nimport { generateClient } from 'aws-amplify/data'\nimport type { Schema } from '../amplify/data/resource'\nimport { useQueryClient, useMutation } from \"@tanstack/react-query\";\n\n\nconst client = generateClient<Schema>()\n\n\nfunction App() {\nCopy\nhighlighted code example\n  const queryClient = useQueryClient();\n\n\nCopy\nhighlighted code example\n   const updateMutation = useMutation({\n    mutationFn: async (realEstatePropertyDetails: { id: string, name?: string, address?: string }) => {\n      const { data: updatedProperty } = await client.models.RealEstateProperty.update(realEstatePropertyDetails);\n\n\n      return updatedProperty;\n    },\n    // When mutate is called:\n    onMutate: async (newRealEstateProperty: { id: string, name?: string, address?: string }) => {\n      // Cancel any outgoing refetches\n      // (so they don't overwrite our optimistic update)\n      await queryClient.cancelQueries({\n        queryKey: [\"realEstateProperties\", newRealEstateProperty.id],\n      });\n\n\n      await queryClient.cancelQueries({\n        queryKey: [\"realEstateProperties\"],\n      });\n\n\n      // Snapshot the previous value\n      const previousRealEstateProperty = queryClient.getQueryData([\n        \"realEstateProperties\",\n        newRealEstateProperty.id,\n      ]);\n\n\n      // Optimistically update to the new value\n      if (previousRealEstateProperty) {\n        queryClient.setQueryData(\n          [\"realEstateProperties\", newRealEstateProperty.id],\n          /**\n           * `newRealEstateProperty` will at first only include updated values for\n           * the record. To avoid only rendering optimistic values for updated\n           * fields on the UI, include the previous values for all fields:\n           */\n          { ...previousRealEstateProperty, ...newRealEstateProperty }\n        );\n      }\n\n\n      // Return a context with the previous and new realEstateProperty\n      return { previousRealEstateProperty, newRealEstateProperty };\n    },\n    // If the mutation fails, use the context we returned above\n    onError: (err, newRealEstateProperty, context) => {\n      console.error(\"Error updating record:\", err, newRealEstateProperty);\n      if (context?.previousRealEstateProperty) {\n        queryClient.setQueryData(\n          [\"realEstateProperties\", context.newRealEstateProperty.id],\n          context.previousRealEstateProperty\n        );\n      }\n    },\n    // Always refetch after error or success:\n    onSettled: (newRealEstateProperty) => {\n      if (newRealEstateProperty) {\n        queryClient.invalidateQueries({\n          queryKey: [\"realEstateProperties\", newRealEstateProperty.id],\n        });\n        queryClient.invalidateQueries({\n          queryKey: [\"realEstateProperties\"],\n        });\n      }\n    },\n  });\n}\nOptimistically render deleting a record\n\nTo optimistically render a deletion of a single record, use the TanStack useMutation hook, passing in the delete mutation as the mutationFn parameter. We'll use the same query key combination used by the single record useQuery hook (realEstateProperties and the record's id) as the query key to optimistically render the updates. We'll use the onMutate function to update the cache directly, as well as the onError function to rollback changes when a delete fails.\n\nsrc/App.tsx\nimport { generateClient } from 'aws-amplify/data'\nimport type { Schema } from '../amplify/data/resource'\nimport { useQueryClient, useMutation } from '@tanstack/react-query'\n\n\nconst client = generateClient<Schema>()\n\n\nfunction App() {\nCopy\nhighlighted code example\n  const queryClient = useQueryClient();\n\n\nCopy\nhighlighted code example\n    const deleteMutation = useMutation({\n    mutationFn: async (realEstatePropertyDetails: { id: string }) => {\n      const { data: deletedProperty } = await client.models.RealEstateProperty.delete(realEstatePropertyDetails);\n      return deletedProperty;\n    },\n    // When mutate is called:\n    onMutate: async (newRealEstateProperty) => {\n      // Cancel any outgoing refetches\n      // (so they don't overwrite our optimistic update)\n      await queryClient.cancelQueries({\n        queryKey: [\"realEstateProperties\", newRealEstateProperty.id],\n      });\n\n\n      await queryClient.cancelQueries({\n        queryKey: [\"realEstateProperties\"],\n      });\n\n\n      // Snapshot the previous value\n      const previousRealEstateProperty = queryClient.getQueryData([\n        \"realEstateProperties\",\n        newRealEstateProperty.id,\n      ]);\n\n\n      // Optimistically update to the new value\n      if (previousRealEstateProperty) {\n        queryClient.setQueryData(\n          [\"realEstateProperties\", newRealEstateProperty.id],\n          newRealEstateProperty\n        );\n      }\n\n\n      // Return a context with the previous and new realEstateProperty\n      return { previousRealEstateProperty, newRealEstateProperty };\n    },\n    // If the mutation fails, use the context we returned above\n    onError: (err, newRealEstateProperty, context) => {\n      console.error(\"Error deleting record:\", err, newRealEstateProperty);\n      if (context?.previousRealEstateProperty) {\n        queryClient.setQueryData(\n          [\"realEstateProperties\", context.newRealEstateProperty.id],\n          context.previousRealEstateProperty\n        );\n      }\n    },\n    // Always refetch after error or success:\n    onSettled: (newRealEstateProperty) => {\n      if (newRealEstateProperty) {\n        queryClient.invalidateQueries({\n          queryKey: [\"realEstateProperties\", newRealEstateProperty.id],\n        });\n        queryClient.invalidateQueries({\n          queryKey: [\"realEstateProperties\"],\n        });\n      }\n    },\n  });\n}\nLoading and error states for optimistically rendered data\n\nBoth useQuery and useMutation return isLoading and isError states that indicate the current state of the query or mutation. You can use these states to render loading and error indicators.\n\nIn addition to operation-specific loading states, TanStack Query provides a useIsFetching hook. For the purposes of this demo, we show a global loading indicator in the Complete Example when any queries are fetching (including in the background) in order to help visualize what TanStack is doing in the background:\n\nCopy\ncode example\nfunction GlobalLoadingIndicator() {\n  const isFetching = useIsFetching();\n  return isFetching ? <div style={styles.globalLoadingIndicator}></div> : null;\n}\n\nFor more details on advanced usage of TanStack Query hooks, see the TanStack documentation.\n\nThe following example demonstrates how to use the state returned by TanStack to render a loading indicator while a mutation is in progress, and an error message if the mutation fails. For additional examples, see the Complete Example below.\n\nCopy\ncode example\n<>\n  {updateMutation.isError &&\n  updateMutation.error instanceof Error ? (\n    <div>An error occurred: {updateMutation.error.message}</div>\n  ) : null}\n\n\n  {updateMutation.isSuccess ? (\n    <div>Real Estate Property updated!</div>\n  ) : null}\n\n\n  <button\n    onClick={() =>\n      updateMutation.mutate({\n        id: realEstateProperty.id,\n        address: `${Math.floor(\n          1000 + Math.random() * 9000\n        )} Main St`,\n      })\n    }\n  >\n    Update Address\n  </button>\n</>\nComplete example\nsrc/main.tsx\nCopy\nsrc/main.tsx code example\nimport React from 'react'\nimport ReactDOM from 'react-dom/client'\nimport App from './App.tsx'\nimport './index.css'\nimport { Amplify } from 'aws-amplify'\nimport outputs from '../amplify_outputs.json'\nimport { QueryClient, QueryClientProvider } from \"@tanstack/react-query\";\nimport { ReactQueryDevtools } from \"@tanstack/react-query-devtools\";\n\n\nAmplify.configure(outputs)\n\n\nexport const queryClient = new QueryClient()\n\n\nReactDOM.createRoot(document.getElementById('root')!).render(\n  <React.StrictMode>\n    <QueryClientProvider client={queryClient}>\n      <App />\n      <ReactQueryDevtools initialIsOpen={false} />\n    </QueryClientProvider>\n  </React.StrictMode>,\n)\nsrc/App.tsx\nCopy\nsrc/App.tsx code example\nimport { generateClient } from 'aws-amplify/data'\nimport type { Schema } from '../amplify/data/resource'\nimport './App.css'\nimport { useIsFetching, useMutation, useQuery } from '@tanstack/react-query'\nimport { queryClient } from './main'\nimport { useState } from 'react'\n\n\n\n\nconst client = generateClient<Schema>({\n  authMode: 'iam'\n})\n\n\nfunction GlobalLoadingIndicator() {\n  const isFetching = useIsFetching();\n\n\n  return isFetching ? <div style={styles.globalLoadingIndicator}></div> : null;\n}\n\n\n\n\nfunction App() {\n  const [currentRealEstatePropertyId, setCurrentRealEstatePropertyId] =\n  useState<string | null>(null);\n\n\n  const {\n    data: realEstateProperties,\n    isLoading,\n    isSuccess,\n    isError: isErrorQuery,\n  } = useQuery({\n    queryKey: [\"realEstateProperties\"],\n    queryFn: async () => {\n      const response = await client.models.RealEstateProperty.list();\n\n\n      const allRealEstateProperties = response.data;\n\n\n      if (!allRealEstateProperties) return null;\n\n\n      return allRealEstateProperties;\n    },\n  });\n\n\n  const createMutation = useMutation({\n    mutationFn: async (input: { name: string, address: string }) => {\n      const { data: newRealEstateProperty } = await client.models.RealEstateProperty.create(input)\n      return newRealEstateProperty;\n    },\n    // When mutate is called:\n    onMutate: async (newRealEstateProperty) => {\n      // Cancel any outgoing refetches\n      // (so they don't overwrite our optimistic update)\n      await queryClient.cancelQueries({ queryKey: [\"realEstateProperties\"] });\n\n\n      // Snapshot the previous value\n      const previousRealEstateProperties = queryClient.getQueryData([\n        \"realEstateProperties\",\n      ]);\n\n\n      // Optimistically update to the new value\n      if (previousRealEstateProperties) {\n        queryClient.setQueryData([\"realEstateProperties\"], (old: Schema[\"RealEstateProperty\"][\"type\"][]) => [\n          ...old,\n          newRealEstateProperty,\n        ]);\n      }\n\n\n      // Return a context object with the snapshotted value\n      return { previousRealEstateProperties };\n    },\n    // If the mutation fails,\n    // use the context returned from onMutate to rollback\n    onError: (err, newRealEstateProperty, context) => {\n      console.error(\"Error saving record:\", err, newRealEstateProperty);\n      if (context?.previousRealEstateProperties) {\n        queryClient.setQueryData(\n          [\"realEstateProperties\"],\n          context.previousRealEstateProperties\n        );\n      }\n    },\n    // Always refetch after error or success:\n    onSettled: () => {\n      queryClient.invalidateQueries({ queryKey: [\"realEstateProperties\"] });\n    },\n  });\n\n\n  function RealEstatePropertyDetailView() {\n\n\n    const {\n      data: realEstateProperty,\n      isLoading,\n      isSuccess,\n      isError: isErrorQuery,\n    } = useQuery({\n      queryKey: [\"realEstateProperties\", currentRealEstatePropertyId],\n      queryFn: async () => {\n        if (!currentRealEstatePropertyId) { return }\n\n\n        const { data: property } = await client.models.RealEstateProperty.get({ id: currentRealEstatePropertyId });\n        return property\n      },\n    });\n\n\n\n\n    const updateMutation = useMutation({\n      mutationFn: async (realEstatePropertyDetails: { id: string, name?: string, address?: string }) => {\n        const { data: updatedProperty } = await client.models.RealEstateProperty.update(realEstatePropertyDetails);\n\n\n        return updatedProperty;\n      },\n      // When mutate is called:\n      onMutate: async (newRealEstateProperty: { id: string, name?: string, address?: string }) => {\n        // Cancel any outgoing refetches\n        // (so they don't overwrite our optimistic update)\n        await queryClient.cancelQueries({\n          queryKey: [\"realEstateProperties\", newRealEstateProperty.id],\n        });\n\n\n        await queryClient.cancelQueries({\n          queryKey: [\"realEstateProperties\"],\n        });\n\n\n        // Snapshot the previous value\n        const previousRealEstateProperty = queryClient.getQueryData([\n          \"realEstateProperties\",\n          newRealEstateProperty.id,\n        ]);\n\n\n        // Optimistically update to the new value\n        if (previousRealEstateProperty) {\n          queryClient.setQueryData(\n            [\"realEstateProperties\", newRealEstateProperty.id],\n            /**\n             * `newRealEstateProperty` will at first only include updated values for\n             * the record. To avoid only rendering optimistic values for updated\n             * fields on the UI, include the previous values for all fields:\n             */\n            { ...previousRealEstateProperty, ...newRealEstateProperty }\n          );\n        }\n\n\n        // Return a context with the previous and new realEstateProperty\n        return { previousRealEstateProperty, newRealEstateProperty };\n      },\n      // If the mutation fails, use the context we returned above\n      onError: (err, newRealEstateProperty, context) => {\n        console.error(\"Error updating record:\", err, newRealEstateProperty);\n        if (context?.previousRealEstateProperty) {\n          queryClient.setQueryData(\n            [\"realEstateProperties\", context.newRealEstateProperty.id],\n            context.previousRealEstateProperty\n          );\n        }\n      },\n      // Always refetch after error or success:\n      onSettled: (newRealEstateProperty) => {\n        if (newRealEstateProperty) {\n          queryClient.invalidateQueries({\n            queryKey: [\"realEstateProperties\", newRealEstateProperty.id],\n          });\n          queryClient.invalidateQueries({\n            queryKey: [\"realEstateProperties\"],\n          });\n        }\n      },\n    });\n\n\n    const deleteMutation = useMutation({\n      mutationFn: async (realEstatePropertyDetails: { id: string }) => {\n        const { data: deletedProperty } = await client.models.RealEstateProperty.delete(realEstatePropertyDetails);\n        return deletedProperty;\n      },\n      // When mutate is called:\n      onMutate: async (newRealEstateProperty) => {\n        // Cancel any outgoing refetches\n        // (so they don't overwrite our optimistic update)\n        await queryClient.cancelQueries({\n          queryKey: [\"realEstateProperties\", newRealEstateProperty.id],\n        });\n\n\n        await queryClient.cancelQueries({\n          queryKey: [\"realEstateProperties\"],\n        });\n\n\n        // Snapshot the previous value\n        const previousRealEstateProperty = queryClient.getQueryData([\n          \"realEstateProperties\",\n          newRealEstateProperty.id,\n        ]);\n\n\n        // Optimistically update to the new value\n        if (previousRealEstateProperty) {\n          queryClient.setQueryData(\n            [\"realEstateProperties\", newRealEstateProperty.id],\n            newRealEstateProperty\n          );\n        }\n\n\n        // Return a context with the previous and new realEstateProperty\n        return { previousRealEstateProperty, newRealEstateProperty };\n      },\n      // If the mutation fails, use the context we returned above\n      onError: (err, newRealEstateProperty, context) => {\n        console.error(\"Error deleting record:\", err, newRealEstateProperty);\n        if (context?.previousRealEstateProperty) {\n          queryClient.setQueryData(\n            [\"realEstateProperties\", context.newRealEstateProperty.id],\n            context.previousRealEstateProperty\n          );\n        }\n      },\n      // Always refetch after error or success:\n      onSettled: (newRealEstateProperty) => {\n        if (newRealEstateProperty) {\n          queryClient.invalidateQueries({\n            queryKey: [\"realEstateProperties\", newRealEstateProperty.id],\n          });\n          queryClient.invalidateQueries({\n            queryKey: [\"realEstateProperties\"],\n          });\n        }\n      },\n    });\n\n\n    return (\n      <div style={styles.detailViewContainer}>\n        <h2>Real Estate Property Detail View</h2>\n        {isErrorQuery && <div>{\"Problem loading Real Estate Property\"}</div>}\n        {isLoading && (\n          <div style={styles.loadingIndicator}>\n            {\"Loading Real Estate Property...\"}\n          </div>\n        )}\n        {isSuccess && (\n          <div>\n            <p>{`Name: ${realEstateProperty?.name}`}</p>\n            <p>{`Address: ${realEstateProperty?.address}`}</p>\n          </div>\n        )}\n        {realEstateProperty && (\n          <div>\n            <div>\n              {updateMutation.isPending ? (\n                \"Updating Real Estate Property...\"\n              ) : (\n                <>\n                  {updateMutation.isError &&\n                    updateMutation.error instanceof Error ? (\n                    <div>An error occurred: {updateMutation.error.message}</div>\n                  ) : null}\n\n\n                  {updateMutation.isSuccess ? (\n                    <div>Real Estate Property updated!</div>\n                  ) : null}\n\n\n                  <button\n                    onClick={() =>\n                      updateMutation.mutate({\n                        id: realEstateProperty.id,\n                        name: `Updated Home ${Date.now()}`,\n                      })\n                    }\n                  >\n                    Update Name\n                  </button>\n                  <button\n                    onClick={() =>\n                      updateMutation.mutate({\n                        id: realEstateProperty.id,\n                        address: `${Math.floor(\n                          1000 + Math.random() * 9000\n                        )} Main St`,\n                      })\n                    }\n                  >\n                    Update Address\n                  </button>\n                </>\n              )}\n            </div>\n\n\n            <div>\n              {deleteMutation.isPending ? (\n                \"Deleting Real Estate Property...\"\n              ) : (\n                <>\n                  {deleteMutation.isError &&\n                    deleteMutation.error instanceof Error ? (\n                    <div>An error occurred: {deleteMutation.error.message}</div>\n                  ) : null}\n\n\n                  {deleteMutation.isSuccess ? (\n                    <div>Real Estate Property deleted!</div>\n                  ) : null}\n\n\n                  <button\n                    onClick={() =>\n                      deleteMutation.mutate({\n                        id: realEstateProperty.id,\n                      })\n                    }\n                  >\n                    Delete\n                  </button>\n                </>\n              )}\n            </div>\n          </div>\n        )}\n        <button onClick={() => setCurrentRealEstatePropertyId(null)}>\n          Back\n        </button>\n      </div>\n    );\n\n\n\n\n  }\n  return (\n    <div>\n      {!currentRealEstatePropertyId && (\n        <div style={styles.appContainer}>\n          <h1>Real Estate Properties:</h1>\n          <div>\n            {createMutation.isPending ? (\n              \"Adding Real Estate Property...\"\n            ) : (\n              <>\n                {createMutation.isError &&\n                createMutation.error instanceof Error ? (\n                  <div>An error occurred: {createMutation.error.message}</div>\n                ) : null}\n\n\n                {createMutation.isSuccess ? (\n                  <div>Real Estate Property added!</div>\n                ) : null}\n\n\n                <button\n                  onClick={() => {\n                    createMutation.mutate({\n                      name: `New Home ${Date.now()}`,\n                      address: `${Math.floor(\n                        1000 + Math.random() * 9000\n                      )} Main St`,\n                    });\n                  }}\n                >\n                  Add RealEstateProperty\n                </button>\n              </>\n            )}\n          </div>\n          <ul style={styles.propertiesList}>\n            {isLoading && (\n              <div style={styles.loadingIndicator}>\n                {\"Loading Real Estate Properties...\"}\n              </div>\n            )}\n            {isErrorQuery && (\n              <div>{\"Problem loading Real Estate Properties\"}</div>\n            )}\n            {isSuccess &&\n              realEstateProperties?.map((realEstateProperty, idx) => {\n                if (!realEstateProperty) return null;\n                return (\n                  <li\n                    style={styles.listItem}\n                    key={`${idx}-${realEstateProperty.id}`}\n                  >\n                    <p>{realEstateProperty.name}</p>\n                    <button\n                      style={styles.detailViewButton}\n                      onClick={() =>\n                        setCurrentRealEstatePropertyId(realEstateProperty.id)\n                      }\n                    >\n                      Detail View\n                    </button>\n                  </li>\n                );\n              })}\n          </ul>\n        </div>\n      )}\n      {currentRealEstatePropertyId && <RealEstatePropertyDetailView />}\n      <GlobalLoadingIndicator />\n    </div>\n  );\n\n\n}\n\n\nexport default App\n\n\nconst styles = {\n  appContainer: {\n    display: \"flex\",\n    flexDirection: \"column\",\n    alignItems: \"center\",\n  },\n  detailViewButton: { marginLeft: \"1rem\" },\n  detailViewContainer: { border: \"1px solid black\", padding: \"3rem\" },\n  globalLoadingIndicator: {\n    position: \"fixed\",\n    top: 0,\n    left: 0,\n    width: \"100%\",\n    height: \"100%\",\n    border: \"4px solid blue\",\n    pointerEvents: \"none\",\n  },\n  listItem: {\n    display: \"flex\",\n    justifyContent: \"space-between\",\n    border: \"1px dotted grey\",\n    padding: \".5rem\",\n    margin: \".1rem\",\n  },\n  loadingIndicator: {\n    border: \"1px solid black\",\n    padding: \"1rem\",\n    margin: \"1rem\",\n  },\n  propertiesList: {\n    display: \"flex\",\n    flexDirection: \"column\",\n    alignItems: \"center\",\n    justifyContent: \"start\",\n    width: \"50%\",\n    border: \"1px solid black\",\n    padding: \"1rem\",\n    listStyleType: \"none\",\n  },\n} as const;\nPREVIOUS\nConnect to data from Server-side Runtimes\nNEXT\nModify Amplify-generated AWS resources"
  },
  {
    "title": "Manage Data with Amplify console - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/manage-with-amplify-console/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nManage Data with Amplify console\nManage Data with Amplify console\n\nThe Data manager page in the Amplify Console offers a user-friendly interface for managing the backend GraphQL API data of an application. It enables real-time creation and updates of application data, eliminating the need to build separate admin views.\n\nIf you have not yet created a data resource, visit the Data setup guide.\n\nAccess Data manager\n\nAfter you've deployed your data resource, you can access the manager on Amplify console.\n\nLog in to the Amplify console and choose your app.\nSelect the branch you would like to access.\nSelect Data from the left navigation bar.\nThen, select Data manager.\nTo create a record\nOn the Data manager page, select a table from the Select table dropdown. For this example, we are using a Todo table.\nSelect Create Todo.\nIn the Add Todo pane, specify your custom values for the fields in the table. For example, enter my first todo for the Content field and toggle the Is done field.\nSelect Submit.\nTo update a record\nOn the Data manager page, select a table from the Select table dropdown.\nFrom the list of records, select a record you want to update.\nIn the Edit Todo pane, make any changes to your record, and then select Submit.\nTo delete a record(s)\nOn the Data manager page, select a table from the Select table dropdown.\nFrom the list of records, select the checkbox to the left of the record(s) you want to delete.\nSelect the Actions dropdown, and then select delete item(s) .\nTo Seed records\nOn the Data manager page, select a table from the Select table dropdown.\nSelect the Actions dropdown and then select Auto-generate data.\nIn the Auto-generate data pane, specify how many rows of data you want to generate and constraints for the generated data.\nThen select Generate data\n\nYou can generate up to 100 records at a time.\n\nSeed data cannot be generated for tables that have the following field types: AWSPhone, Enum, Custom Type, or Relationship\n\nTo download records\nOn the Data manager page, select a table from the Select table dropdown.\nSelect the Actions dropdown.\nHere you have two options for downloading data.\nChoose Download selected items (.csv) to download only the selected rows of data.\nChoose Download all items (.csv) to download all rows of records on the currently selected table.\nOnce you have selected a download option, your data should immediately start downloading as a CSV file.\nPREVIOUS\nModify Amplify-generated AWS resources"
  },
  {
    "title": "Modify Amplify-generated AWS resources - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/override-resources/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nModify Amplify-generated AWS resources\nModify Amplify-generated AWS resources\n\nAmplify GraphQL API uses a variety of auto-generated, underlying AWS services and resources. You can customize these underlying resources to optimize the deployed stack for your specific use case.\n\nIn your Amplify app, you can access every underlying resource using CDK \"L2\" or \"L1\" constructs. Access the generated resources as L2 constructs via the .resources property on the returned stack or access the generated resources as L1 constructs using the .resources.cfnResources property.\n\nCopy\ncode example\nimport { defineBackend } from '@aws-amplify/backend';\nimport { data } from './data/resource';\n\n\nconst backend = defineBackend({\n  data\n});\n\n\nconst dataResources = backend.data.resources;\n\n\nObject.values(dataResources.cfnResources.amplifyDynamoDbTables).forEach((table) => {\n  table.pointInTimeRecoveryEnabled = true;\n});\nCustomize Amplify-generated AppSync GraphQL API resources\n\nApply all the customizations on backend.data.resources.graphqlApi or backend.data.resources.cfnResources.cfnGraphqlApi. For example, to enable X-Ray tracing for the AppSync GraphQL API:\n\nCopy\ncode example\nimport { defineBackend } from '@aws-amplify/backend';\nimport { data } from './data/resource';\n\n\nconst backend = defineBackend({\n  data\n});\n\n\nconst dataResources = backend.data.resources;\n\n\ndataResources.cfnResources.cfnGraphqlApi.xrayEnabled = true;\nCustomize Amplify-generated resources for data models\n\nPass in the model type name into backend.data.resources.amplifyDynamoDbTables[\"MODEL_NAME\"] to modify the resources generated for that particular model type. For example, to enable time-to-live on the Todo @model type's DynamoDB table:\n\nCopy\ncode example\nimport { defineBackend } from '@aws-amplify/backend';\nimport { data } from './data/resource';\n\n\nconst backend = defineBackend({\n  data\n});\n\n\nconst dataResources = backend.data.resources;\n\n\ndataResources.cfnResources.amplifyDynamoDbTables[\"Todo\"].timeToLiveAttribute = {\n  attributeName: \"ttl\",\n  enabled: true,\n};\nExample - Configure billing mode on a DynamoDB table\n\nSet the DynamoDB billing mode for the DynamoDB table as either \"PROVISIONED\" or \"PAY_PER_REQUEST\".\n\nCopy\ncode example\nimport { defineBackend } from '@aws-amplify/backend';\nimport { data } from './data/resource';\nimport { BillingMode } from \"aws-cdk-lib/aws-dynamodb\";\n\n\nconst backend = defineBackend({\n  data\n});\nconst dataResources = backend.data.resources;\n\n\ndataResources.cfnResources.amplifyDynamoDbTables['Todo'].billingMode = BillingMode.PAY_PER_REQUEST;\nExample - Configure provisioned throughput for a DynamoDB table\n\nOverride the default ProvisionedThroughput provisioned for each model table and its Global Secondary Indexes (GSI). This override is only valid if the \"DynamoDBBillingMode\" is set to \"PROVISIONED\".\n\nCopy\ncode example\nimport { defineBackend } from '@aws-amplify/backend';\nimport { data } from './data/resource';\n\n\nconst backend = defineBackend({\n  data\n});\n\n\nconst dataResources = backend.data.resources;\n\n\ndataResources.cfnResources.amplifyDynamoDbTables[\"Todo\"].provisionedThroughput = {\n  readCapacityUnits: 5,\n  writeCapacityUnits: 5,\n};\nExample - Enable point-in-time recovery for a DynamoDB table\n\nEnable/disable DynamoDB point-in-time recovery for each model table.\n\nCopy\ncode example\nimport { defineBackend } from '@aws-amplify/backend';\nimport { data } from './data/resource';\n\n\nconst backend = defineBackend({\n  data\n});\n\n\nconst dataResources = backend.data.resources;\n\n\ndataResources.cfnResources.amplifyDynamoDbTables['Todo'].pointInTimeRecoveryEnabled = true;\nPREVIOUS\nOptimistic UI\nNEXT\nManage Data with Amplify console"
  },
  {
    "title": "Next.js server runtime - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/connect-from-server-runtime/nextjs-server-runtime/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nConnect to data from Server-side Runtimes\n/\nNext.js server runtime\nNext.js server runtime\n\nThis guide walks through how you can connect to Amplify Data from Next.js Server-side Runtimes (SSR). For Next.js applications, Amplify provides first-class support for the App Router (React Server Components, Route Handlers, and Server Actions), the Pages Router (Components, API Routes), and Middleware.\n\nBefore you begin, you will need:\n\nA Next.js application created\nInstalled and configured Amplify libraries for Next.js\nDeployed Amplify Data resources, or directly using AWS AppSync\nConnect to Amplify Data from a Next.js server runtime\n\nConnecting to Amplify Data will include choosing the correct data client for Next.js server runtimes, generating the data client, and then calling the API.\n\nStep 1 - Choose the correct Data client for Next.js server runtimes\n\nAmplify offers two specialized data clients for Next.js server runtimes (from @aws-amplify/adapter-nextjs/data) that you should use depending whether you retrieve the user tokens using cookies or NextRequest and NextResponse:\n\ngenerateServerClientUsingCookies() 🍪 generates a data client with the Next.js cookies function from next/headers. Each API request dynamically refetches the cookies at runtime.\ngenerateServerClientUsingReqRes() 🌐 generates a data client requiring NextRequest and NextResponse provided to an runWithAmplifyServerContext function to prevent token contamination.\n\nChoose the correct data client based on your Next.js Router (App or Pages) and then the use case:\n\nApp Router\nPages Router\nUse case\tRequired Data client\nReact Server Component\tgenerateServerClientUsingCookies() 🍪\nServer Actions\tgenerateServerClientUsingCookies() 🍪\nRoute Handler\tgenerateServerClientUsingCookies() 🍪\nMiddleware\tgenerateServerClientUsingReqRes() 🌐\nStep 2 - Generate the Data client for Next.js server runtimes\ngenerateServerClientUsingCookies() 🍪\ngenerateServerClientUsingReqRes() 🌐\n\nTo generate a Data client for the Next.js server runtime using cookies, you need to provide both your Amplify configuration and the cookies function from Next.js.\n\nCopy\ncode example\nimport { type Schema } from '@/amplify/data/resource';\nimport { generateServerClientUsingCookies } from '@aws-amplify/adapter-nextjs/data';\nimport outputs from '@/amplify_outputs.json';\nimport { cookies } from 'next/headers';\n\n\nexport const cookieBasedClient = generateServerClientUsingCookies<Schema>({\n  config: outputs,\n  cookies,\n});\n\nWe recommend you generate Amplify Data's server client in a utility file. Then, import the generated client in your Next.js React Server Components, Server Actions, or Route Handlers.\n\nStep 3 - Call API using generated server Data clients\n\nYou can make any available query or mutation request with the generated server data clients; however, note that subscriptions are not available within server runtimes.\n\ngenerateServerClientUsingCookies() 🍪\ngenerateServerClientUsingReqRes() 🌐\n\nImport the cookie-based server Data client in your Next.js React Server Component code and make your API requests.\n\nCopy\ncode example\nimport { type Schema } from '@/amplify/data/resource';\nimport { generateServerClientUsingCookies } from '@aws-amplify/adapter-nextjs/data';\nimport outputs from '@/amplify_outputs.json';\nimport { cookies } from 'next/headers';\n\n\nexport const cookieBasedClient = generateServerClientUsingCookies<Schema>({\n  config: outputs,\n  cookies,\n});\n\n\nconst fetchTodos = async () => {\n  const { data: todos, errors } = await cookieBasedClient.models.Todo.list();\n\n\n  if (!errors) {\n    return todos;\n  }\n};\nNEXT\nNuxt.js server runtime"
  },
  {
    "title": "Connect to external Amazon DynamoDB data sources - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/connect-to-existing-data-sources/connect-external-ddb-table/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nConnect to existing data sources\n/\nConnect to external Amazon DynamoDB data sources\nConnect to external Amazon DynamoDB data sources\n\nThe a.model() data model allows you to define a GraphQL schema for an AWS AppSync API where models are backed by DynamoDB Tables managed by Amplify. The generated schema also provides queries and mutations to the Amplify Data client. However, you may want to connect to an external DynamoDB table and execute custom business logic against it instead.\n\nUsing an external DynamoDB table as a data source may be useful if you need to leverage patterns such as single table design.\n\nIn the following sections, we walk through the steps to add and use an external DynamoDB table as a data source for your API:\n\nSet up your Amazon DynamoDB table\nAdd your Amazon DynamoDB table as a data source\nDefine custom queries and mutations\nConfigure custom business logic handler code\nInvoke custom queries or mutations\nStep 1 - Set up your Amazon DynamoDB table\n\nFor the purpose of this guide we will define a Post type and create an external DynamoDB table that will store records for it. In Amplify Gen 2, customType adds a type to the schema that is not backed by an Amplify-generated DynamoDB table.\n\nWith the Post type defined, it can then be referenced as the return type when defining your custom queries and mutations.\n\nFirst, add the Post custom type to your schema:\n\namplify/data/resource.ts\nimport { type ClientSchema, a, defineData } from \"@aws-amplify/backend\";\n\n\nconst schema = a.schema({\n  Todo: a\n    .model({\n      content: a.string(),\n    })\n    .authorization(allow => [allow.publicApiKey()]),\nCopy\nhighlighted code example\n  Post: a.customType({\n    id: a.id().required(),\n    author: a.string().required(),\n    title: a.string(),\n    content: a.string(),\n    url: a.string(),\n    ups: a.integer(),\n    downs: a.integer(),\n    version: a.integer(),\n  }),\n});\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    defaultAuthorizationMode: 'apiKey',\n    apiKeyAuthorizationMode: {\n      expiresInDays: 30,\n    },\n  },\n});\n\nNOTE: To comply with the GraphQL spec, at least one query is required for a schema to be valid. Otherwise, deployments will fail with a schema error. The Amplify Data schema is auto-generated with a Todo model and corresponding queries under the hood. You can leave the Todo model in the schema until you add the first custom query to the schema in the next steps.\n\nOnce the deployment successfully completes, navigate to the AppSync console and select your Amplify-generated API. Follow these steps to create a new DynamoDB table:\n\nOn the Schema page, choose Create Resources.\n\nChoose Use existing type, then choose the Post type.\n\nSet the Primary key to id and the Sort key to None.\n\nDisable Automatically generate GraphQL. In this example, we'll create the resolver ourselves.\n\nChoose Create.\n\nYou now have a new DynamoDB table named PostTable, which you can see by visiting Data sources in the side tab. You will use this table as the data source for your custom queries and mutations to your Amazon DynamoDB table.\n\nStep 2 - Add your Amazon DynamoDB table as a data source\n\nIn your amplify/backend.ts file, add your DynamoDB table as a data source for your API:\n\namplify/backend.ts\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\nimport { aws_dynamodb } from \"aws-cdk-lib\";\n\n\nexport const backend = defineBackend({\n  auth,\n  data,\n});\n\n\nCopy\nhighlighted code example\nconst externalDataSourcesStack = backend.createStack(\"MyExternalDataSources\");\n\n\nconst externalTable = aws_dynamodb.Table.fromTableName(\n  externalDataSourcesStack,\n  \"MyExternalPostTable\",\n  \"PostTable\"\n);\n\n\nbackend.data.addDynamoDbDataSource(\n  \"ExternalPostTableDataSource\",\n  externalTable\n);\nStep 3 - Define custom queries and mutations\n\nNow that your DynamoDB table has been added as a data source, you can reference it in custom queries and mutations using the a.handler.custom() modifier which accepts the name of the data source and an entry point for your resolvers.\n\nUse the following code examples to add addPost, getPost, updatePost, and deletePost as custom queries and mutations to your schema:\n\naddPost\ngetPost\nupdatePost\ndeletePost\namplify/data/resource.ts\nimport { type ClientSchema, a, defineData } from \"@aws-amplify/backend\";\n\n\nconst schema = a.schema({\n  Post: a.customType({\n    author: a.string().required(),\n    title: a.string(),\n    content: a.string(),\n    url: a.string(),\n    ups: a.integer(),\n    downs: a.integer(),\n    version: a.integer(),\n  }),\nCopy\nhighlighted code example\n  addPost: a\n    .mutation()\n    .arguments({\n      id: a.id(),\n      author: a.string().required(),\n      title: a.string(),\n      content: a.string(),\n      url: a.string(),\n    })\n    .returns(a.ref(\"Post\"))\n    .authorization(allow => [allow.publicApiKey()])\n    .handler(\n      a.handler.custom({\n        dataSource: \"ExternalPostTableDataSource\",\n        entry: \"./addPost.js\",\n      })\n    ),\n});\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    defaultAuthorizationMode: 'apiKey',\n    apiKeyAuthorizationMode: {\n      expiresInDays: 30,\n    },\n  },\n});\nStep 4 - Configure custom business logic handler code\n\nNext, create the following files in your amplify/data folder and use the code examples to define custom resolvers for the custom queries and mutations added to your schema from the previous step. These are AppSync JavaScript resolvers\n\naddPost\ngetPost\nupdatePost\ndeletePost\namplify/data/addPost.js\nCopy\namplify/data/addPost.js code example\nimport { util } from \"@aws-appsync/utils\";\nimport * as ddb from \"@aws-appsync/utils/dynamodb\";\n\n\nexport function request(ctx) {\n  const item = { ...ctx.arguments, ups: 1, downs: 0, version: 1 };\n  const key = { id: ctx.args.id ?? util.autoId() };\n  return ddb.put({ key, item });\n}\n\n\nexport function response(ctx) {\n  return ctx.result;\n}\nStep 5 - Invoke custom queries or mutations\n\nFrom your generated Data client, you can find all your custom queries and mutations under the client.queries. and client.mutations. APIs respectively.\n\naddPost\ngetPost\nupdatePost\ndeletePost\nApp.tsx\nCopy\nApp.tsx code example\nconst { data, errors } = await client.mutations.addPost({\n  title: \"My Post\",\n  content: \"My Content\",\n  author: \"Chris\",\n});\nConclusion\n\nIn this guide, you’ve added an external DynamoDB table as a data source to an Amplify GraphQL API and defined custom queries and mutations, handled by AppSync JS resolvers, to manipulate Post items in an external DynamoDB table using the Amplify Gen 2 Data client.\n\nTo clean up, you can delete your sandbox by accepting the prompt when terminating the sandbox process in your terminal. Alternatively, you can also use the AWS Amplify console to manage and delete sandbox environments.\n\nTo delete your external DynamoDB table, you can navigate to the AppSync console and click on the name of the table in the data sources list. This takes you to the DynamoDB console where you can delete the table.\n\nAll DynamoDB operations & example resolvers\nGetItem\n\nReference - The GetItem request lets you tell the AWS AppSync DynamoDB function to make a GetItem request to DynamoDB, and enables you to specify:\n\nThe key of the item in DynamoDB\n\nWhether to use a consistent read or not\n\nExample:\n\nCopy\ncode example\nexport function request(ctx) {\n  const {foo, bar} = ctx.args\n  return {\n    operation : \"GetItem\",\n    key : util.dynamodb.toMapValues({foo, bar}),\n    consistentRead : true\n  }\n}\nPutItem\n\nPutItem - The PutItem request mapping document lets you tell the AWS AppSync DynamoDB function to make a PutItem request to DynamoDB, and enables you to specify the following:\n\nThe key of the item in DynamoDB\n\nThe full contents of the item (composed of key and attributeValues)\n\nConditions for the operation to succeed\n\nExample:\n\nCopy\ncode example\nimport { util } from '@aws-appsync/utils';\nexport function request(ctx) {\n  const { foo, bar, ...values} = ctx.args\n  return {\n    operation: 'PutItem',\n    key: util.dynamodb.toMapValues({foo, bar}),\n    attributeValues: util.dynamodb.toMapValues(values),\n  };\n}\nUpdateItem\n\nUpdateItem - The UpdateItem request enables you to tell the AWS AppSync DynamoDB function to make a UpdateItem request to DynamoDB and allows you to specify the following:\n\nThe key of the item in DynamoDB\n\nAn update expression describing how to update the item in DynamoDB\n\nConditions for the operation to succeed\n\nExample:\n\nCopy\ncode example\nimport { util } from '@aws-appsync/utils';\nexport function request(ctx) {\n  const { id } = ctx.args;\n  return {\n    operation: 'UpdateItem',\n    key: util.dynamodb.toMapValues({ id }),\n    update: {\n      expression: 'ADD #voteField :plusOne, version :plusOne',\n      expressionNames: { '#voteField': 'upvotes' },\n      expressionValues: { ':plusOne': { N: 1 } },\n    },\n  };\n}\nDeleteItem\n\nDeleteItem - The DeleteItem request lets you tell the AWS AppSync DynamoDB function to make a DeleteItem request to DynamoDB, and enables you to specify the following:\n\nThe key of the item in DynamoDB\n\nConditions for the operation to succeed\n\nExample:\n\nCopy\ncode example\nimport { util } from '@aws-appsync/utils';\nexport function request(ctx) {\n  return {\n    operation: 'DeleteItem',\n    key: util.dynamodb.toMapValues({ id: ctx.args.id }),\n  };\n}\nQuery\n\nQuery - The Query request object lets you tell the AWS AppSync DynamoDB resolver to make a Query request to DynamoDB, and enables you to specify the following:\n\nKey expression\n\nWhich index to use\n\nAny additional filter\n\nHow many items to return\n\nWhether to use consistent reads\n\nquery direction (forward or backward)\n\nPagination token\n\nExample:\n\nCopy\ncode example\nimport { util } from '@aws-appsync/utils';\n\n\nexport function request(ctx) {\n  const { owner } = ctx.args;\n  return {\n    operation: 'Query',\n    query: {\n      expression: 'ownerId = :ownerId',\n      expressionValues: util.dynamodb.toMapValues({ ':ownerId': owner }),\n    },\n    index: 'owner-index',\n  };\n}\nScan\n\nScan - The Scan request lets you tell the AWS AppSync DynamoDB function to make a Scan request to DynamoDB, and enables you to specify the following:\n\nA filter to exclude results\n\nWhich index to use\n\nHow many items to return\n\nWhether to use consistent reads\n\nPagination token\n\nParallel scans\n\nExample:\n\nCopy\ncode example\nexport function request(ctx) {\n  return { operation: 'Scan' };\n}\nSync\n\nSync - The Sync request object lets you retrieve all the results from a DynamoDB table and then receive only the data altered since your last query (the delta updates). Sync requests can only be made to versioned DynamoDB data sources. You can specify the following:\n\nA filter to exclude results\n\nHow many items to return\n\nPagination Token\n\nWhen your last Sync operation was started\n\nExample:\n\nCopy\ncode example\nexport function request(ctx) {\n  const { nextToken, lastSync } = ctx.args;\n  return { operation: 'Sync', limit: 100, nextToken, lastSync };\n}\nBatchGetItem\n\nBatchGetItem - The BatchGetItem request object lets you tell the AWS AppSync DynamoDB function to make a BatchGetItem request to DynamoDB to retrieve multiple items, potentially across multiple tables. For this request object, you must specify the following:\n\nThe table names where to retrieve the items from\n\nThe keys of the items to retrieve from each table\n\nThe DynamoDB BatchGetItem limits apply and no condition expression can be provided.\n\nExample:\n\nCopy\ncode example\nimport { util } from '@aws-appsync/utils';\n\n\nexport function request(ctx) {\n  const { authorId, postId } = ctx.args;\n  return {\n    operation: 'BatchGetItem',\n    tables: {\n      authors: [util.dynamodb.toMapValues({ authorId })],\n      posts: [util.dynamodb.toMapValues({ authorId, postId })],\n    },\n  };\n}\nBatchDeleteItem\n\nBatchDeleteItem - The BatchDeleteItem request object lets you tell the AWS AppSync DynamoDB function to make a BatchWriteItem request to DynamoDB to delete multiple items, potentially across multiple tables. For this request object, you must specify the following:\n\nThe table names where to delete the items from\n\nThe keys of the items to delete from each table\n\nThe DynamoDB BatchWriteItem limits apply and no condition expression can be provided.\n\nExample:\n\nCopy\ncode example\nimport { util } from '@aws-appsync/utils';\n\n\nexport function request(ctx) {\n  const { authorId, postId } = ctx.args;\n  return {\n    operation: 'BatchDeleteItem',\n    tables: {\n      authors: [util.dynamodb.toMapValues({ authorId })],\n      posts: [util.dynamodb.toMapValues({ authorId, postId })],\n    },\n  };\n}\nBatchPutItem\n\nBatchPutItem - The BatchPutItem request object lets you tell the AWS AppSync DynamoDB function to make a BatchWriteItem request to DynamoDB to put multiple items, potentially across multiple tables. For this request object, you must specify the following:\n\nThe table names where to put the items in\n\nThe full items to put in each table\n\nThe DynamoDB BatchWriteItem limits apply and no condition expression can be provided.\n\nExample:\n\nCopy\ncode example\nimport { util } from '@aws-appsync/utils';\n\n\nexport function request(ctx) {\n  const { authorId, postId, name, title } = ctx.args;\n  return {\n    operation: 'BatchPutItem',\n    tables: {\n      authors: [util.dynamodb.toMapValues({ authorId, name })],\n      posts: [util.dynamodb.toMapValues({ authorId, postId, title })],\n    },\n  };\n}\nTransactGetItems\n\nTransactGetItems - The TransactGetItems request object lets you to tell the AWS AppSync DynamoDB function to make a TransactGetItems request to DynamoDB to retrieve multiple items, potentially across multiple tables. For this request object, you must specify the following:\n\nThe table name of each request item where to retrieve the item from\n\nThe key of each request item to retrieve from each table\n\nThe DynamoDB TransactGetItems limits apply and no condition expression can be provided.\n\nExample:\n\nCopy\ncode example\nimport { util } from '@aws-appsync/utils';\n\n\nexport function request(ctx) {\n  const { authorId, postId } = ctx.args;\n  return {\n    operation: 'TransactGetItems',\n    transactItems: [\n      {\n        table: 'posts',\n        key: util.dynamodb.toMapValues({ postId }),\n      },\n      {\n        table: 'authors',\n        key: util.dynamodb.toMapValues({ authorId }),\n      },\n    ],\n  };\n}\nTransactWriteItems\n\nTransactWriteItems - The TransactWriteItems request object lets you tell the AWS AppSync DynamoDB function to make a TransactWriteItems request to DynamoDB to write multiple items, potentially to multiple tables. For this request object, you must specify the following:\n\nThe destination table name of each request item\n\nThe operation of each request item to perform. There are four types of operations that are supported: PutItem, UpdateItem, DeleteItem, and ConditionCheck\n\nThe key of each request item to write\n\nThe DynamoDB TransactWriteItems limits apply.\n\nExample:\n\nCopy\ncode example\nimport { util } from '@aws-appsync/utils';\n\n\nexport function request(ctx) {\n  const { authorId, postId, title, description, oldTitle, authorName } = ctx.args;\n  return {\n    operation: 'TransactWriteItems',\n    transactItems: [\n      {\n        table: 'posts',\n        operation: 'PutItem',\n        key: util.dynamodb.toMapValues({ postId }),\n        attributeValues: util.dynamodb.toMapValues({ title, description }),\n        condition: util.transform.toDynamoDBConditionExpression({\n          title: { eq: oldTitle },\n        }),\n      },\n      {\n        table: 'authors',\n        operation: 'UpdateItem',\n        key: util.dynamodb.toMapValues({ authorId }),\n        update: {\n          expression: 'SET authorName = :name',\n          expressionValues: util.dynamodb.toMapValues({ ':name': authorName }),\n        },\n      },\n    ],\n  };\n}\nPREVIOUS\nConnect your app to existing MySQL and PostgreSQL database"
  },
  {
    "title": "Connect your app to existing MySQL and PostgreSQL database - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/connect-to-existing-data-sources/connect-postgres-mysql-database/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nConnect to existing data sources\n/\nConnect your app to existing MySQL and PostgreSQL database\nConnect your app to existing MySQL and PostgreSQL database\n\nAmplify's native integration supports any MySQL or Postgres database, no matter if they're hosted on AWS within a VPC or outside of AWS with a 3rd party hosted database provider.\n\nYou must create a connection string using the following database information to get started:\n\nDatabase hostname\nDatabase port\nDatabase username\nDatabase user password\nDatabase name\n\nOnly databases with certificates from well-known certificate providers are supported. Support for databases using custom or self-signed SSL certificates is under active development.\n\nAmplify's MySQL and PostgreSQL feature builds on top of AWS Lambda with a Node.js runtime. By default, Node.js includes root certificate authority (CA) certificates from well-known certificate providers. Lambda Node.js runtimes up to Node.js 18 augments these certificates with Amazon-specific CA certificates, making it easier to create functions accessing other AWS services.\n\nStep 1 - Set secrets for database connection\n\nFirst, provide all the database connection information as secrets, you can use the Amplify sandbox's secret functionality to set them or go to the Amplify console to set secrets in a shared environment:\n\nCopy\ncode example\nnpx ampx sandbox secret set SQL_CONNECTION_STRING\nMySQL\nPostgreSQL\n\nConnection string format for MySQL\n\nmysql://user:password@hostname:port/db-name\nStep 2 - Generate TypeScript representation of your database schema\n\nRun the following command to generate the Data schema with your database connection information. It'll infer an a.model() representation for all database tables that have primary key specified.\n\nCopy\ncode example\nnpx ampx generate schema-from-database --connection-uri-secret SQL_CONNECTION_STRING --out amplify/data/schema.sql.ts\nInfo\nConnecting to a database behind the VPC\nInfo\nHandling of implicit fields (id, createdAt, updatedAt)\nLearn more\nRDS Proxy for improved connectivity\n\nThis creates a new schema.sql.ts with a schema reflecting the types of your database. Do not edit the schema.sql.ts file directly. Import the schema to your amplify/data/resource.ts file and apply any additive changes there. This ensures that you can continuously regenerate the TypeScript schema representation of your SQL database without losing any additive changes that you apply out-of-band.\n\nimport { type ClientSchema, a, defineData } from '@aws-amplify/backend';\nCopy\nhighlighted code example\nimport { schema as generatedSqlSchema } from './schema.sql';\n\n\n// Add a global authorization rule\nconst sqlSchema = generatedSqlSchema.authorization(allow => allow.guest())\n\n\n// Relational database sources can coexist with DynamoDB tables managed by Amplify.\nconst schema = a.schema({\n  Todo: a.model({\n    content: a.string(),\n  }).authorization(allow => [allow.guest()])\n});\n\n\n// Use the a.combine() operator to stitch together the models backed by DynamoDB\n// and the models backed by Postgres or MySQL databases.\nCopy\nhighlighted code example\nconst combinedSchema = a.combine([schema, sqlSchema]);\n\n\n// Don't forget to update your client types to take into account the types from\n// both schemas.\nCopy\nhighlighted code example\nexport type Schema = ClientSchema<typeof combinedSchema>;\n\n\nexport const data = defineData({\n  // Update the data definition to use the combined schema, instead of just\n  // your DynamoDB-backed schema\nCopy\nhighlighted code example\n  schema: combinedSchema\n});\nStep 3 - Fine-grained authorization rules\n\nUse the .setAuthorization() modifier to set model-level and field-level authorization rules for the SQL-backed data models. Review Customize your auth rules for detailed authorization rule options.\n\n// Add an authorization rule to the schema\nCopy\nhighlighted code example\nconst sqlSchema = generatedSqlSchema.setAuthorization((models) => [\n  // Model-level authorization rules\n  models.event.authorization((allow) => [allow.publicApiKey()]),\n  // Field-level authorization rules\n  models.event.fields.id.authorization(allow => [allow.publicApiKey(), allow.guest()]),\n  models.event.fields.created_at.authorization(allow => [allow.publicApiKey(), allow.guest()])\n]);\nStep 4 - Deploy your Data resources using the cloud sandbox\n\nFinally, you can now validate your Data resources with your cloud sandbox:\n\nCopy\ncode example\nnpx ampx sandbox\n\nOn the client side, you can now make create, read, update, delete, and subscribe to your SQL-backed data models:\n\nCopy\ncode example\nconst { data: events } = await client.models.event.list()\nStep 5 - Configuring database connection for production\n\nWhen deploying your app to production, you need to add the database connection string as a secret. Make sure to add the appropriate database connection string with the same secret name you used in the sandbox environment. For example, we used SQL_CONNECTION_STRING above.\n\nRename generated models and fields\n\nTo improve the ergonomics of your API, you might want to rename the generate fields or types to better accommodate your use case. Use the renameModels() and renameModelFields() modifiers to rename the auto-inferred data models and their fields.\n\n// Rename models or fields to be more idiomatic for frontend code\nconst sqlSchema = generatedSqlSchema.authorization(allow => allow.guest())\nCopy\nhighlighted code example\n  .renameModels(() => [\n    //⌄⌄⌄⌄⌄ existing model name based on table name\n    ['event', 'Event']\n    //        ^^^^^^ renamed data model name\n  ])\nAdd relationships between tables\nconst sqlSchema = generatedSqlSchema\n  .authorization(allow => allow.guest())\nCopy\nhighlighted code example\n  .setRelationships((models) => [\n    models.Note.relationships({\n      comments: a.hasMany(\"Comment\", \"note_id\"),\n    }),\n    models.Comment.relationships({\n      note: a.belongsTo(\"Note\", \"note_id\")\n    })\n  ]);\nAdd custom queries, mutations, subscriptions auto-generated SQL data schema\n\nUse the .addToSchema(...) to add in additional queries, mutations, and subscriptions to your auto-generated SQL data schema.\n\nNote: you can't add additional data models via a.model(). They should be exclusively generated via npx ampx generate schema-from-database.\n\nUse an inline SQL statement as a query or mutation handler\n// Add custom mutations or queries that execute SQL statements\nconst sqlSchema = generatedSqlSchema.authorization(allow => allow.guest())\nCopy\nhighlighted code example\n  .addToSchema({\n    listEventsWithDecodedLatLong: a.query()\n      // reference custom types added to the schema\n      .returns(a.ref(\"EventWithDecodedCoord\").array())\n      .handler(a.handler.inlineSql(\n          `SELECT\n            id,\n            name,\n            address,\n            ST_X(geom) AS longitude,\n            ST_Y(geom) AS latitude\n          FROM locations;`\n      ))\n      .authorization(allow => [allow.guest()]),\n\n\n      // Define custom types to provide end-to-end typed results\n      // for custom queries / mutations\n      EventWithDecodedCoord: a.customType({\n        id: a.integer(),\n        name: a.string(),\n        address: a.string(),\n        longitude: a.float(),\n        latitude: a.float(),\n      })\n  })\nReference an existing SQL file as a query or mutation handler\n\nYou can define the different SQL handlers in separate .sql files and reference them in your custom queries / mutations.\n\nFirst, configure the custom query or mutation in your amplify/data/resource.ts file:\n\nconst sqlSchema = generatedSqlSchema.authorization(allow => allow.guest())\n  .addToSchema({\n    createNewLocationWithLongLat: a.mutation()\n      .arguments({\n        lat: a.float().required(),\n        long: a.float().required(),\n        name: a.string().required(),\n        address: a.string().required()\n      })\n      .returns(a.json().array())\n      .authorization(allow => allow.authenticated())\nCopy\nhighlighted code example\n      .handler(a.handler.sqlReference('./createNewLocationWithLongLat.sql'))\n  })\n\nNext, add a corresponding sql file to handle the request:\n\nMySQL\nPostgreSQL\ncreateNewLocationWithLongLat.sql\nCopy\ncreateNewLocationWithLongLat.sql code example\nINSERT INTO locations (name, address, geom)\nVALUES (:name, :address, ST_GEOMFROMTEXT(CONCAT('POINT (', :long, ' ', :lat, ')'), 4326));\n\nThe return type for custom queries and mutations expecting to return row data from SQL statements must be an array of the corresponding model. This is true even for custom get queries, where a single row is expected.\n\nExample\n\ngetPostBySlug: a\n  .query()\n  .arguments({\n    slug: a.string().required(),\n  })\nCopy\nhighlighted code example\n  .returns(a.ref(\"Post\").array())\n  .handler(\n    a.handler.inlineSql(`\n    SELECT id, title, slug, content, created_at, updated_at\n    FROM posts\n    WHERE slug = :slug;\n    `)\n  )\nHow does it work?\n\nThe Amplify uses AWS Lambda functions to enable features like querying data from your database. To work properly, these Lambda functions need access to common logic and dependencies.\n\nAmplify provides this shared code in the form of Lambda Layers. You can think of Lambda Layers as a package of reusable runtime code that Lambda functions can reference.\n\nWhen you deploy an Amplify API, it will create two Lambda functions:\n\nSQL Lambda\n\nThis allows you to query and write data to your database from your API.\n\nNOTE: If the database is in a VPC, this Lambda function will be deployed in the same VPC as the database. The usage of Amazon Virtual Private Cloud (VPC) or VPC peering, with AWS Lambda functions will incur additional charges as explained, this comes with an additional cost as explained on the Amazon Elastic Compute Cloud (EC2) on-demand pricing page.\n\nUpdater Lambda\n\nThis automatically keeps the SQL Lambda up-to-date by managing its Lambda Layers.\n\nA Lambda layer that includes all the core SQL connection logic lives within the AWS Amplify service account but is executed within your AWS account, when invoked by the SQL Lambda. This allows the Amplify service team to own the ongoing maintenance and security enhancements of the SQL connection logic.\n\nThis allows the Amplify team to maintain and enhance the SQL Layer without needing direct access to your Lambdas. If updates to the Layer are needed, the Updater Lambda will receive a signal from Amplify and automatically update the SQL Lambda with the latest Layer.\n\nMapping of SQL data types to field types for auto-generated schema\n\nNote: MySQL does not support time zone offsets in date time or timestamp fields. Instead, we will convert these values to datetime, without the offset. Unlike MySQL, PostgreSQL does support date time or timestamp values with an offset.\n\nSQL\tMapped field types\nString\t\nchar\ta.string()\nvarchar\ta.string()\ntinytext\ta.string()\ntext\ta.string()\nmediumtext\ta.string()\nlongtext\ta.string()\nGeometry\t\ngeometry\ta.string()\npoint\ta.string()\nlinestring\ta.string()\ngeometryCollection\ta.string()\nNumeric\t\nsmallint\ta.integer()\nmediumint\ta.integer()\nint\ta.integer()\ninteger\ta.integer()\nbigint\ta.integer()\ntinyint\ta.integer()\nfloat\ta.float()\ndouble\ta.float()\ndecimal\ta.float()\ndec\ta.float()\nnumeric\ta.float()\nDate and Time\t\ndate\ta.date()\ndatetime\ta.datetime()\ntimestamp\ta.datetime()\ntime\ta.time()\nyear\ta.integer()\nBinary\t\nbinary\ta.string()\nvarbinary\ta.string()\ntinyblob\ta.string()\nblob\ta.string()\nmediumblob\ta.string()\nlongblob\ta.string()\nOthers\t\nbool\ta.boolean()\nboolean\ta.boolean()\nbit\ta.integer()\njson\ta.json()\nenum\ta.enum()\nTroubleshooting\nDebug Mode\n\nTo return the actual SQL error instead of a generic error from underlying API responses, an environment variable DEBUG_MODE can be set to true on the Amplify-generated SQL Lambda function. You can find this Lambda function in the AWS Lambda console with the naming convention of: <stack-name>-<api-name>-SQLLambdaFunction<hash>.\n\nMy SQL table doesn't get generated when running npx ampx generate schema-from-database\n\nThis is likely because the table doesn't have a designated primary key. A primary key is required for npx ampx generate schema-from-database to infer the table structure and create a create, read, update, and delete API.\n\nNEXT\nConnect to external Amazon DynamoDB data sources"
  },
  {
    "title": "Connect to data from Server-side Runtimes - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/connect-from-server-runtime/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nConnect to data from Server-side Runtimes\nConnect to data from Server-side Runtimes\nNext.js server runtime\nConnect to Amplify Data from Next.js Server-side Runtime (SSR).\nNuxt.js server runtime\nConnect to Amplify Data from Nuxt.js Server-side Runtime (SSR)."
  },
  {
    "title": "Connect to existing data sources - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/connect-to-existing-data-sources/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nConnect to existing data sources\nConnect to existing data sources\nConnect your app to existing MySQL and PostgreSQL database\nLearn how to connect your app to existing MySQL and PostgreSQL database.\nConnect to external Amazon DynamoDB data sources\nConnect to external Amazon DynamoDB data sources with custom queries and mutations"
  },
  {
    "title": "Working with files/attachments - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/working-with-files/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nWorking with files/attachments\nWorking with files/attachments\n\nThe Storage and GraphQL API categories can be used together to associate a file, such as an image or video, with a particular record. For example, you might create a User model with a profile picture, or a Post model with an associated image. With Amplify's GraphQL API and Storage categories, you can reference the file within the model itself to create an association.\n\nSet up the project\n\nSet up your project by following the instructions in the Quickstart guide.\n\nDefine the model\n\nOpen amplify/data/resource.ts and add the following model as shown below:\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\nimport { type ClientSchema, a, defineData } from \"@aws-amplify/backend\";\n\n\nconst schema = a.schema({\n  Song: a\n    .model({\n      id: a.id().required(),\n      name: a.string().required(),\n      coverArtPath: a.string(),\n    })\n    .authorization((allow) => [allow.publicApiKey()]),\n});\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    defaultAuthorizationMode: \"apiKey\",\n\n\n    apiKeyAuthorizationMode: {\n      expiresInDays: 30,\n    },\n  },\n});\nSetup the Storage\n\nNext, Let's configure Storage and allow access to all authenticated(signed in) users of your application. create a file amplify/storage/resource.ts and add the following code,This will restrict file access to only the signed-in user.\n\namplify/storage/resource.ts\nCopy\namplify/storage/resource.ts code example\nimport { defineStorage } from \"@aws-amplify/backend\";\n\n\nexport const storage = defineStorage({\n  name: \"amplify-gen2-files\",\n  access: (allow) => ({\n    \"images/*\": [allow.authenticated.to([\"read\", \"write\", \"delete\"])],\n  }),\n});\n\nConfigure the storage in the amplify/backend.ts file as demonstrated below:\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\nimport { storage } from \"./storage/resource\";\n\n\nexport const backend = defineBackend({\n  auth,\n  data,\n  storage,\n});\nConfiguring authorization\n\nYour application needs authorization credentials for reading and writing to both Storage and the Data, except in the case where all data and files are intended to be publicly accessible.\n\nThe Storage and Data categories govern data access based on their own authorization patterns, meaning that it's necessary to configure appropriate auth roles for each individual category. Although both categories share the same access credentials set up through the Auth category, they work independently from one another. For instance, adding an allow.authenticated() to the Data does not guard against file access in the Storage category. Likewise, adding authorization rules to the Storage category does not guard against data access in the API.\n\nWhen you configure Storage, Amplify will configure appropriate IAM policies on the bucket using a Cognito Identity Pool role. You will then have the option of adding CRUD (Create, Update, Read and Delete) based permissions as well, so that Authenticated and Guest users will be granted limited permissions within these levels. Even after adding this configuration, all Storage access is still guest by default. To guard against accidental public access, the Storage access levels must either be configured on the Storage object globally, or set within individual function calls. This guide uses the former approach, setting all Storage access to authenticated users.\n\nThe ability to independently configure authorization rules for each category allows for more granular control over data access, and adds greater flexibility. For scenarios where authorization patterns must be mixed and matched, configure the access level on individual Storage function calls. For example, you may want to use entity_id CRUD access on an individual Storage function call for files that should only be accessible by the owner (such as personal files), authenticated read access to allow all logged in users to view common files (such as images in a shared photo album), and guest read access to allow all users to view a file (such as a public profile picture).\n\nFor more details on how to configure Storage authorization levels, see the Storage documentation. For more on configuring Data authorization, see the API documentation.\n\nCreate a record with an associated file\n\nYou can create a record via the Amplify Data client, upload a file to Storage, and finally update the record to associate it with the uploaded file. Use the following example with the Amplify Data client and Amplify Storage library helpers, uploadData and getUrl, to create a record and associate it the file with the record.\n\nThe API record's id is prepended to the Storage file name to ensure uniqueness. If this is excluded, multiple API records could then be associated with the same file path unintentionally.\n\nsrc/App.tsx\nCopy\nsrc/App.tsx code example\nimport { generateClient } from \"aws-amplify/api\";\nimport { uploadData, getUrl } from \"aws-amplify/storage\";\nimport type { Schema } from \"../amplify/data/resource\";\n\n\n// Generating the client\nconst client = generateClient<Schema>({\n  authMode: \"apiKey\",\n});\n\n\n// Create the API record:\nconst response = await client.models.Song.create({\n  name: `My first song`,\n});\n\n\nconst song = response.data;\n\n\nif (!song) return;\n\n\n// Upload the Storage file:\nconst result = await uploadData({\n  path: `images/${song.id}-${file.name}`,\n  data: file,\n  options: {\n    contentType: \"image/png\", // contentType is optional\n  },\n}).result;\n\n\n// Add the file association to the record:\nconst updateResponse = await client.models.Song.update({\n  id: song.id,\n  coverArtPath: result?.path,\n});\n\n\nconst updatedSong = updateResponse.data;\n\n\nsetCurrentSong(updatedSong);\n\n\n// If the record has no associated file, we can return early.\nif (!updatedSong.coverArtPath) return;\n\n\n// Retrieve the file's signed URL:\nconst signedURL = await getUrl({ path: updatedSong.coverArtPath });\nAdd or update a file for an associated record\n\nTo associate a file with a record, update the record with the path returned by the Storage upload. The following example uploads the file using Storage, updates the record with the file's path, then retrieves the signed URL to download the image. If an image is already associated with the record, this will update the record with the new image.\n\nsrc/App.tsx\nCopy\nsrc/App.tsx code example\nimport { generateClient } from \"aws-amplify/api\";\nimport { uploadData, getUrl } from \"aws-amplify/storage\";\nimport type { Schema } from \"../amplify/data/resource\";\n\n\n// Generating the client\nconst client = generateClient<Schema>({\n  authMode: \"apiKey\",\n});\n\n\n// Upload the Storage file:\nconst result = await uploadData({\n  path: `images/${currentSong.id}-${file.name}`,\n  data: file,\n  options: {\n    contentType: \"image/png\", // contentType is optional\n  },\n}).result;\n\n\n// Add the file association to the record:\nconst response = await client.models.Song.update({\n  id: currentSong.id,\n  coverArtPath: result?.path,\n});\n\n\nconst updatedSong = response.data;\n\n\nsetCurrentSong(updatedSong);\n\n\n// If the record has no associated file, we can return early.\nif (!updatedSong?.coverArtPath) return;\n\n\n// Retrieve the file's signed URL:\nconst signedURL = await getUrl({ path: updatedSong.coverArtPath });\nQuery a record and retrieve the associated file\n\nTo retrieve the file associated with a record, first query the record, then use Storage to get the signed URL. The signed URL can then be used to download the file, display an image, etc:\n\nsrc/App.tsx\nCopy\nsrc/App.tsx code example\nimport { generateClient } from \"aws-amplify/api\";\nimport { getUrl } from \"aws-amplify/storage\";\nimport type { Schema } from \"../amplify/data/resource\";\n\n\n// Generating the client\nconst client = generateClient<Schema>({\n  authMode: \"apiKey\",\n});\n\n\nconst response = await client.models.Song.get({\n  id: currentSong.id,\n});\n\n\nconst song = response.data;\n\n\n// If the record has no associated file, we can return early.\nif (!song?.coverArtPath) return;\n\n\n// Retrieve the signed URL:\nconst signedURL = await getUrl({ path: song.coverArtPath });\nDelete and remove files associated with API records\n\nThere are three common deletion workflows when working with Storage files and the GraphQL API:\n\nRemove the file association, continue to persist both file and record.\nRemove the record association and delete the file.\nDelete both file and record.\nRemove the file association, continue to persist both file and record\n\nThe following example removes the file association from the record, but does not delete the file from S3, nor the record from the database.\n\nsrc/App.tsx\nCopy\nsrc/App.tsx code example\nimport { generateClient } from \"aws-amplify/api\";\nimport type { Schema } from \"../amplify/data/resource\";\n\n\n// Generating the client\nconst client = generateClient<Schema>({\n  authMode: \"apiKey\",\n});\n\n\nconst response = await client.models.Song.get({\n  id: currentSong.id,\n});\n\n\nconst song = response.data;\n\n\n// If the record has no associated file, we can return early.\nif (!song?.coverArtPath) return;\n\n\nconst updatedSong = await client.models.Song.update({\n  id: song.id,\n  coverArtPath: null,\n});\nRemove the record association and delete the file\n\nThe following example removes the file from the record, then deletes the file from S3:\n\nsrc/App.tsx\nCopy\nsrc/App.tsx code example\nimport { generateClient } from \"aws-amplify/api\";\nimport { remove } from \"aws-amplify/storage\";\nimport type { Schema } from \"../amplify/data/resource\";\n\n\n// Generating the client\nconst client = generateClient<Schema>({\n  authMode: \"apiKey\",\n});\nconst response = await client.models.Song.get({\n  id: currentSong.id,\n});\nconst song = response?.data;\n\n\n// If the record has no associated file, we can return early.\nif (!song?.coverArtPath) return;\n\n\n// Remove associated file from record\nconst updatedSong = await client.models.Song.update({\n  id: song.id,\n  coverArtPath: null,\n});\n\n\n// Delete the file from S3:\nawait remove({ path: song.coverArtPath });\nDelete both file and record\nsrc/App.tsx\nCopy\nsrc/App.tsx code example\nimport { generateClient } from \"aws-amplify/api\";\nimport { remove } from \"aws-amplify/storage\";\nimport type { Schema } from \"../amplify/data/resource\";\n\n\n// Generating the client\nconst client = generateClient<Schema>({\n  authMode: \"apiKey\",\n});\nconst response = await client.models.Song.get({\n  id: currentSong.id,\n});\n\n\nconst song = response.data;\n\n\n// If the record has no associated file, we can return early.\nif (!song?.coverArtPath) return;\n\n\nawait remove({ path: song.coverArtPath });\n\n\n// Delete the record from the API:\nawait client.models.Song.delete({ id: song.id });\nWorking with multiple files\n\nYou may want to add multiple files to a single record, such as a user profile with multiple images. To do this, you can add a list of file keys to the record. The following example adds a list of file keys to a record:\n\nGraphQL schema to associate a data model with multiple files\n\nAdd the following model in `amplify/data/resource.ts\" file.\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\nconst schema = a.schema({\n  PhotoAlbum: a\n    .model({\n      id: a.id().required(),\n      name: a.string().required(),\n      imagePaths: a.string().array(),\n    })\n    .authorization((allow) => [allow.publicApiKey()]),\n});\n\nCRUD operations when working with multiple files is the same as when working with a single file, with the exception that we are now working with a list of image keys, as opposed to a single image key.\n\nCreate a record with multiple associated files\n\nFirst create a record via the GraphQL API, then upload the files to Storage, and finally add the associations between the record and files.\n\nsrc/App.tsx\nCopy\nsrc/App.tsx code example\nimport { generateClient } from \"aws-amplify/api\";\nimport { uploadData, getUrl } from \"aws-amplify/storage\";\nimport type { Schema } from \"../amplify/data/resource\";\n\n\n// Generating the client\nconst client = generateClient<Schema>({\n  authMode: \"apiKey\",\n});\n\n\n// Create the API record:\nconst response = await client.models.PhotoAlbum.create({\n  name: `My first photoAlbum`,\n});\n\n\nconst photoAlbum = response.data.createPhotoAlbum;\n\n\nif (!photoAlbum) return;\n\n\n// Upload all files to Storage:\nconst imagePaths = await Promise.all(\n  Array.from(e.target.files).map(async (file) => {\n    const result = await uploadData({\n      path: `images/${photoAlbum.id}-${file.name}`,\n      data: file,\n      options: {\n        contentType: \"image/png\", // contentType is optional\n      },\n    }).result;\n\n\n    return result.path;\n  })\n);\n\n\nconst updatePhotoAlbumDetails = {\n  id: photoAlbum.id,\n  imagePaths: imagePaths,\n};\n\n\n// Add the file association to the record:\nconst updateResponse = await client.graphql({\n  query: mutations.updatePhotoAlbum,\n  variables: { input: updatePhotoAlbumDetails },\n});\n\n\nconst updatedPhotoAlbum = updateResponse.data.updatePhotoAlbum;\n\n\n// If the record has no associated file, we can return early.\nif (!updatedPhotoAlbum.imageKeys?.length) return;\n\n\n// Retrieve signed urls for all files:\nconst signedUrls = await Promise.all(\n  updatedPhotoAlbum?.imagePaths.map(\n    async (path) => await getUrl({ path: path! })\n  )\n);\nAdd new files to an associated record\n\nTo associate additional files with a record, update the record with the paths returned by the Storage uploads.\n\nsrc/App.tsx\nCopy\nsrc/App.tsx code example\nimport { generateClient } from \"aws-amplify/api\";\nimport { uploadData, getUrl } from \"aws-amplify/storage\";\nimport type { Schema } from \"../amplify/data/resource\";\n\n\n// Generating the client\nconst client = generateClient<Schema>({\n  authMode: \"apiKey\",\n});\n\n\n// Upload all files to Storage:\nconst newimagePaths = await Promise.all(\n  Array.from(e.target.files).map(async (file) => {\n    const result = await uploadData({\n      path: `images/${currentPhotoAlbum.id}-${file.name}`,\n      data: file,\n      options: {\n        contentType: \"image/png\", // contentType is optional\n      },\n    }).result;\n\n\n    return result.path;\n  })\n);\n\n\n// Query existing record to retrieve currently associated files:\nconst queriedResponse = await client.models.PhotoAlbum.get({\n  id: currentPhotoAlbum.id,\n});\n\n\nconst photoAlbum = queriedResponse.data;\n\n\nif (!photoAlbum?.imagePaths) return;\n\n\n// Merge existing and new file paths:\nconst updatedimagePaths = [...newimagePaths, ...photoAlbum.imagePaths];\n\n\n// Update record with merged file associations:\nconst response = await client.models.PhotoAlbum.update({\n  id: currentPhotoAlbum.id,\n  imagePaths: updatedimagePaths,\n});\n\n\nconst updatedPhotoAlbum = response.data;\n\n\n// If the record has no associated file, we can return early.\nif (!updatedPhotoAlbum?.imageKeys) return;\n\n\n// Retrieve signed urls for merged image paths:\nconst signedUrls = await Promise.all(\n  updatedPhotoAlbum?.imagePaths.map(\n    async (path) => await getUrl({ path: path! })\n  )\n);\nUpdate the file for an associated record\n\nUpdating a file for an associated record is the same as updating a file for a single file record, with the exception that you will need to update the list of file keys.\n\nsrc/App.tsx\nCopy\nsrc/App.tsx code example\nimport { generateClient } from \"aws-amplify/api\";\nimport { uploadData, getUrl } from \"aws-amplify/storage\";\nimport type { Schema } from \"../amplify/data/resource\";\n\n\n// Generating the client\nconst client = generateClient<Schema>({\n  authMode: \"apiKey\",\n});\n\n\n// Upload new file to Storage:\nconst result = await uploadData({\n  path: `images/${currentPhotoAlbum.id}-${file.name}`,\n  data: file,\n  options: {\n    contentType: \"image/png\", // contentType is optional\n  },\n}).result;\n\n\nconst newFilePath = result.path;\n\n\n// Query existing record to retrieve currently associated files:\nconst queriedResponse = await client.models.PhotoAlbum.get({\n  id: currentPhotoAlbum.id,\n});\n\n\nconst photoAlbum = queriedResponse.data;\n\n\nif (!photoAlbum?.imagePaths?.length) return;\n\n\n// Retrieve last image path:\nconst [lastImagePath] = photoAlbum.imagePaths.slice(-1);\n\n\n// Remove last file association by path\nconst updatedimagePaths = [\n  ...photoAlbum.imagePaths.filter((path) => path !== lastImagePath),\n  newFilePath,\n];\n\n\n// Update record with updated file associations:\nconst response = await client.models.PhotoAlbum.update({\n  id: currentPhotoAlbum.id,\n  imagePaths: updatedimagePaths,\n});\n\n\nconst updatedPhotoAlbum = response.data;\n\n\n// If the record has no associated file, we can return early.\nif (!updatedPhotoAlbum?.imagePaths) return;\n\n\n// Retrieve signed urls for merged image paths:\nconst signedUrls = await Promise.all(\n  updatedPhotoAlbum?.imagePaths.map(\n    async (path) => await getUrl({ path: path! })\n  )\n);\nQuery a record and retrieve the associated files\n\nTo retrieve the files associated with a record, first query the record, then use Storage to retrieve all of the signed URLs.\n\nsrc/App.tsx\nCopy\nsrc/App.tsx code example\nasync function getImagesForPhotoAlbum() {\nimport { generateClient } from \"aws-amplify/api\";\nimport { uploadData, getUrl } from \"aws-amplify/storage\";\nimport type { Schema } from \"../amplify/data/resource\";\n\n\n// Generating the client\nconst client = generateClient<Schema>({\n  authMode: \"apiKey\",\n});\n\n\n// Query the record to get the file paths:\nconst response = await client.models.PhotoAlbum.get({\n  id: currentPhotoAlbum.id,\n});\n\n\nconst photoAlbum = response.data;\n\n\n// If the record has no associated files, we can return early.\nif (!photoAlbum?.imagePaths) return;\n\n\n// Retrieve the signed URLs for the associated images:\nconst signedUrls = await Promise.all(\n  photoAlbum.imagePaths.map(async (imagePath) => {\n    if (!imagePath) return;\n    return await getUrl({ path: imagePath });\n  })\n);\n}\nDelete and remove files associated with API records\n\nThe workflow for deleting and removing files associated with API records is the same as when working with a single file, except that when performing a delete you will need to iterate over the list of file paths and call Storage.remove() for each file.\n\nRemove the file association, continue to persist both files and record\nsrc/App.tsx\nCopy\nsrc/App.tsx code example\nimport { generateClient } from \"aws-amplify/api\";\nimport type { Schema } from \"../amplify/data/resource\";\n\n\n// Generating the client\nconst client = generateClient<Schema>({\n  authMode: \"apiKey\",\n});\n\n\nconst response = await client.models.PhotoAlbum.get({\n  id: currentPhotoAlbum.id,\n});\n\n\nconst photoAlbum = response.data;\n\n\n// If the record has no associated file, we can return early.\nif (!photoAlbum?.imagePaths) return;\n\n\nconst updatedPhotoAlbum = await client.models.PhotoAlbum.update({\n  id: photoAlbum.id,\n  imagePaths: null,\n});\nRemove the record association and delete the files\nsrc/App.tsx\nCopy\nsrc/App.tsx code example\nimport { generateClient } from \"aws-amplify/api\";\nimport { remove } from \"aws-amplify/storage\";\nimport type { Schema } from \"../amplify/data/resource\";\n\n\n// Generating the client\nconst client = generateClient<Schema>({\n  authMode: \"apiKey\",\n});\n\n\nconst response = await client.models.PhotoAlbum.get({\n  id: currentPhotoAlbum.id,\n});\n\n\nconst photoAlbum = response.data;\n\n\n// If the record has no associated files, we can return early.\nif (!photoAlbum?.imagePaths) return;\n\n\n// Remove associated files from record\nconst updateResponse = await client.models.PhotoAlbum.update({\n  id: photoAlbum.id,\n  imagePaths: null, // Set the file association to `null`\n});\n\n\nconst updatedPhotoAlbum = updateResponse.data;\n\n\n// Delete the files from S3:\nawait Promise.all(\n  photoAlbum?.imagePaths.map(async (imagePath) => {\n    if (!imagePath) return;\n    await remove({ path: imagePath });\n  })\n);\nDelete record and all associated files\nsrc/App.tsx\nCopy\nsrc/App.tsx code example\nimport { generateClient } from \"aws-amplify/api\";\nimport { remove } from \"aws-amplify/storage\";\nimport type { Schema } from \"../amplify/data/resource\";\n\n\n// Generating the client\nconst client = generateClient<Schema>({\n  authMode: \"apiKey\",\n});\n\n\nconst response = await client.models.PhotoAlbum.get({\n  id: currentPhotoAlbum.id,\n});\n\n\nconst photoAlbum = response.data;\n\n\nif (!photoAlbum) return;\n\n\nawait client.models.PhotoAlbum.delete({\n  id: photoAlbum.id,\n});\n\n\nsetCurrentPhotoAlbum(null);\n\n\n// If the record has no associated file, we can return early.\nif (!photoAlbum?.imagePaths) return;\n\n\nawait Promise.all(\n  photoAlbum?.imagePaths.map(async (imagePath) => {\n    if (!imagePath) return;\n    await remove({ path: imagePath });\n  })\n);\nData consistency when working with records and files\n\nThe recommended access patterns in these docs attempt to remove deleted files, but favor leaving orphans over leaving records that point to non-existent files. This optimizes for read latency by ensuring clients rarely attempt to fetch a non-existent file from Storage. However, any app that deletes files can inherently cause records on-device to point to non-existent files.\n\nOne example is when we create an API record, associate the Storage file with that record, and then retrieve the file's signed URL. \"Device A\" calls the GraphQL API to create API_Record_1, and then associates that record with First_Photo. Before \"Device A\" is about to retrieve the signed URL, \"Device B\" might query API_Record_1, delete First_Photo, and update the record accordingly. However, \"Device A\" is still using the old API_Record_1, which is now out-of-date. Even though the shared global state is correctly in sync at every stage, the individual device (\"Device A\") has an out-of-date record that points to a non-existent file. Similar issues can conceivably occur for updates. Depending on your app, some of these mismatches can be minimized even more with real-time data / GraphQL subscriptions.\n\nIt is important to understand when these mismatches can occur and to add meaningful error handling around these cases. This guide does not include exhaustive error handling, real-time subscriptions, re-querying of outdated records, or attempts to retry failed operations. However, these are all important considerations for a production-level application.\n\nComplete examples\nSingle File (TS)\nMulti-File (TS)\nsrc/App.tsx\nCopy\nsrc/App.tsx code example\nimport \"./App.css\";\nimport { generateClient } from \"aws-amplify/api\";\nimport { uploadData, getUrl, remove } from \"aws-amplify/storage\";\nimport React, { useState } from \"react\";\nimport type { Schema } from \"../amplify/data/resource\";\nimport \"@aws-amplify/ui-react/styles.css\";\nimport {\n  type WithAuthenticatorProps,\n  withAuthenticator,\n} from \"@aws-amplify/ui-react\";\nimport { Amplify } from \"aws-amplify\";\nimport outputs from \"../amplify_outputs.json\";\n\n\nAmplify.configure(outputs);\n\n\n// Generating the client\nconst client = generateClient<Schema>({\n  authMode: \"apiKey\",\n});\n\n\ntype Song = Schema[\"Song\"][\"type\"];\n\n\nfunction App({ signOut, user }: WithAuthenticatorProps) {\n\n\n  const [currentSong, setCurrentSong] = useState<Song | null>(null);\n\n\n  // Used to display image for current song:\n  const [currentImageUrl, setCurrentImageUrl] = useState<\n    string | null | undefined\n    >(\"\");\n\n\n  async function createSongWithImage(e: React.ChangeEvent<HTMLInputElement>) {\n    if (!e.target.files) return;\n    const file = e.target.files[0];\n    try {\n\n\n      // Create the API record:\n      const response = await client.models.Song.create({\n        name: `My first song`,\n      });\n\n\n      const song = response.data;\n\n\n      if (!song) return;\n\n\n      // Upload the Storage file:\n      const result = await uploadData({\n        path: `images/${song.id}-${file.name}`,\n        data: file,\n        options: {\n          contentType: \"image/png\", // contentType is optional\n        },\n      }).result;\n\n\n      // Add the file association to the record:\n      const updateResponse = await client.models.Song.update({\n        id: song.id,\n        coverArtPath: result?.path,\n      });\n\n\n      const updatedSong = updateResponse.data;\n      setCurrentSong(updatedSong);\n\n\n      // If the record has no associated file, we can return early.\n      if (!updatedSong?.coverArtPath) return;\n\n\n      // Retrieve the file's signed URL:\n      const signedURL = await getUrl({ path: updatedSong.coverArtPath });\n\n\n      setCurrentImageUrl(signedURL.url.toString());\n    } catch (error) {\n      console.error(\"Error create song / file:\", error);\n    }\n  }\n\n\n  // Upload image, add to song, retrieve signed URL and retrieve the image.\n  // Also updates image if one already exists.\n  async function addNewImageToSong(e: React.ChangeEvent<HTMLInputElement>) {\n\n\n    if (!currentSong) return;\n\n\n    if (!e.target.files) return;\n\n\n    const file = e.target.files[0];\n\n\n    try {\n      // Upload the Storage file:\n      const result = await uploadData({\n        path: `images/${currentSong.id}-${file.name}`,\n        data: file,\n        options: {\n          contentType: \"image/png\", // contentType is optional\n        },\n      }).result;\n\n\n      // Add the file association to the record:\n      const response = await client.models.Song.update({\n        id: currentSong.id,\n        coverArtPath: result?.path,\n      });\n\n\n      const updatedSong = response.data;\n\n\n      setCurrentSong(updatedSong);\n\n\n      // If the record has no associated file, we can return early.\n      if (!updatedSong?.coverArtPath) return;\n\n\n      // Retrieve the file's signed URL:\n      const signedURL = await getUrl({ path: updatedSong.coverArtPath });\n      setCurrentImageUrl(signedURL.url.toString());\n\n\n    } catch (error) {\n      console.error(\"Error uploading image / adding image to song: \", error);\n    }\n  }\n\n\n  async function getImageForCurrentSong() {\n    if (!currentSong) return;\n\n\n    try {\n      // Query the record to get the file path:\n      const response = await client.models.Song.get({\n        id: currentSong.id,\n      });\n\n\n      const song = response.data;\n\n\n      // If the record has no associated file, we can return early.\n      if (!song?.coverArtPath) return;\n\n\n      // Retrieve the signed URL:\n      const signedURL = await getUrl({ path: song.coverArtPath });\n      setCurrentImageUrl(signedURL.url.toString());\n    } catch (error) {\n      console.error(\"Error getting song / image:\", error);\n    }\n  }\n\n\n  // Remove the file association, continue to persist both file and record\n  async function removeImageFromSong() {\n\n\n    if (!currentSong) return;\n\n\n    try {\n      const response = await client.models.Song.get({\n        id: currentSong.id,\n      });\n\n\n      const song = response.data;\n\n\n      // If the record has no associated file, we can return early.\n      if (!song?.coverArtPath) return;\n\n\n      const updatedSong = await client.models.Song.update({\n        id: song.id,\n        coverArtPath: null,\n      });\n\n\n      // If successful, the response here will be `null`:\n      setCurrentSong(updatedSong.data);\n\n\n      setCurrentImageUrl(updatedSong.data?.coverArtPath);\n\n\n    } catch (error) {\n      console.error(\"Error removing image from song: \", error);\n    }\n  }\n\n\n  // Remove the record association and delete the file\n  async function deleteImageForCurrentSong() {\n\n\n    if (!currentSong) return;\n\n\n    try {\n      const response = await client.models.Song.get({\n        id: currentSong.id,\n      });\n\n\n      const song = response?.data;\n\n\n      // If the record has no associated file, we can return early.\n      if (!song?.coverArtPath) return;\n\n\n      // Remove associated file from record\n      const updatedSong = await client.models.Song.update({\n        id: song.id,\n        coverArtPath: null,\n      });\n\n\n      // Delete the file from S3:\n      await remove({ path: song.coverArtPath });\n\n\n      // If successful, the response here will be `null`:\n      setCurrentSong(updatedSong.data);\n\n\n      setCurrentImageUrl(updatedSong.data?.coverArtPath);\n\n\n    } catch (error) {\n      console.error(\"Error deleting image: \", error);\n    }\n  }\n\n\n  // Delete both file and record\n  async function deleteCurrentSongAndImage() {\n\n\n    if (!currentSong) return;\n    try {\n      const response = await client.models.Song.get({\n        id: currentSong.id,\n      });\n      const song = response.data;\n\n\n      // If the record has no associated file, we can return early.\n      if (!song?.coverArtPath) return;\n\n\n      await remove({ path: song.coverArtPath });\n\n\n      // Delete the record from the API:\n      await client.models.Song.delete({ id: song.id });\n\n\n      clearLocalState();\n\n\n    } catch (error) {\n      console.error(\"Error deleting song: \", error);\n    }\n  }\n\n\n  function clearLocalState() {\n    setCurrentSong(null);\n    setCurrentImageUrl(\"\");\n  }\n\n\n  return (\n    <>\n      <h1>Hello {user?.username}</h1>\n      <button onClick={signOut}>Sign out</button>\n      <div>\n        <label>\n          <h2>{`Current Song: ${currentSong?.id}`}</h2>\n          Create song with file:\n          <input id=\"name\" type=\"file\" onChange={createSongWithImage} />\n        </label>\n        <label>\n          Add / update song image:\n          <input\n            id=\"name\"\n            type=\"file\"\n            onChange={addNewImageToSong}\n            disabled={!currentSong}\n          />\n        </label>\n        <button\n          onClick={getImageForCurrentSong}\n          disabled={!currentSong || !currentImageUrl}\n        >\n          Get image for current song\n        </button>\n        <button\n          onClick={removeImageFromSong}\n          disabled={!currentSong || !currentImageUrl}\n        >\n          Remove image from current song (does not delete image)\n        </button>\n        <button\n          onClick={deleteImageForCurrentSong}\n          disabled={!currentSong || !currentImageUrl}\n        >\n          Remove image from current song, then delete image\n        </button>\n        <button onClick={deleteCurrentSongAndImage} disabled={!currentSong}>\n          Delete current song (and image, if it exists)\n        </button>\n        <button onClick={signOut} className=\"app-button\">\n          Sign out\n        </button>\n      </div>\n    </>\n  );\n}\n\n\nexport default withAuthenticator(App);\nPREVIOUS\nAdd custom queries and mutations\nNEXT\nAdd custom real-time subscriptions"
  },
  {
    "title": "Add custom real-time subscriptions - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/custom-subscription/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nAdd custom real-time subscriptions\nAdd custom real-time subscriptions\n\nCreate a custom real-time subscription for any mutation to enable PubSub use cases.\n\nDefine a custom subscription\n\nFor every custom subscription, you need to set:\n\nthe mutation(s) that should trigger a subscription event,\na return type that matches the subscribed mutations' return type,\nauthorization rules.\n\nOptionally, you can set filter arguments to customize the server-side subscription filter rules.\n\nUse a.subscription() to define your custom subscription in your amplify/data/resource.ts file:\n\namplify/data/resource.ts\nimport { type ClientSchema, a, defineData } from '@aws-amplify/backend';\n\n\nconst schema = a.schema({\n  // Message type that's used for this PubSub sample\n  Message: a.customType({\n    content: a.string().required(),\n    channelName: a.string().required()\n  }),\n\n\n  // Message publish mutation\n  publish: a.mutation()\n    .arguments({\n      channelName: a.string().required(),\n      content: a.string().required()\n    })\n    .returns(a.ref('Message'))\n    .handler(a.handler.custom({ entry: './publish.js' }))\n    .authorization(allow => [allow.publicApiKey()]),\n\n\nCopy\nhighlighted code example\n  // Subscribe to incoming messages\n  receive: a.subscription()\n    // subscribes to the 'publish' mutation\n    .for(a.ref('publish')) \n    // subscription handler to set custom filters\n    .handler(a.handler.custom({entry: './receive.js'})) \n    // authorization rules as to who can subscribe to the data\n    .authorization(allow => [allow.publicApiKey()]),\n\n\n  // A data model to manage channels\n  Channel: a.model({\n    name: a.string(),\n  }).authorization(allow => [allow.publicApiKey()]),\n});\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema\n});\n\nFor this example, we're building a generic PubSub capability. This requires us to convert the arguments for publish into the Channel's format. Create a new publish.js file in your amplify/data/ folder with the following contents:\n\namplify/data/publish.js\nCopy\namplify/data/publish.js code example\n// This handler simply passes through the arguments of the mutation through as the result\nexport function request() {\n  return {}\n}\n\n\n/**\n * @param {import('@aws-appsync/utils').Context} ctx\n */\nexport function response(ctx) {\n  return ctx.args\n}\n\nNext, create a new receive.js file in your amplify/data/ folder to define handlers for your subscription. In this case, it'll just be a simple passthrough. In the next section, we'll explore how to use this handler to construct more advanced subscription filters.\n\nNote: We're planning a developer experience enhancement in the near future that'll create this passthrough under the hood.\n\namplify/data/receive.js\nCopy\namplify/data/receive.js code example\nexport function request() {\n  return {};\n}\n\n\nexport const response = (ctx) => {\n  return ctx.result;\n};\nSubscribe to custom subscriptions client-side\n\nFrom your generated Data client, you can find all your custom subscriptions under client.subscriptions. Subscribe using the .subscribe() function and then use the next function to handle incoming events.\n\nCopy\ncode example\nimport { generateClient } from 'aws-amplify/data'\nimport type { Schema } from '../amplify/data/resource'\n\n\nconst client = generateClient<Schema>()\n\n\nconst sub = client.subscriptions.receive()\n  .subscribe({\n    next: event => {\n      console.log(event)\n    }\n  }\n)\n\nYou can try publishing an event using the custom mutation to test the real-time subscription.\n\nCopy\ncode example\nclient.mutations.publish({\n  channelName: \"world\",\n  content: \"My first message!\"\n})\n\nYour subscription event should be received and logs the payload into your app's developer console. Unsubscribe your subscription to disconnect using the unsubscribe() function.\n\nCopy\ncode example\nsub.unsubscribe()\n(Optionally) Add server-side subscription filters\n\nYou can add subscription filters by adding arguments to the custom subscriptions.\n\nIf you want to customize the filters, modify the subscription handler. For this example, we'll allow a customer to pass in a namePrefix parameter that allows the end users to only receive channel events in channels that start with the namePrefix.\n\namplify/data/resource.ts\nimport { type ClientSchema, a, defineData } from '@aws-amplify/backend';\n\n\nconst schema = a.schema({\n  Channel: a.model({\n    name: a.string(),\n  }).authorization(allow => [allow.publicApiKey()]),\n\n\n  Message: a.customType({\n    content: a.string().required(),\n    channelName: a.string().required()\n  }),\n\n\n  publish: a.mutation()\n    .arguments({\n      channelName: a.string().required(),\n      content: a.string().required()\n    })\n    .returns(a.ref('Message'))\n    .handler(a.handler.custom({ entry: './publish.js' }))\n    .authorization(allow => [allow.publicApiKey()]),\n\n\n  receive: a.subscription()\n    .for(a.ref('publish'))\nCopy\nhighlighted code example\n    .arguments({ namePrefix: a.string() })\n    .handler(a.handler.custom({entry: './receive.js'}))\n    .authorization(allow => [allow.publicApiKey()])\n});\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema\n});\n\nIn your handler, you can set custom subscription filters based on arguments passed into the custom subscription. For this example, create a new receive.js file alongside the amplify/data/resource.ts file:\n\nCopy\ncode example\nimport { util, extensions } from \"@aws-appsync/utils\"\n\n\n// Subscription handlers must return a `null` payload on the request\nexport function request() { return { payload: null } }\n\n\n/**\n * @param {import('@aws-appsync/utils').Context} ctx\n */\nexport function response(ctx) {\n  const filter = {\n    channelName: {\n      beginsWith: ctx.args.namePrefix\n    }\n  }\n\n\n  extensions.setSubscriptionFilter(util.transform.toSubscriptionFilter(filter))\n\n\n  return null\n}\nPREVIOUS\nWorking with files/attachments\nNEXT\nConnect to existing data sources"
  },
  {
    "title": "Connect to an external HTTP endpoint - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/custom-business-logic/connect-http-datasource/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nAdd custom queries and mutations\n/\nConnect to an external HTTP endpoint\nConnect to an external HTTP endpoint\n\nThe HTTP Datasource allows you to quickly configure HTTP resolvers within your Data API.\n\nThis guide will demonstrate how to establish a connection to an external REST API using an HTTP data source and use Amplify Data's custom mutations and queries to interact with the REST API.\n\nStep 1 - Set up your custom type\n\nFor the purpose of this guide we will define a Post type and use an existing external REST API that will store records for it. In Amplify Gen 2, customType adds a type to the schema that is not backed by an Amplify-generated DynamoDB table.\n\nWith the Post type defined, it can then be referenced as the return type when defining your custom queries and mutations.\n\nFirst, add the Post custom type to your schema:\n\namplify/data/resource.ts\nimport { type ClientSchema, a, defineData } from \"@aws-amplify/backend\";\n\n\nconst schema = a.schema({\n  Todo: a\n    .model({\n      content: a.string(),\n    })\n    .authorization(allow => [allow.publicApiKey()]),\nCopy\nhighlighted code example\n  Post: a.customType({\n    title: a.string(),\n    content: a.string(),\n    author: a.string().required(),\n  }),\n});\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    defaultAuthorizationMode: 'apiKey',\n    apiKeyAuthorizationMode: {\n      expiresInDays: 30,\n    },\n  },\n});\nStep 2 - Add your REST API or HTTP API as Datasource\n\nTo integrate the external REST API or HTTP API, you'll need to set it up as the HTTP Datasource. Add the following code in your amplify/backend.ts file.\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\n\n\nconst backend = defineBackend({\n  auth,\n  data,\n});\n\n\nconst httpDataSource = backend.data.addHttpDataSource(\n  \"HttpDataSource\",\n  \"https://www.example.com\"\n);\nStep 3 - Define custom queries and mutations\n\nNow that your REST API has been added as a data source, you can reference it in custom queries and mutations using the a.handler.custom() modifier which accepts the name of the data source and an entry point for your resolvers.\n\nUse the following code examples to add addPost, getPost, updatePost, and deletePost as custom queries and mutations to your schema:\n\naddPost\ngetPost\nupdatePost\ndeletePost\namplify/data/resource.ts\nimport { type ClientSchema, a, defineData } from \"@aws-amplify/backend\";\n\n\nconst schema = a.schema({\n  Post: a.customType({\n    title: a.string(),\n    content: a.string(),\n    author: a.string().required(),\n  }),\nCopy\nhighlighted code example\n  addPost: a\n    .mutation()\n    .arguments({\n      title: a.string(),\n      content: a.string(),\n      author: a.string().required(),\n    })\n    .returns(a.ref(\"Post\"))\n    .authorization(allow => [allow.publicApiKey()])\n    .handler(\n      a.handler.custom({\n        dataSource: \"HttpDataSource\",\n        entry: \"./addPost.js\",\n      })\n    ),\n});\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    defaultAuthorizationMode: 'apiKey',\n    apiKeyAuthorizationMode: {\n      expiresInDays: 30,\n    },\n  },\n});\nStep 4 - Configure custom business logic handler code\n\nNext, create the following files in your amplify/data folder and use the code examples to define custom resolvers for the custom queries and mutations added to your schema from the previous step. These are AppSync JavaScript resolvers.\n\naddPost\ngetPost\nupdatePost\ndeletePost\namplify/data/addPost.js\nCopy\namplify/data/addPost.js code example\nimport { util } from \"@aws-appsync/utils\";\n\n\nexport function request(ctx) {\n  return {\n    method: \"POST\",\n    resourcePath: \"/post\",\n    params: {\n      headers: {\n        \"Content-Type\": \"application/json\",\n      },\n      body: {\n        title: ctx.arguments.title,\n        content: ctx.arguments.content,\n        author: ctx.arguments.author,\n      },\n    },\n  };\n}\n\n\nexport function response(ctx) {\n  if (ctx.error) {\n    return util.error(ctx.error.message, ctx.error.type);\n  }\n  if (ctx.result.statusCode == 200) {\n    return JSON.parse(ctx.result.body).data;\n  } else {\n    return util.appendError(ctx.result.body, \"ctx.result.statusCode\");\n  }\n}\nStep 5 - Invoke custom queries or mutations\n\nFrom your generated Data client, you can find all your custom queries and mutations under the client.queries. and client.mutations. APIs respectively.\n\naddPost\ngetPost\nupdatePost\ndeletePost\nApp.tsx\nCopy\nApp.tsx code example\nconst { data, errors } = await client.mutations.addPost({\n  title: \"My Post\",\n  content: \"My Content\",\n  author: \"Chris\",\n});\nConclusion\n\nIn this guide, you’ve added an external REST API as a HTTP data source to an Amplify Data API and defined custom queries and mutations, handled by AppSync JS resolvers, to manipulate Post items in an external REST API using the Amplify Gen 2 Data client.\n\nTo clean up, you can delete your sandbox by accepting the prompt when terminating the sandbox process in your terminal. Alternatively, you can also use the AWS Amplify console to manage and delete sandbox environments.\n\nPREVIOUS\nConnect to Amazon Translate for language translation APIs"
  },
  {
    "title": "Connect to Amazon Translate for language translation APIs - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/custom-business-logic/connect-amazon-translate/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nAdd custom queries and mutations\n/\nConnect to Amazon Translate for language translation APIs\nConnect to Amazon Translate for language translation APIs\n\nAmazon Translate is a neural machine translation service provided by Amazon Web Services (AWS). It uses advanced deep learning technologies to deliver fast and high-quality language translation. With Amazon Translate, you can easily add multilingual support to your applications and services, enabling users to communicate and interact in their preferred language.\n\nKey features of Amazon Translate include:\n\nAccurate and Fluent Translations: Amazon Translate produces translations that are both accurate and natural-sounding, providing a seamless experience for users.\n\nSupport for Multiple Languages: The service supports a broad range of languages, allowing you to expand your application’s reach to diverse audiences around the world.\n\nReal-Time and Batch Translation: Amazon Translate can handle real-time translation for dynamic content and batch translation for larger volumes of text, making it suitable for various use cases.\n\nCost-Effective and Scalable: With its pay-as-you-go pricing model and automatic scaling, Amazon Translate is an economical and flexible solution for adding translation capabilities to your applications.\n\nIn this section, you will learn how to integrate Amazon Translate into your application using AWS Amplify, enabling you to leverage its powerful translation capabilities effortlessly.\n\nStep 1 - Set up the project\n\nSet up your project by following the instructions in the Quickstart guide.\n\nStep 2 - Install Amazon Translate libraries\n\nTo install the Amazon Translate SDK, run the following command in your project's root folder:\n\nTerminal\nCopy\nTerminal code example\nnpm add @aws-sdk/client-translate\nStep 3 - Add your Amazon Translate as Datasource\n\nTo access Amazon Translate service, you need to add Amazon Translate as an HTTP Data Source and configure the proper IAM policy for AWS Lambda to utilize the desired feature effectively. Update amplify/backend.ts file as shown below.\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource';\nimport { data } from \"./data/resource\";\nimport { Stack } from 'aws-cdk-lib';\nimport { PolicyStatement } from 'aws-cdk-lib/aws-iam';\n\n\nconst backend = defineBackend({\n auth,\n data\n});\n\n\nconst dataStack = Stack.of(backend.data)\n\n\nconst translateDataSource = backend.data.addHttpDataSource(\n \"TranslateDataSource\",\n `https://translate.${dataStack.region}.amazonaws.com`,\n {\n   authorizationConfig: {\n     signingRegion: dataStack.region,\n     signingServiceName: \"translate\",\n   },\n }\n);\n\n\ntranslateDataSource.grantPrincipal.addToPrincipalPolicy(\n new PolicyStatement({\n   actions: [\"translate:TranslateText\"],\n   resources: [\"*\"],\n })\n);\nStep 4 - Configure custom business logic handler\n\nNext, create the following translate.js file in your amplify/data folder and use the code below to define custom resolvers.\n\namplify/data/translate.js\nCopy\namplify/data/translate.js code example\nexport function request(ctx) {\n  return {\n    method: 'POST',\n    resourcePath: '/',\n    params: {\n      body: {\n        SourceLanguageCode: ctx.arguments.sourceLanguage,\n        TargetLanguageCode: ctx.arguments.targetLanguage,\n        Text: ctx.arguments.text\n      },\n      headers: {\n        'Content-Type': 'application/x-amz-json-1.1',\n        'X-Amz-Target': 'AWSShineFrontendService_20170701.TranslateText'\n      }\n    },\n  }\n}\n\n\nexport function response(ctx) {\n  return JSON.parse(ctx.result.body).TranslatedText\n}\nStep 5 - Define the custom query\n\nAfter adding Amazon Translate as a data source, you can reference it in a custom query using the a.handler.custom() modifier, which takes the name of the data source and an entry point for your resolvers. In your amplify/data/resource.ts file, specify TranslateDataSource as the data source and translate.js as the entry point, as shown below.\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\nimport { type ClientSchema, a, defineData } from '@aws-amplify/backend';\n\n\n\n\nconst schema = a.schema({\n  translate: a.query()\n    .arguments({\n      sourceLanguage: a.string().required(),\n      targetLanguage: a.string().required(),\n      text: a.string().required()\n    })\n    .returns(a.string())\n    .authorization(allow => [allow.publicApiKey()])\n    .handler(a.handler.custom({\n      dataSource: \"TranslateDataSource\",\n      entry: './translate.js'\n    }))\n});\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    defaultAuthorizationMode: 'apiKey',\n    apiKeyAuthorizationMode: {\n      expiresInDays: 30,\n    },\n  },\n});\nStep 6 - Configure the frontend\n\nImport and load the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point.\n\nmain.tsx\nCopy\nmain.tsx code example\nimport { Amplify } from \"aws-amplify\";\nimport outputs from \"../amplify_outputs.json\";\n\n\nAmplify.configure(outputs);\nInvoke the API\n\nSample frontend code to translate text from one language to another.\n\nCopy\ncode example\nimport { generateClient } from 'aws-amplify/data';\nimport { type Schema } from '../amplify/data/resource';\n\n\nconst client = generateClient<Schema>();\n\n\n\n\nconst { data } = await client.queries.translate({\n  sourceLanguage: \"en\",\n  targetLanguage: \"es\",\n  text: \"Hello World!\",\n});\nPREVIOUS\nConnect to Amazon Rekognition for Image Analysis APIs\nNEXT\nConnect to an external HTTP endpoint"
  },
  {
    "title": "Connect to Amazon Rekognition for Image Analysis APIs - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/custom-business-logic/connect-amazon-rekognition/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nAdd custom queries and mutations\n/\nConnect to Amazon Rekognition for Image Analysis APIs\nConnect to Amazon Rekognition for Image Analysis APIs\n\nAmazon Rekognition is an advanced machine learning service provided by Amazon Web Services (AWS), allowing developers to incorporate image and video analysis into their applications. It uses state-of-the-art machine learning models to analyze images and videos, providing valuable insights such as object and scene detection, text recognition, face analysis, and more.\n\nKey features of Amazon Rekognition include:\n\nObject and Scene Detection: Amazon Rekognition can identify thousands of objects and scenes in images and videos, providing valuable context for your media content.\n\nText Detection and Recognition: The service can detect and recognize text within images and videos, making it an invaluable tool for applications requiring text extraction.\n\nFacial Analysis: Amazon Rekognition offers accurate facial analysis, enabling you to detect, analyze, and compare faces in images and videos.\n\nFacial Recognition: You can build applications with the capability to recognize and verify individuals using facial recognition.\n\nContent Moderation: Amazon Rekognition can analyze images and videos to identify inappropriate or objectionable content, helping you maintain safe and compliant content.\n\nIn this section, you will learn how to integrate Amazon Rekognition into your application using AWS Amplify, leveraging its powerful image analysis capabilities seamlessly.\n\nStep 1 - Set up the project\n\nSet up your project by following the instructions in the Quickstart guide.\n\nStep 2 - Install Rekognition Libraries\n\nCreate a new API endpoint that'll use the the AWS SDK to call the Amazon Rekognition service. To install the Amazon Rekognition SDK, run the following command in your project's root folder:\n\nTerminal\nCopy\nTerminal code example\nnpm add @aws-sdk/client-rekognition\nStep 3 - Setup Storage\n\nCreate a file named amplify/storage/resource.ts and add the following content to configure a storage resource:\n\namplify/storage/resource.ts\nCopy\namplify/storage/resource.ts code example\nimport { defineStorage } from '@aws-amplify/backend';\n\n\nexport const storage = defineStorage({\n  name: 'predictions_gen2'\n});\nStep 4 - Add your Amazon Rekognition as Datasource\n\nTo use the Amazon Rekognition service, you need to add Amazon Rekognition as an HTTP Data Source and configure the proper IAM policy for Lambda to effectively utilize the desired feature and grant permission to access the storage. In this case, you can add the rekognition:DetectText and rekognition:DetectLabels actions to the policy. Update the amplify/backend.ts file as shown below.\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource';\nimport { data } from './data/resource';\nimport { Stack } from 'aws-cdk-lib';\nimport { PolicyStatement } from 'aws-cdk-lib/aws-iam';\nimport { storage } from './storage/resource';\n\n\nconst backend = defineBackend({\n auth,\n data,\n storage\n});\n\n\nconst dataStack = Stack.of(backend.data)\n\n\n// Set environment variables for the S3 Bucket name\nbackend.data.resources.cfnResources.cfnGraphqlApi.environmentVariables = {\n S3_BUCKET_NAME: backend.storage.resources.bucket.bucketName,\n};\n\n\nconst rekognitionDataSource = backend.data.addHttpDataSource(\n \"RekognitionDataSource\",\n `https://rekognition.${dataStack.region}.amazonaws.com`,\n {\n   authorizationConfig: {\n     signingRegion: dataStack.region,\n     signingServiceName: \"rekognition\",\n   },\n }\n);\n\n\nrekognitionDataSource.grantPrincipal.addToPrincipalPolicy(\n new PolicyStatement({\n   actions: [\"rekognition:DetectText\", \"rekognition:DetectLabels\"],\n   resources: [\"*\"],\n })\n);\n\n\nbackend.storage.resources.bucket.grantReadWrite(\n rekognitionDataSource.grantPrincipal\n);\nStep 5 - Configure the function handler\n\nDefine the function handler by creating a new file, amplify/data/identifyText.ts. This function analyzes the image and extracts text using the Amazon Rekognition DetectText service.\n\namplify/data/identifyText.ts\nCopy\namplify/data/identifyText.ts code example\nexport function request(ctx) {\n  return {\n    method: \"POST\",\n    resourcePath: \"/\",\n    params: {\n      body: {\n        Image: {\n          S3Object: {\n            Bucket: ctx.env.S3_BUCKET_NAME,\n            Name: ctx.arguments.path,\n          },\n        },\n      },\n      headers: {\n        \"Content-Type\": \"application/x-amz-json-1.1\",\n        \"X-Amz-Target\": \"RekognitionService.DetectText\",\n      },\n    },\n  };\n}\n\n\nexport function response(ctx) {\n  return JSON.parse(ctx.result.body)\n    .TextDetections.filter((item) => item.Type === \"LINE\")\n    .map((item) => item.DetectedText)\n    .join(\"\\n\")\n    .trim();\n}\nStep 6 - Define the custom query\n\nAfter adding Amazon Rekognition as a data source, you can reference it in custom query using the a.handler.custom() modifier, which takes the name of the data source and an entry point for your resolvers. In your amplify/data/resource.ts file, specify RekognitionDataSource as the data source and identifyText.js as the entry point, as shown below.\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\nimport { type ClientSchema, a, defineData } from \"@aws-amplify/backend\";\n\n\nconst schema = a.schema({\n  identifyText: a\n    .query()\n    .arguments({\n      path: a.string(),\n    })\n    .returns(a.string())\n    .authorization((allow) => [allow.publicApiKey()])\n    .handler(\n      a.handler.custom({\n        entry: \"./identifyText.js\",\n        dataSource: \"RekognitionDataSource\",\n      })\n    ),\n});\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    defaultAuthorizationMode: \"apiKey\",\n    apiKeyAuthorizationMode: {\n      expiresInDays: 30,\n    },\n  },\n});\nStep 7 - Update Storage permissions\n\nCustomize your storage settings to manage access to various paths within your storage bucket. Modify the file amplify/storage/resource.ts as shown below.\n\namplify/storage/resource.ts\nCopy\namplify/storage/resource.ts code example\nimport { defineStorage } from \"@aws-amplify/backend\"\n\n\nexport const storage = defineStorage({\n  name: \"predictions_gen2\",\n  access: allow => ({\n    'public/*': [\n      allow.guest.to(['list', 'write', 'get'])\n    ]\n  })\n})\nStep 8 - Configure the frontend\n\nImport and load the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point.\n\nmain.tsx\nCopy\nmain.tsx code example\nimport { Amplify } from \"aws-amplify\";\nimport outputs from \"../amplify_outputs.json\";\n\n\nAmplify.configure(outputs);\nInvoke the Text Recognition API\n\nThis code sets up a React app to upload an image to an S3 bucket and then use Amazon Rekognition to recognize the text in the uploaded image.\n\nApp.tsx\nCopy\nApp.tsx code example\nimport { type ChangeEvent, useState } from \"react\";\nimport { generateClient } from \"aws-amplify/api\";\nimport { uploadData } from \"aws-amplify/storage\";\nimport { Schema } from \"@/amplify/data/resource\";\nimport \"./App.css\";\n\n\n// Generating the client\nconst client = generateClient<Schema>();\n\n\ntype IdentifyTextReturnType = Schema[\"identifyText\"][\"returnType\"];\n\n\nfunction App() {\n  // State to hold the recognized text\n  const [path, setPath] = useState<string>(\"\");\n  const [textData, setTextData] = useState<IdentifyTextReturnType>();\n\n\n  // Function to handle file upload to S3 bucket\n  const handleTranslate = async (event: ChangeEvent<HTMLInputElement>) => {\n    if (event.target.files) {\n      const file = event.target.files[0];\n\n\n      const s3Path = \"public/\" + file.name;\n\n\n      try {\n        uploadData({\n          path: s3Path,\n          data: file,\n        });\n\n\n        setPath(s3Path);\n      } catch (error) {\n        console.error(error);\n      }\n    }\n  };\n\n\n  // Function to recognize text from the uploaded image\n  const recognizeText = async () => {\n    // Identifying text in the uploaded image\n    const { data } = await client.queries.identifyText({\n      path, // File name\n    });\n    setTextData(data);\n  };\n\n\n  return (\n    <div>\n      <h1>Amazon Rekognition Text Recognition</h1>\n      <div>\n        <input type=\"file\" onChange={handleTranslate} />\n        <button onClick={recognizeText}>Recognize Text</button>\n        <div>\n          <h3>Recognized Text:</h3>\n          {textData}\n        </div>\n      </div>\n    </div>\n  );\n}\n\n\nexport default App;\nPREVIOUS\nConnect to Amazon Bedrock for generative AI use cases\nNEXT\nConnect to Amazon Translate for language translation APIs"
  },
  {
    "title": "Connect to Amazon Polly for Text-To-Speech APIs - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/custom-business-logic/connect-amazon-polly/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nAdd custom queries and mutations\n/\nConnect to Amazon Polly for Text-To-Speech APIs\nConnect to Amazon Polly for Text-To-Speech APIs\n\nAmazon Polly is a text-to-speech (TTS) service offered by Amazon Web Services (AWS). It uses advanced deep learning technologies to convert written text into lifelike speech, enabling you to create applications with speech capabilities in various languages and voices.\n\nWith Amazon Polly, you can easily add voice interactions and accessibility features to your applications. The service supports a wide range of use cases, such as providing audio content for the visually impaired, enhancing e-learning experiences, creating interactive voice response (IVR) systems, and more.\n\nKey features of Amazon Polly include:\n\nMultiple Voices and Languages: Amazon Polly supports dozens of voices across various languages and dialects, giving you the flexibility to choose the most appropriate voice for your use case.\n\nHigh-Quality Speech: Amazon Polly's neural and standard voices offer natural and realistic speech quality.\n\nSpeech Marks and Speech Synthesis Markup Language: Customize your speech output with Speech Synthesis Markup Language tags and obtain speech timing information with speech marks.\n\nScalable and Cost-Effective: Amazon Polly's pay-as-you-go pricing model makes it a cost-effective solution for adding speech capabilities to your applications.\n\nIn this section, you'll learn how to integrate Amazon Polly into your application using AWS Amplify, enabling you to leverage its powerful text-to-speech capabilities seamlessly.\n\nStep 1 - Setup the project\n\nSet up your project by following the instructions in the Quickstart guide.\n\nStep 2 - Install Polly Libraries\n\nWe'll create a new API endpoint that'll use the the AWS SDK to call the Amazon Polly service. To install the Amazon Polly SDK, run the following command in your project's root folder:\n\nTerminal\nCopy\nTerminal code example\nnpm add @aws-sdk/client-polly\nStep 3 - Setup Storage\n\nCreate a file named amplify/storage/resource.ts and add the following content to configure a storage resource:\n\namplify/storage/resource.ts\nCopy\namplify/storage/resource.ts code example\nimport { defineStorage } from '@aws-amplify/backend';\n\n\nexport const storage = defineStorage({\n  name: 'predictions_gen2'\n});\nStep 4 - Configure IAM Roles\n\nTo access Amazon Polly service, you need to configure the proper IAM policy for Lambda to utilize the desired feature effectively. Update the amplify/backend.ts file with the following code to add the necessary permissions to a lambda's Role policy.\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { auth } from \"./auth/resource\";\nimport { data, convertTextToSpeech } from \"./data/resource\";\nimport { Stack } from \"aws-cdk-lib\";\nimport { PolicyStatement } from \"aws-cdk-lib/aws-iam\";\nimport { storage } from \"./storage/resource\";\n\n\nconst backend = defineBackend({\n auth,\n data,\n storage,\n convertTextToSpeech,\n});\n\n\nbackend.convertTextToSpeech.resources.lambda.addToRolePolicy(\n new PolicyStatement({\n   actions: [\"polly:StartSpeechSynthesisTask\"],\n   resources: [\"*\"],\n })\n);\nStep 5 - Configure the function handler\n\nDefine the function handler by creating a new file, amplify/data/convertTextToSpeech.ts. This function converts text into speech using Amazon Polly and stores the synthesized speech as an MP3 file in an S3 bucket.\n\namplify/data/convertTextToSpeech.ts\nCopy\namplify/data/convertTextToSpeech.ts code example\nimport { Schema } from \"./resource\";\nimport {\n  PollyClient,\n  StartSpeechSynthesisTaskCommand,\n} from \"@aws-sdk/client-polly\";\nimport { env } from \"$amplify/env/convertTextToSpeech\";\n\n\nexport const handler: Schema[\"convertTextToSpeech\"][\"functionHandler\"] = async (\n  event\n) => {\n  const client = new PollyClient();\n  const task = new StartSpeechSynthesisTaskCommand({\n    OutputFormat: \"mp3\",\n    SampleRate: \"8000\",\n    Text: event.arguments.text,\n    TextType: \"text\",\n    VoiceId: \"Amy\",\n    OutputS3BucketName: env.PREDICTIONS_GEN_2_BUCKET_NAME,\n    OutputS3KeyPrefix: \"public/\",\n  });\n  const result = await client.send(task);\n\n\n  return (\n    result.SynthesisTask?.OutputUri?.replace(\n      \"https://s3.us-east-1.amazonaws.com/\" +\n        env.PREDICTIONS_GEN_2_BUCKET_NAME +\n        \"/public/\",\n      \"\"\n    ) ?? \"\"\n  );\n};\nStep 6 - Define the custom mutation and function\n\nIn your amplify/data/resource.ts file, define the function using defineFunction and then reference the function with your mutation using a.handler.function() as a handler.\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\nimport {\n  type ClientSchema,\n  a,\n  defineData,\n  defineFunction,\n} from \"@aws-amplify/backend\";\n\n\nexport const convertTextToSpeech = defineFunction({\n  entry: \"./convertTextToSpeech.ts\",\n});\n\n\nconst schema = a.schema({\n  Todo: a\n    .model({\n      content: a.string(),\n    })\n    .authorization(allow => [allow.publicApiKey()]),\n  convertTextToSpeech: a\n    .mutation()\n    .arguments({\n      text: a.string().required(),\n    })\n    .returns(a.string().required())\n    .authorization(allow => [allow.publicApiKey()])\n    .handler(a.handler.function(convertTextToSpeech)),\n});\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    defaultAuthorizationMode: \"apiKey\",\n    // API Key is used for allow.publicApiKey() rules\n    apiKeyAuthorizationMode: {\n      expiresInDays: 30,\n    },\n  },\n});\n\nNOTE: At least one query is required for a schema to be valid. Otherwise, deployments will fail a schema error. The Amplify Data schema is auto-generated with a Todo model and corresponding queries under the hood. You can leave the Todo model in the schema until you add the first custom query to the schema in the next steps.\n\nStep 7 - Update Storage permissions\n\nCustomize your storage settings to manage access to various paths within your storage bucket. It's necessary to update the Storage resource to provide access to the convertTextToSpeech resource. Modify the file amplify/storage/resource.ts as shown below.\n\namplify/storage/resource.ts\nCopy\namplify/storage/resource.ts code example\nimport { defineStorage } from \"@aws-amplify/backend\";\nimport { convertTextToSpeech } from \"../data/resource\";\n\n\nexport const storage = defineStorage({\n  name: \"predictions_gen2\",\n  access: (allow) => ({\n    \"public/*\": [\n      allow.resource(convertTextToSpeech).to([\"write\"]),\n      allow.guest.to([\"read\", \"write\"]),\n    ],\n  }),\n});\nStep 8 - Configure the frontend\n\nImport and load the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point.\n\nmain.tsx\nCopy\nmain.tsx code example\nimport { Amplify } from \"aws-amplify\";\nimport outputs from \"../amplify_outputs.json\";\n\n\nAmplify.configure(outputs);\nInvoke the API\n\nExample frontend code to create an audio buffer for playback using a text input.\n\nApp.tsx\nCopy\nApp.tsx code example\nimport \"./App.css\";\nimport { generateClient } from \"aws-amplify/api\";\nimport type { Schema } from \"../amplify/data/resource\";\nimport { getUrl } from \"aws-amplify/storage\";\nimport { useState } from \"react\";\n\n\nconst client = generateClient<Schema>();\n\n\ntype PollyReturnType = Schema[\"convertTextToSpeech\"][\"returnType\"];\n\n\nfunction App() {\n  const [src, setSrc] = useState(\"\");\n  const [file, setFile] = useState<PollyReturnType>(\"\");\n  return (\n    <div className=\"flex flex-col\">\n      <button\n        onClick={async () => {\n          const { data, errors } = await client.mutations.convertTextToSpeech({\n            text: \"Hello World!\",\n          });\n\n\n          if (!errors && data) {\n            setFile(data);\n          } else {\n            console.log(errors);\n          }\n        }}\n      >\n        Synth\n      </button>\n      <button\n        onClick={async () => {\n          const res = await getUrl({\n            path: \"public/\" + file,\n          });\n\n\n          setSrc(res.url.toString());\n        }}\n      >\n        Fetch audio\n      </button>\n      <a href={src}>Get audio file</a>\n    </div>\n  );\n}\n\n\nexport default App;\nPREVIOUS\nConnect to Amazon EventBridge to send and receive events\nNEXT\nConnect to Amazon Bedrock for generative AI use cases"
  },
  {
    "title": "Connect to Amazon Bedrock for generative AI use cases - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/custom-business-logic/connect-bedrock/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nAdd custom queries and mutations\n/\nConnect to Amazon Bedrock for generative AI use cases\nConnect to Amazon Bedrock for generative AI use cases\n\nAmazon Bedrock is a fully managed service that removes the complexity of using foundation models (FMs) for generative AI development. It acts as a central hub, offering a curated selection of high-performing FMs from leading AI companies like Anthropic, AI21 Labs, Cohere, and Amazon itself.\n\nAmazon Bedrock streamlines generative AI development by providing:\n\nChoice and Flexibility: Experiment and evaluate a wide range of FMs to find the perfect fit for your use case.\n\nSimplified Integration: Access and use FMs through a single, unified API, reducing development time.\n\nEnhanced Security and Privacy: Benefit from built-in safeguards to protect your data and prevent misuse.\n\nResponsible AI Features: Implement guardrails to control outputs and mitigate bias.\n\nIn the following sections, we walk through the steps to add Amazon Bedrock to your API as a data source and connect to it from your Amplify app:\n\nAdd Amazon Bedrock as a data source\nDefine a custom query\nConfigure custom business logic handler code\nInvoke a custom query to prompt a generative AI model\nStep 1 - Add Amazon Bedrock as a data source\n\nTo connect to Amazon Bedrock as a data source, you can choose between two methods - using a Lambda function or a custom resolver powered by AppSync JavaScript resolvers. The following steps demonstrate both methods:\n\nFunction\nCustom resolver powered by AppSync JavaScript resolvers\n\nIn your amplify/backend.ts file, replace the content with the following code to add a lambda function to your backend and grant it permission to invoke a generative AI model in Amazon Bedrock. The generateHaikuFunction lambda function will be defined in and exported from the amplify/data/resource.ts file in the next steps:\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { auth } from \"./auth/resource\";\nimport { data, MODEL_ID, generateHaikuFunction } from \"./data/resource\";\nimport { Effect, PolicyStatement } from \"aws-cdk-lib/aws-iam\";\n\n\nexport const backend = defineBackend({\n  auth,\n  data,\n  generateHaikuFunction,\n});\n\n\nbackend.generateHaikuFunction.resources.lambda.addToRolePolicy(\n  new PolicyStatement({\n    effect: Effect.ALLOW,\n    actions: [\"bedrock:InvokeModel\"],\n    resources: [\n      `arn:aws:bedrock:*::foundation-model/${MODEL_ID}`,\n    ],\n  })\n);\n\nFor the purpose of this guide, we will use Anthropic's Claude 3 Haiku to generate content. If you want to use a different model, you can find the ID for your model of choice in the Amazon Bedrock documentation's list of model IDs or the Amazon Bedrock console and replace the value of MODEL_ID.\n\nThe availability of Amazon Bedrock and its foundation models may vary by region.\n\nThe policy statement in the code above assumes that your Amplify app is deployed in a region supported by Amazon Bedrock and the Claude 3 Haiku model. If you are deploying your app in a region where Amazon Bedrock is not available, update the code above accordingly.\n\nFor a list of supported regions please refer to the Amazon Bedrock documentation.\n\nStep 2 - Define a custom query\nFunction\nCustom resolver powered by AppSync JavaScript resolvers\n\nNext, replace the contents of your amplify/data/resource.ts file with the following code. This will define and export a lambda function that was granted permission to invoke a generative AI model in Amazon Bedrock in the previous step. A custom query named generateHaiku is added to the schema with the generateHaikuFunction as the handler using the a.handler.function() modifier:\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\nimport {\n  type ClientSchema,\n  a,\n  defineData,\n  defineFunction,\n} from \"@aws-amplify/backend\";\n\n\nexport const MODEL_ID = \"anthropic.claude-3-haiku-20240307-v1:0\";\n\n\nexport const generateHaikuFunction = defineFunction({\n  entry: \"./generateHaiku.ts\",\n  environment: {\n    MODEL_ID,\n  },\n});\n\n\nconst schema = a.schema({\n  generateHaiku: a\n    .query()\n    .arguments({ prompt: a.string().required() })\n    .returns(a.string())\n    .authorization((allow) => [allow.publicApiKey()])\n    .handler(a.handler.function(generateHaikuFunction)),\n});\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    defaultAuthorizationMode: \"apiKey\",\n    apiKeyAuthorizationMode: {\n      expiresInDays: 30,\n    },\n  },\n});\nStep 3 - Configure custom business logic handler code\nFunction\nCustom resolver powered by AppSync JavaScript resolvers\n\nNext, create a generateHaiku.ts file in your amplify/data folder and use the following code to define a custom resolver for the custom query added to your schema in the previous step:\n\nThe following code uses the BedrockRuntimeClient from the @aws-sdk/client-bedrock-runtime package to invoke the generative AI model in Amazon Bedrock. The handler function takes the user prompt as an argument, invokes the model, and returns the generated haiku.\n\namplify/data/generateHaiku.ts\nCopy\namplify/data/generateHaiku.ts code example\nimport type { Schema } from \"./resource\";\nimport {\n  BedrockRuntimeClient,\n  InvokeModelCommand,\n  InvokeModelCommandInput,\n} from \"@aws-sdk/client-bedrock-runtime\";\n\n\n// initialize bedrock runtime client\nconst client = new BedrockRuntimeClient();\n\n\nexport const handler: Schema[\"generateHaiku\"][\"functionHandler\"] = async (\n  event,\n  context\n) => {\n  // User prompt\n  const prompt = event.arguments.prompt;\n\n\n  // Invoke model\n  const input = {\n    modelId: process.env.MODEL_ID,\n    contentType: \"application/json\",\n    accept: \"application/json\",\n    body: JSON.stringify({\n      anthropic_version: \"bedrock-2023-05-31\",\n      system:\n        \"You are a an expert at crafting a haiku. You are able to craft a haiku out of anything and therefore answer only in haiku.\",\n      messages: [\n        {\n          role: \"user\",\n          content: [\n            {\n              type: \"text\",\n              text: prompt,\n            },\n          ],\n        },\n      ],\n      max_tokens: 1000,\n      temperature: 0.5,\n    }),\n  } as InvokeModelCommandInput;\n\n\n  const command = new InvokeModelCommand(input);\n\n\n  const response = await client.send(command);\n\n\n  // Parse the response and return the generated haiku\n  const data = JSON.parse(Buffer.from(response.body).toString());\n\n\n  return data.content[0].text;\n};\n\nThe code above uses the Messages API, which is supported by chat models such as Anthropic's Claude 3 Haiku.\n\nThe system prompt is used to give the model a persona or directives to follow, and the messages array can contain a history of messages. The max_tokens parameter controls the maximum number of tokens the model can generate, and the temperature parameter determines the randomness, or creativity, of the generated response.\n\nStep 4 - Invoke a custom query to prompt a generative AI model\n\nFrom your generated Data client, you can find all your custom queries and mutations under the client.queries and client.mutations APIs respectively.\n\nThe custom query below will prompt a generative AI model to create a haiku based on the given prompt. Replace the prompt value with your desired prompt text or user input and invoke the query as shown below:\n\nApp.tsx\nCopy\nApp.tsx code example\nconst { data, errors } = await client.queries.generateHaiku({\n  prompt: \"Frank Herbert's Dune\",\n});\n\nHere's an example of a simple UI that prompts a generative AI model to create a haiku based on user input:\n\nApp.tsx\nCopy\nApp.tsx code example\nimport { FormEvent, useState } from \"react\";\n\n\nimport { generateClient } from \"aws-amplify/api\";\nimport { Schema } from \"@/amplify/data/resource\";\n\n\nimport { Amplify } from \"aws-amplify\";\nimport outputs from \"@/amplify_outputs.json\";\n\n\nAmplify.configure(outputs);\n\n\nconst client = generateClient<Schema>();\n\n\nexport default function App() {\n  const [prompt, setPrompt] = useState<string>(\"\");\n  const [answer, setAnswer] = useState<string | null>(null);\n\n\n  const sendPrompt = async (e: FormEvent<HTMLFormElement>) => {\n    e.preventDefault();\n\n\n    const { data, errors } = await client.queries.generateHaiku({\n      prompt,\n    });\n\n\n    if (!errors) {\n      setAnswer(data);\n      setPrompt(\"\");\n    } else {\n      console.log(errors);\n    }\n  };\n\n\n  return (\n    <main className=\"flex min-h-screen flex-col items-center justify-center p-24 dark:text-white\">\n      <div>\n        <h1 className=\"text-3xl font-bold text-center mb-4\">Haiku Generator</h1>\n\n\n        <form className=\"mb-4 self-center max-w-[500px]\" onSubmit={sendPrompt}>\n          <input\n            className=\"text-black p-2 w-full\"\n            placeholder=\"Enter a prompt...\"\n            name=\"prompt\"\n            value={prompt}\n            onChange={(e) => setPrompt(e.target.value)}\n          />\n        </form>\n\n\n        <div className=\"text-center\">\n          <pre>{answer}</pre>\n        </div>\n      </div>\n    </main>\n  );\n}\n\nConclusion\n\nIn this guide, you learned how to connect to Amazon Bedrock from your Amplify app. By adding Bedrock as a data source, defining a custom query, configuring custom business logic handler code, and invoking custom queries, you can leverage the power of generative AI models in your application.\n\nTo clean up, you can delete your sandbox by accepting the prompt when terminating the sandbox process in your terminal. Alternatively, you can also use the AWS Amplify console to manage and delete sandbox environments.\n\nPREVIOUS\nConnect to Amazon Polly for Text-To-Speech APIs\nNEXT\nConnect to Amazon Rekognition for Image Analysis APIs"
  },
  {
    "title": "Connect to Amazon EventBridge to send and receive events - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/custom-business-logic/connect-eventbridge-datasource/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nAdd custom queries and mutations\n/\nConnect to Amazon EventBridge to send and receive events\nConnect to Amazon EventBridge to send and receive events\n\nAmazon EventBridge is a serverless event bus that simplifies how applications communicate with each other. It acts as a central hub for events generated by various sources, including AWS services, custom applications, and third-party SaaS providers.\n\nEventBridge delivers this event data in real-time, allowing you to build applications that react swiftly to changes. You define rules to filter and route these events to specific destinations, known as targets. Targets can include services like AWS Lambda, Amazon SQS Queues, Amazon SNS Topics. For the purpose of this guide, we will use AWS AppSync as the target for events.\n\nBy adopting an event-driven architecture with EventBridge, you can achieve:\n\nLoose Coupling: Applications become independent and communicate through events, improving scalability and maintainability.\n\nIncreased Resilience: System failures are isolated as events are delivered asynchronously, ensuring overall application availability.\n\nSimplified Integration: EventBridge provides a unified interface for integrating diverse event sources, streamlining development.\n\nThis section will guide you through adding an event bus as a datasource to your API, defining routing rules, and configuring targets to build robust event-driven applications with AWS Amplify Gen 2 and Amazon EventBridge.\n\nSet up your API\nAdd your Amazon EventBridge event bus as a data source\nDefine custom queries and mutations\nConfigure custom business logic handler code\nInvoke custom mutations to send events to EventBridge\nSubscribe to mutations invoked by EventBridge\nInvoke mutations and trigger subscriptions from EventBridge\nStep 1 - Set up your API\n\nFor the purpose of this guide, we will define an OrderStatusChange custom type that represents an order status change event. This type includes fields for the order ID, status, and message.\n\nIn your amplify/data/resource.ts file, use the following code to define an OrderStatusChange custom type and an OrderStatus enum, adding them to your schema:\n\namplify/data/resource.ts\nimport { type ClientSchema, a, defineData } from \"@aws-amplify/backend\";\n\n\nconst schema = a.schema({\n  Todo: a\n    .model({\n      content: a.string(),\n    })\n    .authorization(allow => [allow.publicApiKey()]),\nCopy\nhighlighted code example\n  OrderStatus: a.enum([\"OrderPending\", \"OrderShipped\", \"OrderDelivered\"]),\n  OrderStatusChange: a.customType({\n    orderId: a.id().required(),\n    status: a.ref(\"OrderStatus\").required(),\n    message: a.string().required(),\n  }),\n});\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    defaultAuthorizationMode: 'apiKey',\n    apiKeyAuthorizationMode: {\n      expiresInDays: 30,\n    },\n  },\n});\n\nNOTE: At least one query is required for a schema to be valid. Otherwise, deployments will fail a schema error. The Amplify Data schema is auto-generated with a Todo model and corresponding queries under the hood. You can leave the Todo model in the schema until you add the first custom query to the schema in the next steps.\n\nStep 2 - Add your Amazon EventBridge event bus as a data source\n\nIn your amplify/backend.ts file, use the following code to add the default event bus as a data source for your API:\n\namplify/backend.ts\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\nimport { aws_events } from \"aws-cdk-lib\";\nimport {\n  Effect,\n  PolicyDocument,\n  PolicyStatement,\n  Role,\n  ServicePrincipal,\n} from \"aws-cdk-lib/aws-iam\";\n\n\nexport const backend = defineBackend({\n  auth,\n  data,\n});\n\n\n// Create a new stack for the EventBridge data source\nconst eventStack = backend.createStack(\"MyExternalDataSources\");\n\n\n// Reference or create an EventBridge EventBus\nconst eventBus = aws_events.EventBus.fromEventBusName(\n  eventStack,\n  \"MyEventBus\",\n  \"default\"\n);\n\n\n// Add the EventBridge data source\nCopy\nhighlighted code example\nbackend.data.addEventBridgeDataSource(\"MyEventBridgeDataSource\", eventBus);\n\n\n// Create a policy statement to allow invoking the AppSync API's mutations\nconst policyStatement = new PolicyStatement({\n  effect: Effect.ALLOW,\n  actions: [\"appsync:GraphQL\"],\n  resources: [`${backend.data.resources.graphqlApi.arn}/types/Mutation/*`],\n});\n\n\n// Create a role for the EventBus to assume\nconst eventBusRole = new Role(eventStack, \"AppSyncInvokeRole\", {\n  assumedBy: new ServicePrincipal(\"events.amazonaws.com\"),\n  inlinePolicies: {\n    PolicyStatement: new PolicyDocument({\n      statements: [policyStatement],\n    }),\n  },\n});\n\n\n// Create an EventBridge rule to route events to the AppSync API\nconst rule = new aws_events.CfnRule(eventStack, \"MyOrderRule\", {\n  eventBusName: eventBus.eventBusName,\n  name: \"broadcastOrderStatusChange\",\n  eventPattern: {\n    source: [\"amplify.orders\"],\n    /* The shape of the event pattern must match EventBridge's event message structure.\n    So, this field must be spelled as \"detail-type\". Otherwise, events will not trigger the rule.\n\n\n    https://docs.aws.amazon.com/AmazonS3/latest/userguide/ev-events.html\n    */\n    [\"detail-type\"]: [\"OrderStatusChange\"],\n    detail: {\n      orderId: [{ exists: true }],\n      status: [\"PENDING\", \"SHIPPED\", \"DELIVERED\"],\n      message: [{ exists: true }],\n    },\n  },\n  targets: [\n    {\n      id: \"orderStatusChangeReceiver\",\n      arn: backend.data.resources.cfnResources.cfnGraphqlApi\n        .attrGraphQlEndpointArn,\n      roleArn: eventBusRole.roleArn,\n      appSyncParameters: {\n        graphQlOperation: `\n        mutation PublishOrderFromEventBridge(\n          $orderId: String!\n          $status: String!\n          $message: String!\n        ) {\n          publishOrderFromEventBridge(orderId: $orderId, status: $status, message: $message) {\n            orderId\n            status\n            message\n          }\n        }`,\n      },\n      inputTransformer: {\n        inputPathsMap: {\n          orderId: \"$.detail.orderId\",\n          status: \"$.detail.status\",\n          message: \"$.detail.message\",\n        },\n        inputTemplate: JSON.stringify({\n          orderId: \"<orderId>\",\n          status: \"<status>\",\n          message: \"<message>\",\n        }),\n      },\n    },\n  ],\n});\n\nThe selection set returned by the mutation must match the selection set of the subscription. If the selection set of the mutation is different from the selection set of the subscription, the subscription will not receive the event.\n\nIn the code snippet above, the addEventBridgeDataSource method is used to add the default event bus as a data source to your API. This allows you to reference the event bus in your custom queries and mutations.\n\nThe CfnRule construct is used to create an EventBridge rule that routes events to the AppSync API. The rule specifies the event pattern to match and the target to invoke when the event is received. In this example, the target is an AppSync mutation named publishOrderFromEventBridge.\n\nThe appSyncParameters property specifies the mutation to invoke when the event is received. The inputTransformer property maps the event data to the mutation arguments.\n\nStep 3 - Define custom queries and mutations\n\nNow that your event bus has been added as a data source, you can reference it in custom queries and mutations using the a.handler.custom() modifier which accepts the name of the data source and an entry point for your resolver.\n\nUse the following code to add publishOrderToEventBridge and publishOrderFromEventBridge custom mutations, and an onOrderStatusChange custom subscription to your schema:\n\namplify/data/resource.ts\nimport { type ClientSchema, a, defineData } from \"@aws-amplify/backend\";\n\n\nconst schema = a.schema({\n  // ...\n  OrderStatus: a.enum([\"OrderPending\", \"OrderShipped\", \"OrderDelivered\"]),\n  OrderStatusChange: a.customType({\n    orderId: a.id().required(),\n    status: a.ref(\"OrderStatus\").required(),\n    message: a.string().required(),\n  }),\nCopy\nhighlighted code example\n  publishOrderToEventBridge: a\n    .mutation()\n    .arguments({\n      orderId: a.id().required(),\n      status: a.string().required(),\n      message: a.string().required(),\n    })\n    .returns(a.ref(\"OrderStatusChange\"))\n    .authorization((allow) => [allow.publicApiKey()])\n    .handler(\n      a.handler.custom({\n        dataSource: \"EventBridgeDataSource\",\n        entry: \"./publishOrderToEventBridge.js\",\n      })\n    ),\n  publishOrderFromEventBridge: a\n    .mutation()\n    .arguments({\n      orderId: a.id().required(),\n      status: a.string().required(),\n      message: a.string().required(),\n    })\n    .returns(a.ref(\"OrderStatusChange\"))\n    .authorization((allow) => [allow.publicApiKey(), allow.guest()])\n    .handler(\n      a.handler.custom({\n        entry: \"./publishOrderFromEventBridge.js\",\n      })\n    ),\n  onOrderFromEventBridge: a\n    .subscription()\n    .for(a.ref(\"publishOrderFromEventBridge\"))\n    .authorization((allow) => [allow.publicApiKey()])\n    .handler(\n      a.handler.custom({\n        entry: \"./onOrderFromEventBridge.js\",\n      })\n    ),\n});\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema,\n  name: \"MyLibrary\",\n  authorizationModes: {\n    defaultAuthorizationMode: \"apiKey\",\n    apiKeyAuthorizationMode: {\n      expiresInDays: 30,\n    },\n  },\n});\n\nIn the code snippet above:\n\nThe publishOrderToEventBridge custom mutation uses an EventBridge data source and so it is able to publish events to the event bus from its resolver.\n\nThe publishOrderFromEventBridge custom mutation uses a None data source as a passthrough and is invoked by the EventBridge rule when an event is received that matches the rule pattern. The allow.guest rule uses IAM under the hood and allows the mutation to be invoked by the EventBridge rule.\n\nThe onOrderFromEventBridge custom subscription can be triggered either by EventBridge invoking the publishOrderFromEventBridge mutation or by a client invoking the publishOrderToEventBridge mutation.\n\nStep 4 - Configure custom business logic handler code\n\nNext, create the following files in your amplify/data folder and use the code examples to define custom resolvers for the custom queries and mutations added to your schema from the previous step. These are AppSync JavaScript resolvers\n\nSubscription\nPublish Order to EventBridge\nPublish Order From EventBridge\n\nThe following code defines the custom business logic handler for the onOrderStatusChange subscription. Since the subscription uses a None data source the response function is empty as the subscription does not require any additional processing.\n\namplify/data/onOrderStatusChange.js\nCopy\namplify/data/onOrderStatusChange.js code example\nexport function request(ctx) {\n  return {\n    payload: {},\n  };\n}\n\n\nexport function response(ctx) {\n}\nStep 5 - Invoke custom mutations to send events to EventBridge\n\nFrom your generated Data client, you can find all your custom queries and mutations under the client.queries and client.mutations APIs respectively.\n\nThe custom mutation below will publish an order status change event to the event bus:\n\nApp.tsx\nCopy\nApp.tsx code example\nawait client.mutations.publishOrderToEventBridge({\n  orderId: \"12345\",\n  status: \"SHIPPED\",\n  message: \"Order has been shipped\",\n});\nStep 6 - Subscribe to mutations invoked by EventBridge\n\nTo subscribe to events from your event bus, you can use the client.subscriptions API:\n\nApp.tsx\nCopy\nApp.tsx code example\n// Subscribe to the mutations triggered by the EventBridge rule\nconst sub = client.subscriptions.onOrderStatusChange().subscribe({\n  next: (data) => {\n    console.log(data);\n  },\n});\n\n\n//...\n\n\n// Clean up subscription\nsub.unsubscribe();\nStep 7 - Invoke a mutation and trigger a subscription from EventBridge\n\nYou can test your custom mutation and subscriptions by using the EventBridge console to send an event which will invoke the custom mutation. You can then observe the results from the subscription being triggered:\n\nNavigate to the Amazon EventBridge console and choose \"Send Events\"\n\nFill out the form, specifying the event source to be amplify.orders and the detail-type to be OrderStatusChange.\n\nChoose \"Send\" and observe the subscription output in the AppSync Queries console.\n\nConclusion\n\nIn this guide, you’ve added an Amazon EventBridge event bus as a data source to an Amplify API and defined custom queries and mutations to publish and receive events from the event bus. You’ve also configured custom business logic handler code to handle the event data and invoke the appropriate mutations.\n\nTo clean up, you can delete your sandbox by accepting the prompt when terminating the sandbox process in your terminal. Alternatively, you can also use the AWS Amplify console to manage and delete sandbox environments.\n\nPREVIOUS\nConnect to Amazon OpenSearch for search and aggregate queries\nNEXT\nConnect to Amazon Polly for Text-To-Speech APIs"
  },
  {
    "title": "Connect to Amazon OpenSearch for search and aggregate queries - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/custom-business-logic/search-and-aggregate-queries/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nAdd custom queries and mutations\n/\nConnect to Amazon OpenSearch for search and aggregate queries\nConnect to Amazon OpenSearch for search and aggregate queries\n\nAmazon OpenSearch Service provides a managed platform for deploying search and analytics solutions with OpenSearch or Elasticsearch. The zero-ETL integration between Amazon DynamoDB and OpenSearch Service allows seamless search on DynamoDB data by automatically replicating and transforming it without requiring custom code or infrastructure. This integration simplifies processes and reduces the operational workload of managing data pipelines.\n\nDynamoDB users gain access to advanced OpenSearch features like full-text search, fuzzy search, auto-complete, and vector search for machine learning capabilities. Amazon OpenSearch Ingestion synchronizes data between DynamoDB and OpenSearch Service, enabling near-instant updates and comprehensive insights across multiple DynamoDB tables. Developers can adjust index mapping templates to match Amazon DynamoDB fields with OpenSearch Service indexes.\n\nAmazon OpenSearch Ingestion, combined with S3 exports and DynamoDB streams, facilitates seamless data input from DynamoDB tables and automatic ingestion into OpenSearch. Additionally, the pipeline can back up data to S3 for potential future re-ingestion as needed.\n\nStep 1: Setup the project\n\nBegin by setting up your project by following the instructions in the Quickstart guide. For the purpose of this guide, we'll sync a Todo table from DynamoDB to OpenSearch.\n\nFirstly, add the Todo model to your schema:\n\namplify/data/resource.ts\nimport { type ClientSchema, a, defineData } from \"@aws-amplify/backend\";\n\n\nconst schema = a.schema({\nCopy\nhighlighted code example\n  Todo: a\n    .model({\n      content: a.string(),\n      done: a.boolean(),\n      priority: a.enum([\"low\", \"medium\", \"high\"]),\n    })\n    .authorization((allow) => [allow.publicApiKey()])\n});\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    defaultAuthorizationMode: \"apiKey\",\n    apiKeyAuthorizationMode: {\n      expiresInDays: 30,\n    },\n  },\n});\n\nImportant considerations:\n\nEnsure Point in Time Recovery (PITR) is enabled, which is crucial for the pipeline integration. Enable DynamoDB streams to capture item changes that will be ingested into OpenSearch.\n\namplify/backend.ts\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\nCopy\nhighlighted code example\nimport * as dynamodb from \"aws-cdk-lib/aws-dynamodb\";\n\n\nconst backend = defineBackend({\n  auth,\n  data,\n});\n\n\nCopy\nhighlighted code example\nconst todoTable =\n  backend.data.resources.cfnResources.amplifyDynamoDbTables[\"Todo\"];\n\n\n// Update table settings\ntodoTable.pointInTimeRecoveryEnabled = true;\n\n\ntodoTable.streamSpecification = {\n  streamViewType: dynamodb.StreamViewType.NEW_IMAGE,\n};\n\n\n// Get the DynamoDB table ARN\nconst tableArn = backend.data.resources.tables[\"Todo\"].tableArn;\n// Get the DynamoDB table name\nconst tableName = backend.data.resources.tables[\"Todo\"].tableName;\nStep 2: Setting Up the OpenSearch Instance\n\nCreate an OpenSearch instance with encryption.\n\namplify/backend.ts\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\nCopy\nhighlighted code example\nimport * as opensearch from \"aws-cdk-lib/aws-opensearchservice\";\nimport {  Stack } from \"aws-cdk-lib\";\n\n\nconst todoTable =\n  backend.data.resources.cfnResources.amplifyDynamoDbTables[\"Todo\"];\n\n\n// Update table settings\ntodoTable.pointInTimeRecoveryEnabled = true;\n\n\ntodoTable.streamSpecification = {\n  streamViewType: dynamodb.StreamViewType.NEW_IMAGE,\n};\n\n\n// Get the DynamoDB table ARN\nconst tableArn = backend.data.resources.tables[\"Todo\"].tableArn;\n// Get the DynamoDB table name\nconst tableName = backend.data.resources.tables[\"Todo\"].tableName;\n\n\nCopy\nhighlighted code example\n// Get the data stack\nconst dataStack = Stack.of(backend.data);\n\n\n// Create the OpenSearch domain\nconst openSearchDomain = new opensearch.Domain(\n  dataStack,\n  \"OpenSearchDomain\",\n  {\n    version: opensearch.EngineVersion.OPENSEARCH_2_11,\n    nodeToNodeEncryption: true,\n    encryptionAtRest: {\n      enabled: true,\n    },\n  }\n);\nStep 3: Setting Up Zero ETL from DynamoDB to OpenSearch\nStep 3a: Setup Storage and IAM Role\n\nEstablish Storage to back up raw events consumed by the OpenSearch pipeline. Generate a file named amplify/storage/resource.ts and insert the provided content to set up a storage resource. Tailor your storage configurations to regulate access to different paths within your storage bucket.\n\namplify/storage/resource.ts\nCopy\namplify/storage/resource.ts code example\nimport { defineStorage } from \"@aws-amplify/backend\"\n\n\nexport const storage = defineStorage({\n  name: \"opensearch-backup-bucket-amplify-gen-2\",\n  access: allow => ({\n    'public/*': [\n      allow.guest.to(['list', 'write', 'get'])\n    ]\n  })\n})\n\nGet the s3BucketArn and s3BucketName values from storage resource as shown below. Additionally, configure an IAM role for the pipeline and assign the roles as indicated below. For further information on the required IAM roles, please refer to the Setting up roles and users documentation.\n\namplify/backend.ts\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\nimport * as dynamodb from \"aws-cdk-lib/aws-dynamodb\";\nimport * as opensearch from \"aws-cdk-lib/aws-opensearchservice\";\nimport { Stack } from \"aws-cdk-lib\";\n\n\nCopy\nhighlighted code example\nimport { storage } from \"./storage/resource\";\nimport * as iam from \"aws-cdk-lib/aws-iam\";\n\n\n// Define backend resources\nconst backend = defineBackend({\n  auth,\n  data,\nCopy\nhighlighted code example\n  storage,\n});\n\n\nconst todoTable =\n  backend.data.resources.cfnResources.amplifyDynamoDbTables[\"Todo\"];\n\n\n// Update table settings\ntodoTable.pointInTimeRecoveryEnabled = true;\n\n\ntodoTable.streamSpecification = {\n  streamViewType: dynamodb.StreamViewType.NEW_IMAGE,\n};\n\n\n// Get the DynamoDB table ARN\nconst tableArn = backend.data.resources.tables[\"Todo\"].tableArn;\n// Get the DynamoDB table name\nconst tableName = backend.data.resources.tables[\"Todo\"].tableName;\n\n\n// Get the data stack\nconst dataStack = Stack.of(backend.data);\n\n\n// Create the OpenSearch domain\nconst openSearchDomain = new opensearch.Domain(\n  dataStack,\n  \"OpenSearchDomain\",\n  {\n    version: opensearch.EngineVersion.OPENSEARCH_2_11,\n    nodeToNodeEncryption: true,\n    encryptionAtRest: {\n      enabled: true,\n    },\n  }\n);\nCopy\nhighlighted code example\n// Get the S3Bucket ARN\nconst s3BucketArn = backend.storage.resources.bucket.bucketArn;\n// Get the S3Bucket Name\nconst s3BucketName = backend.storage.resources.bucket.bucketName;\n\n\n//Get the region\nconst region = dataStack.region;\n\n\n// Create an IAM role for OpenSearch integration\nconst openSearchIntegrationPipelineRole = new iam.Role(\n  dataStack,\n  \"OpenSearchIntegrationPipelineRole\",\n  {\n    assumedBy: new iam.ServicePrincipal(\"osis-pipelines.amazonaws.com\"),\n    inlinePolicies: {\n      openSearchPipelinePolicy: new iam.PolicyDocument({\n        statements: [\n          new iam.PolicyStatement({\n            actions: [\"es:DescribeDomain\"],\n            resources: [\n              openSearchDomain.domainArn,\n              openSearchDomain.domainArn + \"/*\",\n            ],\n            effect: iam.Effect.ALLOW,\n          }),\n          new iam.PolicyStatement({\n            actions: [\"es:ESHttp*\"],\n            resources: [\n              openSearchDomain.domainArn,\n              openSearchDomain.domainArn + \"/*\",\n            ],\n            effect: iam.Effect.ALLOW,\n          }),\n          new iam.PolicyStatement({\n            effect: iam.Effect.ALLOW,\n            actions: [\n              \"s3:GetObject\",\n              \"s3:AbortMultipartUpload\",\n              \"s3:PutObject\",\n              \"s3:PutObjectAcl\",\n            ],\n            resources: [s3BucketArn, s3BucketArn + \"/*\"],\n          }),\n          new iam.PolicyStatement({\n            effect: iam.Effect.ALLOW,\n            actions: [\n              \"dynamodb:DescribeTable\",\n              \"dynamodb:DescribeContinuousBackups\",\n              \"dynamodb:ExportTableToPointInTime\",\n              \"dynamodb:DescribeExport\",\n              \"dynamodb:DescribeStream\",\n              \"dynamodb:GetRecords\",\n              \"dynamodb:GetShardIterator\",\n            ],\n            resources: [tableArn, tableArn + \"/*\"],\n          }),\n        ],\n      }),\n    },\n    managedPolicies: [\n      iam.ManagedPolicy.fromAwsManagedPolicyName(\n        \"AmazonOpenSearchIngestionFullAccess\"\n      ),\n    ],\n  }\n);\n\nFor the S3 bucket, follow standard security practices: block public access, encrypt data at rest, and enable versioning.\n\nThe IAM role should allow the OpenSearch Ingestion Service (OSIS) pipelines to assume it. Grant specific OpenSearch Service permissions and also provide DynamoDB and S3 access. You may customize permissions to follow the principle of least privilege.\n\nStep 3b: OpenSearch Service Pipeline\n\nDefine the pipeline construct and its configuration.\n\nWhen using OpenSearch, you can define the index template or mapping in advance based on your data structure, which allows you to set data types for each field in the document. This approach can be incredibly powerful for precise data ingestion and search. For more information on index mapping/templates, please refer to OpenSearch documentation.\n\nCustomize the template_content JSON-representation to define the data structure for the ingestion pipeline.\n\namplify/backend.ts\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\nimport * as dynamodb from \"aws-cdk-lib/aws-dynamodb\";\nimport * as opensearch from \"aws-cdk-lib/aws-opensearchservice\";\nimport { Stack } from \"aws-cdk-lib\"; \nimport { storage } from \"./storage/resource\";\nimport * as iam from \"aws-cdk-lib/aws-iam\";\n \n// Define backend resources\nconst backend = defineBackend({\n  auth,\n  data,\n  storage,\n});\n\n\nconst todoTable =\n  backend.data.resources.cfnResources.amplifyDynamoDbTables[\"Todo\"];\n\n\n// Update table settings\ntodoTable.pointInTimeRecoveryEnabled = true;\n\n\ntodoTable.streamSpecification = {\n  streamViewType: dynamodb.StreamViewType.NEW_IMAGE,\n};\n\n\n// Get the DynamoDB table ARN\nconst tableArn = backend.data.resources.tables[\"Todo\"].tableArn;\n// Get the DynamoDB table name\nconst tableName = backend.data.resources.tables[\"Todo\"].tableName;\n\n\n// Get the data stack\nconst dataStack = Stack.of(backend.data);\n\n\n// Create the OpenSearch domain\nconst openSearchDomain = new opensearch.Domain(\n  dataStack,\n  \"OpenSearchDomain\",\n  {\n    version: opensearch.EngineVersion.OPENSEARCH_2_11,\n    nodeToNodeEncryption: true,\n    encryptionAtRest: {\n      enabled: true,\n    },\n  }\n);\n\n\n// Get the S3Bucket ARN\nconst s3BucketArn = backend.storage.resources.bucket.bucketArn;\n// Get the S3Bucket Name\nconst s3BucketName = backend.storage.resources.bucket.bucketName;\n\n\n//Get the region\nconst region = dataStack.region;\n\n\n// Create an IAM role for OpenSearch integration\nconst openSearchIntegrationPipelineRole = new iam.Role(\n  dataStack,\n  \"OpenSearchIntegrationPipelineRole\",\n  {\n    assumedBy: new iam.ServicePrincipal(\"osis-pipelines.amazonaws.com\"),\n    inlinePolicies: {\n      openSearchPipelinePolicy: new iam.PolicyDocument({\n        statements: [\n          new iam.PolicyStatement({\n            actions: [\"es:DescribeDomain\"],\n            resources: [\n              openSearchDomain.domainArn,\n              openSearchDomain.domainArn + \"/*\",\n            ],\n            effect: iam.Effect.ALLOW,\n          }),\n          new iam.PolicyStatement({\n            actions: [\"es:ESHttp*\"],\n            resources: [\n              openSearchDomain.domainArn,\n              openSearchDomain.domainArn + \"/*\",\n            ],\n            effect: iam.Effect.ALLOW,\n          }),\n          new iam.PolicyStatement({\n            effect: iam.Effect.ALLOW,\n            actions: [\n              \"s3:GetObject\",\n              \"s3:AbortMultipartUpload\",\n              \"s3:PutObject\",\n              \"s3:PutObjectAcl\",\n            ],\n            resources: [s3BucketArn, s3BucketArn + \"/*\"],\n          }),\n          new iam.PolicyStatement({\n            effect: iam.Effect.ALLOW,\n            actions: [\n              \"dynamodb:DescribeTable\",\n              \"dynamodb:DescribeContinuousBackups\",\n              \"dynamodb:ExportTableToPointInTime\",\n              \"dynamodb:DescribeExport\",\n              \"dynamodb:DescribeStream\",\n              \"dynamodb:GetRecords\",\n              \"dynamodb:GetShardIterator\",\n            ],\n            resources: [tableArn, tableArn + \"/*\"],\n          }),\n        ],\n      }),\n    },\n    managedPolicies: [\n      iam.ManagedPolicy.fromAwsManagedPolicyName(\n        \"AmazonOpenSearchIngestionFullAccess\"\n      ),\n    ],\n  }\n);\n\n\nCopy\nhighlighted code example\n\n\n// Define OpenSearch index mappings\nconst indexName = \"todo\";\n\n\nconst indexMapping = {\n  settings: {\n    number_of_shards: 1,\n    number_of_replicas: 0,\n  },\n  mappings: {\n    properties: {\n      id: {\n        type: \"keyword\",\n      },\n      isDone: {\n        type: \"boolean\",\n      },\n      content: {\n        type: \"text\",\n      },\n    },\n  },\n};\n\nThe configuration is a data-prepper feature of OpenSearch. For specific documentation on DynamoDB configuration, refer to OpenSearch data-prepper documentation.\n\namplify/backend.ts\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\nimport * as dynamodb from \"aws-cdk-lib/aws-dynamodb\";\nimport * as opensearch from \"aws-cdk-lib/aws-opensearchservice\";\nimport { Stack } from \"aws-cdk-lib\"; \nimport { storage } from \"./storage/resource\";\nimport * as iam from \"aws-cdk-lib/aws-iam\";\n \n// Define backend resources\nconst backend = defineBackend({\n  auth,\n  data,\n  storage,\n});\n\n\nconst todoTable =\n  backend.data.resources.cfnResources.amplifyDynamoDbTables[\"Todo\"];\n\n\n// Update table settings\ntodoTable.pointInTimeRecoveryEnabled = true;\n\n\ntodoTable.streamSpecification = {\n  streamViewType: dynamodb.StreamViewType.NEW_IMAGE,\n};\n\n\n// Get the DynamoDB table ARN\nconst tableArn = backend.data.resources.tables[\"Todo\"].tableArn;\n// Get the DynamoDB table name\nconst tableName = backend.data.resources.tables[\"Todo\"].tableName;\n\n\n// Get the data stack\nconst dataStack = Stack.of(backend.data);\n\n\n// Create the OpenSearch domain\nconst openSearchDomain = new opensearch.Domain(\n  dataStack,\n  \"OpenSearchDomain\",\n  {\n    version: opensearch.EngineVersion.OPENSEARCH_2_11,\n    nodeToNodeEncryption: true,\n    encryptionAtRest: {\n      enabled: true,\n    },\n  }\n);\n\n\n// Get the S3Bucket ARN\nconst s3BucketArn = backend.storage.resources.bucket.bucketArn;\n// Get the S3Bucket Name\nconst s3BucketName = backend.storage.resources.bucket.bucketName;\n\n\n//Get the region\nconst region = dataStack.region;\n\n\n// Create an IAM role for OpenSearch integration\nconst openSearchIntegrationPipelineRole = new iam.Role(\n  dataStack,\n  \"OpenSearchIntegrationPipelineRole\",\n  {\n    assumedBy: new iam.ServicePrincipal(\"osis-pipelines.amazonaws.com\"),\n    inlinePolicies: {\n      openSearchPipelinePolicy: new iam.PolicyDocument({\n        statements: [\n          new iam.PolicyStatement({\n            actions: [\"es:DescribeDomain\"],\n            resources: [\n              openSearchDomain.domainArn,\n              openSearchDomain.domainArn + \"/*\",\n            ],\n            effect: iam.Effect.ALLOW,\n          }),\n          new iam.PolicyStatement({\n            actions: [\"es:ESHttp*\"],\n            resources: [\n              openSearchDomain.domainArn,\n              openSearchDomain.domainArn + \"/*\",\n            ],\n            effect: iam.Effect.ALLOW,\n          }),\n          new iam.PolicyStatement({\n            effect: iam.Effect.ALLOW,\n            actions: [\n              \"s3:GetObject\",\n              \"s3:AbortMultipartUpload\",\n              \"s3:PutObject\",\n              \"s3:PutObjectAcl\",\n            ],\n            resources: [s3BucketArn, s3BucketArn + \"/*\"],\n          }),\n          new iam.PolicyStatement({\n            effect: iam.Effect.ALLOW,\n            actions: [\n              \"dynamodb:DescribeTable\",\n              \"dynamodb:DescribeContinuousBackups\",\n              \"dynamodb:ExportTableToPointInTime\",\n              \"dynamodb:DescribeExport\",\n              \"dynamodb:DescribeStream\",\n              \"dynamodb:GetRecords\",\n              \"dynamodb:GetShardIterator\",\n            ],\n            resources: [tableArn, tableArn + \"/*\"],\n          }),\n        ],\n      }),\n    },\n    managedPolicies: [\n      iam.ManagedPolicy.fromAwsManagedPolicyName(\n        \"AmazonOpenSearchIngestionFullAccess\"\n      ),\n    ],\n  }\n);\n\n\n// Define OpenSearch index mappings\nconst indexName = \"todo\";\n\n\nconst indexMapping = {\n  settings: {\n    number_of_shards: 1,\n    number_of_replicas: 0,\n  },\n  mappings: {\n    properties: {\n      id: {\n        type: \"keyword\",\n      },\n      isDone: {\n        type: \"boolean\",\n      },\n      content: {\n        type: \"text\",\n      },\n      priority: {\n        type: \"text\",\n      },\n    },\n  },\n};\n\n\nCopy\nhighlighted code example\n\n\n// OpenSearch template definition\nconst openSearchTemplate = `\nversion: \"2\"\ndynamodb-pipeline:\n  source:\n    dynamodb:\n      acknowledgments: true\n      tables:\n        - table_arn: \"${tableArn}\"\n          stream:\n            start_position: \"LATEST\"\n          export:\n            s3_bucket: \"${s3BucketName}\"\n            s3_region: \"${region}\"\n            s3_prefix: \"${tableName}/\"\n      aws:\n        sts_role_arn: \"${openSearchIntegrationPipelineRole.roleArn}\"\n        region: \"${region}\"\n  sink:\n    - opensearch:\n        hosts:\n          - \"https://${openSearchDomain.domainEndpoint}\"\n        index: \"${indexName}\"\n        index_type: \"custom\"\n        template_content: |\n          ${JSON.stringify(indexMapping)}\n        document_id: '\\${getMetadata(\"primary_key\")}'\n        action: '\\${getMetadata(\"opensearch_action\")}'\n        document_version: '\\${getMetadata(\"document_version\")}'\n        document_version_type: \"external\"\n        bulk_size: 4\n        aws:\n          sts_role_arn: \"${openSearchIntegrationPipelineRole.roleArn}\"\n          region: \"${region}\"\n`;\n\nThis configuration defines the desired behavior of the pipeline for a single model.\n\nIn the source configuration, DynamoDB is specified as the data source, along with the target table for ingestion and the starting point of the stream. Additionally, besides ingesting the stream into OpenSearch, a target S3 bucket is defined for backup purposes. Furthermore, an IAM role is set for the ingestion pipeline, ensuring it possesses the necessary permissions and policies as detailed in the documentation.\n\nRegarding the sink configuration, the OpenSearch domain cluster is specified by setting the host, index name, type, and template content (index mapping) for data formatting. Document-related metadata is configured along with the maximum bulk size for requests to OpenSearch in MB. Once again, an IAM role is specified for the sink portion of the pipeline. For further details on Sink configuration, please refer to the OpenSearch documentation.\n\nThe sink configuration is an array. To create a different index on the same table, you can achieve this by adding a second OpenSearch configuration to the sink array.\n\nTo index multiple tables, you'll need to configure multiple pipelines in the configuration. For further guidance, please consult the pipeline section of the OpenSearch documentation.\n\nNOTE: An OpenSearch Ingestion pipeline supports only one DynamoDB table as its source. For more details on current limitations, Please refer to Amazon OpenSearch Limitation section.\n\nNow, create the OSIS pipeline resource:\n\namplify/backend.ts\nimport { defineBackend } from \"@aws-amplify/backend\";\nimport { auth } from \"./auth/resource\";\nimport { data } from \"./data/resource\";\nimport * as dynamodb from \"aws-cdk-lib/aws-dynamodb\";\nimport * as opensearch from \"aws-cdk-lib/aws-opensearchservice\";\nimport { Stack } from \"aws-cdk-lib\"; \nimport { storage } from \"./storage/resource\";\nimport * as iam from \"aws-cdk-lib/aws-iam\";\nCopy\nhighlighted code example\nimport * as osis from \"aws-cdk-lib/aws-osis\";\nimport * as logs from \"aws-cdk-lib/aws-logs\";\nimport { RemovalPolicy } from \"aws-cdk-lib\"; \n// Define backend resources\nconst backend = defineBackend({\n  auth,\n  data,\n  storage,\n});\n\n\nconst todoTable =\n  backend.data.resources.cfnResources.amplifyDynamoDbTables[\"Todo\"];\n\n\n// Update table settings\ntodoTable.pointInTimeRecoveryEnabled = true;\n\n\ntodoTable.streamSpecification = {\n  streamViewType: dynamodb.StreamViewType.NEW_IMAGE,\n};\n\n\n// Get the DynamoDB table ARN\nconst tableArn = backend.data.resources.tables[\"Todo\"].tableArn;\n// Get the DynamoDB table name\nconst tableName = backend.data.resources.tables[\"Todo\"].tableName;\n\n\n// Get the data stack\nconst dataStack = Stack.of(backend.data);\n\n\n// Create the OpenSearch domain\nconst openSearchDomain = new opensearch.Domain(\n  dataStack,\n  \"OpenSearchDomain\",\n  {\n    version: opensearch.EngineVersion.OPENSEARCH_2_11,\n    nodeToNodeEncryption: true,\n    encryptionAtRest: {\n      enabled: true,\n    },\n  }\n);\n\n\n// Get the S3Bucket ARN\nconst s3BucketArn = backend.storage.resources.bucket.bucketArn;\n// Get the S3Bucket Name\nconst s3BucketName = backend.storage.resources.bucket.bucketName;\n\n\n//Get the region\nconst region = dataStack.region;\n\n\n// Create an IAM role for OpenSearch integration\nconst openSearchIntegrationPipelineRole = new iam.Role(\n  dataStack,\n  \"OpenSearchIntegrationPipelineRole\",\n  {\n    assumedBy: new iam.ServicePrincipal(\"osis-pipelines.amazonaws.com\"),\n    inlinePolicies: {\n      openSearchPipelinePolicy: new iam.PolicyDocument({\n        statements: [\n          new iam.PolicyStatement({\n            actions: [\"es:DescribeDomain\"],\n            resources: [\n              openSearchDomain.domainArn,\n              openSearchDomain.domainArn + \"/*\",\n            ],\n            effect: iam.Effect.ALLOW,\n          }),\n          new iam.PolicyStatement({\n            actions: [\"es:ESHttp*\"],\n            resources: [\n              openSearchDomain.domainArn,\n              openSearchDomain.domainArn + \"/*\",\n            ],\n            effect: iam.Effect.ALLOW,\n          }),\n          new iam.PolicyStatement({\n            effect: iam.Effect.ALLOW,\n            actions: [\n              \"s3:GetObject\",\n              \"s3:AbortMultipartUpload\",\n              \"s3:PutObject\",\n              \"s3:PutObjectAcl\",\n            ],\n            resources: [s3BucketArn, s3BucketArn + \"/*\"],\n          }),\n          new iam.PolicyStatement({\n            effect: iam.Effect.ALLOW,\n            actions: [\n              \"dynamodb:DescribeTable\",\n              \"dynamodb:DescribeContinuousBackups\",\n              \"dynamodb:ExportTableToPointInTime\",\n              \"dynamodb:DescribeExport\",\n              \"dynamodb:DescribeStream\",\n              \"dynamodb:GetRecords\",\n              \"dynamodb:GetShardIterator\",\n            ],\n            resources: [tableArn, tableArn + \"/*\"],\n          }),\n        ],\n      }),\n    },\n    managedPolicies: [\n      iam.ManagedPolicy.fromAwsManagedPolicyName(\n        \"AmazonOpenSearchIngestionFullAccess\"\n      ),\n    ],\n  }\n);\n\n\n// Define OpenSearch index mappings\nconst indexName = \"todo\";\n\n\nconst indexMapping = {\n  settings: {\n    number_of_shards: 1,\n    number_of_replicas: 0,\n  },\n  mappings: {\n    properties: {\n      id: {\n        type: \"keyword\",\n      },\n      isDone: {\n        type: \"boolean\",\n      },\n      content: {\n        type: \"text\",\n      },\n      priority: {\n        type: \"text\",\n      },\n    },\n  },\n};\n\n\n// OpenSearch template definition\nconst openSearchTemplate = `\nversion: \"2\"\ndynamodb-pipeline:\n  source:\n    dynamodb:\n      acknowledgments: true\n      tables:\n        - table_arn: \"${tableArn}\"\n          stream:\n            start_position: \"LATEST\"\n          export:\n            s3_bucket: \"${s3BucketName}\"\n            s3_region: \"${region}\"\n            s3_prefix: \"${tableName}/\"\n      aws:\n        sts_role_arn: \"${openSearchIntegrationPipelineRole.roleArn}\"\n        region: \"${region}\"\n  sink:\n    - opensearch:\n        hosts:\n          - \"https://${openSearchDomain.domainEndpoint}\"\n        index: \"${indexName}\"\n        index_type: \"custom\"\n        template_content: |\n          ${JSON.stringify(indexMapping)}\n        document_id: '\\${getMetadata(\"primary_key\")}'\n        action: '\\${getMetadata(\"opensearch_action\")}'\n        document_version: '\\${getMetadata(\"document_version\")}'\n        document_version_type: \"external\"\n        bulk_size: 4\n        aws:\n          sts_role_arn: \"${openSearchIntegrationPipelineRole.roleArn}\"\n          region: \"${region}\"\n`;\n\n\nCopy\nhighlighted code example\n// Create a CloudWatch log group\nconst logGroup = new logs.LogGroup(dataStack, \"LogGroup\", {\n  logGroupName: \"/aws/vended-logs/OpenSearchService/pipelines/1\",\n  removalPolicy: RemovalPolicy.DESTROY,\n});\n\n\n// Create an OpenSearch Integration Service pipeline\nconst cfnPipeline = new osis.CfnPipeline(\n  dataStack,\n  \"OpenSearchIntegrationPipeline\",\n  {\n    maxUnits: 4,\n    minUnits: 1,\n    pipelineConfigurationBody: openSearchTemplate,\n    pipelineName: \"dynamodb-integration-2\",\n    logPublishingOptions: {\n      isLoggingEnabled: true,\n      cloudWatchLogDestination: {\n        logGroup: logGroup.logGroupName,\n      },\n    },\n  }\n);\n\n\n\nAfter deploying the resources, you can test the data ingestion process by adding an item to the Todo table. However, before doing that, let's verify that the pipeline has been set up correctly.\n\nIn the AWS console, navigate to OpenSearch and then to the pipelines section. You should find your configured pipeline and review its settings to ensure they match your expectations:\n\nYou can also check this in the DynamoDB console by going to the Integrations section of the tables.\n\nStep 4: Expose new queries on OpenSearch\nStep 4a:Add OpenSearch Datasource to backend\n\nFirst, Add the OpenSearch data source to the data backend. Add the following code to the end of the amplify/backend.ts file.\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\n// Add OpenSearch data source \nconst osDataSource = backend.data.addOpenSearchDataSource(\n  \"osDataSource\",\n  openSearchDomain\n);\nStep 4b: Create Resolver and attach to query\n\nLet's create the search resolver. Create a new file named amplify/data/searchTodoResolver.js and paste the following code. For additional details please refer to Amazon OpenSearch Service Resolvers\n\namplify/data/searchTodoResolver.js\nCopy\namplify/data/searchTodoResolver.js code example\nimport { util } from \"@aws-appsync/utils\";\n\n\n/**\n * Searches for documents by using an input term\n * @param {import('@aws-appsync/utils').Context} ctx the context\n * @returns {*} the request\n */\n\n\nexport function request(ctx) {\n  return {\n    operation: \"GET\",\n    path: \"/todo/_search\",\n  };\n}\n\n\n/**\n * Returns the fetched items\n * @param {import('@aws-appsync/utils').Context} ctx the context\n * @returns {*} the result\n */\n\n\nexport function response(ctx) {\n  if (ctx.error) {\n    util.error(ctx.error.message, ctx.error.type);\n  }\n  return ctx.result.hits.hits.map((hit) => hit._source);\n}\nStep 4c: Add the AppSync Resolver for the Search Query\n\nUpdate the schema and add a searchTodo query.\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\nconst schema = a.schema({\n  Todo: a\n    .model({\n      content: a.string(),\n      done: a.boolean(),\n      priority: a.enum([\"low\", \"medium\", \"high\"]),\n    })\n    .authorization((allow) => [allow.publicApiKey()]),\n\n\nCopy\nhighlighted code example\n    searchTodos: a\n    .query()\n    .returns(a.ref(\"Todo\").array())\n    .authorization((allow) => [allow.publicApiKey()])\n    .handler(\n      a.handler.custom({\n        entry: \"./searchTodoResolver.js\",\n        dataSource: \"osDataSource\",\n      })\n    ),\n\n\n});\n\nOnce you've deployed the resources, you can verify the changes by checking the AppSync console. Run the 'searchTodo' query and review the results to confirm their accuracy.\n\nNEXT\nConnect to Amazon EventBridge to send and receive events"
  },
  {
    "title": "Add custom queries and mutations - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/custom-business-logic/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nAdd custom queries and mutations\nAdd custom queries and mutations\n\nThe a.model() data model provides a solid foundation for querying, mutating, and fetching data. However, you may need additional customizations to meet specific requirements around custom API requests, response formatting, and/or fetching from external data sources.\n\nIn the following sections, we walk through the three steps to create a custom query or mutation:\n\nDefine a custom query or mutation\nConfigure custom business logic handler code\nInvoke the custom query or mutation\nStep 1 - Define a custom query or mutation\nType\tWhen to choose\nQuery\tWhen the request only needs to read data and will not modify any backend data\nMutation\tWhen the request will modify backend data\n\nFor every custom query or mutation, you need to set a return type and, optionally, arguments. Use a.query() or a.mutation() to define your custom query or mutation in your amplify/data/resource.ts file:\n\nCustom query\nCustom mutation\nCopy\ncode example\nimport { type ClientSchema, a, defineData } from '@aws-amplify/backend';\n\n\nconst schema = a.schema({\n  // 1. Define your return type as a custom type\n  EchoResponse: a.customType({\n    content: a.string(),\n    executionDuration: a.float()\n  }),\n\n\n  // 2. Define your query with the return type and, optionally, arguments\n  echo: a\n    .query()\n    // arguments that this query accepts\n    .arguments({\n      content: a.string()\n    })\n    // return type of the query\n    .returns(a.ref('EchoResponse'))\n    // only allow signed-in users to call this API\n    .authorization(allow => [allow.authenticated()])\n});\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema\n});\nStep 2 - Configure custom business logic handler code\n\nAfter your query or mutation is defined, you need to author your custom business logic. You can either define it in a function or using a custom resolver powered by AppSync JavaScript resolver.\n\nFunction\nCustom resolver powered by AppSync JavaScript resolvers\n\nIn your amplify/data/echo-handler/ folder, create a handler.ts file. You can import a utility type for your function handler via the Schema type from your backend resource. This gives you type-safe handler parameters and return values.\n\namplify/data/echo-handler/handler.ts\nCopy\namplify/data/echo-handler/handler.ts code example\nimport type { Schema } from '../resource'\n\n\nexport const handler: Schema[\"echo\"][\"functionHandler\"] = async (event, context) => {\n  const start = performance.now();\n  return {\n    content: `Echoing content: ${event.arguments.content}`,\n    executionDuration: performance.now() - start\n  };\n};\n\nIn your amplify/data/resource.ts file, define the function using defineFunction and then reference the function with your query or mutation using a.handler.function() as a handler.\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\nimport {\n  type ClientSchema,\n  a,\n  defineData,\n  defineFunction // 1.Import \"defineFunction\" to create new functions\n} from '@aws-amplify/backend';\n\n\n// 2. define a function\nconst echoHandler = defineFunction({\n  entry: './echo-handler/handler.ts'\n})\n\n\nconst schema = a.schema({\n  EchoResponse: a.customType({\n    content: a.string(),\n    executionDuration: a.float()\n  }),\n\n\n  echo: a\n    .query()\n    .arguments({ content: a.string() })\n    .returns(a.ref('EchoResponse'))\n    .authorization(allow => [allow.publicApiKey()])\n    // 3. set the function has the handler\n    .handler(a.handler.function(echoHandler))\n});\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    defaultAuthorizationMode: 'apiKey',\n    apiKeyAuthorizationMode: {\n      expiresInDays: 30\n    },\n  },\n});\n\nAll handlers must be of the same type. For example, you can't mix and match a.handler.function with a.handler.custom within a single .handler() modifier.\n\nStep 3 - Invoke the custom query or mutation\n\nFrom your generated Data client, you can find all your custom queries and mutations under the client.queries. and client.mutations. APIs respectively.\n\nCustom query\nCustom mutation\nCopy\ncode example\nconst { data, errors } = await client.queries.echo({\n  content: 'hello world!!!'\n});\nPREVIOUS\nCustomize your auth rules\nNEXT\nWorking with files/attachments"
  },
  {
    "title": "Grant Lambda function access to API and Data - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/customize-authz/grant-lambda-function-access-to-api/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nCustomize your auth rules\n/\nGrant Lambda function access to API and Data\nGrant Lambda function access to API and Data\n\nFunction access to defineData can be configured using an authorization rule on the schema object.\n\namplify/data/resource.ts\nimport {\n  a,\n  defineData,\n  defineFunction,\n  type ClientSchema\n} from '@aws-amplify/backend';\n\n\nconst functionWithDataAccess = defineFunction({\n  entry: '../functions/data-access.ts'\n});\n\n\nconst schema = a\n  .schema({\n    Todo: a.model({\n      name: a.string(),\n      description: a.string()\n    })\n  })\nCopy\nhighlighted code example\n  .authorization(allow => [allow.resource(functionWithDataAccess)]);\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema\n});\n\nThe object returned from defineFunction can be passed directly to allow.resource() in the schema authorization rules. This will grant the function the ability to execute Query, Mutation, and Subscription operations against the GraphQL API. Use the .to() method to narrow down access to one or more operations.\n\nconst schema = a\n  .schema({\n    Todo: a.model({\n      name: a.string(),\n      description: a.string()\n    })\n  })\nCopy\nhighlighted code example\n  .authorization(allow => [\n    allow.resource(functionWithDataAccess).to(['query', 'listen'])\n  ]); // allow query and subscription operations but not mutations\n\nWhen configuring function access, the function will be provided the API endpoint as an environment variable named <defineDataName>_GRAPHQL_ENDPOINT, where defineDataName is transformed to SCREAMING_SNAKE_CASE. The default name is AMPLIFY_DATA_GRAPHQL_ENDPOINT unless you have specified a different name in defineData.\n\nFunction access can only be configured on the schema object. It cannot be configured on individual models or fields.\n\nAccess the API using aws-amplify\n\nIn the handler file for your function, configure the Amplify data client\n\namplify/functions/data-access.ts\nCopy\namplify/functions/data-access.ts code example\nimport { Amplify } from 'aws-amplify';\nimport { generateClient } from 'aws-amplify/data';\nimport { Schema } from '../data/resource';\nimport { env } from '$amplify/env/<function-name>'; // replace with your function name\n\n\n\n\nAmplify.configure(\n  {\n    API: {\n      GraphQL: {\n        endpoint: env.<amplifyData>_GRAPHQL_ENDPOINT, // replace with your defineData name\n        region: env.AWS_REGION,\n        defaultAuthMode: 'identityPool'\n      }\n    }\n  },\n  {\n    Auth: {\n      credentialsProvider: {\n        getCredentialsAndIdentityId: async () => ({\n          credentials: {\n            accessKeyId: env.AWS_ACCESS_KEY_ID,\n            secretAccessKey: env.AWS_SECRET_ACCESS_KEY,\n            sessionToken: env.AWS_SESSION_TOKEN,\n          },\n        }),\n        clearCredentialsAndIdentityId: () => {\n          /* noop */\n        },\n      },\n    },\n  }\n);\n\n\nconst dataClient = generateClient<Schema>();\n\n\nexport const handler = async (event) => {\n  // your function code goes here\n}\n\nUse the command below to generate GraphQL client code to call your data backend.\n\nNote: We are working on bringing the end-to-end typed experience to connect to your data from within function resources without needing this step. If you'd like to provide feedback the experience or have early access, join our Discord community.\n\nTerminal\nCopy\nTerminal code example\nnpx ampx generate graphql-client-code --out <path-function-handler-dir>/graphql\n\nNote: Whenever you update your data model, you will need to run the command above again.\n\nOnce you have generated the client code, update the function to access the data. The following code creates a todo and then lists all todos.\n\namplify/functions/data-access.ts\nCopy\namplify/functions/data-access.ts code example\nconst client = generateClient<Schema>();\n\n\nexport const handler = async (event) => {\n  await client.graphql({\n    query: createTodo,\n    variables: {\n      input: {\n        name: \"My first todo\",\n        description: \"This is my first todo\",\n      },\n    },\n  });\n\n\n\n\n  await client.graphql({\n    query: listTodos,\n  });\n\n\n  return event;\n};\nPREVIOUS\nConfigure custom identity and group claims"
  },
  {
    "title": "Configure custom identity and group claims - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/customize-authz/configure-custom-identity-and-group-claim/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nCustomize your auth rules\n/\nConfigure custom identity and group claims\nConfigure custom identity and group claims\n\nAmplify Data supports using custom identity and group claims if you do not wish to use the default Amazon Cognito-provided cognito:groups or the double-colon-delimited claims, sub::username, from your JWT token. This can be helpful if you are using tokens from a 3rd party OIDC system or if you wish to populate a claim with a list of groups from an external system, such as when using a Pre Token Generation Lambda Trigger which reads from a database.\n\nTo use custom claims specify identityClaim or groupClaim as appropriate. In the example below, the identityClaim is specified and the record owner will check against this user_id claim. Similarly, if the user_groups claim contains a \"Moderator\" string then access will be granted.\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\nimport { a, defineData, type ClientSchema } from '@aws-amplify/backend';\n\n\nconst schema = a.schema({\n  Post: a\n    .model({\n      id: a.id(),\n      owner: a.string(),\n      postname: a.string(),\n      content: a.string(),\n    })\n    .authorization(allow => [\n      allow.owner().identityClaim('user_id'),\n      allow.groups(['Moderator']).withClaimIn('user_groups'),\n    ]),\n});\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({ schema });\n\nIn your application, you can perform CRUD operations against the model using client.models.<model-name> with the userPool auth mode.\n\nimport { generateClient } from 'aws-amplify/data';\nimport type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition\n\n\nconst client = generateClient<Schema>();\n\n\nconst { errors, data: newTodo } = await client.models.Todo.create(\n  {\n    postname: 'My New Post'\n    content: 'My post content',\n  },\nCopy\nhighlighted code example\n  {\n    authMode: 'userPool',\n  }\n);\nPREVIOUS\nUse OpenID Connect as an authorization provider\nNEXT\nGrant Lambda function access to API and Data"
  },
  {
    "title": "Custom data access using Lambda functions - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/customize-authz/custom-data-access-patterns/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nCustomize your auth rules\n/\nCustom data access using Lambda functions\nCustom data access using Lambda functions\n\nYou can define your own custom authorization rule with a Lambda function.\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\nimport {\n  type ClientSchema,\n  a,\n  defineData,\n  defineFunction,\n} from '@aws-amplify/backend';\n\n\nconst schema = a.schema({\n  Todo: a\n    .model({\n      content: a.string(),\n    })\n    // STEP 1\n    // Indicate which models / fields should use a custom authorization rule\n    .authorization(allow => [allow.custom()]),\n});\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    defaultAuthorizationMode: 'lambda',\n    // STEP 2\n    // Pass in the function to be used for a custom authorization rule\n    lambdaAuthorizationMode: {\n      function: defineFunction({\n        entry: './custom-authorizer.ts',\n      }),\n      // (Optional) STEP 3\n      // Configure the token's time to live\n      timeToLiveInSeconds: 300,\n    },\n  },\n});\n\nIn your application, you can perform CRUD operations against the model using client.models.<model-name> with the lambda auth mode.\n\nimport { generateClient } from 'aws-amplify/data';\nimport type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition\n\n\nconst client = generateClient<Schema>();\n\n\nconst { errors, data: newTodo } = await client.models.Todo.create(\n  {\n    content: 'My new todo',\n  },\nCopy\nhighlighted code example\n  {\n    authMode: 'lambda',\n  }\n);\n\nThe Lambda function of choice will receive an authorization token from the client and execute the desired authorization logic. The AppSync GraphQL API will receive a payload from Lambda after invocation to allow or deny the API call accordingly.\n\nTo configure a Lambda function as the authorization mode, create a new file amplify/data/custom-authorizer.ts. You can use this Lambda function code template as a starting point for your authorization handler code:\n\nCopy\ncode example\n// amplify/data/custom-authorizer.ts\n\n\n// This is sample code. Update this to suite your needs\nimport type { AppSyncAuthorizerHandler } from 'aws-lambda'; // types imported from @types/aws-lambda\n\n\ntype ResolverContext = {\n  userid: string;\n  info: string;\n  more_info: string;\n};\n\n\nexport const handler: AppSyncAuthorizerHandler<ResolverContext> = async (\n  event\n) => {\n  console.log(`EVENT: ${JSON.stringify(event)}`);\n  const {\n    authorizationToken,\n    requestContext: { apiId, accountId }\n  } = event;\n  const response = {\n    isAuthorized: authorizationToken === 'custom-authorized',\n    resolverContext: {\n      // eslint-disable-next-line spellcheck/spell-checker\n      userid: 'user-id',\n      info: 'contextual information A',\n      more_info: 'contextual information B'\n    },\n    deniedFields: [\n      `arn:aws:appsync:${process.env.AWS_REGION}:${accountId}:apis/${apiId}/types/Event/fields/comments`,\n      `Mutation.createEvent`\n    ],\n    ttlOverride: 300\n  };\n  console.log(`RESPONSE: ${JSON.stringify(response, null, 2)}`);\n  return response;\n};\n\nYou can use the template above as a starting point for your custom authorization rule. The authorization Lambda function receives the following event:\n\nCopy\ncode example\n{\n    \"authorizationToken\": \"ExampleAuthToken123123123\", # Authorization token specified by client\n    \"requestContext\": {\n        \"apiId\": \"aaaaaa123123123example123\", # AppSync API ID\n        \"accountId\": \"111122223333\", # AWS Account ID\n        \"requestId\": \"f4081827-1111-4444-5555-5cf4695f339f\",\n        \"queryString\": \"mutation CreateEvent {...}\\n\\nquery MyQuery {...}\\n\", # GraphQL query\n        \"operationName\": \"MyQuery\", # GraphQL operation name\n        \"variables\": {} # any additional variables supplied to the operation\n    }\n}\n\nYour Lambda authorization function needs to return the following JSON:\n\nCopy\ncode example\n{\n  // required\n  \"isAuthorized\": true, // if \"false\" then an UnauthorizedException is raised, access is denied\n  \"resolverContext\": { \"banana\": \"very yellow\" }, // JSON object visible as $ctx.identity.resolverContext in VTL resolver templates\n\n\n  // optional\n  \"deniedFields\": [\"TypeName.FieldName\"], // Forces the fields to \"null\" when returned to the client\n  \"ttlOverride\": 10 // The number of seconds that the response should be cached for. Overrides default specified in \"amplify update api\"\n}\n\nReview the Amplify documentation to set the custom authorization token for the Data client.\n\nPREVIOUS\nUser group-based data access\nNEXT\nUse OpenID Connect as an authorization provider"
  },
  {
    "title": "Use OpenID Connect as an authorization provider - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/customize-authz/using-oidc-authorization-provider/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nCustomize your auth rules\n/\nUse OpenID Connect as an authorization provider\nUse OpenID Connect as an authorization provider\n\nPrivate, owner, and group authorization can be configured with an OpenID Connect (OIDC) authorization mode. Add \"oidc\" to the authorization rule as the provider. Use the oidcAuthorizationMode property to configure the OpenID Connect provider name, OpenID Connect provider domain, Client ID, Issued at TTL, and Auth Time TTL.\n\nThe example below highlights the supported authorization strategies with a oidc authorization provider. For owner and group-based authorization, you also will need to specify a custom identity and group claim.\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\n// amplify/data/resource.ts\nimport { a, defineData, type ClientSchema } from '@aws-amplify/backend';\n\n\nconst schema = a.schema({\n  Todo: a\n    .model({\n      content: a.string(),\n    })\n    .authorization(allow => [\n      allow.owner('oidc').identityClaim('user_id'),\n      allow.authenticated('oidc'),\n      allow\n        .groups(['testGroupName'], 'oidc')\n        .withClaimIn('user_groups'),\n    ]),\n});\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    defaultAuthorizationMode: 'oidc',\n    oidcAuthorizationMode: {\n      oidcProviderName: 'oidc-provider-name',\n      oidcIssuerUrl: 'https://example.com',\n      clientId: 'client-id',\n      tokenExpiryFromAuthInSeconds: 300,\n      tokenExpireFromIssueInSeconds: 600,\n    },\n  },\n});\n\nIn your application, you can perform CRUD operations against the model using client.models.<model-name> by specifying the oidc auth mode.\n\nimport { generateClient } from 'aws-amplify/data';\nimport type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition\n\n\nconst client = generateClient<Schema>();\n\n\nconst { errors, data: todos } = await client.models.Todo.list({\nCopy\nhighlighted code example\n  authMode: \"oidc\",\n});\nPREVIOUS\nCustom data access using Lambda functions\nNEXT\nConfigure custom identity and group claims"
  },
  {
    "title": "User group-based data access - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/customize-authz/user-group-based-data-access/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nCustomize your auth rules\n/\nUser group-based data access\nUser group-based data access\n\nYou can use the group authorization strategy to restrict access based on user groups. The user group authorization strategy allows restricting data access to specific user groups or groups defined dynamically on each data record.\n\nAdd authorization rules for specific user groups\n\nWhen you want to restrict access to a specific set of user groups, provide the group names in the groups parameter. In the example below, only users that are part of the \"Admin\" user group are granted access to the Salary model.\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\n// allow one specific group\nconst schema = a.schema({\n  Salary: a\n    .model({\n      wage: a.float(),\n      currency: a.string(),\n    })\n    .authorization(allow => [allow.group('Admin')]),\n});\n\nIn your application, you can perform CRUD operations against the model using client.models.<model-name> with the userPool auth mode.\n\nimport { generateClient } from 'aws-amplify/data';\nimport type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition\n\n\nconst client = generateClient<Schema>();\n\n\n// As a signed-in user that belongs to the 'Admin' User Pool Group\nconst { errors, data: newSalary } = await client.models.Salary.create(\n  {\n    wage: 50.25,\n    currency: 'USD'\n  },\nCopy\nhighlighted code example\n  {\n    authMode: 'userPool',\n  }\n);\n\nThis can then be updated to allow access to multiple defined groups; in this example below we added access for \"Leadership\".\n\nCopy\ncode example\n// allow multiple specific groups\nconst schema = a.schema({\n  Salary: a\n    .model({\n      wage: a.float(),\n      currency: a.string(),\n    })\n    .authorization(allow => [allow.groups(['Admin', 'Leadership'])]),\n});\nAdd authorization rules for dynamically set user groups\n\nWith dynamic group authorization, each record contains an attribute specifying what Cognito groups should be able to access it. Use the first argument to specify which attribute in the underlying data store holds this group information. To specify that a single group should have access, use a field of type a.string(). To specify that multiple groups should have access, use a field of type a.string().array().\n\nCopy\ncode example\n// Dynamic group authorization with multiple groups\nconst schema = a.schema({\n  Post: a\n    .model({\n      title: a.string(),\n      groups: a.string().array(),\n    })\n    .authorization(allow => [allow.groupsDefinedIn('groups')]),\n});\nCopy\ncode example\n// Dynamic group authorization with a single group\nconst schema = a.schema({\n  Post: a\n    .model({\n      title: a.string(),\n      group: a.string(),\n    })\n    .authorization(allow => [allow.groupDefinedIn('group')]),\n});\n\nBy default, group authorization leverages Amazon Cognito user pool groups but you can also use OpenID Connect with group authorization. See OpenID Connect as an authorization provider.\n\nKnown limitations for real-time subscriptions when using dynamic group authorization:\n\nIf you authorize based on a single group per record, then subscriptions are only supported if the user is part of 5 or fewer user groups\nIf you authorize via an array of groups (groups: a.string().array() used in the example above),\nsubscriptions are only supported if the user is part of 20 or fewer groups\nyou can only authorize 20 or fewer user groups per record\nPREVIOUS\nSigned-in user data access\nNEXT\nCustom data access using Lambda functions"
  },
  {
    "title": "Signed-in user data access - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/customize-authz/signed-in-user-data-access/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nCustomize your auth rules\n/\nSigned-in user data access\nSigned-in user data access\n\nThe authenticated authorization strategy restricts record access to only signed-in users authenticated through IAM, Cognito, or OpenID Connect, applying the authorization rule to all users. It provides a simple way to make data private to all authenticated users.\n\nAdd signed-in user authorization rule\n\nYou can use the authenticated authorization strategy to restrict a record's access to every signed-in user.\n\nNote: If you want to restrict a record's access to a specific user, see Per-user/per-owner data access. The authenticated authorization strategy detailed on this page applies the authorization rule for data access to every signed-in user.\n\nIn the example below, anyone with a valid JWT token from the Cognito user pool is allowed access to all Todos.\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\nconst schema = a.schema({\n  Todo: a\n    .model({\n      content: a.string(),\n    })\n    .authorization(allow => [allow.authenticated()]),\n});\n\nIn your application, you can perform CRUD operations against the model using client.models.<model-name> with the userPool auth mode.\n\nimport { generateClient } from 'aws-amplify/data';\nimport type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition\n\n\nconst client = generateClient<Schema>();\n\n\nconst { errors, data: newTodo } = await client.models.Todo.create(\n  {\n    content: 'My new todo',\n  },\nCopy\nhighlighted code example\n  {\n    authMode: 'userPool',\n  }\n);\nUse identity pool for signed-in user authentication\n\nYou can also override the authorization provider. In the example below, identityPool is specified as the provider which allows you to use an \"Unauthenticated Role\" from the Cognito identity pool for public access instead of an API key. Your Auth resources defined in amplify/auth/resource.ts generates scoped down IAM policies for the \"Unauthenticated role\" in the Cognito identity pool automatically.\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\nconst schema = a.schema({\n  Todo: a\n    .model({\n      content: a.string(),\n    })\n    .authorization(allow => [allow.authenticated('identityPool')]),\n});\n\nIn your application, you can perform CRUD operations against the model using client.models.<model-name> with the iam auth mode.\n\nThe user must be logged in for the Amplify Library to use the authenticated role from your Cognito identity pool.\n\nimport { generateClient } from 'aws-amplify/data';\nimport type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition\n\n\nconst client = generateClient<Schema>();\n\n\nconst { errors, data: newTodo } = await client.models.Todo.create(\n  {\n    content: 'My new todo',\n  },\nCopy\nhighlighted code example\n  {\n    authMode: 'identityPool',\n  }\n);\n\nIn addition, you can also use OpenID Connect with authenticated authorization. See OpenID Connect as an authorization provider.\n\nPREVIOUS\nMulti-user data access\nNEXT\nUser group-based data access"
  },
  {
    "title": "Per-user/per-owner data access - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/customize-authz/per-user-per-owner-data-access/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nCustomize your auth rules\n/\nPer-user/per-owner data access\nPer-user/per-owner data access\n\nThe owner authorization strategy restricts operations on a record to only the record's owner. When configured, the owner field will automatically be added and populated with the identity of the created user. The API will authorize against the owner field to allow or deny operations.\n\nAdd per-user/per-owner authorization rule\n\nYou can use the owner authorization strategy to restrict a record's access to a specific user. When owner authorization is configured, only the record's owner is allowed the specified operations.\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\n// The \"owner\" of a Todo is allowed to create, read, update, and delete their own todos\nconst schema = a.schema({\n  Todo: a\n    .model({\n      content: a.string(),\n    })\n    .authorization(allow => [allow.owner()]),\n});\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\n// The \"owner\" of a Todo record is only allowed to create, read, and update it.\n// The \"owner\" of a Todo record is denied to delete it.\nconst schema = a.schema({\n  Todo: a\n    .model({\n      content: a.string(),\n    })\n    .authorization(allow => [allow.owner().to(['create', 'read', 'update'])]),\n});\n\nIn your application, you can perform CRUD operations against the model using client.models.<model-name> with the userPool auth mode.\n\nimport { generateClient } from 'aws-amplify/data';\nimport type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition\n\n\nconst client = generateClient<Schema>();\n\n\nconst { errors, data: newTodo } = await client.models.Todo.create(\n  {\n    content: 'My new todo',\n  },\nCopy\nhighlighted code example\n  {\n    authMode: 'userPool',\n  }\n);\n\nBehind the scenes, Amplify will automatically add a owner: a.string() field to each record which contains the record owner's identity information upon record creation.\n\nBy default, the Cognito user pool's user information is populated into the owner field. The value saved includes sub and username in the format <sub>::<username>. The API will authorize against the full value of <sub>::<username> or sub / username separately and return username. You can alternatively configure OpenID Connect as an authorization provider.\n\nBy default, owners can reassign the owner of their existing record to another user.\n\nTo prevent an owner from reassigning their record to another user, protect the owner field (by default owner: String) with a field-level authorization rule. For example, in a social media app, you would want to prevent Alice from being able to reassign Alice's Post to Bob.\n\nCopy\ncode example\nconst schema = a.schema({\n  Todo: a\n    .model({\n      content: a.string(),\n      owner: a.string().authorization(allow => [allow.owner().to(['read', 'delete'])]),\n    })\n    .authorization(allow => [allow.owner()]),\n});\nCustomize the owner field\n\nYou can override the owner field to your own preferred field, by specifying a custom ownerField in the authorization rule.\n\nCopy\ncode example\nconst schema = a.schema({\n  Todo: a\n    .model({\n      content: a.string(),\n      author: a.string(), // record owner information now stored in \"author\" field\n    })\n    .authorization(allow => [allow.ownerDefinedIn('author')]),\n});\nPREVIOUS\nPublic data access\nNEXT\nMulti-user data access"
  },
  {
    "title": "Multi-user data access - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/customize-authz/multi-user-data-access/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nCustomize your auth rules\n/\nMulti-user data access\nMulti-user data access\n\nThe ownersDefinedIn rule grants a set of users access to a record by automatically creating an owners field to store the allowed record owners. You can override the default owners field name by specifying inField with the desired field name to store the owner information. You can dynamically manage which users can access a record by updating the owner field.\n\nAdd multi-user authorization rule\n\nIf you want to grant a set of users access to a record, you use the ownersDefinedIn rule. This automatically creates a owners: a.string().array() field to store the allowed owners.\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\nconst schema = a.schema({\n  Todo: a\n    .model({\n      content: a.string(),\n      owners: a.string().array(),\n    })\n    .authorization(allow => [allow.ownersDefinedIn('owners')]),\n});\n\nIn your application, you can perform CRUD operations against the model using client.models.<model-name> with the userPool auth mode.\n\nimport { generateClient } from 'aws-amplify/data';\nimport type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition\n\n\nconst client = generateClient<Schema>();\n\n\n// Create a record with current user as first owner\nconst { errors, data: newTodo } = await client.models.Todo.create(\n  {\n    content: 'My new todo',\n  },\nCopy\nhighlighted code example\n  {\n    authMode: 'userPool',\n  }\n);\n\nAdd another user as an owner\n\nawait client.models.Todo.update(\n  {\n    id: newTodo.id,\n    owners: [...(newTodo.owners as string[]), otherUserId],\n  },\nCopy\nhighlighted code example\n  {\n    authMode: \"userPool\"\n  }\n);\nOverride to a list of owners\n\nYou can override the inField to a list of owners. Use this if you want a dynamic set of users to have access to a record. In the example below, the authors list is populated with the creator of the record upon record creation. The creator can then update the authors field with additional users. Any user listed in the authors field can access the record.\n\nCopy\ncode example\nconst schema = a.schema({\n  Todo: a\n    .model({\n      content: a.string(),\n      authors: a.string().array(), // record owner information now stored in \"authors\" field\n    })\n    .authorization(allow => [allow.ownersDefinedIn('authors')]),\n});\nPREVIOUS\nPer-user/per-owner data access\nNEXT\nSigned-in user data access"
  },
  {
    "title": "Customize your auth rules - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/customize-authz/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nCustomize your auth rules\nCustomize your auth rules\n\nUse the .authorization() modifier to configure authorization rules for public, signed-in user, per user, and per user group data access. Authorization rules operate on the deny-by-default principle. Meaning that if an authorization rule is not specifically configured, it is denied.\n\nCopy\ncode example\nconst schema = a.schema({\n  Post: a.model({\n    content: a.string()\n  }).authorization(allow => [\n    // Allow anyone auth'd with an API key to read everyone's posts.\n    allow.publicApiKey().to(['read']),\n    // Allow signed-in user to create, read, update,\n    // and delete their __OWN__ posts.\n    allow.owner(),\n  ])\n})\n\nIn the example above, everyone (public) can read every Post but authenticated users (owner) can create, read, update, and delete their own posts. Amplify also allows you to restrict the allowed operations, combine multiple authorization rules, and apply fine-grained field-level authorization.\n\nAvailable authorization strategies\n\nUse the guide below to select the correct authorization strategy for your use case:\n\nRecommended use case\tStrategy\tauthMode\nPublic data access where users or devices are anonymous. Anyone with the AppSync API key is granted access.\tpublicApiKey\tapiKey\nRecommended for production environment's public data access. Public data access where unauthenticated users or devices are granted permissions using Amazon Cognito identity pool's role for unauthenticated identities.\tguest\tidentityPool\nPer user data access. Access is restricted to the \"owner\" of a record. Leverages amplify/auth/resource.ts Cognito user pool by default.\towner/ownerDefinedIn/ownersDefinedIn\tuserPool / oidc\nAny signed-in data access. Unlike owner-based access, any signed-in user has access.\tauthenticated\tuserPool / oidc / identityPool\nPer user group data access. A specific or dynamically configured group of users has access.\tgroup/groupDefinedIn/groups/groupsDefinedIn\tuserPool / oidc\nDefine your own custom authorization rule within a serverless function.\tcustom\tlambda\nUnderstand how authorization rules are applied\n\nAuthorization rules can be applied globally across all data models in a schema, onto specific data models, and onto specific fields.\n\nAmplify will always use the most specific authorization rule that is available. For example, if there is an authorization rule for a field and an authorization rule for the model that the field belongs to, Amplify will evaluate against the field-level authorization rule. Review Field-level authorization rules to learn more.\n\nIf there are multiple authorization rules present, they will be logically OR'ed. Review Configure multiple authorization rules to learn more. For userPools and oidc authorization modes, the rules are evaluated in the sequence authenticated > group(s) > owner(s)DefinedIn > group(s)DefinedIn.\n\nGlobal authorization rule (only for getting started)\n\nTo help you get started, you can define an authorization rule on the data schema that will be applied to all data models that do not have a model-level authorization rule. Instead of having a global authorization rule for all production environments, we recommend creating specific authorization rules for each model or field.\n\nThe global authorization rule below uses allow.publicApiKey(). This example allows anyone to create, read, update, and delete and is applied to every data model.\n\nCopy\ncode example\nconst schema = a.schema({\n  // Because no model-level authorization rule is present\n  // this model will use the global authorization rule.\n  Todo: a.model({\n    content: a.string()\n  }),\n\n\n  // Will use model-level authorization rule\n  Notes: a.model({\n    content: a.string()\n    // [Model-level authorization rule]\n  }).authorization(allow => [allow.publicApiKey().to(['read'])])\n\n\n// [Global authorization rule]\n}).authorization(allow => [\n  allow.publicApiKey()\n])\nModel-level authorization rules\n\nAdd an authorization rule to a model to apply the authorization rule to all fields of that model.\n\nCopy\ncode example\nconst schema = a.schema({\n  Post: a.model({\n    content: a.string(),\n    createdBy: a.string()\n    // [Model-level authorization rule]\n    // All fields (content, createdBy) will be protected by\n    // this authorization rule\n  }).authorization(allow => [\n    allow.publicApiKey().to(['read']),\n    allow.owner(),\n  ])\n})\nField-level authorization rules\n\nWhen an authorization rule is added to a field, it will strictly define the authorization rules applied on the field. Field-level authorization rules do not inherit model-level authorization rules. Meaning, only the specified field-level authorization rule is applied.\n\nIn the example below:\n\nOwners are allowed to create, read, update, and delete Employee records they own\nAny signed in user has read access and can read data with the exception of the ssn field\nOnly the ssn field has owner auth applied and this field-level auth rule means that model-level auth rules are not applied\nCopy\ncode example\nconst schema = a.schema({\n  Employee: a.model({\n    name: a.string(),\n    email: a.string(),\n    // [Field-level authorization rule]\n    // This auth rule will be used for the \"ssn\" field\n    // All other fields will use the model-level auth rule\n    ssn: a.string().authorization(allow => [allow.owner()]),\n  })\n\n\n  // [Model-level authorization rule]\n  .authorization(allow => [\n    allow.authenticated().to([\"read\"]),\n    allow.owner()\n  ]),\n});\nNon-model authorization rules\n\nNon-model types are any types added to the schema without using a.model(). These consist of modifiers such as a.customType(), a.enum(),a.query(), a.mutation(), or a.subscription().\n\nDynamic authorization rules such as allow.owner(), allow.ownerDefinedIn(), allow.groupDefinedIn() are not supported for non-model types.\n\nCopy\ncode example\nconst schema = a.schema({\n  // ...\n  listCustomType: a\n    .query()\n    .returns(a.ref(\"CustomType\").array())\n    .handler(\n      a.handler.custom({\n        entry: \"./handler.js\",\n      })\n    )\n    .authorization((allow) => [\n      // Static auth rules - Supported\n      allow.guest(),\n      allow.publicApiKey(),\n      allow.authenticated(),\n      allow.group(\"Admin\"),\n      allow.groups([\"Teacher\", \"Student\"]),\n\n\n      // Dynamic auth rules - Not supported\n      allow.owner(),\n      allow.ownerDefinedIn(\"owner\"),\n      allow.ownersDefinedIn(\"otherOwners\"),\n      allow.groupDefinedIn(\"group\"),\n      allow.groupsDefinedIn(\"otherGroups\"),\n    ]),\n});\n\nThere are TS warnings and validation checks in place that will cause a sandbox deployment to fail if unsupported auth rules are defined on custom queries and mutations.\n\nConfigure multiple authorization rules\n\nWhen combining multiple authorization rules, they are \"logically OR\"-ed. In the following example:\n\nAny user (using Amazon Cognito identity pool's unauthenticated roles) is allowed to read all posts\nOwners are allowed to create, read, update, and delete their own posts\nCopy\ncode example\nconst schema = a.schema({\n  Post: a.model({\n    title: a.string(),\n    content: a.string()\n  }).authorization(allow => [\n    allow.guest().to([\"read\"]),\n    allow.owner()\n  ])\n})\n\nOn the client side, make sure to always authenticate with the corresponding authorization mode.\n\nCopy\ncode example\nimport { generateClient } from 'aws-amplify/data'\nimport type { Schema } from '@/amplify/data/resource' // Path to your backend resource definition\n\n\nconst client = generateClient<Schema>()\n\n\n// Creating a post is restricted to Cognito User Pools\nconst { data: newPostResult , errors } = await client.models.Post.create({\n\tquery: queries.createPost,\n\tvariables: { input: { title: 'Hello World' } },\n\tauthMode: 'userPool',\n});\n\n\n// Listing posts is available to unauthenticated users (verified by Amazon Cognito identity pool's unauthenticated role)\nconst { data: listPostsResult , errors } = await client.models.Post.list({\n\tquery: queries.listPosts,\n\tauthMode: 'identityPool',\n});\n\nNote: Authorization rules are only supported on data models (model-level and field-level) and custom operations (queries, mutations and subscriptions). They are not fully supported on custom types.\n\nLearn more about specific authorization strategies\nPublic data access\nThe public authorization strategy grants everyone access to the API, which is protected behind the scenes with an API key. You can also override the authorization provider to use an unauthenticated IAM role from Cognito instead of an API key for public access.\nPer-user/per-owner data access\nThe owner authorization strategy restricts operations on a record to only the record's owner. When configured, the owner field (default 'owner') will automatically be added and populated with the identity of the created user. The API will authorize against the 'owner' field to allow or deny operations.\nMulti-user data access\nThe 'ownersDefinedIn' rule grants a set of users access to a record by automatically creating an 'owners' field to store the allowed record owners. You can override the default owners field name by specifying 'inField' with the desired field name to store the owner information. You can dynamically manage which users can access a record by updating the owner field.\nSigned-in user data access\nThe 'private' authorization strategy restricts record access to only signed-in users authenticated through IAM, Cognito, or OpenID Connect, applying the authorization rule to all users. It provides a simple way to make data private to all authenticated users.\nUser group-based data access\nThe user group authorization strategy allows restricting data access to specific user groups or groups defined dynamically on each data record. Both static and dynamic group authorization options are available, with some limitations around real-time subscriptions when using dynamic group authorization.\nCustom data access using Lambda functions\nDefine a custom authorization rule with a Lambda function.\nUse OpenID Connect as an authorization provider\nUse OpenID Connect with 'private', 'owner', and 'group' authorization strategies.\nConfigure custom identity and group claims\nAmplify Data allows you to configure custom identity and group claims instead of using the default Cognito claims, which can be useful if you want to populate claims from an external source like a database or 3rd party auth provider. The example shows how to check the 'user_id' identity claim and the 'user_groups' group claim that could come from a custom pre token generation Lambda trigger. Defining these custom claims provides more flexibility in authorization rules.\nGrant Lambda function access to API and Data\nAmplify Data uses a 'deny-by-default' authorization model. Function access must be explicitly defined in the schema."
  },
  {
    "title": "Public data access - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/customize-authz/public-data-access/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nCustomize your auth rules\n/\nPublic data access\nPublic data access\n\nThe public authorization strategy grants everyone access to the API, which is protected behind the scenes with an API key. You can also override the authorization provider to use an unauthenticated IAM role from Cognito instead of an API key for public access.\n\nAdd public authorization rule using API key-based authentication\n\nTo grant everyone access, use the .public() authorization strategy. Behind the scenes, the API will be protected with an API key.\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\nconst schema = a.schema({\n  Todo: a\n    .model({\n      content: a.string(),\n    })\n    .authorization(allow => [allow.publicApiKey()]),\n});\n\nIn your application, you can perform CRUD operations against the model using client.models.<model-name> by specifying the apiKey auth mode.\n\nimport { generateClient } from 'aws-amplify/data';\nimport type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition\n\n\nconst client = generateClient<Schema>();\n\n\nconst { errors, data: newTodo } = await client.models.Todo.create(\n  {\n    content: 'My new todo',\n  },\nCopy\nhighlighted code example\n  {\n    authMode: 'apiKey',\n  }\n);\nAdd public authorization rule using Amazon Cognito identity pool's unauthenticated role\n\nYou can also override the authorization provider. In the example below, identityPool is specified as the provider which allows you to use an \"Unauthenticated Role\" from the Cognito identity pool for public access instead of an API key. Your Auth resources defined in amplify/auth/resource.ts generates scoped down IAM policies for the \"Unauthenticated role\" in the Cognito identity pool automatically.\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\nconst schema = a.schema({\n  Todo: a\n    .model({\n      content: a.string(),\n    })\n    .authorization(allow => [allow.guest()]),\n});\n\nIn your application, you can perform CRUD operations against the model using client.models.<model-name> with the identityPool auth mode.\n\nIf you're not using the auto-generated amplify_outputs.json file, then you must set the Amplify Library resource configuration's allowGuestAccess flag to true. This lets the Amplify Library use the unauthenticated role from your Cognito identity pool when your user isn't logged in.\n\nAmplify configuration\nsrc/App.tsx\nimport { generateClient } from 'aws-amplify/data';\nimport type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition\n\n\nconst client = generateClient<Schema>();\n\n\nconst { errors, data: newTodo } = await client.models.Todo.create(\n  {\n    content: 'My new todo',\n  },\nCopy\nhighlighted code example\n  {\n    authMode: 'identityPool',\n  }\n);\nNEXT\nPer-user/per-owner data access"
  },
  {
    "title": "Modeling relationships - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/data-modeling/relationships/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nCustomize your data model\n/\nModeling relationships\nModeling relationships\n\nWhen modeling application data, you often need to establish relationships between different data models. In Amplify Data, you can create one-to-many, one-to-one, and many-to-many relationships in your Data schema. On the client-side, Amplify Data allows you to lazy or eager load of related data.\n\nWith Amplify Data Construct @aws-amplify/data-construct@1.8.4, an improvement was made to how relational field data is handled in subscriptions when different authorization rules apply to related models in a schema. The improvement redacts the values for the relational fields, displaying them as null or empty, to prevent unauthorized access to relational data.\n\nThis redaction occurs whenever it cannot be determined that the child model will be protected by the same permissions as the parent model.\n\nBecause subscriptions are tied to mutations and the selection set provided in the result of a mutation is then passed through to the subscription, relational fields in the result of mutations must be redacted.\n\nIf an authorized end-user needs access to the redacted relational fields, they should perform a query to read the relational data.\n\nAdditionally, subscriptions will inherit related authorization when relational fields are set as required. To better protect relational data, consider modifying the schema to use optional relational fields.\n\nTypes of relationships\nRelationship\tCode\tDescription\tExample\none to many\ta.hasMany(...) & a.belongsTo(...)\tCreates a one-to-many relationship between two models.\tA Team has many Members. A Member belongs to a Team.\none to one\ta.hasOne(...) & a.belongsTo(...)\tCreates a one-to-one relationship between two models.\tA Customer has one Cart. A Cart belongs to one Customer.\nmany to many\tTwo a.hasMany(...) & a.belongsTo(...) on join tables\tCreate two one-to-many relationships between the related models in a join table.\tA Post has many Tags. A Tag has many Posts.\nModel one-to-many relationships\n\nCreate a one-to-many relationship between two models using the hasMany() and belongsTo() method. In the example below, a Team has many Members and a Member belongs to exactly one Team.\n\nCreate a reference field called teamId on the Member model. This reference field's type MUST match the type of Team's identifier. In this case, it's an auto-generated id: a.id().required() field.\nAdd a relationship field called team that references the teamId field. This allows you to query for the team information from the Member model.\nAdd a relationship field called members that references the teamId field on the Member model.\nCopy\ncode example\nconst schema = a.schema({\n  Member: a.model({\n    name: a.string().required(),\n    // 1. Create a reference field\n    teamId: a.id(),\n    // 2. Create a belongsTo relationship with the reference field\n    team: a.belongsTo('Team', 'teamId'),\n  })\n  .authorization(allow => [allow.publicApiKey()]),\n\n\n  Team: a.model({\n    mantra: a.string().required(),\n    // 3. Create a hasMany relationship with the reference field\n    //    from the `Member`s model.\n    members: a.hasMany('Member', 'teamId'),\n  })\n  .authorization(allow => [allow.publicApiKey()]),\n});\nCreate a \"Has Many\" relationship between records\nCopy\ncode example\nconst { data: team } = await client.models.Team.create({\n  mantra: 'Go Frontend!',\n});\n\n\nconst { data: member } = await client.models.Member.create({\n  name: \"Tim\",\n  teamId: team.id,\n});\nUpdate a \"Has Many\" relationship between records\nCopy\ncode example\nconst { data: newTeam } = await client.models.Team.create({\n  mantra: 'Go Fullstack',\n});\n\n\nawait client.models.Member.update({\n  id: \"MY_MEMBER_ID\",\n  teamId: newTeam.id,\n});\nDelete a \"Has Many\" relationship between records\n\nIf your reference field is not required, then you can \"delete\" a one-to-many relationship by setting the relationship value to null.\n\nCopy\ncode example\nawait client.models.Member.update({\n  id: \"MY_MEMBER_ID\",\n  teamId: null,\n});\nLazy load a \"Has Many\" relationship\nCopy\ncode example\nconst { data: team } = await client.models.Team.get({ id: \"MY_TEAM_ID\"});\n\n\nconst { data: members } = await team.members();\n\n\nmembers.forEach(member => console.log(member.id));\nEagerly load a \"Has Many\" relationship\nCopy\ncode example\nconst { data: teamWithMembers } = await client.models.Team.get(\n  { id: \"MY_TEAM_ID\" },\n  { selectionSet: [\"id\", \"members.*\"] },\n);\n\n\nteamWithMembers.members.forEach(member => console.log(member.id));\nModel a \"one-to-one\" relationship\n\nCreate a one-to-one relationship between two models using the hasOne() and belongsTo() methods. In the example below, a Customer has a Cart and a Cart belongs to a Customer.\n\nCreate a reference field called customerId on the Cart model. This reference field's type MUST match the type of Customer's identifier. In this case, it's an auto-generated id: a.id().required() field.\nAdd a relationship field called customer that references the customerId field. This allows you to query for the customer information from the Cart model.\nAdd a relationship field called activeCart that references the customerId field on the Cart model.\nCopy\ncode example\nconst schema = a.schema({\n  Cart: a.model({\n    items: a.string().required().array(),\n    // 1. Create reference field\n    customerId: a.id(),\n    // 2. Create relationship field with the reference field\n    customer: a.belongsTo('Customer', 'customerId'),\n  }),\n  Customer: a.model({\n    name: a.string(),\n    // 3. Create relationship field with the reference field\n    //    from the Cart model\n    activeCart: a.hasOne('Cart', 'customerId')\n  }),\n});\nCreate a \"Has One\" relationship between records\n\nTo create a \"has one\" relationship between records, first create the parent item and then create the child item and assign the parent.\n\nCopy\ncode example\nconst { data: customer, errors } = await client.models.Customer.create({\n  name: \"Rene\",\n});\n\n\n\n\nconst { data: cart } = await client.models.Cart.create({\n  items: [\"Tomato\", \"Ice\", \"Mint\"],\n  customerId: customer?.id,\n});\nUpdate a \"Has One\" relationship between records\n\nTo update a \"Has One\" relationship between records, you first retrieve the child item and then update the reference to the parent to another parent. For example, to reassign a Cart to another Customer:\n\nCopy\ncode example\nconst { data: newCustomer } = await client.models.Customer.create({\n  name: 'Ian',\n});\n\n\nawait client.models.Cart.update({\n  id: cart.id,\n  customerId: newCustomer?.id,\n});\nDelete a \"Has One\" relationship between records\n\nYou can set the relationship field to null to delete a \"Has One\" relationship between records.\n\nCopy\ncode example\nawait client.models.Cart.update({\n  id: project.id,\n  customerId: null,\n});\nLazy load a \"Has One\" relationship\nCopy\ncode example\nconst { data: cart } = await client.models.Cart.get({ id: \"MY_CART_ID\"});\nconst { data: customer } = await cart.customer();\nEagerly load a \"Has One\" relationship\nCopy\ncode example\nconst { data: cart } = await client.models.Cart.get(\n  { id: \"MY_CART_ID\" },\n  { selectionSet: ['id', 'customer.*'] },\n);\n\n\nconsole.log(cart.customer.id)\nModel a \"many-to-many\" relationship\n\nIn order to create a many-to-many relationship between two models, you have to create a model that serves as a \"join table\". This \"join table\" should contain two one-to-many relationships between the two related entities. For example, to model a Post that has many Tags and a Tag has many Posts, you'll need to create a new PostTag model that represents the relationship between these two entities.\n\nconst schema = a.schema({\n  PostTag: a.model({\n    // 1. Create reference fields to both ends of\n    //    the many-to-many relationship\nCopy\nhighlighted code example\n    postId: a.id().required(),\n    tagId: a.id().required(),\n    // 2. Create relationship fields to both ends of\n    //    the many-to-many relationship using their\n    //    respective reference fields\nCopy\nhighlighted code example\n    post: a.belongsTo('Post', 'postId'),\n    tag: a.belongsTo('Tag', 'tagId'),\n  }),\n  Post: a.model({\n    title: a.string(),\n    content: a.string(),\n    // 3. Add relationship field to the join model\n    //    with the reference of `postId`\nCopy\nhighlighted code example\n    tags: a.hasMany('PostTag', 'postId'),\n  }),\n  Tag: a.model({\n    name: a.string(),\n    // 4. Add relationship field to the join model\n    //    with the reference of `tagId`\nCopy\nhighlighted code example\n    posts: a.hasMany('PostTag', 'tagId'),\n  }),\n}).authorization(allow => [allow.publicApiKey()]);\nModel multiple relationships between two models\n\nRelationships are defined uniquely by their reference fields. For example, a Post can have separate relationships with a Person model for author and editor.\n\nconst schema = a.schema({\n  Post: a.model({\n    title: a.string().required(),\n    content: a.string().required(),\nCopy\nhighlighted code example\n    authorId: a.id(),\n    author: a.belongsTo('Person', 'authorId'),\n    editorId: a.id(),\n    editor: a.belongsTo('Person', 'editorId'),\n  }),\n  Person: a.model({\n    name: a.string(),\nCopy\nhighlighted code example\n    editedPosts: a.hasMany('Post', 'editorId'),\n    authoredPosts: a.hasMany('Post', 'authorId'),\n  }),\n}).authorization(allow => [allow.publicApiKey()]);\n\nOn the client-side, you can fetch the related data with the following code:\n\nCopy\ncode example\nconst client = generateClient<Schema>();\n\n\nconst { data: post } = await client.models.Post.get({ id: \"SOME_POST_ID\" });\n\n\nconst { data: author } = await post?.author();\nconst { data: editor } = await post?.editor();\nModel relationships for models with sort keys in their identifier\n\nIn cases where your data model uses sort keys in the identifier, you need to also add reference fields and store the sort key fields in the related data model:\n\nconst schema = a.schema({\n  Post: a.model({\n    title: a.string().required(),\n    content: a.string().required(),\n    // Reference fields must correspond to identifier fields.\nCopy\nhighlighted code example\n    authorName: a.string(),\n    authorDoB: a.date(),\n    // Must pass references in the same order as identifiers.\n    author: a.belongsTo('Person', ['authorName', 'authorDoB']),\n  }),\n  Person: a.model({\n    name: a.string().required(),\n    dateOfBirth: a.date().required(),\n    // Must reference all reference fields corresponding to the\n    // identifier of this model.\n    authoredPosts: a.hasMany('Post', ['authorName', 'authorDoB']),\nCopy\nhighlighted code example\n  }).identifier(['name', 'dateOfBirth']),\n}).authorization(allow => [allow.publicApiKey()]);\nMake relationships required or optional\n\nAmplify Data's relationships use reference fields to determine if a relationship is required or not. If you mark a reference field as required, then you can't \"delete\" a relationship between two models. You'd have to delete the related record as a whole.\n\nconst schema = a.schema({\n  Post: a.model({\n    title: a.string().required(),\n    content: a.string().required(),\n    // You must supply an author when creating the post\n    // Author can't be set to `null`.\nCopy\nhighlighted code example\n    authorId: a.id().required(),\n    author: a.belongsTo('Person', 'authorId'),\n    // You can optionally supply an editor when creating the post.\n    // Editor can also be set to `null`.\nCopy\nhighlighted code example\n    editorId: a.id(),\n    editor: a.belongsTo('Person', 'editorId'),\n  }),\n  Person: a.model({\n    name: a.string(),\nCopy\nhighlighted code example\n    editedPosts: a.hasMany('Post', 'editorId'),\n    authoredPosts: a.hasMany('Post', 'authorId'),\n  }),\n})\nPREVIOUS\nAdd fields to data model\nNEXT\nCustomize data model identifiers"
  },
  {
    "title": "Customize secondary indexes - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/data-modeling/secondary-index/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nCustomize your data model\n/\nCustomize secondary indexes\nCustomize secondary indexes\n\nYou can optimize your list queries based on \"secondary indexes\". For example, if you have a Customer model, you can query based on the customer's id identifier field by default but you can add a secondary index based on the accountRepresentativeId to get list customers for a given account representative.\n\nA secondary index consists of a \"hash key\" and, optionally, a \"sort key\". Use the \"hash key\" to perform strict equality and the \"sort key\" for greater than (gt), greater than or equal to (ge), less than (lt), less than or equal to (le), equals (eq), begins with, and between operations.\n\namplify/data/resource.ts\nexport const schema = a.schema({\n  Customer: a\n    .model({\n      name: a.string(),\n      phoneNumber: a.phone(),\n      accountRepresentativeId: a.id().required(),\n    })\nCopy\nhighlighted code example\n    .secondaryIndexes((index) => [index(\"accountRepresentativeId\")])\n    .authorization(allow => [allow.publicApiKey()]),\n});\n\nThe example client query below allows you to query for \"Customer\" records based on their accountRepresentativeId:\n\nsrc/App.tsx\nimport { type Schema } from '../amplify/data/resource';\nimport { generateClient } from 'aws-amplify/data';\n\n\nconst client = generateClient<Schema>();\n\n\nconst { data, errors } =\nCopy\nhighlighted code example\n  await client.models.Customer.listCustomerByAccountRepresentativeId({\n    accountRepresentativeId: \"YOUR_REP_ID\",\n  });\nReview how this works under the hood with Amazon DynamoDB\nAdd sort keys to secondary indexes\n\nYou can define \"sort keys\" to add a set of flexible filters to your query, such as \"greater than\" (gt), \"greater than or equal to\" (ge), \"less than\" (lt), \"less than or equal to\" (le), \"equals\" (eq), \"begins with\" (beginsWith), and \"between\" operations.\n\namplify/data/resource.ts\nexport const schema = a.schema({\n  Customer: a\n    .model({\n      name: a.string(),\n      phoneNumber: a.phone(),\n      accountRepresentativeId: a.id().required(),\n    })\n    .secondaryIndexes((index) => [\n      index(\"accountRepresentativeId\")\nCopy\nhighlighted code example\n        .sortKeys([\"name\"]),\n    ])\n    .authorization(allow => [allow.owner()]),\n});\n\nOn the client side, you should find a new listBy... query that's named after hash key and sort keys. For example, in this case: listByAccountRepresentativeIdAndName. You can supply the filter as part of this new list query:\n\nsrc/App.tsx\nconst { data, errors } =\nCopy\nhighlighted code example\n  await client.models.Customer.listCustomerByAccountRepresentativeIdAndName({\n    accountRepresentativeId: \"YOUR_REP_ID\",\n    name: {\n      beginsWith: \"Rene\",\n    },\n  });\nCustomize the query field for secondary indexes\n\nYou can also customize the auto-generated query name under client.models.<MODEL_NAME>.listBy... by setting the queryField() modifier.\n\namplify/data/resource.ts\nconst schema = a.schema({\n  Customer: a\n    .model({\n      name: a.string(),\n      phoneNumber: a.phone(),\n      accountRepresentativeId: a.id().required(),\n    })\n    .secondaryIndexes((index) => [\n      index(\"accountRepresentativeId\")\nCopy\nhighlighted code example\n        .queryField(\"listByRep\"),\n    ])\n    .authorization(allow => [allow.owner()]),\n});\n\nIn your client app code, you'll see query updated under the Data client:\n\nsrc/App.tsx\nconst {\n  data,\n  errors\nCopy\nhighlighted code example\n} = await client.models.Customer.listByRep({\n  accountRepresentativeId: 'YOUR_REP_ID',\n})\nCustomize the name of secondary indexes\n\nTo customize the underlying DynamoDB's index name, you can optionally provide the name() modifier.\n\namplify/data/resource.ts\nconst schema = a.schema({\n  Customer: a\n    .model({\n      name: a.string(),\n      phoneNumber: a.phone(),\n      accountRepresentativeId: a.id().required(),\n    })\n    .secondaryIndexes((index) => [\n      index(\"accountRepresentativeId\")\nCopy\nhighlighted code example\n        .name(\"MyCustomIndexName\"),\n    ])\n    .authorization(allow => [allow.owner()]),\n});\nPREVIOUS\nCustomize data model identifiers"
  },
  {
    "title": "Add fields to data model - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/data-modeling/add-fields/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nCustomize your data model\n/\nAdd fields to data model\nAdd fields to data model\n\nAmplify Data supports all AWS AppSync scalar types as field types. The following scalar types are available:\n\nField type\tDescription\tTypeScript validation\tGraphQL Scalar Type\na.id()\tA unique identifier for an object. This scalar is serialized like a String but isn't meant to be human-readable. If not specified on create operations, a UUID will be generated.\tstring\tID\na.string()\tA UTF-8 character sequence.\tstring\tString\na.integer()\tAn integer value between -(2^31) and 2^31-1.\tnumber but rounded to closest integer value upon query/mutation\tInt\na.float()\tAn IEEE 754 floating point value.\tnumber\tFloat\na.boolean()\tA Boolean value, either true or false.\tboolean\tBoolean\na.date()\tAn extended ISO 8601 date string in the format YYYY-MM-DD.\tstring\tAWSDate\na.time()\tAn extended ISO 8601 time string in the format hh:mm:ss.sss.\tstring\tAWSTime\na.datetime()\tAn extended ISO 8601 date and time string in the format YYYY-MM-DDThh:mm:ss.sssZ.\tstring\tAWSDateTime\na.timestamp()\tAn integer value representing the number of seconds before or after 1970-01-01-T00:00Z.\tnumber\tAWSTimestamp\na.email()\tAn email address in the format local-part@domain-part as defined by RFC 822.\tstring with local-part and domain-part type enforcement\tAWSEmail\na.json()\tA JSON string. Any valid JSON construct is automatically parsed and loaded in the resolver code as maps, lists, or scalar values, rather than as the literal input strings. Unquoted strings or otherwise invalid JSON result in a validation error.\tany\tAWSJSON\na.phone()\tA phone number. This value is stored as a string. Phone numbers can contain either spaces or hyphens to separate digit groups. Phone numbers without a country code are assumed to be US/North American numbers adhering to the North American Numbering Plan.\tstring validation only happening service-side\tAWSPhone\na.url()\tA URL as defined by RFC 1738. For example, https://www.amazon.com/dp/B000NZW3KC/ or mailto:example@example.com. URLs must contain a schema (http, mailto) and can't contain two forward slashes (//) in the path part.\tstring but with type enforcement on the schema part\tAWSURL\na.ipAddress()\tA valid IPv4 or IPv6 address. IPv4 addresses are expected in quad-dotted notation (123.12.34.56). IPv6 addresses are expected in non-bracketed, colon-separated format (1a2b:3c4b:1234:4567). You can include an optional CIDR suffix (123.45.67.89/16) to indicate subnet mask.\tstring with type enforcement for IPv4 and IPv6 pattern\tAWSIPAddress\nSpecify a custom field type\n\nSometimes, the built-in types do not meet the needs of your application. In those cases, you can specify custom types. You can either define the custom types inline or explicitly define the custom type in the schema.\n\nInline definition: The \"location\" field will become a new non-model type that uses PascalCase, a naming convention in which the first letter of each word in a compound word is capitalized. If there are conflicts with another schema-level definition (model, custom type, enum), you will receive a Type error with a warning that you need to sift the value out as a separate item and use a \"ref\".\n\nCopy\ncode example\na.schema({\n  Post: a.model({\n    location: a.customType({\n      lat: a.float(),\n      long: a.float(),\n    }),\n    content: a.string(),\n  }),\n});\n\nExplicit definition: Specify the \"Location\" as a.customType() in your schema. To use the custom type, reference it through a.ref() in the respective field definitions.\n\nCopy\ncode example\na.schema({\n  Location: a.customType({\n      lat: a.float(),\n      long: a.float(),\n  }),\n\n\n  Post: a.model({\n    location: a.ref('Location'),\n    content: a.string(),\n  }),\n\n\n  User: a.model({\n    lastKnownLocation: a.ref('Location'),\n  }),\n});\n\nTo set or read the location field on the client side, you can expand a nested object and the type system will auto-infer the allowed values.\n\nCopy\ncode example\nconst { data: newPost, errors } = await client.models.Post.create({\n  location: {\n    lat: 48.837006,\n    long: 8.28245,\n  },\n});\n\n\nconsole.log(newPost?.location?.lat, newPost?.location?.long);\nSpecify an enum field type\n\nEnum has a similar developer experience as custom types: short-hand and long-form approaches.\n\nShort-hand approach\n\nCopy\ncode example\na.schema({\n  Post: a.model({\n    privacySetting: a.enum(['PRIVATE', 'FRIENDS_ONLY', 'PUBLIC']),\n    content: a.string(),\n  }),\n});\n\nLong-form approach\n\nCopy\ncode example\na.schema({\n  PrivacySetting: a.enum([\n    'PRIVATE',\n    'FRIENDS_ONLY',\n    'PUBLIC'\n  ]),\n\n\n  Post: a.model({\n    content: a.string(),\n    privacySetting: a.ref('PrivacySetting'),\n  }),\n\n\n  Video: a.model({\n    privacySetting: a.ref('PrivacySetting'),\n  }),\n});\n\nWhen creating a new item client-side, the enums are also type-enforced:\n\nCopy\ncode example\nclient.models.Post.create({\n  content: 'hello',\n  // WORKS - value auto-completed\n  privacySetting: 'PRIVATE',\n\n\n  // DOES NOT WORK - TYPE ERROR\n  privacySetting: 'NOT_PUBLIC',\n});\nList enum values client-side\n\nYou can list available enum values client-side using the client.enums.<ENUM_NAME>.values() API. For example, this allows you to display the available enum values within a dropdown UI.\n\nCopy\ncode example\nconst availableSettings = client.enums.PrivacySetting.values()\n// availableSettings returns [\"PRIVATE\", \"FRIENDS_ONLY\", \"PUBLIC\"]\nMark fields as required\n\nBy default, fields are optional. To mark a field as required, use the .required() modifier.\n\nCopy\ncode example\nconst schema = a.schema({\n  Todo: a.model({\n    content: a.string().required(),\n  }),\n});\nMark fields as arrays\n\nAny field can be modified to be an array using the .array() modifier.\n\nCopy\ncode example\nconst schema = a.schema({\n  Todo: a.model({\n    content: a.string().required(),\n    notes: a.string().array(),\n  }),\n});\nAssign default values for fields\n\nYou can use the .default(...) modifier to specify a default value for optional scalar type fields and arrays. The .default(...) modifier is not available for custom types, enums, or relationships.\n\nCopy\ncode example\nconst schema = a.schema({\n  Todo: a.model({\n    content: a.string().default('My new Todo'),\n  }),\n});\n\nNote: The .default(...) modifier can't be applied to required fields.\n\nNEXT\nModeling relationships"
  },
  {
    "title": "Customize data model identifiers - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/data-modeling/identifiers/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nCustomize your data model\n/\nCustomize data model identifiers\nCustomize data model identifiers\n\nIdentifiers are defined using the .identifier() method on a model definition. Usage of the .identifier() method is optional; when it's not present, the model will automatically have a field called id of type ID that is automatically generated unless manually specified.\n\nCopy\ncode example\nconst schema = a.schema({\n  Todo: a.model({\n    content: a.string(),\n    completed: a.boolean(),\n  })\n  .authorization(allow => [allow.publicApiKey()]),\n});\nCopy\ncode example\nconst client = generateClient<Schema>();\n\n\nconst todo = await client.models.Todo.create({ content: 'Buy Milk', completed: false });\nconsole.log(`New Todo created: ${todo.id}`); // New Todo created: 5DB6B4CC-CD41-49F5-9844-57C0AB506B69\n\nIf you want, you can use Amplify Data to define single-field and composite identifiers:\n\nSingle-field identifier with a consumer-provided value (type: id or string, and must be marked required)\nComposite identifier with a set of consumer-provided values (type: id or string, and must be marked required)\nSingle-field identifier\n\nIf the default id identifier field needs to be customized, you can do so by passing the name of another field.\n\nCopy\ncode example\nconst schema = a.schema({\n  Todo: a.model({\n    todoId: a.id().required(),\n    content: a.string(),\n    completed: a.boolean(),\n  })\n  .identifier(['todoId'])\n  .authorization(allow => [allow.publicApiKey()]),\n});\nCopy\ncode example\nconst client = generateClient<Schema>();\n\n\nconst { data: todo, errors } = await client.models.Todo.create({ todoId: 'MyUniqueTodoId', content: 'Buy Milk', completed: false });\nconsole.log(`New Todo created: ${todo.todoId}`); // New Todo created: MyUniqueTodoId\nComposite identifier\n\nFor cases where items are uniquely identified by more than a single field, you can pass an array of the field names to the identifier() function:\n\nCopy\ncode example\nconst schema = a.schema({\n  StoreBranch: a.model({\n    geoId: a.id().required(),\n    name: a.string().required(),\n    country: a.string(),\n    state: a.string(),\n    city: a.string(),\n    zipCode: a.string(),\n    streetAddress: a.string(),\n  }).identifier(['geoId', 'name'])\n  .authorization(allow => [allow.publicApiKey()]),\n});\nCopy\ncode example\nconst client = generateClient<Schema>();\n\n\nconst branch = await client.models.StoreBranch.get({ geoId: '123', name: 'Downtown' }); // All identifier fields are required when retrieving an item\nPREVIOUS\nModeling relationships\nNEXT\nCustomize secondary indexes"
  },
  {
    "title": "Subscribe to real-time events - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/subscribe-data/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nSubscribe to real-time events\nSubscribe to real-time events\n\nIn this guide, we will outline the benefits of enabling real-time data integrations and how to set up and filter these subscriptions. We will also cover how to unsubscribe from subscriptions.\n\nBefore you begin, you will need:\n\nAn application connected to the API\nData already created to modify\n\nWith Amplify Data Construct @aws-amplify/data-construct@1.8.4, an improvement was made to how relational field data is handled in subscriptions when different authorization rules apply to related models in a schema. The improvement redacts the values for the relational fields, displaying them as null or empty, to prevent unauthorized access to relational data.\n\nThis redaction occurs whenever it cannot be determined that the child model will be protected by the same permissions as the parent model.\n\nBecause subscriptions are tied to mutations and the selection set provided in the result of a mutation is then passed through to the subscription, relational fields in the result of mutations must be redacted.\n\nIf an authorized end-user needs access to the redacted relational fields, they should perform a query to read the relational data.\n\nAdditionally, subscriptions will inherit related authorization when relational fields are set as required. To better protect relational data, consider modifying the schema to use optional relational fields.\n\nSet up a real-time list query\n\nThe recommended way to fetch a list of data is to use observeQuery to get a real-time list of your app data at all times. You can integrate observeQuery with React's useState and useEffect hooks in the following way:\n\nCopy\ncode example\nimport { useState, useEffect } from 'react';\nimport { generateClient } from 'aws-amplify/data';\nimport type { Schema } from '../amplify/data/resource';\n\n\ntype Todo = Schema['Todo']['type'];\n\n\nconst client = generateClient<Schema>();\n\n\nexport default function MyComponent() {\n  const [todos, setTodos] = useState<Todo[]>([]);\n\n\n  useEffect(() => {\n    const sub = client.models.Todo.observeQuery().subscribe({\n      next: ({ items, isSynced }) => {\n        setTodos([...items]);\n      },\n    });\n    return () => sub.unsubscribe();\n  }, []);\n\n\n  return (\n    <ul>\n      {todos.map((todo) => (\n        <li key={todo.id}>{todo.content}</li>\n      ))}\n    </ul>\n  );\n}\n\nobserveQuery fetches and paginates through all of your available data in the cloud. While data is syncing from the cloud, snapshots will contain all of the items synced so far and an isSynced status of false. When the sync process is complete, a snapshot will be emitted with all the records in the local store and an isSynced status of true.\n\nSet up a real-time event subscription\n\nSubscriptions is a feature that allows the server to send data to its clients when a specific event happens. For example, you can subscribe to an event when a new record is created, updated, or deleted through the API. Subscriptions are automatically available for any a.model() in your Amplify Data schema.\n\nCopy\ncode example\nimport { generateClient } from 'aws-amplify/data';\nimport type { Schema } from '../amplify/data/resource';\n\n\nconst client = generateClient<Schema>();\n\n\n// Subscribe to creation of Todo\nconst createSub = client.models.Todo.onCreate().subscribe({\n  next: (data) => console.log(data),\n  error: (error) => console.warn(error),\n});\n\n\n// Subscribe to update of Todo\nconst updateSub = client.models.Todo.onUpdate().subscribe({\n  next: (data) => console.log(data),\n  error: (error) => console.warn(error),\n});\n\n\n// Subscribe to deletion of Todo\nconst deleteSub = client.models.Todo.onDelete().subscribe({\n  next: (data) => console.log(data),\n  error: (error) => console.warn(error),\n});\n\n\n// Stop receiving data updates from the subscription\ncreateSub.unsubscribe();\nupdateSub.unsubscribe();\ndeleteSub.unsubscribe();\nSet up server-side subscription filters\n\nSubscriptions take an optional filter argument to define service-side subscription filters:\n\nCopy\ncode example\nimport { generateClient } from 'aws-amplify/data';\nimport type { Schema } from '../amplify/data/resource';\n\n\nconst client = generateClient<Schema>();\n\n\nconst sub = client.models.Todo.onCreate({\n  filter: {\n    content: {\n      contains: 'groceries',\n    },\n  },\n}).subscribe({\n  next: (data) => console.log(data),\n  error: (error) => console.warn(error),\n});\n\nIf you want to get all subscription events, don't specify any filter parameters.\n\nLimitations:\n\nSpecifying an empty object {} as a filter is not recommended. Using {} as a filter might cause inconsistent behavior based on your data model's authorization rules.\nIf you're using dynamic group authorization and you authorize based on a single group per record, subscriptions are only supported if the user is part of five or fewer user groups.\nAdditionally, if you authorize by using an array of groups (groups: [String]),\nsubscriptions are only supported if the user is part of 20 or fewer groups\nyou can only authorize 20 or fewer user groups per record\nSubscription connection status updates\n\nNow that your application is set up and using subscriptions, you may want to know when the subscription is finally established, or reflect to your users when the subscription isn't healthy. You can monitor the connection state for changes through the Hub local eventing system.\n\nCopy\ncode example\nimport { CONNECTION_STATE_CHANGE, ConnectionState } from 'aws-amplify/data';\nimport { Hub } from 'aws-amplify/utils';\n\n\nHub.listen('api', (data: any) => {\n  const { payload } = data;\n  if (payload.event === CONNECTION_STATE_CHANGE) {\n    const connectionState = payload.data.connectionState as ConnectionState;\n    console.log(connectionState);\n  }\n});\nSubscription connection states\nConnected - Connected and working with no issues.\nConnectedPendingDisconnect - The connection has no active subscriptions and is disconnecting.\nConnectedPendingKeepAlive - The connection is open, but has missed expected keep-alive messages.\nConnectedPendingNetwork - The connection is open, but the network connection has been disrupted. When the network recovers, the connection will continue serving traffic.\nConnecting - Attempting to connect.\nConnectionDisrupted - The connection is disrupted and the network is available.\nConnectionDisruptedPendingNetwork - The connection is disrupted and the network connection is unavailable.\nDisconnected - Connection has no active subscriptions and is disconnecting.\nTroubleshooting\nTroubleshoot connection issues and automated reconnection\nUnsubscribe from a subscription\n\nYou can also unsubscribe from events by using subscriptions by implementing the following:\n\nCopy\ncode example\n// Stop receiving data updates from the subscription\nsub.unsubscribe();\nConclusion\n\nCongratulations! You have finished the Subscribe to real-time events guide. In this guide, you set up subscriptions for real-time events and learned how to filter and cancel these subscriptions when needed.\n\nNext steps\n\nOur recommended next steps include continuing to build out and customize your information architecture for your data. Some resources that will help with this work include:\n\nCustomize your auth rules\nCustomize your data model\nAdd custom business logic\nPREVIOUS\nRead application data\nNEXT\nCustomize your data model"
  },
  {
    "title": "Customize your data model - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/data-modeling/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nCustomize your data model\nCustomize your data model\nData modeling capabilities\n\nEvery data model is defined as part of a data schema (a.schema()). You can enhance your data model with various fields, customize their identifiers, apply authorization rules, or model relationships. Every data model (a.model()) automatically provides create, read, update, and delete API operations as well as real-time subscription events. Below is a quick tour of the many functionalities you can add to your data model:\n\nCopy\ncode example\nimport { type ClientSchema, a, defineData } from '@aws-amplify/backend';\n\n\nconst schema = a\n  .schema({\n    Customer: a\n      .model({\n        customerId: a.id().required(),\n        // fields can be of various scalar types,\n        // such as string, boolean, float, integers etc.\n        name: a.string(),\n        // fields can be of custom types\n        location: a.customType({\n          // fields can be required or optional\n          lat: a.float().required(),\n          long: a.float().required(),\n        }),\n        // fields can be enums\n        engagementStage: a.enum([\"PROSPECT\", \"INTERESTED\", \"PURCHASED\"]),\n        collectionId: a.id(),\n        collection: a.belongsTo(\"Collection\", \"collectionId\")\n        // Use custom identifiers. By default, it uses an `id: a.id()` field\n      })\n      .identifier([\"customerId\"]),\n    Collection: a\n      .model({\n        customers: a.hasMany(\"Customer\", \"collectionId\"), // setup relationships between types\n        tags: a.string().array(), // fields can be arrays\n        representativeId: a.id().required(),\n        // customize secondary indexes to optimize your query performance\n      })\n      .secondaryIndexes((index) => [index(\"representativeId\")]),\n  })\n  .authorization((allow) => [allow.publicApiKey()]);\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    defaultAuthorizationMode: \"apiKey\",\n    apiKeyAuthorizationMode: {\n      expiresInDays: 30,\n    },\n  },\n});\nAdd fields to data model\nConfigure built-in and custom field types.\nModeling relationships\nLearn about the types of model relationships and modeling relationships.\nCustomize data model identifiers\nDefine the primary key for a model using single-field or composite identifiers.\nCustomize secondary indexes\nDefine the secondary indexes for your data model to optimize query performance\nGen 1 schema support\n\nIf you are coming from Gen 1, you can continue to use the GraphQL Schema Definition Language (SDL) for defining your schema. However, we strongly recommend you use the TypeScript-first schema builder experience in your project as it provides type safety and is the recommended way of working with Amplify going forward.\n\nNote: Some features available in Gen 1 GraphQL SDL are not available in Gen 2. See the feature matrix for features supported in Gen 2.\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\nimport { defineData } from '@aws-amplify/backend';\n\n\nconst schema = /* GraphQL */`\n  type Todo @model @auth(rules: [{ allow: owner }]) {\n    content: String\n    isDone: Boolean\n  }\n`;\n\n\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    defaultAuthorizationMode: \"apiKey\",\n    apiKeyAuthorizationMode: {\n      expiresInDays: 30,\n    },\n  },\n});"
  },
  {
    "title": "Create, update, and delete application data - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/mutate-data/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nCreate, update, and delete application data\nCreate, update, and delete application data\n\nIn this guide, you will learn how to create, update, and delete your data using Amplify Libraries' Data client.\n\nBefore you begin, you will need:\n\nAn application connected to the API\nCreate an item\n\nYou can create an item by first generating the Data client with your backend Data schema. Then you can add an item:\n\nCopy\ncode example\nimport { generateClient } from 'aws-amplify/data';\nimport { type Schema } from '../amplify/data/resource'\n\n\nconst client = generateClient<Schema>();\n\n\nconst { errors, data: newTodo } = await client.models.Todo.create({\n  content: \"My new todo\",\n  isDone: true,\n})\n\nNote: You do not need to specify createdAt or updatedAt fields because Amplify automatically populates these fields for you.\n\nUpdate an item\n\nTo update the item, use the update function:\n\nCopy\ncode example\nimport { generateClient } from 'aws-amplify/data';\nimport { type Schema } from '../amplify/data/resource';\n\n\nconst client = generateClient<Schema>();\n\n\nconst todo = {\n  id: 'some_id',\n  content: 'Updated content',\n};\n\n\nconst { data: updatedTodo, errors } = await client.models.Todo.update(todo);\n\nNotes:\n\nYou do not need to specify the updatedAt field. Amplify will automatically populate this field for you.\nIf you specify extra input fields not expected by the API, this query will fail. You can see this in the errors field returned by the query. With Amplify Data, errors are not thrown like exceptions. Instead, any errors are captured and returned as part of the query result in the errors field.\nDelete an item\n\nYou can then delete the Todo by using the delete mutation. To specify which item to delete, you only need to provide the id of that item:\n\nCopy\ncode example\nimport { generateClient } from 'aws-amplify/data';\nimport { type Schema } from '../amplify/data/resource'\n\n\nconst client = generateClient<Schema>();\n\n\nconst toBeDeletedTodo = {\n  id: '123123213'\n}\n\n\nconst { data: deletedTodo, errors } = await client.models.Todo.delete(toBeDeletedTodo)\n\nNote: When deleting items in many-to-many relationships, the join table records must be deleted before deleting the associated records. For example, for a many-to-many relationship between Posts and Tags, delete the PostTags join record before deleting a Post or Tag. Review Many-to-many relationships for more details.\n\nTroubleshooting\nTroubleshoot unauthorized errors\nCancel create, update, and delete requests\n\nYou can cancel any mutation API request by calling .cancel on the mutation request promise that's returned by .create(...), .update(...), or .delete(...).\n\nCopy\ncode example\nconst promise = client.models.Todo.create({ content: 'New Todo ' });\n//  ^ Note: we're not awaiting the request, we're returning the promise\n\n\ntry {\n  await promise;\n} catch (error) {\n  console.log(error);\n  // If the error is because the request was cancelled you can confirm here.\n  if (client.isCancelError(error)) {\n    console.log(error.message); // \"my message for cancellation\"\n    // handle user cancellation logic\n  }\n}\n\n\n//...\n\n\n// To cancel the above request\nclient.cancel(promise, 'my message for cancellation');\n\nYou need to ensure that the promise returned from .create(), .update(), and .delete() has not been modified. Typically, async functions wrap the promise being returned into another promise. For example, the following will not work:\n\nCopy\ncode example\nasync function makeAPICall() {\n  return client.models.Todo.create({ content: 'New Todo' });\n}\nconst promise = makeAPICall();\n\n\n// The following will NOT cancel the request.\nclient.cancel(promise, 'my error message');\nConclusion\n\nCongratulations! You have finished the Create, update, and delete application data guide. In this guide, you created, updated, and deleted your app data.\n\nNext steps\n\nOur recommended next steps include using the API to query data and subscribe to real-time events to look for mutations in your data. Some resources that will help with this work include:\n\nRead application data\nSubscribe to real-time events\nPREVIOUS\nConnect your app code to API\nNEXT\nRead application data"
  },
  {
    "title": "Read application data - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/query-data/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nRead application data\nRead application data\n\nYou can read application data using the Amplify Data client. In this guide, we will review the difference between reading data and getting data, how to filter query results to get just the data you need, and how to paginate results to make your data more manageable. We will also show you how to cancel these requests when needed.\n\nBefore you begin, you will need:\n\nAn application connected to the API\nData already created to view\nList and get your data\n\nQueries are used to read data through the API and include the list and get operations. Amplify Data automatically creates list and get queries for any a.model() type in your schema. The list query retrieves multiple items, such as Todo items, without needing to specific an identifier for a particular record. This is best suited for getting an overview or summary of items, or for enhancing the list operation to filter the items by specific criteria. When you want to query a single entry by an identifier, you would use get to retrieve a specific Todo item.\n\nNote: The cost structure of your underlying data source can impact the cost to run some queries. For example, the list operation uses Amazon DynamoDB \"scan operations,\" which can use more read request units than the get operation. You will want to review the associated costs for these operations for your data source. In our example, we are using DynamoDB. You can learn more about how DynamoDB costs are calculated by visiting Amazon DynamoDB pricing.\n\nYou can list items by first generating the Data client with your backend Data schema. Then you can list items of your desired model:\n\nCopy\ncode example\nimport { generateClient } from 'aws-amplify/data';\nimport { type Schema } from '@/amplify/data/resource';\n\n\nconst client = generateClient<Schema>();\n\n\n// list all items\nconst { data: todos, errors } = await client.models.Todo.list();\n\n\n// get a specific item\nconst { data: todo, errors } = await client.models.Todo.get({\n  id: '...',\n});\nTroubleshooting\nTroubleshoot unauthorized errors\nFilter list queries\n\nAs your data grows, you will need to paginate your list queries. Fortunately, this is already built in to Amplify Data.\n\nCopy\ncode example\nimport { generateClient } from 'aws-amplify/data';\nimport { type Schema } from '@/amplify/data/resource';\n\n\nconst client = generateClient<Schema>();\n\n\nconst { data: todos, errors } = await client.models.Todo.list({\n  filter: {\n    content: {\n      beginsWith: 'hello'\n    }\n  }\n});\nCompound filters\n\nYou can combine filters with and, or, and not Boolean logic. Observe that filter is recursive in respect to those fields. So if, for example, you wanted to filter for priority values of 1 or 2, you would do this:\n\nCopy\ncode example\nimport { generateClient } from 'aws-amplify/data';\nimport { type Schema } from '@/amplify/data/resource';\n\n\nconst client = generateClient<Schema>();\n\n\nconst { data: todos, errors } = await client.models.Todo.list({\n  filter: {\n    or: [\n      {\n        priority: { eq: '1' }\n      },\n      {\n        priority: { eq: '2' }\n      }\n    ]\n  }\n});\n\nNote that querying for priority of 1 and 2 would return no results, because this is Boolean logic instead of natural language.\n\nPaginate list queries\n\nTo paginate your list query results, make a subsequent list query request with the nextToken and limit input variable set. The limit variable limits how many results are returned. The response will include a nextToken you can use to request the next page of data. A nextToken is a very long string that represents the cursor to the starting item of the next query made with these filters.\n\nCopy\ncode example\nimport { generateClient } from 'aws-amplify/data';\nimport { type Schema } from '@/amplify/data/resource';\n\n\nconst client = generateClient<Schema>();\n\n\nconst {\n  data: todos,\n  nextToken, // Repeat this API call with the nextToken until the returned nextToken is `null`\n  errors\n} = await client.models.Todo.list({\n  limit: 100, // default value is 100\n  nextToken: 'eyJ2ZXJzaW9uejE1a2...' // previous nextToken\n});\n\nIf you're building a React application, you can use the usePagination hook in Amplify UI to help with managing the pagination user experience.\n\nCopy\ncode example\nimport * as React from 'react';\nimport { Pagination } from '@aws-amplify/ui-react';\n\n\nexport const PaginationHasMorePagesExample = () => {\n  const [pageTokens, setPageTokens] = React.useState([null]);\n  const [currentPageIndex, setCurrentPageIndex] = React.useState(1);\n  const [hasMorePages, setHasMorePages] = React.useState(true);\n\n\n  const handleNextPage = async () => {\n    if (hasMorePages && currentPageIndex === pageTokens.length) {\n      const { data: todos, nextToken } = await client.models.Todo.list({\n        nextToken: pageTokens[pageTokens.length - 1]\n      });\n\n\n      if (!nextToken) {\n        setHasMorePages(false);\n      }\n\n\n      setPageTokens([...pageTokens, nextToken]);\n    }\n\n\n    setCurrentPageIndex(currentPageIndex + 1);\n  };\n\n\n  return (\n    <Pagination\n      currentPage={currentPageIndex}\n      totalPages={pageTokens.length}\n      hasMorePages={hasMorePages}\n      onNext={handleNextPage}\n      onPrevious={() => setCurrentPageIndex(currentPageIndex - 1)}\n      onChange={(pageIndex) => setCurrentPageIndex(pageIndex)}\n    />\n  );\n};\n\nLimitations:\n\nThere is no API to get a total page count at this time. Note that scanning all items is a potentially expensive operation.\nYou cannot query by page number; you have to query by nextToken.\nFetch only the data you need with custom selection set\n\nA business domain model may contain many models with numerous fields. However, apps typically only need subsets of the data or fields to meet the requirements of different components or screens. It is necessary to have a mechanism to retrieve subsets of models and their relationships. This mechanism would help optimize data usage for screens and components by only transferring needed data. Having this capability would improve the app's data efficiency, latency, and the end user's perceived performance.\n\nA custom selection set allows consumers to specify, on a per-call basis, the fields the consumer wants to retrieve; this is possible for all operations that return data (CRUDL + observeQuery). The desired fields are specified in a strongly typed way (discoverable through IntelliSense) with a \"dot notation\".\n\nCopy\ncode example\n// same way for all CRUDL: .create, .get, .update, .delete, .list, .observeQuery\nconst { data: blogWithSubsetOfData, errors } = await client.models.Blog.get(\n  { id: blog.id },\n  {\n    selectionSet: ['author.email', 'posts.*'],\n  }\n);\nTypeScript type helpers for Amplify Data\n\nWhen using TypeScript, you frequently need to specify data model types for type generics. For instance, with React's useState, you provide a type in TypeScript to ensure type-safety in your component code using the state. Use the Schema[\"MODEL_NAME\"][\"type\"] pattern to get TypeScript types for the shapes of data models returned from the backend API. This allows you to get consumable TypeScript types for the shapes of the data model return values coming from the backend API.\n\nCopy\ncode example\nimport { type Schema } from '@/amplify/data/resource';\n\n\ntype Post = Schema['Post']['type'];\n\n\nconst [posts, setPosts] = useState<Post[]>([]);\n\nYou can combine the Schema[\"MODEL_NAME\"][\"type\"] type with the SelectionSet helper type to describe the return type of API requests using the selectionSet parameter:\n\nCopy\ncode example\nimport type { SelectionSet } from 'aws-amplify/data';\nimport type { Schema } from '../amplify/data/resource';\n\n\n\n\nconst selectionSet = ['content', 'blog.author.*', 'comments.*'] as const;\ntype PostWithComments = SelectionSet<Schema['Post']['type'], typeof selectionSet>;\n\n\n// ...\nconst [posts, setPosts] = useState<PostWithComments[]>([]);\n\n\nconst fetchPosts = async () => {\n  const { data: postsWithComments } = await client.models.Post.list({\n    selectionSet,\n  });\n  setPosts(postsWithComments);\n}\nCancel read requests\n\nYou can cancel any query API request by calling .cancel on the query request promise that's returned by .list(...) or .get(...).\n\nCopy\ncode example\nconst promise = client.models.Todo.list();\n//  ^ Note: we're not awaiting the request, we're returning the promise\n\n\ntry {\n  await promise;\n} catch (error) {\n  console.log(error);\n  // If the error is because the request was cancelled you can confirm here.\n  if (client.isCancelError(error)) {\n    console.log(error.message); // \"my message for cancellation\"\n    // handle user cancellation logic\n  }\n}\n...\n\n\n// To cancel the above request\nclient.cancel(promise, \"my message for cancellation\");\n\nYou need to ensure that the promise returned from .list() or .get() has not been modified. Typically, async functions wrap the promise being returned into another promise. For example, the following will not work:\n\nCopy\ncode example\nasync function makeAPICall() {\n  return client.models.Todo.list();\n}\nconst promise = makeAPICall();\n\n\n// The following will NOT cancel the request.\nclient.cancel(promise, 'my error message');\nConclusion\n\nCongratulations! You have finished the Read application data guide. In this guide, you learned how to read your data through get and list queries.\n\nNext steps\n\nOur recommended next steps include subscribing to real-time events to look for mutations in your data and continuing to build out and customize your information architecture for your data. Some resources that will help with this work include:\n\nSubscribe to real-time events\nCustomize your auth rules\nCustomize your data model\nAdd custom business logic\nPREVIOUS\nCreate, update, and delete application data\nNEXT\nSubscribe to real-time events"
  },
  {
    "title": "Connect your app code to API - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/connect-to-API/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nConnect your app code to API\nConnect your app code to API\n\nIn this guide, you will connect your application code to the backend API using the Amplify Libraries. Before you begin, you will need:\n\nYour cloud sandbox with an Amplify Data resource up and running (npx ampx sandbox)\nA frontend application set up with the Amplify library installed\nnpm installed\nConfigure the Amplify Library\n\nWhen you deploy you're iterating on your backend (npx ampx sandbox), an amplify_outputs.json file is generated for you. This file contains your API's endpoint information and auth configurations. Add the following code to your app's entrypoint to initialize and configure the Amplify client library:\n\nCopy\ncode example\nimport { Amplify } from 'aws-amplify';\nimport outputs from '../amplify_outputs.json';\n\n\nAmplify.configure(outputs);\nGenerate the Amplify Data client\n\nOnce the Amplify library is configured, you can generate a \"Data client\" for your frontend code to make fully-typed API requests to your backend.\n\nIf you're using Amplify with a JavaScript-only frontend (i.e. not TypeScript), then you can still get a fully-typed data fetching experience by annotating the generated client with a JSDoc comment. Select the JavaScript in the code block below to see how.\n\nTo generate a new Data client, use the following code:\n\nTypeScript\nJavaScript\nCopy\ncode example\nimport { generateClient } from 'aws-amplify/data';\nimport type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition\n\n\nconst client = generateClient<Schema>();\n\n\n// Now you should be able to make CRUDL operations with the\n// Data client\nconst fetchTodos = async () => {\n  const { data: todos, errors } = await client.models.Todo.list();\n};\nConfigure authorization mode\n\nThe Authorization Mode determines how a request should be authorized with the backend. By default, Amplify Data uses the \"userPool\" authorization which uses the signed-in user credentials to sign an API request. If you use a allow.publicApiKey() authorization rules for your data models, you need to use \"apiKey\" as an authorization mode. Review Customize your auth rules to learn more about which authorization modes to choose for which type of request. A Default Authorization Mode is provided as part of the amplify_outputs.json that is generated upon a successful deployment.\n\nYou can generate different Data clients with different authorization modes or pass in the authorization mode at the request time.\n\nSet authorization mode on a per-client basis\n\nTo apply the same authorization mode on all requests from a Data client, specify the authMode parameter on the generateClient function.\n\nAPI Key\nAmazon Cognito user pool\nAWS IAM (including Amazon Cognito identity pool roles)\nOpenID Connect (OIDC)\nLambda Authorizer\n\nUse \"API Key\" as your authorization mode when if defined the allow.publicApiKey() authorization rule.\n\nCopy\ncode example\nimport { generateClient } from 'aws-amplify/data';\nimport type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition\n\n\nconst client = generateClient<Schema>({\n  authMode: 'apiKey',\n});\nSet authorization mode on the request-level\n\nYou can also specify the authorization mode on each individual API request. This is useful if your application typically only uses one authorization mode with a small number of exceptions.\n\nAPI Key\nAmazon Cognito user pool\nAWS IAM (including Amazon Cognito identity pool roles)\nOpenID Connect (OIDC)\nLambda Authorizer\nCopy\ncode example\nconst { data: todos, errors } = await client.models.Todo.list({\n  authMode: 'apiKey',\n});\nSet custom request headers\n\nWhen working with the Amplify Data endpoint, you may need to set request headers for authorization purposes or to pass additional metadata from your frontend to the backend API.\n\nThis is done by specifying a headers parameter into the configuration. You can define headers either on a per Data client-level or on a per-request level:\n\nCustom headers per Data client\nCustom headers per request\nCopy\ncode example\nimport type { Schema } from '../amplify/data/resource';\nimport { generateClient } from 'aws-amplify/data';\n\n\nconst client = generateClient<Schema>({\n  headers: {\n    'My-Custom-Header': 'my value',\n  },\n});\n\nThe examples above show you how to set static headers but you can also programmatically set headers by specifying an async function for headers:\n\nCustom headers per Data client\nCustom headers per request\nCopy\ncode example\nimport type { Schema } from '../amplify/data/resource';\nimport { generateClient } from 'aws-amplify/data';\n\n\nconst client = generateClient<Schema>({\n  headers: async (requestOptions) => {\n    console.log(requestOptions);\n    /* The request options allow you to customize your headers based on the request options such\n       as http method, headers, request URI, and query string. These options are typically used\n       to create a request signature.\n    {\n      method: '...',\n      headers: { },\n      uri: '/',\n      queryString: \"\"\n    }\n    */\n    return {\n      'My-Custom-Header': 'my value',\n    };\n  },\n});\nPREVIOUS\nSet up Amplify Data\nNEXT\nCreate, update, and delete application data"
  },
  {
    "title": "Set up Amplify Data - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/set-up-data/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\n/\nSet up Amplify Data\nSet up Amplify Data\n\nIn this guide, you will learn how to set up Amplify Data. This includes building a real-time API and database using TypeScript to define your data model, and securing your API with authorization rules. We will also explore using AWS Lambda to scale to custom use cases.\n\nBefore you begin, you will need:\n\nNode.js v18.16.0 or later\nnpm v6.14.4 or later\ngit v2.14.1 or later\n\nWith Amplify Data, you can build a secure, real-time API backed by a database in minutes. After you define your data model using TypeScript, Amplify will deploy a real-time API for you. This API is powered by AWS AppSync and connected to an Amazon DynamoDB database. You can secure your API with authorization rules and scale to custom use cases with AWS Lambda.\n\nBuilding your data backend\n\nIf you've run npm create amplify@latest already, you should see an amplify/data/resource.ts file, which is the central location to configure your data backend. The most important element is the schema object, which defines your backend data models (a.model()) and custom queries (a.query()), mutations (a.mutation()), and subscriptions (a.subscription()).\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\nimport { a, defineData, type ClientSchema } from '@aws-amplify/backend';\n\n\nconst schema = a.schema({\n  Todo: a.model({\n      content: a.string(),\n      isDone: a.boolean()\n    })\n    .authorization(allow => [allow.publicApiKey()])\n});\n\n\n// Used for code completion / highlighting when making requests from frontend\nexport type Schema = ClientSchema<typeof schema>;\n\n\n// defines the data resource to be deployed\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    defaultAuthorizationMode: 'apiKey',\n    apiKeyAuthorizationMode: { expiresInDays: 30 }\n  }\n});\n\nEvery a.model() automatically creates the following resources in the cloud:\n\na DynamoDB database table to store records\nquery and mutation APIs to create, read (list/get), update, and delete records\ncreatedAt and updatedAt fields that help you keep track of when each record was initially created or when it was last updated\nreal-time APIs to subscribe for create, update, and delete events of records\n\nThe allow.publicApiKey() rule designates that anyone authenticated using an API key can create, read, update, and delete todos.\n\nTo deploy these resources to your cloud sandbox, run the following CLI command in your terminal:\n\nTerminal\nCopy\nTerminal code example\nnpx ampx sandbox\nConnect your application code to the data backend\n\nOnce the cloud sandbox is up and running, it will also create an amplify_outputs.json file, which includes the relevant connection information to your data backend, like your API endpoint URL and API key.\n\nTo connect your frontend code to your backend, you need to:\n\nConfigure the Amplify library with the Amplify client configuration file (amplify_outputs.json)\nGenerate a new API client from the Amplify library\nMake an API request with end-to-end type-safety\n\nFirst, install the Amplify client library to your project:\n\nTerminal\nCopy\nTerminal code example\nnpm add aws-amplify\n\nIn your app's entry point, typically main.tsx for React apps created using Vite, make the following edits:\n\nsrc/main.tsx\nCopy\nsrc/main.tsx code example\nimport { Amplify } from 'aws-amplify';\nimport outputs from '../amplify_outputs.json';\n\n\nAmplify.configure(outputs);\nWrite data to your backend\n\nLet's first add a button to create a new todo item. To make a \"create Todo\" API request, generate the data client using generateClient() in your frontend code, and then call .create() operation for the Todo model. The Data client is a fully typed client that gives you in-IDE code completion. To enable this in-IDE code completion capability, pass in the Schema type to the generateClient function.\n\nsrc/TodoList.tsx\nCopy\nsrc/TodoList.tsx code example\nimport type { Schema } from '../amplify/data/resource'\nimport { generateClient } from 'aws-amplify/data'\n\n\nconst client = generateClient<Schema>()\n\n\nexport default function TodoList() {\n  const createTodo = async () => {\n    await client.models.Todo.create({\n      content: window.prompt(\"Todo content?\"),\n      isDone: false\n    })\n  }\n\n\n  return <div>\n    <button onClick={createTodo}>Add new todo</button>\n  </div>\n}\n\nRun the application in local development mode and check your network tab after creating a todo. You should see a successful request to a /graphql endpoint.\n\nTry playing around with the code completion of .update(...) and .delete(...) to get a sense of other mutation operations.\n\nRead data from your backend\n\nNext, list all your todos and then refetch the todos after a todo has been added:\n\nsrc/TodoList.tsx\nCopy\nsrc/TodoList.tsx code example\nimport { useState, useEffect } from \"react\";\nimport type { Schema } from \"../amplify/data/resource\";\nimport { generateClient } from \"aws-amplify/data\";\n\n\nconst client = generateClient<Schema>();\n\n\nexport default function TodoList() {\n  const [todos, setTodos] = useState<Schema[\"Todo\"][\"type\"][]>([]);\n\n\n  const fetchTodos = async () => {\n    const { data: items, errors } = await client.models.Todo.list();\n    setTodos(items);\n  };\n\n\n  useEffect(() => {\n    fetchTodos();\n  }, []);\n\n\n  const createTodo = async () => {\n    await client.models.Todo.create({\n      content: window.prompt(\"Todo content?\"),\n      isDone: false,\n    });\n\n\n    fetchTodos();\n  }\n\n\n  return (\n    <div>\n      <button onClick={createTodo}>Add new todo</button>\n      <ul>\n        {todos.map(({ id, content }) => (\n          <li key={id}>{content}</li>\n        ))}\n      </ul>\n    </div>\n  );\n}\nSubscribe to real-time updates\n\nYou can also use observeQuery to subscribe to a live feed of your backend data. Let's refactor the code to use a real-time observeQuery instead.\n\nsrc/App.tsx\nCopy\nsrc/App.tsx code example\nimport type { Schema } from \"../amplify/data/resource\";\nimport { useState, useEffect } from \"react\";\nimport { generateClient } from \"aws-amplify/data\";\n\n\nconst client = generateClient<Schema>();\n\n\nexport default function TodoList() {\n  const [todos, setTodos] = useState<Schema[\"Todo\"][\"type\"][]>([]);\n\n\n  useEffect(() => {\n    const sub = client.models.Todo.observeQuery().subscribe({\n      next: ({ items }) => {\n        setTodos([...items]);\n      },\n    });\n\n\n    return () => sub.unsubscribe();\n  }, []);\n\n\n  const createTodo = async () => {\n    await client.models.Todo.create({\n      content: window.prompt(\"Todo content?\"),\n      isDone: false,\n    });\n    // no more manual refetchTodos required!\n    // - fetchTodos()\n  };\n\n\n  return (\n    <div>\n      <button onClick={createTodo}>Add new todo</button>\n      <ul>\n        {todos.map(({ id, content }) => (\n          <li key={id}>{content}</li>\n        ))}\n      </ul>\n    </div>\n  );\n}\n\nNow try to open your app in two browser windows and see how creating a todo in one window automatically adds the todo in the second window as well.\n\nYou can also use .onCreate, .onUpdate, or .onDelete to subscribe to specific events. Review Subscribe to real-time events to learn more about subscribing to specific mutation events.\n\nConclusion\n\nSuccess! You've learned how to create your first real-time API and database with Amplify Data.\n\nNext steps\n\nThere's so much more to discover with Amplify Data. Learn more about:\n\nHow to model your database table and their access patterns\nSecure your API with fine-grained authorization rules\nCreate relationships between different database model\nAdd custom business logic\nNEXT\nConnect your app code to API"
  },
  {
    "title": "Data - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/data/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nData\nData\nSet up Amplify Data\nCreate a new cloud API that connects your app with new or existing data sources.\nConnect your app code to API\nLearn how to connect your app code to an API.\nCreate, update, and delete application data\nMutate application data in an API by generating the client, adding items, updating existing items, deleting items, troubleshooting unauthorized errors, and canceling requests.\nRead application data\nRead application data using list and get queries. You can filter query results, paginate list queries, specify only the data fields needed, and cancel requests. This guide covers how to perform these tasks to optimize data access in your application.\nSubscribe to real-time events\nSet up real-time data subscriptions in your app to get live updates, filter those subscriptions on the server side, and unsubscribe when no longer needed.\nCustomize your data model\nLearn how to customize your data model.\nCustomize your auth rules\nLearn how to customize and combine your authorization rules.\nAdd custom queries and mutations\nCustomize your business logic for queries and mutations.\nWorking with files/attachments\nWorking with files/attachments.\nAdd custom real-time subscriptions\nCustomize your business logic to create custom real-time subscriptions.\nConnect to existing data sources\nLearn how to connect your Data API to existing DynamoDB tables, MySQL databases, or PostgreSQL databases.\nConnect to data from Server-side Runtimes\nConnect to Amplify Data from Next.js and Nuxt.js Server-side Runtimes (SSR).\nOptimistic UI\nLearn more about implementing optimistic UI with Amplify Data API.\nModify Amplify-generated AWS resources\nModify and customize existing AWS resources generated by the Amplify GraphQL API.\nManage Data with Amplify console\nManage GraphQL data with Amplify console"
  },
  {
    "title": "Advanced workflows - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/advanced-workflows/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nAdvanced workflows\nAdvanced workflows\nSubscribing to Events\n\nYou can take specific actions when users sign-in or sign-out by subscribing to authentication events in your app. Please see our Hub Module Developer Guide for more information.\n\nIdentity Pool Federation\n\nYou can alternatively create your own custom credentials provider to get AWS credentials directly from Cognito Federated Identities and not use User Pool federation. You must supply the custom credentials provider to Amplify via the Amplify.configure method call. Below, you can see sample code of how such a custom provider can be built to achieve the use case.\n\nCopy\ncode example\nimport { Amplify } from 'aws-amplify';\nimport {\n  fetchAuthSession,\n  CredentialsAndIdentityIdProvider,\n  CredentialsAndIdentityId,\n  GetCredentialsOptions,\n  AuthTokens,\n} from 'aws-amplify/auth';\n\n\n// Note: This example requires installing `@aws-sdk/client-cognito-identity` to obtain Cognito credentials\n// npm i @aws-sdk/client-cognito-identity\nimport { CognitoIdentity } from '@aws-sdk/client-cognito-identity';\n\n\n// You can make use of the sdk to get identityId and credentials\nconst cognitoidentity = new CognitoIdentity({\n  region: '<region-from-config>',\n});\n\n\n// Note: The custom provider class must implement CredentialsAndIdentityIdProvider\nclass CustomCredentialsProvider implements CredentialsAndIdentityIdProvider {\n\n\n  // Example class member that holds the login information\n  federatedLogin?: {\n    domain: string,\n    token: string\n  };\n\n\n  // Custom method to load the federated login information\n  loadFederatedLogin(login?: typeof this.federatedLogin) {\n    // You may also persist this by caching if needed\n    this.federatedLogin = login;\n  }\n\n\n  async getCredentialsAndIdentityId(\n    getCredentialsOptions: GetCredentialsOptions\n  ): Promise<CredentialsAndIdentityId | undefined> {\n    try {\n\n\n      // You can add in some validation to check if the token is available before proceeding\n      // You can also refresh the token if it's expired before proceeding\n\n\n      const getIdResult = await cognitoidentity.getId({\n        // Get the identityPoolId from config\n        IdentityPoolId: '<identity-pool-id-from-config>',\n        Logins: { [this.federatedLogin.domain]: this.federatedLogin.token },\n      });\n\n\n      const cognitoCredentialsResult = await cognitoidentity.getCredentialsForIdentity({\n        IdentityId: getIdResult.IdentityId,\n        Logins: { [this.federatedLogin.domain]: this.federatedLogin.token },\n      });\n\n\n      const credentials: CredentialsAndIdentityId = {\n        credentials: {\n          accessKeyId: cognitoCredentialsResult.Credentials?.AccessKeyId,\n          secretAccessKey: cognitoCredentialsResult.Credentials?.SecretKey,\n          sessionToken: cognitoCredentialsResult.Credentials?.SessionToken,\n          expiration: cognitoCredentialsResult.Credentials?.Expiration,\n        },\n        identityId: getIdResult.IdentityId,\n      };\n      return credentials;\n    } catch (e) {\n      console.log('Error getting credentials: ', e);\n    }\n  }\n  // Implement this to clear any cached credentials and identityId. This can be called when signing out of the federation service.\n  clearCredentialsAndIdentityId(): void {}\n}\n\n\n// Create an instance of your custom provider\nconst customCredentialsProvider = new CustomCredentialsProvider();\nAmplify.configure(awsconfig, {\n  Auth: {\n    // Supply the custom credentials provider to Amplify\n    credentialsProvider: customCredentialsProvider\n  },\n});\n\nNow that the custom credentials provider is built and supplied to Amplify.configure, let's look at how you can use the custom credentials provider to finish federation into Cognito identity pool.\n\nFacebook sign-in (React)\nCopy\ncode example\nimport React, { useEffect } from 'react';\nimport {\n  fetchAuthSession,\n} from 'aws-amplify/auth';\n\n\n// To federated sign in from Facebook\nconst SignInWithFacebook = () => {\n\n\n  useEffect(() => {\n    if (!window.FB) createScript();\n  }, [])\n\n\n  const signIn = () => {\n    const fb = window.FB;\n    fb.getLoginStatus(response => {\n      if (response.status === 'connected') {\n        getAWSCredentials(response.authResponse);\n      } else {\n        fb.login(\n          response => {\n            if (!response || !response.authResponse) {\n              return;\n            }\n            customCredentialsProvider.loadFederatedLogin({\n              domain: 'graph.facebook.com',\n              token: response.authResponse.accessToken,\n            });\n            const fetchSessionResult = await fetchAuthSession(); // will return the credentials\n            console.log('fetchSessionResult: ', fetchSessionResult);\n          },\n          {\n            // the authorized scopes\n            scope: 'public_profile,email'\n          }\n        );\n      }\n    });\n  }\n\n\n  const createScript = () => {\n    // load the sdk\n    window.fbAsyncInit = fbAsyncInit;\n    const script = document.createElement('script');\n    script.src = 'https://connect.facebook.net/en_US/sdk.js';\n    script.async = true;\n    script.onload = initFB;\n    document.body.appendChild(script);\n  }\n\n\n  const initFB = () => {\n    const fb = window.FB;\n    console.log('FB SDK initialized');\n  }\n\n\n  const fbAsyncInit = () => {\n    // init the fb sdk client\n    const fb = window.FB;\n    fb.init({\n      appId   : 'your_facebook_app_id',\n      cookie  : true,\n      xfbml   : true,\n      version : 'v2.11'\n    });\n  }\n\n\n  return (\n    <div>\n      <button onClick={signIn}>Sign in with Facebook</button>\n    </div>\n  );\n}\nGoogle sign-in (React)\nCopy\ncode example\nimport React, { useEffect } from 'react';\nimport jwt from 'jwt-decode';\nimport {\n  fetchAuthSession,\n} from 'aws-amplify/auth';\n\n\nconst SignInWithGoogle = () => {\n  useEffect(() => {\n  // Check for an existing Google client initialization\n    if (!window.google?.accounts) createScript();\n  }, []);\n\n\n  // Load the Google client\n  const createScript = () => {\n    const script = document.createElement('script');\n    script.src = 'https://accounts.google.com/gsi/client';\n    script.async = true;\n    script.defer = true;\n    script.onload = initGsi;\n    document.body.appendChild(script);\n  }\n\n\n  // Initialize Google client and render Google button\n  const initGsi = () => {\n    if (window.google?.accounts) {\n      window.google.accounts.id.initialize({\n        client_id: process.env.GOOGLE_CLIENT_ID,\n        callback: (response: any) => {\n          customCredentialsProvider.loadFederatedLogin({\n            domain: 'accounts.google.com',\n            token: response.credential,\n          });\n          const fetchSessionResult = await fetchAuthSession(); // will return the credentials\n          console.log('fetchSessionResult: ', fetchSessionResult);\n        },\n      });\n      window.google.accounts.id.renderButton(\n        document.getElementById('googleSignInButton'),\n        { theme: 'outline', size: 'large' }\n      );\n    }\n  }\n\n\n  return (\n    <div>\n      <button id='googleSignInButton'/>\n    </div>\n  );\n}\nFederate with Auth0\n\nYou can use Auth0 as one of the providers of your Cognito Identity Pool. This will allow users authenticated via Auth0 have access to your AWS resources.\n\nStep 1. Follow Auth0 integration instructions for Cognito Federated Identity Pools\n\nStep 2. Login with Auth0, then use the id token returned to get AWS credentials from Cognito Federated Identity Pools using custom credentials provider you created at the start:\n\nCopy\ncode example\nimport { fetchAuthSession } from 'aws-amplify/auth';\n\n\nconst { idToken, domain, name, email, phoneNumber } = getFromAuth0(); // get the user credentials and info from auth0\n\n\nasync function getCognitoCredentials() {\n  try {\n    customCredentialsProvider.loadFederatedLogin({\n      domain,\n      token: idToken\n    });\n    const fetchSessionResult = await fetchAuthSession(); // will return the credentials\n    console.log('fetchSessionResult: ', fetchSessionResult);\n  } catch (err) {\n    console.log(err);\n  }\n}\nLambda Triggers\n\nWith the triggers property of defineAuth and defineFunction from the new Functions implementation, you can define Lambda Triggers for your Cognito User Pool. These enable you to add custom functionality to your registration and authentication flows. Check out a preSignUp hook example here.\n\nPre Authentication and Pre Sign-up Lambda triggers\n\nIf you have a Pre Authentication Lambda trigger enabled, you can pass clientMetadata as an option for signIn. This metadata can be used to implement additional validations around authentication.\n\nCopy\ncode example\nimport { signIn } from 'aws-amplify/auth';\n\n\nasync function handleSignIn(username: string, password: string) {\n  try {\n    await signIn({\n      username,\n      password,\n      options: {\n        clientMetadata: {} // Optional, an object of key-value pairs which can contain any key and will be passed to your Lambda trigger as-is.\n      }\n    });\n  } catch (err) {\n    console.log(err);\n  }\n}\nPassing metadata to other Lambda triggers\n\nMany Cognito Lambda Triggers also accept unsanitized key/value pairs in the form of a clientMetadata attribute. This attribute can be specified for various Auth APIs which result in Cognito Lambda Trigger execution.\n\nThese APIs include:\n\nsignIn\nsignUp\nconfirmSignIn\nconfirmSignUp\nresetPassword\nconfirmResetPassword\nresendSignUpCode\nupdateUserAttributes\n\nPlease note that some of triggers which accept a validationData attribute will use clientMetadata as the value for validationData. Exercise caution with using clientMetadata when you are relying on validationData.\n\nWorking with AWS service objects\n\nYou can use AWS Service Interface Objects to work with AWS Services in authenticated State. You can call methods on any AWS Service interface object by passing your credentials from Amplify fetchAuthSession to the service call constructor:\n\nCopy\ncode example\nimport { fetchAuthSession } from 'aws-amplify/auth';\nimport Route53 from 'aws-sdk/clients/route53';\n\n\nasync function changeResourceRecordSets() {\n  try {\n    const { credentials } = await fetchAuthSession();\n\n\n    const route53 = new Route53({\n      apiVersion: '2013-04-01',\n      credentials\n    });\n\n\n    // more code working with route53 object\n    //route53.changeResourceRecordSets();\n  } catch (err) {\n    console.log(err);\n  }\n}\n\nNote: To work with Service Interface Objects, your Amazon Cognito users' IAM role must have the appropriate permissions to call the requested services.\n\nCustom Token providers\n\nCreate a custom Auth token provider for situations where you would like provide your own tokens for a service. For example, using OIDC Auth with AppSync. You must supply the token provider to Amplify via the Amplify.configure method call. Below, you can see sample code of how such a custom provider can be built to achieve the use case.\n\nCopy\ncode example\nimport { Amplify } from 'aws-amplify';\nimport { TokenProvider, decodeJWT } from 'aws-amplify/auth';\n\n\n// ...\n\n\nconst myTokenProvider: TokenProvider = {\n  async getTokens({ forceRefresh } = {}) {\n    if (forceRefresh) {\n      // try to obtain new tokens if possible\n    }\n\n\n    const accessTokenString = '<insert JWT from provider>';\n    const idTokenString = '<insert JWT from provider>';\n    \n    return {\n      accessToken: decodeJWT(accessTokenString),\n      idToken: decodeJWT(idTokenString),\n    };\n  },\n};\n\n\nAmplify.configure(awsconfig, {\n  Auth: {\n    tokenProvider: myTokenProvider\n  }\n});\nAPI reference\n\nFor the complete API documentation for Authentication module, visit our API Reference\n\nPREVIOUS\nMoving to production\nNEXT\nUse existing Cognito resources"
  },
  {
    "title": "Use existing Cognito resources - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/use-existing-cognito-resources/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nUse existing Cognito resources\nUse existing Cognito resources\n\nAmplify Auth can be configured to use an existing Amazon Cognito user pool and identity pool. If you are in a team setting or part of a company that has previously created auth resources, you can configure the client library directly, or maintain references with AWS Cloud Development Kit (AWS CDK) in your Amplify backend.\n\nNote: when using existing auth resources, it may be necessary to add additional policies or permissions for your authenticated and unauthenticated IAM roles. These changes must be performed manually.\n\nUse auth resources without an Amplify backend\n\nYou can use existing resources without an Amplify backend by configuring the client library directly.\n\nsrc/main.ts\nCopy\nsrc/main.ts code example\nimport { Amplify } from \"aws-amplify\"\n\n\nAmplify.configure({\n  Auth: {\n    Cognito: {\n      userPoolId: \"<your-cognito-user-pool-id>\",\n      userPoolClientId: \"<your-cognito-user-pool-client-id>\",\n      identityPoolId: \"<your-cognito-identity-pool-id>\",\n      loginWith: {\n        email: true,\n      },\n      signUpVerificationMethod: \"code\",\n      userAttributes: {\n        email: {\n          required: true,\n        },\n      },\n      allowGuestAccess: true,\n      passwordFormat: {\n        minLength: 8,\n        requireLowercase: true,\n        requireUppercase: true,\n        requireNumbers: true,\n        requireSpecialCharacters: true,\n      },\n    },\n  },\n})\nUse auth resources with an Amplify backend\n\nWarning: Amplify resources do not support including auth configurations by referencing with CDK. We are currently working to improve this experience by providing first-class support for referencing existing auth resources. View the RFC for referenceAuth for more details\n\nNext steps\nLearn how to connect your frontend\nPREVIOUS\nAdvanced workflows"
  },
  {
    "title": "Moving to production - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/moving-to-production/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nMoving to production\nMoving to production\n\nAmplify Auth provisions Amazon Cognito resources that are provisioned with limited capabilities for sending email and SMS messages. In its default state, it is not intended to handle production workloads, but is sufficient for developing your application and associated business logic.\n\nEmail\n\nCognito provides a default email functionality that limits how many emails can be sent in one day. When considering production workloads, Cognito can be configured to send emails using Amazon Simple Email Service (Amazon SES).\n\nAll new AWS accounts default to a \"sandbox\" status with Amazon SES. This comes with the primary caveat that you can only send mail to verified email addresses and domains\n\nTo get started with Amazon SES in production, you must first request production access. Once you submit your request the submission cannot be modified, however you will receive a response from AWS within 24 hours.\n\nAfter you have configured your account for production access and have verified your sender email, you can configure your Cognito user pool to send emails using the verified sender:\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { Stack } from \"aws-cdk-lib/core\"\nimport { EmailIdentity } from \"aws-cdk-lib/aws-ses\"\nimport { defineBackend } from \"@aws-amplify/backend\"\nimport { auth } from \"./auth/resource\"\n\n\nconst backend = defineBackend({\n  auth,\n})\n\n\nconst { cfnUserPool } = backend.auth.resources.cfnResources\nconst authStack = Stack.of(cfnUserPool)\n\n\nconst email = EmailIdentity.fromEmailIdentityName(\n  authStack,\n  \"EmailIdentity\",\n  // your email configured for use in SES\n  process.env.EMAIL\n)\n\n\ncfnUserPool.emailConfiguration = {\n  emailSendingAccount: \"DEVELOPER\",\n  sourceArn: email.emailIdentityArn,\n}\n\nNow when emails are sent on new user sign-ups, password resets, etc., the sending account will be your verified email.\n\nSMS\n\nIn order to send SMS authentication codes, you must request an origination number. Authentication codes will be sent from the origination number. If your AWS account is in the SMS sandbox, you must also add a destination phone number, which can be done by going to the Amazon Pinpoint Console, selecting SMS and voice in the navigation pane, and selecting Add phone number in the Destination phone numbers tab. To check if your AWS account is in the SMS sandbox, go to the SNS console, select the Text messaging (SMS) tab from the navigation pane, and check the status under the Account information section.\n\nPREVIOUS\nModify Amplify-generated Cognito resources with CDK\nNEXT\nAdvanced workflows"
  },
  {
    "title": "Modify Amplify-generated Cognito resources with CDK - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/modify-resources-with-cdk/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nModify Amplify-generated Cognito resources with CDK\nModify Amplify-generated Cognito resources with CDK\n\nAmplify Auth provides sensible defaults for the underlying Amazon Cognito resource definitions. You can customize your authentication resource to enable it to behave exactly as needed for your use cases by modifying it directly using AWS Cloud Development Kit (CDK)\n\nOverride Cognito UserPool password policies\n\nYou can override the password policy by using the L1 cfnUserPool construct and adding a addPropertyOverride.\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource';\n\n\nconst backend = defineBackend({\n  auth,\n});\n// extract L1 CfnUserPool resources\nconst { cfnUserPool } = backend.auth.resources.cfnResources;\n// modify cfnUserPool policies directly\ncfnUserPool.policies = {\n  passwordPolicy: {\n    minimumLength: 10,\n    requireLowercase: true,\n    requireNumbers: true,\n    requireSymbols: true,\n    requireUppercase: true,\n    temporaryPasswordValidityDays: 20,\n  },\n};\nPREVIOUS\nGrant access to auth resources\nNEXT\nMoving to production"
  },
  {
    "title": "Grant access to auth resources - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/grant-access-to-auth-resources/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nGrant access to auth resources\nGrant access to auth resources\n\nAmplify Auth can be defined with an access property, which allows other resources to interact with auth by specifying actions.\n\namplify/auth/resource.ts\nCopy\namplify/auth/resource.ts code example\nimport { defineAuth } from \"@aws-amplify/backend\"\nimport { addUserToGroup } from \"../functions/add-user-to-group/resource\"\n\n\n/**\n * Define and configure your auth resource\n * @see https://docs.amplify.aws/gen2/build-a-backend/auth\n */\nexport const auth = defineAuth({\n  loginWith: {\n    email: true,\n  },\n  access: (allow) => [\n    allow.resource(addUserToGroup).to([\"addUserToGroup\"])\n  ],\n})\n\nWhen you grant a function access to another resource in your Amplify backend it will configure environment variables for that function to make SDK calls to the AWS services it has access to. Those environment variables are typed and available as part of the env object.\n\nList of actions\nAction Name\tDescription\tCognito IAM Actions\nmanageUsers\tGrants CRUD access to users in the UserPool\t\ncognito-idp:AdminConfirmSignUp\ncognito-idp:AdminCreateUser\ncognito-idp:AdminDeleteUser\ncognito-idp:AdminDeleteUserAttributes\ncognito-idp:AdminDisableUser\ncognito-idp:AdminEnableUser\ncognito-idp:AdminGetUser\ncognito-idp:AdminListGroupsForUser\ncognito-idp:AdminRespondToAuthChallenge\ncognito-idp:AdminSetUserMFAPreference\ncognito-idp:AdminSetUserSettings\ncognito-idp:AdminUpdateUserAttributes\ncognito-idp:AdminUserGlobalSignOut\n\nmanageGroupMembership\tGrants permission to add and remove users from groups\t\ncognito-idp:AdminAddUserToGroup\ncognito-idp:AdminRemoveUserFromGroup\n\nmanageGroups\tGrants CRUD access to groups in the UserPool\t\ncognito-idp:GetGroup\ncognito-idp:ListGroups\ncognito-idp:CreateGroup\ncognito-idp:DeleteGroup\ncognito-idp:UpdateGroup\n\nmanageUserDevices\tManages devices registered to users\t\ncognito-idp:AdminForgetDevice\ncognito-idp:AdminGetDevice\ncognito-idp:AdminListDevices\ncognito-idp:AdminUpdateDeviceStatus\n\nmanagePasswordRecovery\tGrants permission to reset user passwords\t\ncognito-idp:AdminResetUserPassword\ncognito-idp:AdminSetUserPassword\n\naddUserToGroup\tGrants permission to add any user to any group.\t\ncognito-idp:AdminAddUserToGroup\n\ncreateUser\tGrants permission to create new users and send welcome messages via email or SMS.\t\ncognito-idp:AdminCreateUser\n\ndeleteUser\tGrants permission to delete any user\t\ncognito-idp:AdminDeleteUser\n\ndeleteUserAttributes\tGrants permission to delete attributes from any user\t\ncognito-idp:AdminDeleteUserAttributes\n\ndisableUser\tGrants permission to deactivate any user\t\ncognito-idp:AdminDisableUser\n\nenableUser\tGrants permission to activate any user\t\ncognito-idp:AdminEnableUser\n\nforgetDevice\tGrants permission to deregister any user's devices\t\ncognito-idp:AdminForgetDevice\n\ngetDevice\tGrants permission to get information about any user's devices\t\ncognito-idp:AdminGetDevice\n\ngetUser\tGrants permission to look up any user by user name\t\ncognito-idp:AdminGetUser\n\nlistUsers\tGrants permission to list users and their basic details in the UserPool\t\ncognito-idp:ListUsers\n\nlistDevices\tGrants permission to list any user's remembered devices\t\ncognito-idp:AdminListDevices\n\nlistGroupsForUser\tGrants permission to list the groups that any user belongs to\t\ncognito-idp:AdminListGroupsForUser\n\nlistUsersInGroup\tGrants permission to list users in the specified group\t\ncognito-idp:ListUsersInGroup\n\nremoveUserFromGroup\tGrants permission to remove any user from any group\t\ncognito-idp:AdminRemoveUserFromGroup\n\nresetUserPassword\tGrants permission to reset any user's password\t\ncognito-idp:AdminResetUserPassword\n\nsetUserMfaPreference\tGrants permission to set any user's preferred MFA method\t\ncognito-idp:AdminSetUserMFAPreference\n\nsetUserPassword\tGrants permission to set any user's password\t\ncognito-idp:AdminSetUserPassword\n\nsetUserSettings\tGrants permission to set user settings for any user\t\ncognito-idp:AdminSetUserSettings\n\nupdateDeviceStatus\tGrants permission to update the status of any user's remembered devices\t\ncognito-idp:AdminUpdateDeviceStatus\n\nupdateUserAttributes\tGrants permission to updates any user's standard or custom attributes\t\ncognito-idp:AdminUpdateUserAttributes\nPREVIOUS\nCustomize auth lifecycle\nNEXT\nModify Amplify-generated Cognito resources with CDK"
  },
  {
    "title": "Triggers - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/customize-auth-lifecycle/triggers/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nCustomize auth lifecycle\n/\nTriggers\nTriggers\n\nAmplify Auth's behavior can be customized through the use of triggers. A trigger is defined as a Function, and is a mechanism to slot some logic to execute during the authentication flow. For example, you can use triggers to validate whether emails include an allowlisted domain, add a user to a group upon confirmation, or create a \"UserProfile\" model upon account confirmation.\n\nTriggers translate to Cognito user pool Lambda triggers.\n\nWhen you have a Lambda trigger assigned to your user pool, Amazon Cognito interrupts its default flow to request information from your function. Amazon Cognito generates a JSON event and passes it to your function. The event contains information about your user's request to create a user account, sign in, reset a password, or update an attribute. Your function then has an opportunity to take action, or to send the event back unmodified.\n\nTo get started, define a function and specify the triggers property on your auth resource:\n\namplify/auth/resource.ts\nimport { defineAuth } from \"@aws-amplify/backend\"\n\n\nexport const auth = defineAuth({\n  loginWith: {\n    email: true,\n  },\nCopy\nhighlighted code example\n  triggers: {}\n})\n\nTo learn more about use cases for triggers, visit the Functions examples.\n\nPREVIOUS\nEmail customization"
  },
  {
    "title": "Email customization - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/customize-auth-lifecycle/email-customization/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nCustomize auth lifecycle\n/\nEmail customization\nEmail customization\n\nBy default, Amplify Auth resources are scaffolded with email as the default method for your users to sign in. When you users sign up they receive a verification email to confirm their ownership of the email they specified during sign-up. Emails such as the verification email can be customized with your app's brand identity.\n\nTo get started, modify email: true to an object to begin customizing its default behavior:\n\namplify/auth/resource.ts\nCopy\namplify/auth/resource.ts code example\nimport { defineAuth } from \"@aws-amplify/backend\"\n\n\nexport const auth = defineAuth({\n  loginWith: {\n-   email: true, \n+   email: {\n+     verificationEmailStyle: \"CODE\",\n+     verificationEmailSubject: \"Welcome to my app!\",\n+     verificationEmailBody: (createCode) => `Use this code to confirm your account: ${createCode()}`,\n+   },\n  },\n})\nNEXT\nTriggers"
  },
  {
    "title": "Customize auth lifecycle - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/customize-auth-lifecycle/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nCustomize auth lifecycle\nCustomize auth lifecycle\nEmail customization\nLearn how to customize emails your users receive when signing up\nTriggers\nLearn how to use Cognito Lambda triggers to customize the authentication lifecycle"
  },
  {
    "title": "Manage users with Amplify console - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/manage-users/with-amplify-console/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nManage users\n/\nManage users with Amplify console\nManage users with Amplify console\n\nThe User management page in the Amplify console provides a user-friendly interface for managing your application's users. You can create and manage users and groups, edit user attributes, and suspend users.\n\nIf you have not yet created an auth resource, visit the Auth setup guide.\n\nAccess User management\n\nAfter you've deployed your auth resource, you can access the manager on Amplify Console.\n\nLog in to the Amplify console and choose your app.\nSelect the branch you would like to access.\nSelect Authentication from the left navigation bar.\nThen, select User management.\nTo create a user\nOn the User management page, select Users tab.\nSelect Create user.\nIn the Create user window, for Unique identifier enter a email address, username, or phone number. For Temporary password enter a password.\nChoose Create user.\n\nA user can be confirmed by using the pre-built UI components and Amplify libraries.\n\nTo create a group\nOn the User management page, choose the Groups tab and then choose Create group.\nIn the Create group window, for Title enter a name for the group.\nChoose Create group.\nTo add a users to a group\nOn the User management page, choose the Groups tab.\nSelect the name of the group to add users to.\nChoose Add users.\nIn the Add users to group window, choose how you want to search for users to add from the Search menu. You can choose Email, Phone number, or Username.\nAdd one user or multiple users to add to the group and then choose Add users.\nTo delete a group\nOn the User management page, choose the Groups tab.\nIn the Groups section, select the name of the group to delete.\nChoose Delete.\nA confirmation window is displayed. Enter Delete and choose, Confirm deletion.\nPREVIOUS\nManage devices"
  },
  {
    "title": "Manage devices - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/manage-users/manage-devices/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nManage users\n/\nManage devices\nManage devices\n\nAmplify Auth enables you to track devices your users use for auditing, MFA, and more. Before you begin it is important to understand the terminology for device statuses:\n\nTracked: Every time the user signs in with a new device, the client is given the device key at the end of a successful authentication event. We use this device key to generate a salt and password verifier which is used to call the ConfirmDevice API. At this point, the device is considered to be tracked. Once the device is in a tracked state, you can use the Amazon Cognito console to see the time it started to be tracked, last authentication time, and other information about that device.\nRemembered: Remembered devices are also tracked. During user authentication, the device key and secret pair assigned to a remembered device is used to authenticate the device to verify that it is the same device that the user previously used to sign in.\nNot Remembered: A not-remembered device is a tracked device where Cognito has been configured to require users to \"Opt-in\" to remember a device, but the user has not opt-ed in to having the device remembered. This use case is used for users signing into their application from a device that they don't own.\nForgotten: a forgotten device is one removed from being remembered\n\nNote: device tracking and remembering features are not available when using federating sign-in with external providers as devices are tracked on the upstream identity provider. These features are also not available when using Cognito's Hosted UI.\n\nRemember devices\n\nYou can remember devices using the following:\n\nCopy\ncode example\nimport { rememberDevice } from 'aws-amplify/auth';\n\n\nawait rememberDevice();\nForget devices\n\nYou can also forget devices but note that forgotten devices are neither remembered nor tracked.\n\nCopy\ncode example\nimport { forgetDevice } from 'aws-amplify/auth';\n\n\nawait forgetDevice();\nFetch devices\n\nYou can fetch a list of remembered devices by using the following:\n\nCopy\ncode example\nimport { fetchDevices } from 'aws-amplify/auth';\n\n\nconst output = await fetchDevices();\n\nYou can now set up devices to be remembered, forgotten, and fetched.\n\nPREVIOUS\nManage passwords\nNEXT\nManage users with Amplify console"
  },
  {
    "title": "With admin actions - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/manage-users/with-admin-actions/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nManage users\n/\nWith admin actions\nWith admin actions\n\nAmplify Auth can be managed with the AWS SDK's @aws-sdk/client-cognito-identity-provider package. This package is intended to use server-side, and can be used within a Function. This example focuses on the addUserToGroup action and will be defined as a custom mutation.\n\nTo get started, create an \"ADMINS\" group that will be used to authorize the mutation:\n\namplify/auth/resource.ts\nimport { defineAuth } from \"@aws-amplify/backend\"\n\n\nexport const auth = defineAuth({\n  loginWith: {\n    email: true,\n  },\nCopy\nhighlighted code example\n  groups: [\"ADMINS\"]\n})\n\nNext, create the Function resource:\n\namplify/data/add-user-to-group/resource.ts\nCopy\namplify/data/add-user-to-group/resource.ts code example\nimport { defineFunction } from \"@aws-amplify/backend\"\n\n\nexport const addUserToGroup = defineFunction({\n  name: \"add-user-to-group\",\n})\n\nThen, in your auth resources, grant access for the function to perform the addUserToGroup action. Learn more about granting access to auth resources.\n\namplify/auth/resource.ts\nimport { defineAuth } from \"@aws-amplify/backend\"\nCopy\nhighlighted code example\nimport { addUserToGroup } from \"../data/add-user-to-group/resource\"\n\n\nexport const auth = defineAuth({\n  loginWith: {\n    email: true,\n  },\n  groups: [\"ADMINS\"],\nCopy\nhighlighted code example\n  access: (allow) => [\n    allow.resource(addUserToGroup).to([\"addUserToGroup\"])\n  ],\n})\n\nYou're now ready to define the custom mutation. Here you will use the newly-created addUserToGroup function resource to handle the addUserToGroup mutation. This mutation can only be called by a user in the \"ADMINS\" group.\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\nimport type { ClientSchema } from \"@aws-amplify/backend\"\nimport { a, defineData } from \"@aws-amplify/backend\"\nimport { addUserToGroup } from \"./resource\"\n\n\nconst schema = a.schema({\n  addUserToGroup: a\n    .mutation()\n    .arguments({\n      userId: a.string().required(),\n      groupName: a.string().required(),\n    })\n    .authorization((allow) => [allow.group(\"ADMINS\")])\n    .handler(a.handler.function(addUserToGroup))\n    .returns(a.json())\n})\n\n\nexport type Schema = ClientSchema<typeof schema>\n\n\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    defaultAuthorizationMode: \"iam\",\n  },\n})\n\nLastly, create the function's handler using the exported client schema to type the handler function, and the generated env to specify the user pool ID you'd like to interact with:\n\namplify/data/add-user-to-group/handler.ts\nCopy\namplify/data/add-user-to-group/handler.ts code example\nimport type { Schema } from \"../resource\"\nimport { env } from \"$amplify/env/add-user-to-group\"\nimport {\n  AdminAddUserToGroupCommand,\n  CognitoIdentityProviderClient,\n} from \"@aws-sdk/client-cognito-identity-provider\"\n\n\ntype Handler = Schema[\"addUserToGroup\"][\"functionHandler\"]\nconst client = new CognitoIdentityProviderClient()\n\n\nexport const handler: Handler = async (event) => {\n  const { userId, groupName } = event.arguments\n  const command = new AdminAddUserToGroupCommand({\n    Username: userId,\n    GroupName: groupName,\n    UserPoolId: env.AMPLIFY_AUTH_USERPOOL_ID,\n  })\n  const response = await client.send(command)\n  return response\n}\n\nIn your frontend, use the generated client to call your mutation using the group name and the user's ID.\n\nsrc/client.ts\nCopy\nsrc/client.ts code example\nimport type { Schema } from \"../amplify/data/resource\"\nimport { generateClient } from \"aws-amplify/data\"\n\n\nconst client = generateClient<Schema>()\n\n\nawait client.mutations.addUserToGroup({\n  groupName: \"ADMINS\",\n  userId: \"5468d468-4061-70ed-8870-45c766d26225\",\n})\nNEXT\nManage passwords"
  },
  {
    "title": "Manage passwords - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/manage-users/manage-passwords/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nManage users\n/\nManage passwords\nManage passwords\n\nAmplify Auth provides a secure way for your users to change their password or recover a forgotten password.\n\nUnderstand password default settings\n\nBy default, your users can retrieve access to their accounts if they forgot their password by using either their phone or email. The following are the default account recovery methods used when either phone or email are used as login options.\n\nLogin option\tUser account verification channel\nphone\tPhone Number\nemail\tEmail\nemail and phone\tEmail\nReset Password\n\nTo reset a user's password, use the resetPassword API which will send a reset code to the destination (e.g. email or SMS) based on the user's settings.\n\nCopy\ncode example\nimport { resetPassword } from 'aws-amplify/auth';\n\n\nconst output = await resetPassword({\n  username: \"hello@mycompany.com\"\n});\n\n\nconst { nextStep } = output;\nswitch (nextStep.resetPasswordStep) {\n  case 'CONFIRM_RESET_PASSWORD_WITH_CODE':\n    const codeDeliveryDetails = nextStep.codeDeliveryDetails;\n    console.log(\n      `Confirmation code was sent to ${codeDeliveryDetails.deliveryMedium}`\n    );\n    // Collect the confirmation code from the user and pass to confirmResetPassword.\n    break;\n  case 'DONE':\n    console.log('Successfully reset password.');\n    break;\n}\n\nTo complete the password reset process, invoke the confirmResetPassword API with the code your user received and the new password they want to set.\n\nCopy\ncode example\nimport { confirmResetPassword } from 'aws-amplify/auth';\n\n\nawait confirmResetPassword({\n  username: \"hello@mycompany.com\",\n  confirmationCode: \"123456\",\n  newPassword: \"hunter3\",\n});\nUpdate password\n\nYou can update a signed in user's password using the updatePassword API.\n\nCopy\ncode example\nimport { updatePassword } from 'aws-amplify/auth';\n\n\nawait updatePassword({\n  oldPassword: \"hunter2\",\n  newPassword: \"hunter3\",\n});\nOverride default user account verification channel\n\nYou can always change the channel used by your authentication resources by overriding the following setting.\n\namplify/auth/resource.ts\nimport { defineAuth } from '@aws-amplify/backend';\n\n\nexport const auth = defineAuth({\n  loginWith: {\n    email: true\n  },\nCopy\nhighlighted code example\n  accountRecovery: 'EMAIL_ONLY'\n});\nOverride default password policy\n\nYou can customize the password format acceptable by your auth backend. By default your password policy is set to the following:\n\nMinLength: 8 characters\nrequireLowercase: true\nrequireUppercase: true\nrequireDigits: true\ntempPasswordValidity: 3 days\namplify/backend.ts\nCopy\namplify/backend.ts code example\n// amplify/backend.ts\nimport { defineBackend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource';\nimport { data } from './data/resource';\n\n\nconst backend = defineBackend({\n  auth,\n  data\n});\n\n\n// extract L1 UserPool construct\nconst { cfnUserPool } = backend.auth.resources.cfnResources;\n// from the CDK use `addPropertyOverride` to modify properties directly\ncfnUserPool.addPropertyOverride('Policies.PasswordPolicy.MinimumLength', 32);\nPREVIOUS\nWith admin actions\nNEXT\nManage devices"
  },
  {
    "title": "Manage users - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/manage-users/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nManage users\nManage users\nWith admin actions\nLearn how to manage users with Admin Actions\nManage passwords\nLearn how to manage user passwords\nManage devices\nLearn how to manage user devices\nManage users with Amplify console\nManage applications Cognito users and groups with Amplify console"
  },
  {
    "title": "Delete user account - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/connect-your-frontend/delete-user-account/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nConnect your frontend\n/\nDelete user account\nDelete user account\n\nEmpowering users to delete their account can improve trust and transparency. You can programmatically enable self-service account deletion with Amplify Auth.\n\nIf you have not yet created an Amplify Gen 2 app, visit the quickstart.\n\nAllow users to delete their account\n\nYou can quickly set up account deletion for your users with the Amplify Libraries. Invoking the deleteUser API to delete a user from the Auth category will also sign out your user.\n\nIf your application uses a Cognito User Pool, which is the default configuration, this action will only delete the user from the Cognito User Pool. It will have no effect if you are federating with a Cognito Identity Pool alone.\n\nBefore invoking the deleteUser API, you may need to first delete associated user data that is not stored in Cognito. For example, if you are using Amplify Data to persist user data, you could follow these instructions to delete associated user data. This allows you to address any guidelines (such as GDPR) that require your app to delete data associated with a user who deletes their account.\n\nYou can enable account deletion using the following method:\n\nCopy\ncode example\nimport { deleteUser } from 'aws-amplify/auth';\n\n\nasync function handleDeleteUser() {\n  try {\n    await deleteUser();\n  } catch (error) {\n    console.log(error);\n  }\n}\n\nWe recommend you update your UI to let your users know that their account is deleted and test the functionality with a test user. Note that your user will be signed out of your application when they delete their account.\n\nPREVIOUS\nListen to auth events"
  },
  {
    "title": "Listen to auth events - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/connect-your-frontend/listen-to-auth-events/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nConnect your frontend\n/\nListen to auth events\nListen to auth events\n\nAmplify Auth emits events during authentication flows, which enables you to react to user flows in real time and trigger custom business logic. For example, you may want to capture data, synchronize your app's state, and personalize the user's experience. You can listen to and respond to events across the Auth lifecycle such as sign-in and sign-out.\n\nExpose hub events triggered in response to auth actions\n\nYou can use Amplify Hub with its built in Amplify Auth events to subscribe a listener using a publish-subscribe pattern and capture events between different parts of your application. The Amplify Auth category publishes in the auth channel when auth events such as signedIn or signedOut happen independent from your app code.\n\nYou can review the Amplify Hub guide to learn more.\n\nChannels are logical group names that help you organize dispatching and listening. However, some channels are protected and cannot be used to publish custom events, and auth is one of these channels. Sending unexpected payloads to protected channels can have undesirable side effects such as impacting authentication flows. See the Amplify Hub guide for more protected channels.\n\nHere is a basic example of setting up a listener that logs an event emitted through the auth channel:\n\nCopy\ncode example\nimport { Hub } from 'aws-amplify/utils';\n\n\nHub.listen('auth', (data) => {\n  console.log(data)\n});\n\nOnce your app is set up to subscribe and listen to specific event types from the auth channel, the listeners will be notified asynchronously when an event occurs. This pattern allows for a one-to-many relationship where one auth event can be shared with many different listeners that have been subscribed. This lets your app react based on the event rather than proactively poll for information.\n\nAdditionally, you can set up your listener to extract data from the event payload and execute a callback that you define. For example, you might update UI elements in your app to reflect your user's authenticated state after the signedIn or signedOut events.\n\nListen to and log auth events\n\nOne of the most common workflows will be to log events. In this example you can see how you can listen and target specific auth events using a switch to log your own messages.\n\nCopy\ncode example\nimport { Hub } from 'aws-amplify/utils';\n\n\nHub.listen('auth', ({ payload }) => {\n  switch (payload.event) {\n    case 'signedIn':\n      console.log('user have been signedIn successfully.');\n      break;\n    case 'signedOut':\n      console.log('user have been signedOut successfully.');\n      break;\n    case 'tokenRefresh':\n      console.log('auth tokens have been refreshed.');\n      break;\n    case 'tokenRefresh_failure':\n      console.log('failure while refreshing auth tokens.');\n      break;\n    case 'signInWithRedirect':\n      console.log('signInWithRedirect API has successfully been resolved.');\n      break;\n    case 'signInWithRedirect_failure':\n      console.log('failure while trying to resolve signInWithRedirect API.');\n      break;\n    case 'customOAuthState':\n      logger.info('custom state returned from CognitoHosted UI');\n      break;\n  }\n});\nStop listening to events\n\nYou can also stop listening for messages by calling the result of the Hub.listen() function. This may be useful if you no longer need to receive messages in your application flow. This can also help you avoid any memory leaks on low powered devices when you are sending large amounts of data through Amplify Hub on multiple channels.\n\nTo stop listening to a certain event, you need to wrap the listener function with a variable and call it once you no longer need it:\n\nCopy\ncode example\n/* start listening for messages */\nconst hubListenerCancelToken = Hub.listen('auth', (data) => {\n  console.log('Listening for all auth events: ', data.payload.data);\n});\n\n\n/* later */\nhubListenerCancelToken(); // stop listening for messages\n\nYou now have a few use cases and examples for listening to and responding to auth events.\n\nPREVIOUS\nManage user attributes\nNEXT\nDelete user account"
  },
  {
    "title": "Manage user attributes - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/connect-your-frontend/manage-user-attributes/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nConnect your frontend\n/\nManage user attributes\nManage user attributes\n\nUser attributes such as email address, phone number help you identify individual users. Defining the user attributes you include for your user profiles makes user data easy to manage at scale. This information will help you personalize user journeys, tailor content, provide intuitive account control, and more. You can capture information upfront during sign-up or enable customers to update their profile after sign-up. In this section we take a closer look at working with user attributes, how to set them up and manage them.\n\nPass user attributes during sign-up\n\nYou can create user attributes during sign-up or when the user is authenticated. To do this as part of sign-up you can pass them in the userAttributes object of the signUp API:\n\nCopy\ncode example\nimport { signUp } from \"aws-amplify/auth\";\n\n\nawait signUp({\n  username: \"jdoe\",\n  password: \"mysecurerandompassword#123\",\n  options: {\n    userAttributes: {\n      email: \"me@domain.com\",\n      phone_number: \"+12128601234\", // E.164 number convention\n      given_name: \"Jane\",\n      family_name: \"Doe\",\n      nickname: \"Jane\",\n    },\n  },\n});\nConfigure custom user attributes during sign-up\n\nCustom attributes can be passed in with the userAttributes option of the signUp API:\n\nCopy\ncode example\nimport { signUp } from \"aws-amplify/auth\";\n\n\nawait signUp({\n  username: 'john.doe@example.com',\n  password: 'hunter2',\n  options: {\n    userAttributes: {\n      'custom:display_name': 'john_doe123',\n    }\n  }\n});\nRetrieve user attributes\n\nYou can retrieve user attributes for your users to read in their profile using the fetchUserAttributes API. This helps you personalize their frontend experience as well as control what they will see.\n\nCopy\ncode example\nimport { fetchUserAttributes } from 'aws-amplify/auth';\n\n\nawait fetchUserAttributes();\nUpdate user attribute\n\nYou can use the updateUserAttribute API to create or update existing user attributes.\n\nTypeScript\nJavaScript\nCopy\ncode example\nimport {\n  updateUserAttribute,\n  type UpdateUserAttributeOutput\n} from 'aws-amplify/auth';\n\n\nasync function handleUpdateUserAttribute(attributeKey: string, value: string) {\n  try {\n    const output = await updateUserAttribute({\n      userAttribute: {\n        attributeKey,\n        value\n      }\n    });\n    handleUpdateUserAttributeNextSteps(output);\n  } catch (error) {\n    console.log(error);\n  }\n}\n\n\nfunction handleUpdateUserAttributeNextSteps(output: UpdateUserAttributeOutput) {\n  const { nextStep } = output;\n\n\n  switch (nextStep.updateAttributeStep) {\n    case 'CONFIRM_ATTRIBUTE_WITH_CODE':\n      const codeDeliveryDetails = nextStep.codeDeliveryDetails;\n      console.log(\n        `Confirmation code was sent to ${codeDeliveryDetails?.deliveryMedium}.`\n      );\n      // Collect the confirmation code from the user and pass to confirmUserAttribute.\n      break;\n    case 'DONE':\n      console.log(`attribute was successfully updated.`);\n      break;\n  }\n}\n\nNote: If you change an attribute that requires confirmation (i.e. email or phone_number), the user will receive a confirmation code either to their email or cellphone. This code can be used with the confirmUserAttribute API to confirm the change.\n\nUpdate user attributes\n\nYou can use the updateUserAttributes API to create or update multiple existing user attributes.\n\nCopy\ncode example\nimport { updateUserAttributes, type UpdateUserAttributesOutput } from \"aws-amplify/auth\";\n\n\nawait updateUserAttributes({\n  userAttributes: {\n    email: \"me@domain.com\",\n    name: \"Jon Doe\",\n  },\n});\nVerify user attribute\n\nSome attributes require confirmation for the attribute update to complete. If the attribute needs to be confirmed, part of the result of the updateUserAttribute or updateUserAttributes APIs will be CONFIRM_ATTRIBUTE_WITH_CODE. A confirmation code will be sent to the delivery medium mentioned in the delivery details. When the user gets the confirmation code, you can present a UI to the user to enter the code and invoke the confirmUserAttribute API with their input:\n\nCopy\ncode example\nimport {\n  confirmUserAttribute,\n  type ConfirmUserAttributeInput\n} from 'aws-amplify/auth';\n\n\nasync function handleConfirmUserAttribute({\n  userAttributeKey,\n  confirmationCode\n}: ConfirmUserAttributeInput) {\n  try {\n    await confirmUserAttribute({ userAttributeKey, confirmationCode });\n  } catch (error) {\n    console.log(error);\n  }\n}\nSend user attribute verification code\n\nIf an attribute needs to be verified while the user is authenticated, invoke the sendUserAttributeVerificationCode API as shown below:\n\nCopy\ncode example\nimport {\n  sendUserAttributeVerificationCode,\n  type VerifiableUserAttributeKey\n} from 'aws-amplify/auth';\n\n\nasync function handleSendUserAttributeVerificationCode(\n  key: VerifiableUserAttributeKey\n) {\n  try {\n    await sendUserAttributeVerificationCode({\n      userAttributeKey: key\n    });\n  } catch (error) {\n    console.log(error);\n  }\n}\nDelete user attributes\n\nThe deleteUserAttributes API allows to delete one or more user attributes.\n\nCopy\ncode example\nimport {\n  deleteUserAttributes,\n  type DeleteUserAttributesInput\n} from 'aws-amplify/auth';\n\n\nasync function handleDeleteUserAttributes(\n  keys: DeleteUserAttributesInput['userAttributeKeys']\n) {\n  try {\n    await deleteUserAttributes({\n      userAttributeKeys: ['custom:my_custom_attribute', ...keys]\n    });\n  } catch (error) {\n    console.log(error);\n  }\n}\nNext Steps\nLearn how to set up password change and recovery\nLearn how to set up custom attributes\nPREVIOUS\nManage user sessions\nNEXT\nListen to auth events"
  },
  {
    "title": "Manage user sessions - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/connect-your-frontend/manage-user-sessions/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nConnect your frontend\n/\nManage user sessions\nManage user sessions\n\nAmplify Auth provides access to current user sessions and tokens to help you retrieve your user's information to determine if they are signed in with a valid session and control their access to your app.\n\nRetrieve your current authenticated user\n\nYou can use the getCurrentUser API to get information about the currently authenticated user including the username, userId and signInDetails.\n\nCopy\ncode example\nimport { getCurrentUser } from 'aws-amplify/auth';\n\n\nconst { username, userId, signInDetails } = await getCurrentUser();\n\n\nconsole.log(\"username\", username);\nconsole.log(\"user id\", userId);\nconsole.log(\"sign-in details\", signInDetails);\n\nThis method can be used to check if a user is signed in. It throws an error if the user is not authenticated.\n\nThe user's signInDetails are not supported when using the Hosted UI or the signInWithRedirect API.\n\nRetrieve a user session\n\nYour user's session is their signed-in state, which grants them access to your app. When your users sign in, their credentials are exchanged for temporary access tokens. You can get session details to access these tokens and use this information to validate user access or perform actions unique to that user.\n\nIf you only need the session details, you can use the fetchAuthSession API which returns a tokens object containing the JSON Web Tokens (JWT).\n\nCopy\ncode example\nimport { fetchAuthSession } from 'aws-amplify/auth';\n\n\nconst session = await fetchAuthSession();\n\n\nconsole.log(\"id token\", session.tokens.idToken)\nconsole.log(\"access token\", session.tokens.accessToken)\nRefreshing sessions\n\nThe fetchAuthSession API automatically refreshes the user's session when the authentication tokens have expired and a valid refreshToken is present. Additionally, you can also refresh the session explicitly by calling the fetchAuthSession API with the forceRefresh flag enabled.\n\nCopy\ncode example\nimport { fetchAuthSession } from 'aws-amplify/auth';\n\n\nawait fetchAuthSession({ forceRefresh: true });\n\nWarning: by default, sessions from external identity providers cannot be refreshed.\n\nPREVIOUS\nSign-out\nNEXT\nManage user attributes"
  },
  {
    "title": "Sign-out - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/connect-your-frontend/sign-out/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nConnect your frontend\n/\nSign-out\nSign-out\n\nAmplify provides a client library that enables you to interact with backend resources such as Amplify Auth.\n\nTo sign a user out of your application use the signOut API.\n\nCopy\ncode example\nimport { signOut } from 'aws-amplify/auth';\n\n\nawait signOut();\n\nYou can also sign out users from all devices by performing a global sign-out. This will also invalidate all refresh tokens issued to a user. The user's current access and ID tokens will remain valid on other devices until the refresh token expires (access and ID tokens expire one hour after they are issued).\n\nCopy\ncode example\nimport { signOut } from 'aws-amplify/auth';\n\n\nawait signOut({ global: true });\nPractical Example\nsrc/App.tsx\nimport { Amplify } from \"aws-amplify\"\nCopy\nhighlighted code example\nimport { signOut } from \"aws-amplify/auth\"\nimport outputs from \"../amplify_outputs.json\"\n\n\nAmplify.configure(outputs)\n\n\nexport default function App() {\n  async function handleSignOut() {\nCopy\nhighlighted code example\n    await signOut()\n  }\n\n\n  return (\n    <button type=\"button\" onClick={handleSignOut}>\n      Sign out\n    </button>\n  )\n}\nPREVIOUS\nSwitching authentication flows\nNEXT\nManage user sessions"
  },
  {
    "title": "Sign-in - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/connect-your-frontend/sign-in/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nConnect your frontend\n/\nSign-in\nSign-in\n\nAmplify provides a client library that enables you to interact with backend resources such as Amplify Auth.\n\nUsing the signIn API\nCopy\ncode example\nimport { signIn } from 'aws-amplify/auth'\n\n\nawait signIn({\n  username: \"hello@mycompany.com\",\n  password: \"hunter2\",\n})\n\nThe signIn API response will include a nextStep property, which can be used to determine if further action is required. It may return the following next steps:\n\nCONFIRM_SIGN_IN_WITH_NEW_PASSWORD_REQUIRED - The user was created with a temporary password and must set a new one. Complete the process with confirmSignIn.\nCONFIRM_SIGN_IN_WITH_CUSTOM_CHALLENGE - The sign-in must be confirmed with a custom challenge response. Complete the process with confirmSignIn.\nCONFIRM_SIGN_IN_WITH_TOTP_CODE - The sign-in must be confirmed with a TOTP code from the user. Complete the process with confirmSignIn.\nCONTINUE_SIGN_IN_WITH_TOTP_SETUP - The TOTP setup process must be continued. Complete the process with confirmSignIn.\nCONFIRM_SIGN_IN_WITH_SMS_CODE - The sign-in must be confirmed with a SMS code from the user. Complete the process with confirmSignIn.\nCONTINUE_SIGN_IN_WITH_MFA_SELECTION - The user must select their mode of MFA verification before signing in. Complete the process with confirmSignIn.\nRESET_PASSWORD - The user must reset their password via resetPassword.\nCONFIRM_SIGN_UP - The user hasn't completed the sign-up flow fully and must be confirmed via confirmSignUp.\nDONE - The sign in process has been completed.\n\nFor more information on handling the TOTP and MFA steps that may be returned, see multi-factor authentication.\n\nConfirm sign-in\nPractical Example\nsrc/App.tsx\nimport type { FormEvent } from \"react\"\nimport { Amplify } from \"aws-amplify\"\nCopy\nhighlighted code example\nimport { signIn } from \"aws-amplify/auth\"\nimport outputs from \"../amplify_outputs.json\"\n\n\nAmplify.configure(outputs)\n\n\ninterface SignInFormElements extends HTMLFormControlsCollection {\n  email: HTMLInputElement\n  password: HTMLInputElement\n}\n\n\ninterface SignInForm extends HTMLFormElement {\n  readonly elements: SignInFormElements\n}\n\n\nexport default function App() {\n  async function handleSubmit(event: FormEvent<SignInForm>) {\n    event.preventDefault()\n    const form = event.currentTarget\n    // ... validate inputs\n    await signIn({\n      username: form.elements.email.value,\n      password: form.elements.password.value,\n    })\n  }\n\n\n  return (\n    <form onSubmit={handleSubmit}>\n      <label htmlFor=\"email\">Email:</label>\n      <input type=\"text\" id=\"email\" name=\"email\" />\n      <label htmlFor=\"password\">Password:</label>\n      <input type=\"password\" id=\"password\" name=\"password\" />\n      <input type=\"submit\" />\n    </form>\n  )\n}\nWith multi-factor auth enabled\n\nWhen multi-factor authentication (MFA) is required with SMS in your backend auth resource, you will need to pass the phone number during sign-up API call. If you are using the email or username as the primary sign-in mechanism, you will need to pass the phone_number attribute as a user attribute. This will change depending on if you enable SMS, TOTP, or both. Visit the multi-factor authentication documentation to learn more about enabling MFA on your backend auth resource.\n\nYou will then confirm sign-up, sign in, and receive a nextStep in the sign-in result of type CONFIRM_SIGN_IN_WITH_SMS_MFA_CODE. A confirmation code will also be texted to the phone number provided above. Pass the code you received to the confirmSignIn API:\n\nSign in with an external identity provider\n\nTo sign in using an external identity provider such as Google, use the signInWithRedirect function.\n\nCopy\ncode example\nimport { signInWithRedirect } from \"aws-amplify/auth\"\n\n\nsignInWithRedirect({ provider: \"Google\" })\n\nNote: if you do not pass an argument to signInWithRedirect it will redirect your users to the Cognito Hosted UI, which has limited support for customization.\n\nAlternatively if you have configured OIDC or SAML-based identity providers in your auth resource, you can specify a \"custom\" provider in signInWithRedirect:\n\nCopy\ncode example\nimport { signInWithRedirect } from \"aws-amplify/auth\"\n\n\nsignInWithRedirect({ provider: {\n  custom: \"MyOidcProvider\"\n}})\nAuto sign-in\n\nThe autoSignIn API will automatically sign-in a user when it was previously enabled by the signUp API and after any of the following cases has completed:\n\nUser confirmed their account with a verification code sent to their phone or email (default option).\nUser confirmed their account with a verification link sent to their phone or email. In order to enable this option you need to go to the Amazon Cognito console, look for your userpool, then go to the Messaging tab and enable link mode inside the Verification message option. Finally you need to define the signUpVerificationMethod to link inside the Cognito option of your Auth config.\nsrc/main.ts\nCopy\nsrc/main.ts code example\nimport { autoSignIn } from 'aws-amplify/auth';\n\n\nawait autoSignIn();\nPREVIOUS\nSign-up\nNEXT\nSwitching authentication flows"
  },
  {
    "title": "Switching authentication flows - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/connect-your-frontend/switching-authentication-flows/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nConnect your frontend\n/\nSwitching authentication flows\nSwitching authentication flows\n\nFor client side authentication there are three different flows:\n\nUSER_SRP_AUTH: The USER_SRP_AUTH flow uses the SRP protocol (Secure Remote Password) where the password never leaves the client and is unknown to the server. This is the recommended flow and is used by default.\n\nUSER_PASSWORD_AUTH: The USER_PASSWORD_AUTH flow will send user credentials to the backend without applying SRP encryption. If you want to migrate users to Cognito using the \"Migration\" trigger and avoid forcing users to reset their passwords, you will need to use this authentication type because the Lambda function invoked by the trigger needs to verify the supplied credentials.\n\nCUSTOM_WITH_SRP & CUSTOM_WITHOUT_SRP: Allows for a series of challenge and response cycles that can be customized to meet different requirements.\n\nThe Auth flow can be customized when calling signIn, for example:\n\nsrc/main.ts\nCopy\nsrc/main.ts code example\nawait signIn({\n\tusername: \"hello@mycompany.com\",\n  password: \"hunter2\",\n  options: {\n      authFlowType: 'USER_PASSWORD_AUTH'\n  }\n})\n\nFor more information about authentication flows, please visit AWS Cognito developer documentation\n\nUSER_PASSWORD_AUTH flow\n\nA use case for the USER_PASSWORD_AUTH authentication flow is migrating users into Amazon Cognito\n\nSet up auth backend\n\nIn order to use the authentication flow USER_PASSWORD_AUTH, your Cognito app client has to be configured to allow it. In the AWS Console, this is done by ticking the checkbox at General settings > App clients > Show Details (for the affected client) > Enable username-password (non-SRP) flow. If you're using the AWS CLI or CloudFormation, update your app client by adding USER_PASSWORD_AUTH to the list of \"Explicit Auth Flows\".\n\nMigrate users with Amazon Cognito\n\nAmazon Cognito provides a trigger to migrate users from your existing user directory seamlessly into Cognito. You achieve this by configuring your User Pool's \"Migration\" trigger which invokes a Lambda function whenever a user that does not already exist in the user pool authenticates, or resets their password.\n\nIn short, the Lambda function will validate the user credentials against your existing user directory and return a response object containing the user attributes and status on success. An error message will be returned if an error occurs. Visit Amazon Cognito user pools import guide for migration flow and more detailed instruction, and Amazon Cognito Lambda trigger guide on how to set up lambda to handle request and response objects.\n\nCUSTOM_WITH_SRP & CUSTOM_WITHOUT_SRP flows\n\nAmazon Cognito user pools supports customizing the authentication flow to enable custom challenge types, in addition to a password in order to verify the identity of users. These challenge types may include CAPTCHAs or dynamic challenge questions. The CUSTOM_WITH_SRP flow requires a password when calling signIn. Both of these flows map to the CUSTOM_AUTH flow in Cognito.\n\nTo define your challenges for custom authentication flow, you need to implement three Lambda triggers for Amazon Cognito.\n\nFor more information about working with Lambda Triggers for custom authentication challenges, please visit Amazon Cognito Developer Documentation.\n\nCustom authentication flow\n\nTo initiate a custom authentication flow in your app, call signIn without a password. A custom challenge needs to be answered using the confirmSignIn API:\n\nsrc/main.ts\nCopy\nsrc/main.ts code example\nimport { signIn, confirmSignIn } from 'aws-amplify/auth';\n\n\nconst challengeResponse = 'the answer for the challenge';\n\n\nconst { nextStep } = await signIn({\n  username,\n  options: {\n    authFlowType: 'CUSTOM_WITHOUT_SRP',\n  },\n});\n\n\nif (nextStep.signInStep === 'CONFIRM_SIGN_IN_WITH_CUSTOM_CHALLENGE') {\n  // to send the answer of the custom challenge\n  await confirmSignIn({ challengeResponse });\n}\nCAPTCHA authentication\n\nTo create a CAPTCHA challenge with a Lambda Trigger, please visit AWS Amplify Google reCAPTCHA challenge example for detailed examples.\n\nFor more information about working with Lambda Triggers for custom authentication challenges, please visit Amazon Cognito Developer Documentation.\n\nPREVIOUS\nSign-in\nNEXT\nSign-out"
  },
  {
    "title": "Sign-up - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/connect-your-frontend/sign-up/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nConnect your frontend\n/\nSign-up\nSign-up\n\nAmplify provides a client library that enables you to interact with backend resources such as Amplify Auth.\n\nTo get started, you can use the signUp() API to create a new user in your backend:\n\nCopy\ncode example\nimport { signUp } from \"aws-amplify/auth\"\n\n\nconst { isSignUpComplete, userId, nextStep } = await signUp({\n  username: \"hello@mycompany.com\",\n  password: \"hunter2\",\n  options: {\n    userAttributes: {\n      email: \"hello@mycompany.com\",\n      phone_number: \"+15555555555\" // E.164 number convention\n    },\n  }\n});\n\nThe signUp API response will include a nextStep property, which can be used to determine if further action is required. It may return the following next steps:\n\nCONFIRM_SIGN_UP - The sign up needs to be confirmed by collecting a code from the user and calling confirmSignUp.\nDONE - The sign up process has been fully completed.\nCOMPLETE_AUTO_SIGN_IN - The sign up process needs to complete by invoking the autoSignIn API.\nConfirm sign-up\n\nBy default, each user that signs up remains in the unconfirmed status until they verify with a confirmation code that was sent to their email or phone number. The following are the default verification methods used when either phone or email are used as loginWith options.\n\nLogin option\tUser account verification channel\nphone\tPhone Number\nemail\tEmail\nemail and phone\tEmail\n\nYou can confirm the sign-up after receiving a confirmation code from the user:\n\nCopy\ncode example\nimport { confirmSignUp } from 'aws-amplify/auth';\n\n\nconst { isSignUpComplete, nextStep } = await confirmSignUp({\n  username: \"hello@mycompany.com\",\n  confirmationCode: \"123456\"\n});\n\nNote: When specifying email or phone as a way for your users to sign-in, these are attributes that are used in place of the username. Visit the concepts page to learn more about usernames.\n\nPractical Example\nsrc/App.tsx\nimport type { FormEvent } from \"react\"\nimport { Amplify } from \"aws-amplify\"\nCopy\nhighlighted code example\nimport { signUp } from \"aws-amplify/auth\"\nimport outputs from \"../amplify_outputs.json\"\n\n\nAmplify.configure(outputs)\n\n\ninterface SignUpFormElements extends HTMLFormControlsCollection {\n  email: HTMLInputElement\n  password: HTMLInputElement\n}\n\n\ninterface SignUpForm extends HTMLFormElement {\n  readonly elements: SignUpFormElements\n}\n\n\nexport default function App() {\n  async function handleSubmit(event: FormEvent<SignUpForm>) {\n    event.preventDefault()\n    const form = event.currentTarget\n    // ... validate inputs\n    await signUp({\n      username: form.elements.email.value,\n      password: form.elements.password.value,\n    })\n  }\n\n\n  return (\n    <form onSubmit={handleSubmit}>\n      <label htmlFor=\"email\">Email:</label>\n      <input type=\"text\" id=\"email\" name=\"email\" />\n      <label htmlFor=\"password\">Password:</label>\n      <input type=\"password\" id=\"password\" name=\"password\" />\n      <input type=\"submit\" />\n    </form>\n  )\n}\nPREVIOUS\nUsing the Authenticator\nNEXT\nSign-in"
  },
  {
    "title": "Using the Authenticator - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/connect-your-frontend/using-the-authenticator/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nConnect your frontend\n/\nUsing the Authenticator\nUsing the Authenticator\n\nThe quickest way to get started with Amplify Auth in your frontend application is with the Authenticator component, which provides a customizable UI and complete authentication flows.\n\nsrc/App.tsx\nCopy\nsrc/App.tsx code example\nimport { Authenticator } from '@aws-amplify/ui-react';\nimport { Amplify } from 'aws-amplify';\nimport '@aws-amplify/ui-react/styles.css';\nimport outputs from \"../amplify_outputs.json\";\n\n\nAmplify.configure(outputs);\n\n\nexport default function App() {\n  return (\n    <Authenticator>\n      {({ signOut, user }) => (\n        <main>\n          <h1>Hello {user?.username}</h1>\n          <button onClick={signOut}>Sign out</button>\n        </main>\n      )}\n    </Authenticator>\n  );\n}\n\nThe Authenticator component is automatically configured based on the outputs generated from your backend. To learn more about the Authenticator and how to customize its appearance, visit the Amplify UI documentation.\n\nConversely, you can bring your own UI and leverage the library from aws-amplify to handle authentication flows manually.\n\nNEXT\nSign-up"
  },
  {
    "title": "Tokens and credentials - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/concepts/tokens-and-credentials/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nConcepts\n/\nTokens and credentials\nTokens and credentials\n\nAmplify Auth interacts with its underlying Amazon Cognito user pool as an OpenID Connect (OIDC) provider. When users successfully authenticate you receive OIDC-compliant JSON web tokens (JWT). These tokens are used to identity your user, and access resources.\n\nAccess tokens are used to verify the bearer of the token (i.e. the Cognito user) is authorized to perform an action against a resource. Below is an example payload of an access token vended by Cognito:\n\nCopy\ncode example\n{\n  \"sub\": \"54288468-e051-706d-a73f-03892273d7e9\",\n  \"iss\": \"https://cognito-idp.us-east-1.amazonaws.com/us-east-1_yoKn9s4Tq\",\n  \"client_id\": \"1sg675g08g6g0e9f64grv9n5sk\",\n  \"origin_jti\": \"0eadb994-a6e0-419e-b309-a7a0d522d72f\",\n  \"event_id\": \"b180897a-181c-4f73-94bb-a2946e8b4ef1\",\n  \"token_use\": \"access\",\n  \"scope\": \"aws.cognito.signin.user.admin\",\n  \"auth_time\": 1714241873,\n  \"exp\": 1714245473,\n  \"iat\": 1714241873,\n  \"jti\": \"57f10a4d-a1f2-453b-8672-d1cfa8187047\",\n  \"username\": \"54288468-e051-706d-a73f-03892273d7e9\"\n}\n\nID tokens are intended to be used within your frontend application only. This token contains personally identifiable information (PII) and should not be used to authorize access against a resource. Below is an example of an ID token with the default Amplify Auth configuration of email and password auth.\n\nCopy\ncode example\n{\n  \"sub\": \"54288468-e051-706d-a73f-03892273d7e9\",\n  \"email_verified\": true,\n  \"iss\": \"https://cognito-idp.us-east-1.amazonaws.com/us-east-1_yoKn9s4Tq\",\n  \"cognito:username\": \"54288468-e051-706d-a73f-03892273d7e9\",\n  \"origin_jti\": \"0eadb994-a6e0-419e-b309-a7a0d522d72f\",\n  \"aud\": \"1sg675g08g6g0e9f64grv9n5sk\",\n  \"event_id\": \"b180897a-181c-4f73-94bb-a2946e8b4ef1\",\n  \"token_use\": \"id\",\n  \"auth_time\": 1714241873,\n  \"exp\": 1714245473,\n  \"iat\": 1714241873,\n  \"jti\": \"bb69af10-3ce0-47c2-8d8d-5bdc8630ab58\",\n  \"email\": \"hello@mycompany.com\"\n}\n\nWhen additional user attributes are specified for Amplify Auth, their values will be found in the ID token. For example, if a nickname attribute is requested it will be available on the ID token with the nickname claim:\n\nCopy\ncode example\n{\n  \"sub\": \"54288468-e051-706d-a73f-03892273d7e9\",\n  \"email_verified\": true,\n  \"iss\": \"https://cognito-idp.us-east-1.amazonaws.com/us-east-1_yoKn9s4Tq\",\n  \"cognito:username\": \"54288468-e051-706d-a73f-03892273d7e9\",\n  \"origin_jti\": \"0eadb994-a6e0-419e-b309-a7a0d522d72f\",\n  \"aud\": \"1sg675g08g6g0e9f64grv9n5sk\",\n  \"event_id\": \"b180897a-181c-4f73-94bb-a2946e8b4ef1\",\n  \"token_use\": \"id\",\n  \"auth_time\": 1714241873,\n+ \"nickname\": \"hello\",\n  \"exp\": 1714245473,\n  \"iat\": 1714241873,\n  \"jti\": \"bb69af10-3ce0-47c2-8d8d-5bdc8630ab58\",\n  \"email\": \"hello@mycompany.com\"\n}\n\nConversely, user pool group claims are found in both the access token and ID token on the cognito:groups claim:\n\nCopy\ncode example\n{\n  \"sub\": \"54288468-e051-706d-a73f-03892273d7e9\",\n  \"email_verified\": true,\n  \"iss\": \"https://cognito-idp.us-east-1.amazonaws.com/us-east-1_yoKn9s4Tq\",\n  \"cognito:username\": \"54288468-e051-706d-a73f-03892273d7e9\",\n  \"cognito:groups\": [\"ADMINS\"],\n  \"origin_jti\": \"0eadb994-a6e0-419e-b309-a7a0d522d72f\",\n  \"aud\": \"1sg675g08g6g0e9f64grv9n5sk\",\n  \"event_id\": \"b180897a-181c-4f73-94bb-a2946e8b4ef1\",\n  \"token_use\": \"id\",\n  \"auth_time\": 1714241873,\n  \"nickname\": \"hello\",\n  \"exp\": 1714245473,\n  \"iat\": 1714241873,\n  \"jti\": \"bb69af10-3ce0-47c2-8d8d-5bdc8630ab58\",\n  \"email\": \"hello@mycompany.com\"\n}\n\nVisit the AWS documentation for using tokens with Cognito user pools to learn more about tokens, how they're used with Cognito, and their intended usage.\n\nUnderstand token management options\n\nToken keys are automatically rotated for you for added security but you can update how they are stored, customize the refresh rate and expiration times, and revoke tokens on sign-out.\n\nUpdate your token-saving mechanism\n\nYou can update the storage mechanism to choose where and how tokens are persisted in your application. The default option is localStorage. Additionally, you can import the sessionStorage, sharedInMemoryStorage or CookieStorage options as well.\n\nIf you want to customize your own mechanism, you can import the KeyValueStorageInterface interface and implement it in your own class.\n\nBrowser Local Storage\n\nIn Amplify the localStorage is the default storage mechanism. It saves the tokens in the browser's localStorage. This local storage will persist across browser sessions and tabs. You can explicitly set to this storage by calling:\n\nCopy\ncode example\nimport { cognitoUserPoolsTokenProvider } from 'aws-amplify/auth/cognito';\nimport { defaultStorage } from 'aws-amplify/utils';\n\n\ncognitoUserPoolsTokenProvider.setKeyValueStorage(defaultStorage);\nCookie Storage\n\nCookieStorage saves the tokens in the browser's Cookies. The cookies will persist across browser sessions and tabs. You can explicitly set to this storage by calling:\n\nCopy\ncode example\nimport { cognitoUserPoolsTokenProvider } from 'aws-amplify/auth/cognito';\nimport { CookieStorage } from 'aws-amplify/utils';\n\n\ncognitoUserPoolsTokenProvider.setKeyValueStorage(new CookieStorage());\nBrowser Session Storage\n\nsessionStorage saves the tokens in the browser's sessionStorage and these tokens will clear when a tab is closed. The benefit to this storage mechanism is that the session only lasts as long as the browser is open and you can sign out users when they close the tab. You can update to this storage by calling:\n\nCopy\ncode example\nimport { cognitoUserPoolsTokenProvider } from 'aws-amplify/auth/cognito';\nimport { sessionStorage } from 'aws-amplify/utils';\n\n\ncognitoUserPoolsTokenProvider.setKeyValueStorage(sessionStorage);\nCustom Storage\n\nYou can implement your own custom storage mechanism by creating a class that implements the storage interface. Here is an example that uses memory storage:\n\nCopy\ncode example\nimport { cognitoUserPoolsTokenProvider } from 'aws-amplify/auth/cognito';\nimport { KeyValueStorageInterface } from 'aws-amplify/utils';\n\n\nclass MyCustomStorage implements KeyValueStorageInterface {\n  storageObject: Record<string, string> = {};\n  async setItem(key: string, value: string): Promise<void> {\n    this.storageObject[key] = value;\n  }\n  async getItem(key: string): Promise<string | null> {\n    return this.storageObject[key];\n  }\n  async removeItem(key: string): Promise<void> {\n    delete this.storageObject[key];\n  }\n  async clear(): Promise<void> {\n    this.storageObject = {};\n  }\n}\n\n\ncognitoUserPoolsTokenProvider.setKeyValueStorage(new MyCustomStorage());\n\nWhen you get the current user session, the tokens will be saved in your custom location.\n\nToken Revocation\n\nToken revocation is enabled automatically in Amplify Auth. To revoke tokens you can set up global sign-out with signOut({ global: true }) to globally sign out your user from all of their devices.\n\nNext steps\nLearn how to customize the ID token\nLearn how to use cookie storage server-side\nPREVIOUS\nGuest access"
  },
  {
    "title": "Connect your frontend - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/connect-your-frontend/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nConnect your frontend\nConnect your frontend\nUsing the Authenticator\nLearn how to use the Authenticator connected component from the Amplify UI library\nSign-up\nLearn how to sign up\nSign-in\nLearn how to sign in\nSwitching authentication flows\nLearn how to switch between different auth flows\nSign-out\nLearn how to sign out\nManage user sessions\nLearn how to manage user sessions\nManage user attributes\nLearn about managing user attributes in your Amplify app\nListen to auth events\nLearn how to listen to auth events\nDelete user account\nEnable users to delete their account."
  },
  {
    "title": "External identity providers - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/concepts/external-identity-providers/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nConcepts\n/\nExternal identity providers\nExternal identity providers\n\nBefore you configure external sign-in with Amplify Auth you will need to set up your developer account with each provider you are using.\n\nNote: Amazon Cognito provides first class support for Facebook Login, Google Sign-In, Login with Amazon, and Sign in with Apple for seamless setup. However you can configure other Identity Providers that support SAML or OpenID Connect (OIDC).\n\nWarning: When configuring external sign-in it's important to exercise caution when designating attributes as \"required.\" Different external identity providers have varied scopes in terms of the information they respond back to Cognito with. User pool attributes that are initially set up as \"required\" cannot be changed later, and may require you to migrate the users or create a new user pool.\n\nFacebook Login\nGoogle Sign-In\nLogin with Amazon\nSign in with Apple\nCreate a developer account with Facebook.\nSign in with your Facebook credentials.\nChoose My Apps from the top navigation bar, and on the page that loads choose Create App. \nFor your use case, choose Set up Facebook Login. \nFor platform, choose Website and select No, I'm not building a game.\nGive your Facebook app a name and choose Create app. \nOn the left navigation bar, choose Settings and then Basic. \nNote the App ID and the App Secret. You will use them in the next section in the CLI flow.\n\nYour developer accounts with the external providers are now set up and you can return to the Amplify specific configuration.\n\nConfigure external sign-in backend\n\nIn amplify/auth/resource.ts the external providers need to be added.\n\nThe following is an example of how you would set up access to all of the external providers supported by Amplify Auth. Please note you will need to configure your callbackUrls and logoutUrls URLs for your application, which will inform your backend resources how to behave when initiating sign in and sign out operations in your app.\n\nSecrets must be created manually with ampx sandbox secret for use with cloud sandbox, or via the Amplify Console for branch environments.\n\namplify/auth/resource.ts\nCopy\namplify/auth/resource.ts code example\nimport { defineAuth, secret } from '@aws-amplify/backend';\n\n\nexport const auth = defineAuth({\n  loginWith: {\n    externalProviders: {\n      google: {\n        clientId: secret('GOOGLE_CLIENT_ID'),\n        clientSecret: secret('GOOGLE_CLIENT_SECRET')\n      },\n      signInWithApple: {\n        clientId: secret('SIWA_CLIENT_ID'),\n        keyId: secret('SIWA_KEY_ID'),\n        privateKey: secret('SIWA_PRIVATE_KEY'),\n        teamId: secret('SIWA_TEAM_ID')\n      },\n      loginWithAmazon: {\n        clientId: secret('LOGINWITHAMAZON_CLIENT_ID'),\n        clientSecret: secret('LOGINWITHAMAZON_CLIENT_SECRET')\n      },\n      facebook: {\n        clientId: secret('FACEBOOK_CLIENT_ID'),\n        clientSecret: secret('FACEBOOK_CLIENT_SECRET')\n      },\n      callbackUrls: [\n        'http://localhost:3000/profile',\n        'https://mywebsite.com/profile'\n      ],\n      logoutUrls: ['http://localhost:3000/', 'https://mywebsite.com'],\n    }\n  }\n});\n\nYou need to now inform your external provider of the newly configured authentication resource and its OAuth redirect URI:\n\nFacebook Login\nGoogle Sign-In\nLogin with Amazon\nSign in with Apple\n\nSign In to your Facebook developer account with your Facebook credentials.\n\nChoose My Apps from the top navigation bar, and on the Apps page, choose your app you created before.\n\nOn the left navigation bar, choose Products. Add Facebook Login if it isn't already added.\n\nIf already added, choose Settings under the Configure dropdown. \n\nUnder Valid OAuth Redirect URIs type your user pool domain with the /oauth2/idpresponse endpoint.\n\nhttps://<your-user-pool-domain>/oauth2/idpresponse\n\nSave your changes.\nCustomizing scopes for retrieving user data from external providers\n\nYou can determine the pieces of data you want to retrieve from each external provider when setting them up in the amplify/auth/resource.ts file using scopes.\n\namplify/auth/resource.ts\nimport { defineAuth } from '@aws-amplify/backend';\n\n\nexport const auth = defineAuth({\n  loginWith: {\n    externalAuthProviders: {\n      loginWithAmazon: {\n        clientId: secret('LOGINWITHAMAZON_CLIENT_ID'),\n        clientSecret: secret('LOGINWITHAMAZON_CLIENT_SECRET'),\nCopy\nhighlighted code example\n        scopes: ['email']\n      },\n      callbackUrls: [\n        'http://localhost:3000/profile',\n        'https://mywebsite.com/profile'\n      ],\n      logoutUrls: ['http://localhost:3000/', 'https://mywebsite.com'],\n    }\n  }\n});\nAttribute mapping\n\nYou can map which attributes are mapped between your external identity provider and your users created in Cognito. We will be able to have the best level of protection for developers if we ensure that attribute mappings that would not work are called out by the type system.\n\nIf you specify an attribute in your authentication resource as required, and it is not allowed for your external providers, signing in with that external provider will cause an error.\n\namplify/auth/resource.ts\nimport { defineAuth } from '@aws-amplify/backend';\n\n\nexport const auth = defineAuth({\n  loginWith: {\n    externalAuthProviders: {\n      loginWithAmazon: {\n        clientId: secret('LOGINWITHAMAZON_CLIENT_ID'),\n        clientSecret: secret('LOGINWITHAMAZON_CLIENT_SECRET'),\nCopy\nhighlighted code example\n        userAttributeMapping: {\n          email: 'email'\n        }\n      },\n      callbackUrls: [\n        'http://localhost:3000/profile',\n        'https://mywebsite.com/profile'\n      ],\n      logoutUrls: ['http://localhost:3000/', 'https://mywebsite.com'],\n    }\n  }\n});\nLearn more about configuring the React Authenticator component for external providers\nConfigure OIDC provider\n\nTo setup a OIDC provider, you can configure them in your amplify/auth/resource.ts file. For example, if you would like to setup a Microsoft EntraID provider, you can do so as follows:\n\namplify/auth/resource.ts\nCopy\namplify/auth/resource.ts code example\nimport { defineAuth, secret } from '@aws-amplify/backend';\n\n\nexport const auth = defineAuth({\n  loginWith: {\n    email: true,\n    externalProviders: {\n      oidc: [\n        {\n          name: 'MicrosoftEntraID',\n          clientId: secret('MICROSOFT_ENTRA_ID_CLIENT_ID'),\n          clientSecret: secret('MICROSOFT_ENTRA_ID_CLIENT_SECRET'),\n          issuerUrl: '<your-issuer-url>',\n        },\n      ],\n      logoutUrls: ['http://localhost:3000/', 'https://mywebsite.com'],\n      callbackUrls: [\n        'http://localhost:3000/profile',\n        'https://mywebsite.com/profile',\n      ],\n    },\n  },\n});\n\nUse the signInWithRedirect API to initiate sign-in with an OIDC identity provider.\n\nsrc/my-client-side-js.js\nCopy\nsrc/my-client-side-js.js code example\nimport { signInWithRedirect } from 'aws-amplify/auth';\n\n\nawait signInWithRedirect({\n  provider: {\n    custom: 'MicrosoftEntraID'\n  }\n});\nConfigure SAML provider\n\nTo setup a SAML provider, you can configure them in your amplify/auth/resource.ts file. For example, if you would like to setup a Microsoft EntraID provider, you can do so as follows:\n\namplify/auth/resource.ts\nCopy\namplify/auth/resource.ts code example\nimport { defineAuth } from '@aws-amplify/backend';\n\n\nexport const auth = defineAuth({\n  loginWith: {\n    email: true,\n    externalProviders: {\n      saml: {\n        name: 'MicrosoftEntraIDSAML',\n        metadata: {\n          metadataContent: '<your-url-hosting-saml-metadata>', // or content of the metadata file\n          metadataType: 'URL', // or 'FILE'\n        },\n      },\n      logoutUrls: ['http://localhost:3000/', 'https://mywebsite.com'],\n      callbackUrls: [\n        'http://localhost:3000/profile',\n        'https://mywebsite.com/profile',\n      ],\n    },\n  },\n});\n\nUse the signInWithRedirect API to initiate sign-in with a SAML identity provider.\n\nsrc/my-client-side-js.js\nCopy\nsrc/my-client-side-js.js code example\nimport { signInWithRedirect } from 'aws-amplify/auth';\n\n\nawait signInWithRedirect({\n  provider: {\n    custom: 'MicrosoftEntraIDSAML'\n  }\n});\nSet up your frontend\n\nIf you are using the Authenticator component with Amplify, this feature works without any additional code. The guide below is for writing your own implementation.\n\nUse the signInWithRedirect API to initiate sign-in with an external identity provider.\n\nsrc/my-client-side-js.js\nCopy\nsrc/my-client-side-js.js code example\nimport { signInWithRedirect } from 'aws-amplify/auth';\n\n\nawait signInWithRedirect({\n  provider: 'Apple'\n});\n(Required for Multi-Page Applications) Complete external Sign In after Redirect\n\nIf you are developing a multi-page application, and the redirected page is not the same page that initiated the sign in, you will need to add the following code to the redirected page to ensure the sign in gets completed:\n\nsrc/my-redirected-page.ts\nCopy\nsrc/my-redirected-page.ts code example\nimport 'aws-amplify/auth/enable-oauth-listener';\nimport { getCurrentUser, fetchUserAttributes } from 'aws-amplify/auth';\nimport { Hub } from 'aws-amplify/utils';\n\n\nHub.listen(\"auth\", ({ payload }) => {\n  switch (payload.event) {\n    case \"signInWithRedirect\":\n      const user = await getCurrentUser();\n      const userAttributes = await fetchUserAttributes();\n      console.log({user, userAttributes});\n      break;\n    case \"signInWithRedirect_failure\":\n      // handle sign in failure\n      break;\n    case \"customOAuthState\":\n      const state = payload.data; // this will be customState provided on signInWithRedirect function\n      console.log(state);\n      break;\n  }\n});\n\nNote: The listener only works on the client side in the context of a SSR-enabled project, so ensure to import the listener on the client side only. For example, in a Next.js project, you should add the above import statement to a component that renders on the client side only by 'use client'.\n\nUnder the hood\nWhy external Sign In needs to be explicitly handled for Multi-Page Applications\nNext steps\nLearn how to sign in with external providers\nPREVIOUS\nMulti-factor authentication\nNEXT\nGuest access"
  },
  {
    "title": "Guest access - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/concepts/guest-access/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nConcepts\n/\nGuest access\nGuest access\n\nAmplify Auth can be configured to automatically obtain guest credentials once the device is online so that you are able to use other categories \"anonymously\" without the need to sign in. You will not be able to perform user specific methods while in this state such as updating attributes, changing your password, or getting the current user. However, you can obtain the unique Identity ID which is assigned to the device through the fetchAuthSession method described here.\n\nAmplify Gen 2 enables guest access by default. To disable it, you can update the backend.ts file with the following changes:\n\namplify/backend.ts\nimport { defineBackend } from '@aws-amplify/backend'\nimport { auth } from './auth/resource'\nimport { data } from './data/resource'\n\n\nconst backend = defineBackend({\n  auth,\n  data,\n});\n\n\nCopy\nhighlighted code example\nconst { cfnIdentityPool } = backend.auth.resources.cfnResources;\ncfnIdentityPool.allowUnauthenticatedIdentities = false;\nPREVIOUS\nExternal identity providers\nNEXT\nTokens and credentials"
  },
  {
    "title": "Multi-factor authentication - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/concepts/multi-factor-authentication/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nConcepts\n/\nMulti-factor authentication\nMulti-factor authentication\n\nAmplify Auth supports Multi-factor Authentication (MFA) for user sign-in flows. MFA is an extra layer of security used to make sure that users trying to gain access to an account are who they say they are. It requires users to provide additional information to verify their identity. Amplify Auth supports the MFA methods with Time-based-One-Time Passwords (TOTP) as well as text messages (SMS). In this guide we will review how you can set up MFA using TOTP and SMS and the tradeoffs between these methods to help you choose the right set up for your application. We will also review how to set up MFA to remember a device and reduce sign-in friction for your users.\n\nConfigure multi-factor authentication\n\nUse defineAuth to enable MFA for your app. The example below is setting up MFA with TOTP but not SMS as you can see that the phone number is not a required attribute. If you are using SMS, then the PhoneNumber attribute must be true.\n\namplify/auth/resource.ts\nimport { defineAuth } from '@aws-amplify/backend';\n\n\nexport const auth = defineAuth({\n  loginWith: {\n    email: true\n  },\nCopy\nhighlighted code example\n  multifactor: {\n    mode: 'OPTIONAL',\n    totp: true\n  }\n});\n\nWhen multi-factor authentication (MFA) is REQUIRED with SMS in your backend auth resource, you will need to pass the phone number during sign-up API call. If you are using the email or username as the primary sign-in mechanism, you will need to pass the phone_number attribute as a user attribute. This will change depending on if you enable SMS, TOTP, or both. Visit the multi-factor authentication documentation to learn more about enabling MFA on your backend auth resource.\n\nUnderstand your MFA options\n\nWhen enabling MFA you will have two key decisions to make:\n\nMFA enforcement: As part of this setup you will determine how MFA is enforced. If you require MFA by setting MFA login to \"ON\", all your users will need to complete MFA to sign in. If you keep it \"Optional\", your users will have the choice whether to enable MFA or not for their account.\nMFA methods: You will also specify which MFA method you are using - TOTP (Time-based One-time Password), SMS (text message), or both. We recommend that you use TOTP-based MFA as it is more secure and you can reserve SMS for account recovery.\nLearn more\nCompare TOTP and SMS MFA methods\nMulti-factor authentication with SMS\n\nOnce you have setup SMS as your second layer of authentication with MFA as shown above, your users will get an authentication code via a text message to complete sign-in after they sign in with their username and password.\n\nWarning: In order to send SMS authentication codes, you must request an origination number. Learn more about configuring your auth resource for production workloads.\n\nEnable SMS MFA during sign-up\n\nYou will need to pass phone_number as a user attribute to enable SMS MFA for your users during sign-up. However, if the primary sign-in mechanism for your Cognito resource is phone_number (without enabling username), then you do not need to pass it as an attribute.\n\nCopy\ncode example\nimport { signUp } from 'aws-amplify/auth';\n\n\nawait signUp({\n  username: \"hello@mycompany.com\",\n  password: \"hunter2\",\n  options: {\n    userAttributes: {\n      phone_number: \"+15555555555\",\n      email: \"hello@mycompany.com\",\n    },\n  },\n});\n\nBy default, you have to verify a user account after they sign up using the confirmSignUp API, which will send a one-time password to the user's phone number or email, depending on your Amazon Cognito configuration.\n\nCopy\ncode example\nimport { confirmSignUp } from 'aws-amplify/auth';\n\n\nawait confirmSignUp({\n  username: \"hello@mycompany.com\",\n  confirmationCode: \"123456\",\n})\nManage SMS MFA during sign-in\n\nAfter a user signs in, if they have MFA enabled for their account, a challenge will be returned that you would need to call the confirmSignIn API where the user provides their confirmation code sent to their phone number.\n\nIf MFA is ON or enabled for the user, you must call confirmSignIn with the OTP sent to their phone.\n\nCopy\ncode example\nimport { confirmSignIn } from 'aws-amplify/auth';\n\n\nawait confirmSignIn({\n  challengeResponse: \"123456\"\n});\n\nAfter a user has been signed in, call updateMFAPreference to record the MFA type as enabled for the user and optionally set it as preferred so that subsequent logins default to using this MFA type.\n\nCopy\ncode example\nimport { updateMFAPreference } from 'aws-amplify/auth';\n\n\nawait updateMFAPreference({ sms: 'PREFERRED' });\nMulti-factor authentication with TOTP\n\nYou can use Time-based One-Time Password (TOTP) for multi-factor authentication (MFA) in your web or mobile applications. The Amplify Auth category includes support for TOTP setup and verification using authenticator apps, offering an integrated solution and enhanced security for your users. These apps, such as Google Authenticator, Microsoft Authenticator, have the TOTP algorithm built-in and work by using a shared secret key and the current time to generate short-lived, six digit passwords.\n\nSet up TOTP for a user\n\nAfter you initiate a user sign in with the signIn API where a user is required to set up TOTP as an MFA method, the API call will return CONTINUE_SIGN_IN_WITH_TOTP_SETUP as a challenge and next step to handle in your app. You will get that challenge if the following conditions are met:\n\nMFA is marked as Required in your user pool.\nTOTP is enabled in your user pool.\nUser does not have TOTP MFA set up already.\n\nThe CONTINUE_SIGN_IN_WITH_TOTP_SETUP step signifies that the user must set up TOTP before they can sign in. The step returns an associated value of type TOTPSetupDetails which must be used to configure an authenticator app like Microsoft Authenticator or Google Authenticator. TOTPSetupDetails provides a helper method called getSetupURI which generates a URI that can be used, for example, in a button to open the user's installed authenticator app. For more advanced use cases, TOTPSetupDetails also contains a sharedSecret which can be used to either generate a QR code or be manually entered into an authenticator app.\n\nOnce the authenticator app is set up, the user can generate a TOTP code and provide it to the library to complete the sign in process.\n\nCopy\ncode example\nimport { signIn, SignInOutput } from 'aws-amplify/auth';\n\n\nconst output = await signIn({\n  username: \"hello@mycompany.com\",\n  password: \"hunter2\"\n});\n\n\nconst { nextStep } = output;\nswitch (nextStep.signInStep) {\n  // ...\n  case 'CONTINUE_SIGN_IN_WITH_TOTP_SETUP':\n    const totpSetupDetails = nextStep.totpSetupDetails;\n    const appName = 'my_app_name';\n    const setupUri = totpSetupDetails.getSetupUri(appName);\n    // Open setupUri with an authenticator APP to retrieve an OTP code\n    break;\n  // ...\n}\n\nThe TOTP code can be obtained from the user via a text field or any other means. Once the user provides the TOTP code, call confirmSignIn with the TOTP code as the challengeResponse parameter.\n\nCopy\ncode example\nimport { confirmSignIn } from 'aws-amplify/auth';\n\n\nawait confirmSignIn({\n  challengeResponse: \"123456\"\n});\n\nAfter a user has been signed in, call updateMFAPreference to record the MFA type as enabled for the user and optionally set it as preferred so that subsequent logins default to using this MFA type.\n\nCopy\ncode example\nimport { updateMFAPreference } from 'aws-amplify/auth';\n\n\nawait updateMFAPreference({ totp: 'PREFERRED' });\nEnable TOTP after a user is signed in\n\nTOTP MFA can be set up after a user has signed in. This can be done when the following conditions are met:\n\nMFA is marked as Optional or Required in your user pool.\nTOTP is marked as an enabled MFA method in your user pool.\n\nTOTP can be set up by calling the setUpTOTP and verifyTOTPSetup APIs in the Auth category.\n\nInvoke the setUpTOTP API to generate a TOTPSetupDetails object which should be used to configure an Authenticator app like Microsoft Authenticator or Google Authenticator. TOTPSetupDetails provides a helper method called getSetupURI which generates a URI that can be used, for example, in a button to open the user's installed Authenticator app. For more advanced use cases, TOTPSetupDetails also contains a sharedSecret which can be used to either generate a QR code or be manually entered into an Authenticator app.\n\nthat contains the sharedSecret which will be used to either to generate a QR code or can be manually entered into an Authenticator app.\n\nCopy\ncode example\nimport { setUpTOTP } from 'aws-amplify/auth';\n\n\nconst totpSetupDetails = await setUpTOTP();\nconst appName = 'my_app_name';\nconst setupUri = totpSetupDetails.getSetupUri(appName);\n// Open setupUri with an authenticator APP to retrieve an OTP code\n\nOnce the Authenticator app is set up, the user must generate a TOTP code and provide it to the library. Pass the code to verifyTOTPSetup to complete the TOTP setup process.\n\nCopy\ncode example\nimport { verifyTOTPSetup } from 'aws-amplify/auth';\n\n\nawait verifyTOTPSetup({ code: \"123456\" });\n\nAfter TOTP setup is complete, call updateMFAPreference to record the MFA type as enabled for the user and optionally set it as preferred so that subsequent logins default to using this MFA type.\n\nCopy\ncode example\nimport { updateMFAPreference } from 'aws-amplify/auth';\n\n\nawait updateMFAPreference({ sms: 'ENABLED', totp: 'PREFERRED' });\nRecover from a lost TOTP device\n\nIf a user loses access to their TOTP device, they will need to contact an administrator to get help accessing their account. Based on the Cognito user pool configuration, the administrator can use the AdminSetUserMFAPreference to either change the MFA preference to a different MFA method or to disable MFA for the user.\n\nIn a scenario where MFA is marked as \"Required\" in the Cognito User Pool and another MFA method is not set up, the administrator would need to first initiate an AdminUpdateUserAttributes call and update the user's phone number attribute. Once this is complete, the administrator can continue changing the MFA preference to SMS as suggested above.\n\nSet up a user's preferred MFA method\nFetch the current user's MFA preferences\n\nInvoke the following API to get the current MFA preference and enabled MFA types, if any, for the current user.\n\nCopy\ncode example\nimport { fetchMFAPreference } from 'aws-amplify/auth';\n\n\nconst { enabled, preferred } = await fetchMFAPreference();\nUpdate the current user's MFA preferences\n\nInvoke the following API to update the MFA preference for the current user.\n\nOnly one MFA method can be marked as preferred at a time. If the user has multiple MFA methods enabled and tries to mark more than one MFA method as preferred, the API will throw an error.\n\nCopy\ncode example\nimport { updateMFAPreference } from 'aws-amplify/auth';\n\n\nawait updateMFAPreference({ sms: 'ENABLED', totp: 'PREFERRED' });\n\nIf multiple MFA methods are enabled for the user, the signIn API will return CONTINUE_SIGN_IN_WITH_MFA_SELECTION as the next step in the auth flow. During this scenario, the user should be prompted to select the MFA method they want to use to sign in and their preference should be passed to confirmSignIn.\n\nCopy\ncode example\nimport { confirmSignIn, SignInOutput } from 'aws-amplify/auth';\n\n\nfunction handleSignInNextSteps(output: SignInOutput) {\n  const { nextStep } = output;\n  switch (nextStep.signInStep) {\n    // ...\n    case 'CONTINUE_SIGN_IN_WITH_MFA_SELECTION':\n      const allowedMFATypes = nextStep.allowedMFATypes;\n      const mfaType = promptUserForMFAType(allowedMFATypes);\n    case 'CONFIRM_SIGN_IN_WITH_SMS_CODE':\n      // display user to enter otp code;\n      break;\n    case 'CONFIRM_SIGN_IN_WITH_TOTP_CODE':\n      // display user to enter otp code;\n      break;\n    // ...\n  }\n}\n\n\nfunction promptUserForMFAType(\n  allowedMFATypes?: ('SMS' | 'TOTP')[]\n): 'SMS' | 'TOTP' {\n  // Prompt user to select MFA type\n}\n\n\nasync function handleMFASelection(mfaType: 'SMS' | 'TOTP') {\n  try {\n    const output = await confirmSignIn({\n      challengeResponse: mfaType\n    });\n    handleSignInNextSteps(output);\n  } catch (error) {\n    console.log(error);\n  }\n}\nRemember a device\n\nRemembering a device is useful in conjunction with MFA because it allows the second factor requirement to be automatically met when your user signs in on that device and reduces friction in their sign-in experience. By default, this feature is turned off.\n\nNote: The device tracking and remembering features are not available if any of the following conditions are met:\n\nthe federated OAuth flow with Cognito User Pools or Hosted UI is used, or\nthe User Pool uses email, phone_number, or alias attributes as sign-in methods\nwhen the signIn API uses the USER_PASSWORD_AUTH as the authFlowType.\nConfigure device tracking\n\nYou can configure device tracking with deviceTracking construct.\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource';\nimport { data } from './data/resource';\n\n\nconst backend = defineBackend({\n  auth,\n  data\n});\n\n\nconst { cfnUserPool } = backend.auth.resources.cfnResources;\n\n\ncfnUserPool.addPropertyOverride('DeviceConfiguration', {\n  ChallengeRequiredOnNewDevice: true,\n  DeviceOnlyRememberedOnUserPrompt: false\n});\nLearn more\nUnderstand key terms used for tracking devices\nNext steps\nLearn how to sign-up with MFA enabled\nLearn how to manage user devices\nPREVIOUS\nUser groups\nNEXT\nExternal identity providers"
  },
  {
    "title": "User groups - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/concepts/user-groups/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nConcepts\n/\nUser groups\nUser groups\n\nAmplify Auth provides a mechanism that allows you to group users. Assigning users to groups enable you to customize access for a collection of users, or leverage for auditing purposes. For example, only \"ADMINS\" users are permitted to delete posts from a bulletin, or only \"EDITORS\" are permitted to modify posts in a \"draft\" state. To get started with groups, configure the groups property:\n\namplify/auth/resource.ts\nimport { defineAuth } from \"@aws-amplify/backend\"\n\n\nexport const auth = defineAuth({\n  loginWith: {\n    email: true,\n  },\nCopy\nhighlighted code example\n  groups: [\"ADMINS\", \"EDITORS\"],\n})\n\nNote: There are a few limitations with groups, including a limit of 10,000 groups per user pool.\n\nDefining access\n\nAmplify resources enable you to define access for groups using common language. For example, you can use allow.groups in data:\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\nimport { type ClientSchema, a, defineData } from \"@aws-amplify/backend\"\n\n\nconst schema = a.schema({\n  Article: a.model({}).authorization(allow => [\n    allow.groups([\"EDITORS\"]).to([\"read\", \"update\"])\n  ])\n})\n\n\n// ...\n\nOr in storage:\n\namplify/storage/articles/resource.ts\nCopy\namplify/storage/articles/resource.ts code example\nimport { defineStorage } from \"@aws-amplify/backend\"\n\n\nexport const storage = defineStorage({\n  name: \"articles\",\n  access: (allow) => ({\n    \"drafts/*\": [allow.groups([\"EDITORS\"]).to([\"read\", \"write\"])],\n  }),\n})\n\nBy defining access with groups, Amplify configures authorization rules to read from the current user's groups. User pool groups are available as a claim in the user's ID token and access token as cognito:groups. Requests can be made to secure resources using the access token and validated against this claim to permit action on the resource.\n\nGroup roles\n\nEach Cognito user pool group is assigned an IAM role. IAM roles can be modified to extend access to other AWS resources. Roles can be accessed from your backend on the role property of your group:\n\namplify/backend.ts\nimport { defineBackend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource';\nimport { data } from './data/resource';\n\n\n/**\n * @see https://docs.amplify.aws/react/build-a-backend/ to add storage, functions, and more\n */\nconst backend = defineBackend({\n  auth,\n  data,\n});\n\n\nCopy\nhighlighted code example\nconst { groups } = backend.auth.resources\n\n\n// https://docs.aws.amazon.com/cdk/api/v2/docs/aws-cdk-lib.aws_iam.IRole.html\ngroups[\"ADMINS\"].role\nNext steps\nLearn how to automatically add a user to a group upon account confirmation\nLearn how to secure access to data models using groups\nLearn how to secure access to storage objects using groups\nPREVIOUS\nUser attributes\nNEXT\nMulti-factor authentication"
  },
  {
    "title": "User attributes - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/concepts/user-attributes/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nConcepts\n/\nUser attributes\nUser attributes\n\nAmplify Auth stores user profile information in user attributes. When the default method for user sign-in, Amplify Auth will automatically configure an email or phoneNumber attribute that is required for sign-in.\n\nTo extend a user profile beyond the default email or phoneNumber attribute that is automatically configured when specified in your auth resource's loginWith property, you can configure attributes with the userAttributes property:\n\nWarning: After you create your auth resource, you cannot switch an attribute between required and not required.\n\namplify/auth/resource.ts\nimport { defineAuth } from \"@aws-amplify/backend\"\n\n\nexport const auth = defineAuth({\n  loginWith: {\n    // this configures a required \"email\" attribute\n    email: true,\n  },\nCopy\nhighlighted code example\n  userAttributes: {\n    // specify a \"birthdate\" attribute\n    birthdate: {\n      mutable: true,\n      required: false,\n    }\n  },\n})\nStandard attributes\n\nUser attributes are defined as Cognito Standard Attributes. Attributes can be configured to be required for user sign-up in addition to whether the values are mutable. When configuring your resource to allow your users to login with email, an email must be specified for user sign-up and cannot be changed later. However additional attributes can be configured to be optional, and mutable after sign-up.\n\nCustom attributes\n\nIn addition to the provided standard attributes, you can configure Custom Attributes. These are attributes that are typically unique to your use case, such as a tenant ID or a user's display name. Custom attributes are identified by the custom: prefix:\n\namplify/auth/resource.ts\nimport { defineAuth } from \"@aws-amplify/backend\"\n\n\nexport const auth = defineAuth({\n  loginWith: {\n    // this configures a required \"email\" attribute\n    email: true,\n  },\n  userAttributes: {\nCopy\nhighlighted code example\n    \"custom:display_name\": {\n      dataType: \"String\",\n      mutable: true,\n      maxLen: 16,\n      minLen: 1,\n    },\n    \"custom:favorite_number\": {\n      dataType: \"Number\",\n      mutable: true,\n      min: 1,\n      max: 100,\n    },\n    \"custom:is_beta_user\": {\n      dataType: \"Boolean\",\n      mutable: true,\n    },\n    \"custom:started_free_trial\": {\n      dataType: \"DateTime\",\n      mutable: true,\n    },\n  },\n})\n\nUnlike standard attributes, custom attributes cannot natively be required for sign-up, however can be codified to require some value by validating user attributes upon sign-up with a pre sign-up trigger.\n\nCustom attributes can also be configured with specific data types. The following data types are supported:\n\nString\nNumber\nBoolean\nDateTime\n\nShown in the snippet above, String and Number can be assigned minimum and maximum constraints. This is useful to defer simple validations to the underlying service, although does not extend to complex validations such as matching against a regular expression.\n\nNext steps\nLearn how attributes are surfaced to tokens\nLearn how to manage your user attributes\nPREVIOUS\nPhone\nNEXT\nUser groups"
  },
  {
    "title": "Phone - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/concepts/phone/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nConcepts\n/\nPhone\nPhone\n\nBy default Amplify Auth is scaffolded with email as the default method for user sign-in, however this can be changed or extended to also allow your users to sign in using their phone number.\n\namplify/auth/resource.ts\nimport { defineAuth } from \"@aws-amplify/backend\"\n\n\nexport const auth = defineAuth({\n  loginWith: {\nCopy\nhighlighted code example\n    phone: true,\n  },\n})\n\nThis will configure the phone_number attribute that is required for sign-up and cannot be changed.\n\nNext steps\nLearn how to use the signIn API\nLearn how to configure your account for production SMS workloads\nPREVIOUS\nEmail\nNEXT\nUser attributes"
  },
  {
    "title": "Email - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/concepts/email/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nConcepts\n/\nEmail\nEmail\n\nBy default Amplify Auth is scaffolded with email as the default method for user sign-in.\n\namplify/auth/resource.ts\nCopy\namplify/auth/resource.ts code example\nimport { defineAuth } from \"@aws-amplify/backend\"\n\n\nexport const auth = defineAuth({\n  loginWith: {\n    email: true,\n  },\n})\n\nThis will configure an email attribute that is required for sign-up and cannot be changed.\n\nNext steps\nLearn how to use the signIn API\nLearn how to customize emails\nLearn how to configure your auth resource for production workloads\nPREVIOUS\nUsernames\nNEXT\nPhone"
  },
  {
    "title": "Usernames - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/concepts/usernames/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nConcepts\n/\nUsernames\nUsernames\n\nAmplify Auth does not support signing in with only username and password, however can be configured to enable usernames for display purposes. Amazon Cognito offers two ways of provisioning login mechanisms:\n\nUsername attributes\nAlias attributes\n\nEach are described in more detail on the AWS documentation for Cognito user pool settings, however at a high-level can be described as follows:\n\nUsername attributes allow you to customize which attribute can be used as the \"username\", or allowing users to sign in with an email or phone in place of a username\nAlias attributes allow you to specify with attribute(s) can be used with sign in in addition to a username\n\nWith Amazon Cognito, usernames are immutable, which means after the initial sign-up users are unable to change their username later. In some applications this may be undesirable, which can motivate the use of alias attributes. Alias attributes allow you to define a mutable \"preferred username\" in addition to an immutable username.\n\nAmplify Auth leverages username attributes to configure Cognito to accept an email or a phone number as the \"username\". Users will then need to verify their ownership of specified email or phone number to confirm their account.\n\nHowever, it is common to consider a \"username\" for display purposes. For example, you can configure your auth resource to accept a \"preferred username\" to be used as the display name:\n\namplify/auth/resource.ts\nimport { defineAuth } from '@aws-amplify/backend';\n\n\n/**\n * Define and configure your auth resource\n * @see https://docs.amplify.aws/gen2/build-a-backend/auth\n */\nexport const auth = defineAuth({\n  loginWith: {\n    email: true,\n  },\nCopy\nhighlighted code example\n  userAttributes: {\n    preferredUsername: {\n      mutable: true,\n      required: false\n    }\n  }\n});\n\nThis is not a username the user will be able to sign in with, but it can be used to mask their personal information such as their email or phone number when displaying publicly.\n\nIf you would like to override the default behavior and allow your users to sign up with an immutable username, you can use CDK to modify your auth resource's usernameAttributes configuration directly:\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from \"@aws-amplify/backend\"\nimport { auth } from \"./auth/resource\"\nimport { data } from \"./data/resource\"\n\n\nconst backend = defineBackend({\n  auth,\n  data,\n})\n\n\nconst { cfnUserPool } = backend.auth.resources.cfnResources\n// an empty array denotes \"email\" and \"phone_number\" cannot be used as a username\ncfnUserPool.usernameAttributes = []\nNext Steps\nLearn how to configure email sign-up\nLearn how to configure phone sign-up\nNEXT\nEmail"
  },
  {
    "title": "Concepts - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/concepts/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nConcepts\nConcepts\n\nAmplify helps you secure your application while providing an easy sign-in experience for your users. This experience is influenced by your security strategy. This security strategy includes the authentication method, security credentials, and enabling additional verification when needed.\n\nAuthentication is a process to validate who you are (abbreviated as AuthN). The system that does this validation is referred to as an Identity Provider or IdP. This can be your own self-hosted IdP or a cloud service. Oftentimes, this IdP is a external provider such as Apple, Facebook, Google, or Amazon.\nAuthorization is the process of validating what you can access (abbreviated as AuthZ). This is sometimes done by looking at tokens with custom logic, predefined rules, or signed requests with policies.\n\nCommon authentication methods and associated risks include:\n\nExternal provider federation which enables easier access for your users but shares data with third parties.\n\nYou can improve security credentials and verification for these authentication methods by:\n\nModifying the default password policy to ensure your users create stronger passwords.\nRequiring additional contact information from users before they can reset passwords.\nEnabling multi-factor authentication (MFA) which adds a layer of security at sign-in but may also add friction for your users.\nWhat is Amazon Cognito?\n\nAmplify Auth is powered by Amazon Cognito. Amazon Cognito is an identity and access management service, enabling you to secure your web or mobile applications, and is comprised of two services:\n\nAmazon Cognito User Pools is a full-featured user directory service to handle user registration, authentication, and account recovery\nAmazon Cognito Federated Identities or Identity Pools is a service used to authorize your users to interact with other AWS services\n\nAmplify interfaces with User Pools to store your user information, including federation with other OpenID providers like Apple, Facebook, Google, or Amazon, and leverages federated identities to manage user access to AWS resources.\n\nAuthorization is often done in one of two ways:\n\nClients pass the tokens to the backend that perform custom logic to allow or deny actions\nClients sign the requests and the backend validates the signature, allowing or denying actions depending on predefined policy. The predefined rules, known as IAM access policies, are automatically configured by Amplify.\n\nThe first is a common authorization method for HTTP or GraphQL APIs, while the second is necessary for interfacing with AWS services such as Amazon S3, Amazon Pinpoint, and others.\n\nBefore you build\n\nAmazon Cognito can be customized based on your security strategy for authentication. However, some initial configuration options cannot be changed after the backend resources are configured:\n\nUser attributes that are used to identify your individual users (such as email and phone) cannot be renamed or deleted.\nSign-in methods (including username, email, and phone) cannot be added or changed after the initial configuration. This includes both defining which attributes are used to sign in and which attributes are required. Required attributes must have a value for all users once set.\nVerification methods (including username and email) are the same as required attributes and cannot be removed once configured.\nThe sub attribute is a unique identifier within each user pool that cannot be modified and can be used to index and search users.\nIf MFA is set to required with phone number for all users, you will need to include MFA setup (i.e. mandating phone number) when users sign up.\n\nVisit the Amazon Cognito documentation for more details on these settings, including User pool attributes and Adding MFA to a user pool.\n\nUsernames\nLearn more about what Amplify Auth provisions and supports\nEmail\nLearn more about what Amplify Auth provisions and supports\nPhone\nLearn more about what Amplify Auth provisions and supports\nUser attributes\nLearn more about what Amplify Auth provisions and supports\nUser groups\nLearn more about what Amplify Auth provisions and supports\nMulti-factor authentication\nLearn more about what Amplify Auth provisions and supports\nExternal identity providers\nLearn more about what Amplify Auth provisions and supports\nGuest access\nAccess services without needing to sign in.\nTokens and credentials\nLearn about how tokens and credentials are used in Amplify applications"
  },
  {
    "title": "Set up Amplify Auth - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/set-up-auth/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\n/\nSet up Amplify Auth\nSet up Amplify Auth\n\nAmplify Auth is powered by Amazon Cognito. Cognito is a robust user directory service that handles user registration, authentication, account recovery, and other operations. Review the concepts to learn more.\n\nTo get started with defining your authentication resource, open or create the auth resource file:\n\namplify/auth/resource.ts\nCopy\namplify/auth/resource.ts code example\nimport { defineAuth } from \"@aws-amplify/backend\"\n\n\n/**\n * Define and configure your auth resource\n * @see https://docs.amplify.aws/gen2/build-a-backend/auth\n */\nexport const auth = defineAuth({\n  loginWith: {\n    email: true,\n  },\n})\n\nBy default, your auth resource is scaffolded using email as the default login mechanism. You can also configure your auth resource to allow signing in with phone numbers or an external provider such as Google, Facebook, Amazon, or Sign in with Apple.\n\nNote: At a minimum you will need to pass a loginWith value to set up how your users sign in to your app. Signing in with email and password is configured by default if you do not provide any value.\n\nDeploy auth resource\n\nAfter you have chosen and defined your authentication resource, run the following command to create your resource in your personal cloud sandbox.\n\nTerminal\nCopy\nTerminal code example\nnpx ampx sandbox\n\nAfter a successful deployment, this command also generates an outputs file (amplify_outputs.json) to enable your frontend app to connect to your backend resources. The values you configure in your backend authentication resource are set in the generated outputs file to automatically configure the frontend Authenticator connected component.\n\nConnect your application code to your auth resource\n\nCreating and correctly implementing the sign-in flow can be challenging and time-consuming. Amplify's Authenticator UI component streamlines this by enabling you to rapidly build the entire authentication flow for your app. The component works seamlessly with configuration in amplify/auth/resource.ts to automatically connect with your backend resources.\n\nAmplify has pre-built UI components for React, Vue, Angular, React Native, Swift, Android, and Flutter. In this guide, we are focusing on those for web applications.\n\nOnce you add the Authenticator component to your app, you can test the sign-up, sign-in, and sign-out functionality. You can also customize the Authenticator connected component to adjust colors and styling as needed.\n\nNext steps\n\nNow that you have completed setting up authentication in your Amplify app with email and password, you may also want to add some additional features. We recommend you learn more about:\n\nLearn more about authentication concepts\nMoving to production\nNEXT\nConcepts"
  },
  {
    "title": "Authentication - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/auth/",
    "html": "Next.js\n/\nBuild & connect backend\n/\nAuthentication\nAuthentication\nSet up Amplify Auth\nLearn how to set up and connect your backend resources for authentication in Amplify.\nConcepts\nLearn more about what Amplify Auth provisions and supports\nConnect your frontend\nLearn how to connect your frontend to your backend auth resource\nManage users\nLearn how to manage users\nCustomize auth lifecycle\nLearn how to customize the auth lifecycle\nGrant access to auth resources\nLearn how to grant access to auth resources\nModify Amplify-generated Cognito resources with CDK\nLearn how to modify Amplify-generated Cognito resources.\nMoving to production\nLearn how to configure your auth resources for production workloads\nAdvanced workflows\nLearn more about advanced workflows in the Amplify auth category. This includes subscribing to events, identity pool federation, auth-related Lambda triggers and working with AWS service objects.\nUse existing Cognito resources\nLearn how to use existing auth resources"
  },
  {
    "title": "Gen 2 for Gen 1 customers - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/start/migrate-to-gen2/",
    "html": "Next.js\n/\nGet started\n/\nGen 2 for Gen 1 customers\nGen 2 for Gen 1 customers\nMigrating from Gen 1 to Gen 2\n\nWe are actively developing migration tooling to aid in transitioning your project from Gen 1 to Gen 2. Until then, we recommend you continue working with your Gen 1 Amplify project. We remain committed to supporting both Gen 1 and Gen 2 for the foreseeable future. For new projects, we recommend adopting Gen 2 to take advantage of its enhanced capabilities. Meanwhile, customers on Gen 1 will continue to receive support for high-priority bugs and essential security updates.\n\nGen 1 vs. Gen 2 feature matrix\n\nThe tables below present a feature matrix for Gen 1 customers who are considering Gen 2 for their apps. This will help determine the support availability for various features.\n\nAuth\nFeature\tGen 1\tGen 2\nConfigure username\tYes\tYes with CDK\nConfigure email\tYes\tYes\nConfigure phone number\tYes\tYes\nFacebook\tYes\tYes\nGoogle\tYes\tYes\nAmazon\tYes\tYes\nSign-in with Apple\tYes\tYes\nAdd user pool groups\tYes\tYes\nUser pool group preference\tYes\tYes\nEmail verification link redirect\tYes\tYes\nSign-up attributes\tYes\tYes\nAuth trigger support\tYes\tYes\nAuth trigger templates: Add Google reCaptcha Challenge\tYes\tYes\nAuth trigger templates: Add user to Group\tYes\tYes\nAuth trigger templates: Email Domain Filtering (denylist)\tYes\tYes\nAuth trigger templates: Email Domain Filtering (allowlist)\tYes\tYes\nAuth trigger templates: Override ID Token Claims\tYes\tYes\nAuth trigger templates: Custom Auth Challenge Flow\tYes\tNo\nConfigure default password policy\tYes\tYes with CDK\nConfigure read/write capabilities for attributes\tYes\tYes with CDK\nOauth flow: Configure authorization v implicit grant\tYes\tYes with CDK\nAdmin queries\tYes\tYes with CDK\nMFA login (on/off/optional)\tYes\tYes\nMFA: SMS\tYes\tYes\nMFA: TOTP\tYes\tYes\nZero-config Authenticator support\tYes\tYes\nUser management in console\tYes\tYes\nConfigure Oauth scopes\tYes\tYes\nEmail verification - code\tYes\tYes\nEmail Verification - Link\tYes\tYes\nOauth flow: Configure redirect URIs\tYes\tYes\nAbility to set a friendly name for User Pool\tYes\tYes\nUnauthenticated logins\tYes\tYes\nCustom attributes\tYes\tYes with CDK\nOauth flow: Configure domain name prefix\tYes\tYes with CDK\nAuth configuration in console\tYes\tNo\nFirst class OIDC support\tNo\tYes\nFirst class SAML support\tNo\tYes\nImport auth\tYes\tNo\nData\nFeature\tGen 1\tGen2\nmodel\tYes\tYes\nprimaryKey\tYes\tYes\nsecondaryKey (name, sortKeyFields, query)\tYes\tYes\nhasOne\tYes\tYes\nhasMany\tYes\tYes\nbelongsTo\tYes\tYes\nmanyToMany\tYes\tNo\ndefault\tYes\tYes\nauth - model level\t\t\nauth - public - apiKey\tYes\tYes\nauth - public - iam\tYes\tYes\nauth - owner - userPools\tYes\tYes\nauth - owner - ownerField - userPools\tYes\tYes\nauth - owner - ownerField as array - userPools\tYes\tYes\nauth - owner - oidc\tYes\tYes\nauth - owner - ownerField - oidc\tYes\tYes\nauth - owner - ownerField as array - oidc\tYes\tYes\nauth - private - userPools\tYes\tYes\nauth - private - oidc\tYes\tYes\nauth - private - iam\tYes\tYes\nauth - group - userPools\tYes\tYes\nauth - group - dynamic - userPools\tYes\tYes\nauth - group - oidc\tYes\tYes\nauth - group - dynamic - oidc\tYes\tYes\nauth - custom - function\tYes\tYes\nauth - field level\t\t\nauth - public - apiKey\tYes\tYes\nauth - public - iam\tYes\tYes\nauth - owner - userPools\tYes\tYes\nauth - owner - ownerField - userPools\tYes\tYes\nauth - owner - ownerField as array - userPools\tYes\tYes\nauth - owner - oidc\tYes\tYes\nauth - owner - ownerField - oidc\tYes\tYes\nauth - owner - ownerField as array - oidc\tYes\tYes\nauth - private - userPools\tYes\tYes\nauth - private - oidc\tYes\tYes\nauth - private - iam\tYes\tYes\nauth - group - userPools\tYes\tYes\nauth - group - dynamic - userPools\tYes\tYes\nauth - group - oidc\tYes\tYes\nauth - group - dynamic - oidc\tYes\tYes\nauth - custom - function\tYes\tYes\nother directives\t\t\nsearchable\tYes\tNo but we offer a guide using Zero-ETL DynamoDB-to-OpenSearch\npredictions\tYes\tNo but we offer a guide with AI service integrations\nCustom Mutations, Queries, Subscriptions\tYes\tYes\nVTL handler\tYes\tYes with CDK\nJavaScript resolver handler\tNo\tYes\nfunction handler\tYes\tYes\nhttp handler\tYes\tYes - we support custom data sources including http\nOther configurations\t\t\nDataStore support\tYes\tNo but we'll offer a migration guide soon\nVisual configuration\tYes\tNo - Gen 2 is code-first by design\n@model queries, mutations, subscriptions, and timestamps modifiers\tYes\tNo\nCustom GraphQL Transformer plugins\tYes\tNo\nMySQL and PostgreSQL support\tNo\tYes\nIn-IDE end-to-end type safety\tNo\tYes\n@hasOne, @hasMany, and @belongsTo on required fields\tYes\tNo\nfields argument on @hasOne, @hasMany, and @belongsTo\tYes\tNo\nStorage\nFeature\tGen 1\tGen 2\nAbility to provision S3 bucket\tYes\tYes\nAuth and Guest access\tYes\tYes\nAuth - Configure CRUD access\tYes\tYes\nConfigure Cognito Group CRUD access\tYes\tYes\nGuest - Configure CRUD access\tYes\tYes\nLambda trigger for S3 bucket\tYes\tYes\nImport an S3 bucket\tYes\tYes\nFile browser in console\tYes\tYes\nAbility to override/custom\tYes\tYes\nS3 Lambda triggers\tYes\tYes\nLocally test\tYes\tYes - with sandbox environments\nVisual configuration\tYes\tNo - Gen 2 is code-first by design\nFile Browser in console\tYes\tYes\nImport S3 buckets\tYes\tNo\nFunctions\nFeature\tGen 1\tGen 2\nFunction runtime: TypeScript\tNo\tYes\nFunction resource access permissions: auth\tYes\tYes\nFunction resource access permissions: function\tYes\tYes\nFunction resource access permissions: API\tYes\tYes\nFunction resource access permissions CRUD operations\tYes\tYes\nFunction resource access permissions: custom\tNo\tYes\nEnvironment variables\tYes\tYes\nSecrets\tYes\tYes\nCron jobs\tYes\tYes\nConfigure memory size\tYes\tYes\nFunction build options for Node.js\tYes\tYes\nFunction templates: AWS AppSync - GraphQL API request (with IAM)\tYes\tYes\nFunction templates: CRUD function for DynamoDB (Integration with API Gateway)\tYes\tYes\nFunction templates: GraphQL Lambda Authorizer\tYes\tYes\nFunction templates: Hello World\tYes\tYes\nFunction templates: Lambda trigger\tYes\tYes\nFunction logs in console\tYes\tYes\nFunction resource access permissions: geo\tYes\tYes with CDK\nFunction resource access permissions: analytics\tYes\tYes with CDK\nFunction runtime: .NET 6\tYes\tYes with CDK\nFunction runtime: Go\tYes\tYes with CDK\nFunction runtime: Java\tYes\tYes with CDK\nFunction runtime: JavaScript\tYes\tYes with CDK\nFunction runtime: Python\tYes\tYes with CDK\nLambda layers\tYes\tNo\nOther categories\nFeature\tGen 1\tGen 2\nREST API\tYes\tYes with custom CDK\nAnalytics\tYes\tYes with custom CDK\nGeo\tYes\tYes with custom CDK\nPredictions\tYes\tYes with custom CDK\nInteractions\tYes\tYes with custom CDK"
  },
  {
    "title": "Build & connect backend - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/build-a-backend/",
    "html": "Next.js\n/\nBuild & connect backend\nBuild & connect backend\nAuthentication\nLearn about the authentication capabilities of AWS Amplify.\nData\nLearn about the data capabilities of AWS Amplify.\nStorage\nSet up and connect to storage.\nFunctions\nUse AWS Lambda functions to perform tasks and customize workflows.\nServer-Side Rendering\nUse Amplify Auth and Data APIs from Next.js server-side runtimes.\nAdd any AWS service\nLearn how you can add any AWS service.\nUse Amazon Q Developer with Amplify\nLearn how to use Amazon Q Developer - inline code suggestions with Amplify\nTroubleshooting\nDebugging guides for frequent customer errors"
  },
  {
    "title": "Connect to AWS resources - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/start/connect-to-aws-resources/",
    "html": "Next.js\n/\nGet started\n/\nConnect to AWS resources\nConnect to AWS resources\n\nAmplify client libraries provide you with the flexibility to directly connect your application to AWS resources such as AWS AppSync, Amazon Cognito, Amazon S3, and more.\n\nTo get started, client libraries must be configured. This is typically done by using the amplify_outputs.json file generated by the Amplify backend tooling, however using the client libraries does not require backend resources to be created by Amplify.\n\nFor JavaScript-based applications, the client library can be configured by using the generated outputs file:\n\nsrc/main.ts\nCopy\nsrc/main.ts code example\nimport { Amplify } from \"aws-amplify\"\nimport outputs from \"../amplify_outputs.json\"\n\n\nAmplify.configure(outputs)\n\nOr by configuring the library directly by passing a ResourcesConfig object. For example, to configure the client library for use with Amazon Cognito, specify the Auth configuration:\n\nsrc/main.ts\nCopy\nsrc/main.ts code example\nimport { Amplify } from \"aws-amplify\"\n\n\nAmplify.configure({\n  Auth: {\n    Cognito: {\n      userPoolId: \"<your-cognito-user-pool-id>\",\n      userPoolClientId: \"<your-cognito-user-pool-client-id>\",\n      identityPoolId: \"<your-cognito-identity-pool-id>\",\n      loginWith: {\n        email: true,\n      },\n      signUpVerificationMethod: \"code\",\n      userAttributes: {\n        email: {\n          required: true,\n        },\n      },\n      allowGuestAccess: true,\n      passwordFormat: {\n        minLength: 8,\n        requireLowercase: true,\n        requireUppercase: true,\n        requireNumbers: true,\n        requireSpecialCharacters: true,\n      },\n    },\n  },\n})\n\nBy configuring the client library, Amplify automates the communication with the underlying AWS resources, and provides a friendly API to author your business logic. In the snippet below, the signIn function does not require passing information from your Cognito resource to initiate the sign-in flow.\n\nsrc/main.ts\nCopy\nsrc/main.ts code example\nimport { signIn } from \"aws-amplify/auth\"\n\n\nawait signIn({\n  username: \"john.doe@example.com\",\n  password: \"hunter2\",\n})\n\nFor more information about how to use the Amplify client libraries with existing AWS resources, visit the guides:\n\nConnect to Cognito\n\nConnect to Cognito resources using Amplify Auth's client library"
  },
  {
    "title": "Manual installation - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/start/manual-installation/",
    "html": "Next.js\n/\nGet started\n/\nManual installation\nManual installation\n\nTo get started with AWS Amplify we recommend that you use our quickstart starter template. However, for some use cases, it may be preferable to start from scratch, either with a brand new directory or an existing frontend app. In that case we recommend to use npm with create-amplify.\n\nTerminal\nCopy\nTerminal code example\nnpm create amplify@latest\nTerminal\n? Where should we create your project? (.) # press enter\n\nRunning this command will scaffold a lightweight Amplify project in your current project with the following files:\n\nCopy\ncode example\n├── amplify/\n│   ├── auth/\n│   │   └── resource.ts\n│   ├── data/\n│   │   └── resource.ts\n│   ├── backend.ts\n│   ├── tsconfig.json\n│   └── package.json\n├── node_modules/\n├── .gitignore\n├── package-lock.json\n├── package.json\n└── tsconfig.json\n\nIf needed, you can manually install AWS Amplify without using create-amplify or the starter template. This guide will walk you through how to initialize your project, install dependencies, and author your first backend.\n\nManual setup\n\nFirst, if your frontend framework of choice doesn't have it already, create your project's package.json with npm init -y. Then, install the Amplify dependencies for building a backend:\n\nTerminal\nCopy\nTerminal code example\nnpm add --save-dev @aws-amplify/backend@latest @aws-amplify/backend-cli@latest typescript\n\nNote: TypeScript is not a requirement but is recommended for an optimal experience.\n\nNext, create the entry point for your backend, amplify/backend.ts, with the following code:\n\nCopy\ncode example\nimport { defineBackend } from '@aws-amplify/backend';\n\n\ndefineBackend({});\n\nNow you can run npx ampx sandbox to create your first backend!\n\nAmplify Gen 2 requires your backend to be configured for use with ECMAScript modules (ESM). If you encounter the following error during ampx sandbox, consider modifying your package.json with \"type\": \"module\":\n\nCopy\ncode example\nThe current file is a CommonJS module whose imports will produce 'require' calls; however, the referenced file is an ECMAScript module and cannot be imported with 'require'. Consider writing a dynamic 'import(\"@aws-amplify/backend\")' call instead.\n\nOr, you can create a local file in the Amplify backend directory, amplify/package.json:\n\nCopy\ncode example\n{\n  \"type\": \"module\"\n}\n\nYou can use define* functions to define your resources. For example, you can define authentication:\n\namplify/auth/resource.ts\nCopy\namplify/auth/resource.ts code example\nimport { defineAuth } from '@aws-amplify/backend';\n\n\nexport const auth = defineAuth({\n  loginWith: {\n    email: true\n  }\n});\n\nOr define your data resource:\n\namplify/data/resource.ts\nCopy\namplify/data/resource.ts code example\nimport { a, defineData, type ClientSchema } from '@aws-amplify/backend';\n\n\nconst schema = a.schema({});\n\n\nexport type Schema = ClientSchema<typeof schema>;\nexport const data = defineData({\n  schema\n});\n\nEach of these newly defined resources are then imported and set in the backend definition:\n\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport { defineBackend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource';\nimport { data } from './data/resource';\n\n\ndefineBackend({\n  auth,\n  data\n});\nUpgrade existing projects\n\nYou can also update an existing frontend app. To upgrade existing Amplify code-first DX (Gen 2) apps, use your Node.js package manager (for example, npm) to update relevant backend packages:\n\nTerminal\nCopy\nTerminal code example\nnpm update @aws-amplify/backend@latest @aws-amplify/backend-cli@latest\nNext steps\n\nWe recommend the following next steps:\n\nLearn more about defining authentication\nLearn more about defining data\nGet started with cloud sandbox\nDeploy and host your first app"
  },
  {
    "title": "Configure AWS for local development - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/start/account-setup/",
    "html": "Next.js\n/\nGet started\n/\nConfigure AWS for local development\nConfigure AWS for local development\n\nNote: If you already have an AWS account and profile configured locally, you do not need to follow this guide. Please add theAmplifyBackendDeployFullAccess IAM role to your configured AWS profile.\n\nThis guide will help you set up Temporary credentials with IAM Identity Center and AWS Organizations, which will enable you to define Single-sign on (SSO), users, groups, permission sets, and more for your team. AWS Organizations can grow to house multiple AWS accounts. Users within the organization can traverse the AWS account(s) as their permission set allows.\n\nAmplify leverages the standard local credentials chain provider to simplify access to AWS services. While this guide highlights IAM Identity Center, you can explore additional methods for authenticating with AWS locally.\n\nIAM Identity Center terminology\nSet up Identity Center\n\nFollow the steps below if you have never set up AWS profiles before. If you already have a profile, attach the AmplifyBackendDeployFullAccess managed policy to your IAM user.\n\n1. Create user with Amplify permissions\n\nSign in to the AWS Console to access IAM Identity Center page and choose Enable.\n\nA dialog will open, prompting you to \"Choose how to configure IAM Identity Center in your AWS environment.\" Select Enable with AWS Organizations and choose Continue.\n\nNext, we are going to automate a number of steps that simulate the operations of setting up a user in the IAM Identity Center console. To get started open CloudShell, located in the console footer.\n\nPaste the following command in the CloudShell terminal and enter an email address you would like to associate with this AWS account:\n\nCloudShell\nCopy\nCloudShell code example\nread -p \"Enter email address: \" user_email # hit enter\nEnter email address: <your-email-address>\n\nNow, run the following command\n\nCloudShell\nCopy\nCloudShell code example\nresponse=$(aws sso-admin list-instances)\nssoId=$(echo $response | jq '.Instances[0].IdentityStoreId' -r)\nssoArn=$(echo $response | jq '.Instances[0].InstanceArn' -r)\nemail_json=$(jq -n --arg email \"$user_email\" '{\"Type\":\"Work\",\"Value\":$email}')\nresponse=$(aws identitystore create-user --identity-store-id $ssoId --user-name amplify-admin --display-name 'Amplify Admin' --name Formatted=string,FamilyName=Admin,GivenName=Amplify --emails \"$email_json\")\nuserId=$(echo $response | jq '.UserId' -r)\nresponse=$(aws sso-admin create-permission-set --name amplify-policy --instance-arn=$ssoArn --session-duration PT12H)\npermissionSetArn=$(echo $response | jq '.PermissionSet.PermissionSetArn' -r)\naws sso-admin attach-managed-policy-to-permission-set --instance-arn $ssoArn --permission-set-arn $permissionSetArn --managed-policy-arn arn:aws:iam::aws:policy/service-role/AmplifyBackendDeployFullAccess\naccountId=$(aws sts get-caller-identity | jq '.Account' -r)\naws sso-admin create-account-assignment --instance-arn $ssoArn --target-id $accountId --target-type AWS_ACCOUNT --permission-set-arn $permissionSetArn --principal-type USER --principal-id $userId\n# Hit enter\n\nTo validate that this worked, run the following command in the CloudShell. If something failed in this process, please report an issue. Keep this information readily available for the next step.\n\nCloudShell\nCopy\nhighlighted code example\nprintf \"\\n\\nStart session url: https://$ssoId.awsapps.com/start\\nRegion: $AWS_REGION\\nUsername: amplify-admin\\n\\n\"\n\n\n# you should see\nStart session url: https://d-XXXXXXXXXX.awsapps.com/start\nRegion: us-east-1\nUsername: amplify-admin\nA step-by-step walkthrough in the console\nPrefer a manual set up?\n2. Create password for user\n\nNow create a password for the user that we need for the next step. In the IdC console, navigate to Users > amplify_admin > Reset password > Send an email to the user with instructions for resetting the password.\n\nCheck your email (make sure you also check your spam folder). Click on the Reset password link and choose a password of your choice. When signing in make sure to use amplify-admin as the Username.\n\nFinish local setup\n\nNow, set up an AWS profile that is linked to the user you just created on your local machine. There are a few options for getting IAM Identity Center user credentials, but we will use the AWS CLI configuration wizard.\n\n3. Install the AWS CLI\n\nInstall the AWS CLI.\n\nMac\nWindows\nLinux\n\nIn your browser, download the macOS pkg file:\n\nInstall on Mac\n\n4. Set up local AWS profile\n\nOpen your terminal, you are ready to configure an AWS profile that uses the SSO user. Use the information from CloudShell to populate the information below.\n\nTerminal\nCopy\nhighlighted code example\naws configure sso\n\n\n| SSO session name (Recommended): amplify-admin\n| SSO start URL: <START SESSION URL>\n| SSO region: <your-region>\n| SSO registration scopes [sso:account:access]: <leave blank>\n| Attempting to automatically open the SSO authorization page in your default browser.\n| If the browser does not open or you wish to use a different device to authorize this request, open the following URL:\n|\n| https://device.sso.us-east-2.amazonaws.com/\n|\n| Then enter the code:\n|\n| SOME-CODE\n\n\n## browser opens\n\nAfter you provide this information, the browser will automatically open asking you to sign in with the username and password you just created and configure a multi-factor device to authenticate.\n\nNow return to the terminal and enter the following information:\n\nTerminal\nThe only AWS account available to you is: <your-aws-account-id>\nUsing the account ID <your-aws-account-id>\nThe only role available to you is: amplify-policy\nUsing the role name \"amplify-policy\"\nCLI default client Region [us-east-1]: <your-region>\nCLI default output format [None]:\n\nMake sure to set the profile name to default. Alternatively, remember the auto-generated profile name; you will need this later.\n\nTerminal\nCLI profile name [amplify-policy-<your-aws-account-id>]: default\nTo use this profile, specify the profile name using --profile, as shown:\n\n\naws s3 ls --profile default\n\nIf you inspect ~/.aws/config, you should now see the SSO profile:\n\n~/.aws/config\nCopy\n~/.aws/config code example\n[profile default]\nsso_session = amplify-admin\nsso_account_id = <your-aws-account-id>\nsso_role_name = AdministratorAccess\nregion = <your-region>\n[sso-session amplify-admin]\nsso_start_url = https://xxxxxx.awsapps.com/start#\nsso_region = <your-region>\nsso_registration_scopes = sso:account:access\n5. Bootstrap your AWS account\n\nNow you are ready to use this AWS profile with AWS Amplify. Open your Amplify project and start the sandbox. If you have multiple local profiles or named your profile something other than default, you can specify a profile with --profile.\n\nTerminal\nCopy\nhighlighted code example\nnpx ampx sandbox\n\n\n# OR\n\n\nCopy\nhighlighted code example\nnpx ampx sandbox --profile <profile-name>\n\nBefore you can start deploying resources in the cloud sandbox environment, Amplify will need to complete a one-time bootstrap setup for the account and AWS Region before it can start deploying resources.\n\nLearn more\nWhat is bootstrapping?\n\nDuring the first-time setup, npx ampx sandbox will ask you to sign in to the AWS Management Console. You must sign in as the account root user or as a user that has AdministratorAccess. Once signed in, you will be redirected to the Amplify console. On the Create new app page, choose Initialize setup now. It may take a few minutes for the bootstrapping process to complete.\n\nSuccess\n\nYou have successfully completed the bootstrapping process and you can now return to the terminal to create a new Amplify sandbox environment:\n\nCopy\ncode example\nnpx ampx sandbox --profile <value>"
  },
  {
    "title": "Next.js App Router - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/start/quickstart/nextjs-app-router-client-components/",
    "html": "Next.js\n/\nGet started\n/\nQuickstart\n/\nNext.js App Router\nNext.js App Router\nPre-requisites\n\nThis Quickstart guide will walk you through how to build a task list application with TypeScript, Next.js App Router with Client Components, and React. Before you begin, make sure you have the following installed:\n\nNode.js v14.x or later\nnpm v6.14.4 or later\ngit v2.14.1 or later\nIf you are new to these technologies, we recommend you go through the official React, Next.js, and TypeScript tutorials first.\nDeploy a fullstack app to AWS\n\nWe've created a starter \"To-do\" application to help get started faster. First, you will create a repository in your GitHub account using our starter Next template.\n\n1. Create the repository\n\nUse our starter template to create a repository in your GitHub account. This template scaffolds create-next-app with Amplify backend capabilities.\n\nCreate repository from template\n\nUse the form in GitHub to finalize your repo's creation.\n\n2. Deploy the starter app\n\nNow that the repository has been created, deploy it with Amplify.\n\nDeploy to AWS\n\nSelect Start with an existing app > GitHub. After you give Amplify access to your GitHub account via the popup window, pick the repository and main branch to deploy. Make no other changes and click through the flow to Save and deploy.\n\n3. View deployed app\nWhile you are waiting for your app to deploy (~5 mins)\nLearn about the project structure\n\nWhen the build completes, visit the newly deployed branch by selecting \"View deployed URL\". Since the build deployed an API, database, and authentication backend, you will be able to create new to-do items.\n\nIn the Amplify console, click into the deployment branch (in this case main) > select Data in the left-hand menu > Data manager to see the data entered in your database.\n\nMake frontend updates\n\nLet's learn how to enhance the app functionality by creating a delete flow for to-do list items.\n\n4. Set up local environment\n\nNow let's set up our local development environment to add features to the frontend. Click on your deployed branch and you will land on the Deployments page which shows you your build history and a list of deployed backend resources.\n\nAt the bottom of the page you will see a tab for Deployed backend resources. Click on the tab and then click the Download amplify_outputs.json file button.\n\nClone the repository locally.\n\nTerminal\nCopy\nTerminal code example\ngit clone https://github.com/<github-user>/amplify-next-template.git\ncd amplify-next-template && npm install\n\nNow move the amplify_outputs.json file you downloaded above to the root of your project.\n\nCopy\ncode example\n├── amplify\n├── src\n├── amplify_outputs.json <== backend outputs file\n├── package.json\n└── tsconfig.json\nLearn more\namplify_outputs.json\n5. Implement delete functionality\n\nGo to the app/page.tsx file and add in a new deleteTodo functionality and pass function into the <li> element's onClick handler.\n\napp/page.tsx\nfunction App() {\n  // ...\nCopy\nhighlighted code example\n  function deleteTodo(id: string) {\n    client.models.Todo.delete({ id })\n  }\n\n\n  return (\n    <main>\n      <h1>My todos</h1>\n      <button onClick={createTodo}>+ new</button>\n      <ul>\n        {todos.map(todo => <li\nCopy\nhighlighted code example\n          onClick={() => deleteTodo(todo.id)}\n          key={todo.id}>\n          {todo.content}\n        </li>)}\n      </ul> \n      <div>\n        🥳 App successfully hosted. Try creating a new todo.\n        <br />\n        <a href=\"https://docs.amplify.aws/nextjs/start/quickstart/nextjs-app-router-client-components/\">Review next step of this tutorial.</a>\n      </div>\n    </main>\n  )\n}\nSee the complete amplify/data/resources.ts\n\nTry out the deletion functionality now by starting the local dev server:\n\nTerminal\nCopy\nTerminal code example\nnpm run dev\n\nThis should start a local dev server at http://localhost:3000.\n\n6. Implement login UI\n\nThe starter application already has a pre-configured auth backend defined in the amplify/auth/resource.ts file. We've configured it to support email and password login but you can extend it to support a variety of login mechanisms, including Google, Amazon, Sign In With Apple, and Facebook.\n\nThe fastest way to get your login experience up and running is to use our Authenticator UI component. First, install the Amplify UI component library:\n\nCopy\ncode example\nnpm add @aws-amplify/ui-react\n\nNext, import the Authenticator UI component and wrap your <main> element.\n\napp/page.tsx\nCopy\nhighlighted code example\nimport { Authenticator } from '@aws-amplify/ui-react'\nimport '@aws-amplify/ui-react/styles.css'\n// ... other imports\n\n\nfunction App() {\n  // ...\n  return (\nCopy\nhighlighted code example\n    <Authenticator>\n      {({ signOut, user }) => (\n        <main>\n          {/*...*/}\nCopy\nhighlighted code example\n          <button onClick={signOut}>Sign out</button>\n        </main>\n      )}\nCopy\nhighlighted code example\n    </Authenticator>\n  )\n}\n\nThe Authenticator component auto-detects your auth backend settings and renders the correct UI state based on the auth backend's authentication flow.\n\nTry out your application in your localhost environment again. You should be presented with a login experience now.\n\nTo get these changes to the cloud, commit them to git and push the changes upstream.\n\nTerminal\nCopy\nTerminal code example\ngit commit -am \"added authenticator\"\ngit push\n\nAmplify automatically deploys the latest version of your app based on your git commits. In just a few minutes, when the application rebuilds, the hosted app will be updated to support the deletion functionality.\n\nMake backend updates\n\nLet's update our backend to implement per-user authorization rules, allowing each user to only access their own to-dos.\n\n7. Set up local AWS credentials\n\nTo make backend updates, we are going to require AWS credentials to deploy backend updates from our local machine.\n\nSkip ahead to step 8, if you already have an AWS profile with credentials on your local machine, and your AWS profile has the AmplifyBackendDeployFullAccess permission policy.\n\nOtherwise, set up local AWS credentials that grant Amplify permissions to deploy backend updates from your local machine.\n\n8. Deploy cloud sandbox\n\nTo update your backend without affecting the production branch, use Amplify's cloud sandbox. This feature provides a separate backend environment for each developer on a team, ideal for local development and testing.\n\nTo start your cloud sandbox, run the following command in a new Terminal window:\n\nTerminal\nCopy\nTerminal code example\nnpx ampx sandbox\n\nOnce the cloud sandbox has been fully deployed (~5 min), you'll see the amplify_outputs.json file updated with connection information to a new isolated authentication and data backend.\n\nThe npx ampx sandbox command should run concurrently to your npm run dev. You can think of the cloud sandbox as the \"localhost-equivalent for your app backend\".\n\n9. Implement per-user authorization\n\nThe to-do items in the starter are currently shared across all users, but, in most cases, you want data to be isolated on a per-user basis.\n\nTo isolate the data on a per-user basis, you can use an \"owner-based authorization rule\". Let's apply the owner-based authorization rule to your to-do items:\n\namplify/data/resource.ts\nimport { type ClientSchema, a, defineData } from '@aws-amplify/backend';\n\n\nconst schema = a.schema({\n  Todo: a.model({\n    content: a.string(),\nCopy\nhighlighted code example\n  }).authorization(allow => [allow.owner()]),\n});\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    // This tells the data client in your app (generateClient())\n    // to sign API requests with the user authentication token. \nCopy\nhighlighted code example\n    defaultAuthorizationMode: 'userPool',\n  },\n});\n\nIn the application client code, let's also render the username to distinguish different users once they're logged in. Go to your app/page.tsx file and render the user property.\n\napp/page.tsx\n// ... imports\n\n\nfunction App() {\n  // ...\n  return (\n    <Authenticator>\nCopy\nhighlighted code example\n      {({ signOut, user }) => (\n        <main>\nCopy\nhighlighted code example\n          <h1>{user?.signInDetails?.loginId}'s todos</h1>\n          {/* ... rest of the UI */}\n        </main>\n      )}\n    </Authenticator>\n  )\n}\n\nNow, let's go back to your local application and test out the user isolation of the to-do items.\n\nYou will need to sign up new users again because now you're working with the cloud sandbox instead of your production backend.\n\nTo get these changes to the cloud, commit them to git and push the changes upstream.\n\nTerminal\nCopy\nTerminal code example\ngit commit -am \"added per-user data isolation\"\ngit push\n\nOnce your build completes in the Amplify Console, the main backend will update to support the changes made within the cloud sandbox. The data in the cloud sandbox is fully isolated and won't pollute your production database.\n\n🥳 Success\n\nThat's it! You have successfully built a fullstack app on AWS Amplify. If you want to learn more about how to work with Amplify, here's the conceptual guide for how Amplify works."
  },
  {
    "title": "Next.js Pages Router - Next.js - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/start/quickstart/nextjs-pages-router/",
    "html": "Next.js\n/\nGet started\n/\nQuickstart\n/\nNext.js Pages Router\nNext.js Pages Router\nPre-requisites\n\nThis Quickstart guide will walk you through how to build a task list application with TypeScript, Next.js App Router with Client Components, and React. Before you begin, make sure you have the following installed:\n\nNode.js v14.x or later\nnpm v6.14.4 or later\ngit v2.14.1 or later\nIf you are new to these technologies, we recommend you go through the official React, Next.js, and TypeScript tutorials first.\nDeploy a fullstack app to AWS\n\nWe've created a starter \"To-do\" application to help get started faster. First, you will create a repository in your GitHub account using our starter Next (Pages) template.\n\n1. Create the repository\n\nUse our starter template to create a repository in your GitHub account. This template scaffolds create-next-app with Amplify backend capabilities.\n\nCreate repository from template\n\nUse the form in GitHub to finalize your repo's creation.\n\n2. Deploy the starter app\n\nNow that the repository has been created, deploy it with Amplify.\n\nDeploy to AWS\n\nSelect Start with an existing app > GitHub. After you give Amplify access to your GitHub account via the popup window, pick the repository and main branch to deploy. Make no other changes and click through the flow to Save and deploy.\n\n3. View deployed app\nWhile you are waiting for your app to deploy (~5 mins)\nLearn about the project structure\n\nWhen the build completes, visit the newly deployed branch by selecting \"View deployed URL\". Since the build deployed an API, database, and authentication backend, you will be able to create new to-do items.\n\nIn the Amplify console, click into the deployment branch (in this case main) > select Data in the left-hand menu > Data manager to see the data entered in your database.\n\nMake frontend updates\n\nLet's learn how to enhance the app functionality by creating a delete flow for to-do list items.\n\n4. Set up local environment\n\nNow let's set up our local development environment to add features to the frontend. Click on your deployed branch and you will land on the Deployments page which shows you your build history and a list of deployed backend resources.\n\nAt the bottom of the page you will see a tab for Deployed backend resources. Click on the tab and then click the Download amplify_outputs.json file button.\n\nClone the repository locally.\n\nTerminal\nCopy\nTerminal code example\ngit clone https://github.com/<github-user>/amplify-next-template.git\ncd amplify-next-template && npm install\n\nNow move the amplify_outputs.json file you downloaded above to the root of your project.\n\nCopy\ncode example\n├── amplify\n├── src\n├── amplify_outputs.json <== backend outputs file\n├── package.json\n└── tsconfig.json\nLearn more\namplify_outputs.json\n5. Implement delete functionality\n\nGo to the pages/index.tsx file and add in a new deleteTodo functionality and pass function into the <li> element's onClick handler.\n\npages/index.tsx\nfunction App() {\n  // ...\nCopy\nhighlighted code example\n  function deleteTodo(id: string) {\n    client.models.Todo.delete({ id })\n  }\n\n\n  return (\n    <main>\n      <h1>My todos</h1>\n      <button onClick={createTodo}>+ new</button>\n      <ul>\n        {todos.map(todo => <li\nCopy\nhighlighted code example\n          onClick={() => deleteTodo(todo.id)}\n          key={todo.id}>\n          {todo.content}\n        </li>)}\n      </ul> \n      <div>\n        🥳 App successfully hosted. Try creating a new todo.\n        <br />\n        <a href=\"https://docs.amplify.aws/nextjs/start/quickstart/nextjs-pages-router/\">Review next step of this tutorial.</a>\n      </div>\n    </main>\n  )\n}\nSee the complete amplify/data/resources.ts\n\nTry out the deletion functionality now by starting the local dev server:\n\nTerminal\nCopy\nTerminal code example\nnpm run dev\n\nThis should start a local dev server at http://localhost:3000.\n\n6. Implement login UI\n\nThe starter application already has a pre-configured auth backend defined in the amplify/auth/resource.ts file. We've configured it to support email and password login but you can extend it to support a variety of login mechanisms, including Google, Amazon, Sign In With Apple, and Facebook.\n\nThe fastest way to get your login experience up and running is to use our Authenticator UI component. First, install the Amplify UI component library:\n\nCopy\ncode example\nnpm add @aws-amplify/ui-react\n\nNext, import the Authenticator UI component and wrap your <main> element.\n\npages/index.tsx\nCopy\nhighlighted code example\nimport { Authenticator } from '@aws-amplify/ui-react'\nimport '@aws-amplify/ui-react/styles.css'\n// ... other imports\n\n\nfunction App() {\n  // ...\n  return (\nCopy\nhighlighted code example\n    <Authenticator>\n      {({ signOut, user }) => (\n        <main>\n          {/*...*/}\nCopy\nhighlighted code example\n          <button onClick={signOut}>Sign out</button>\n        </main>\n      )}\nCopy\nhighlighted code example\n    </Authenticator>\n  )\n}\nSee the complete amplify/auth/resources.ts\n\nThe Authenticator component auto-detects your auth backend settings and renders the correct UI state based on the auth backend's authentication flow.\n\nTry out your application in your localhost environment again. You should be presented with a login experience now.\n\nTo get these changes to the cloud, commit them to git and push the changes upstream.\n\nTerminal\nCopy\nTerminal code example\ngit commit -am \"added authenticator\"\ngit push\n\nAmplify automatically deploys the latest version of your app based on your git commits. In just a few minutes, when the application rebuilds, the hosted app will be updated to support the deletion functionality.\n\nMake backend updates\n\nLet's update our backend to implement per-user authorization rules, allowing each user to only access their own to-dos.\n\n7. Set up local AWS credentials\n\nTo make backend updates, we are going to require AWS credentials to deploy backend updates from our local machine.\n\nSkip ahead to step 8, if you already have an AWS profile with credentials on your local machine, and your AWS profile has the AmplifyBackendDeployFullAccess permission policy.\n\nOtherwise, set up local AWS credentials that grant Amplify permissions to deploy backend updates from your local machine.\n\n8. Deploy cloud sandbox\n\nTo update your backend without affecting the production branch, use Amplify's cloud sandbox. This feature provides a separate backend environment for each developer on a team, ideal for local development and testing.\n\nTo start your cloud sandbox, run the following command in a new Terminal window:\n\nTerminal\nCopy\nTerminal code example\nnpx ampx sandbox\n\nOnce the cloud sandbox has been fully deployed (~5 min), you'll see the amplify_outputs.json file updated with connection information to a new isolated authentication and data backend.\n\nThe npx ampx sandbox command should run concurrently to your npm run dev. You can think of the cloud sandbox as the \"localhost-equivalent for your app backend\".\n\n9. Implement per-user authorization\n\nThe to-do items in the starter are currently shared across all users, but, in most cases, you want data to be isolated on a per-user basis.\n\nTo isolate the data on a per-user basis, you can use an \"owner-based authorization rule\". Let's apply the owner-based authorization rule to your to-do items:\n\namplify/data/resource.ts\nimport { type ClientSchema, a, defineData } from '@aws-amplify/backend';\n\n\nconst schema = a.schema({\n  Todo: a.model({\n    content: a.string(),\nCopy\nhighlighted code example\n  }).authorization(allow => [allow.owner()]),\n});\n\n\nexport type Schema = ClientSchema<typeof schema>;\n\n\nexport const data = defineData({\n  schema,\n  authorizationModes: {\n    // This tells the data client in your app (generateClient())\n    // to sign API requests with the user authentication token. \nCopy\nhighlighted code example\n    defaultAuthorizationMode: 'userPool',\n  },\n});\n\nIn the application client code, let's also render the username to distinguish different users once they're logged in. Go to your src/App.tsx file and render the user property.\n\npages/index.tsx\n// ... imports\n\n\nfunction App() {\n  // ...\n  return (\n    <Authenticator>\nCopy\nhighlighted code example\n      {({ signOut, user }) => (\n        <main>\nCopy\nhighlighted code example\n          <h1>{user?.signInDetails?.loginId}'s todos</h1>\n          {/* ... rest of the UI */}\n        </main>\n      )}\n    </Authenticator>\n  )\n}\n\nNow, let's go back to your local application and test out the user isolation of the to-do items.\n\nYou will need to sign up new users again because now you're working with the cloud sandbox instead of your production backend.\n\nTo get these changes to the cloud, commit them to git and push the changes upstream.\n\nTerminal\nCopy\nTerminal code example\ngit commit -am \"added per-user data isolation\"\ngit push\n\nOnce your build completes in the Amplify Console, the main backend will update to support the changes made within the cloud sandbox. The data in the cloud sandbox is fully isolated and won't pollute your production database.\n\n🥳 Success\n\nThat's it! You have successfully built a fullstack app on AWS Amplify. If you want to learn more about how to work with Amplify, here's the conceptual guide for how Amplify works."
  },
  {
    "title": "Quickstart - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/start/quickstart/",
    "html": "Next.js\n/\nGet started\n/\nQuickstart\nQuickstart\n\n👋 Welcome to AWS Amplify! In this quickstart guide, you will:\n\nDeploy a Next.js app\nBuild and connect to a database with real-time data updates\nConfigure authentication and authorization rules\n\nWe have two Quickstart guides you can follow:\n\nNext.js Pages Router\nGet started with AWS Amplify Gen 2 using the Next.js Pages Router.\nNext.js App Router\nGet started with AWS Amplify Gen 2 using the Next.js App Router."
  },
  {
    "title": "Get started - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/start/",
    "html": "Next.js\n/\nGet started\nGet started\n\nAWS Amplify is a collection of cloud services and libraries for fullstack application development. Amplify provides frontend libraries, UI components, backend building, and frontend hosting for building fullstack cloud apps. This tutorial will teach you how to use Amplify's new code-first developer experience to build a fullstack application with data, authentication, and frontend hosting which are all deployed to AWS. If you're completely new to AWS Amplify, you may want to read more about how it works and the concepts behind the second generation of AWS Amplify, which this tutorial will use.\n\nQuickstart\nGet started with AWS Amplify Gen 2 and React, Next.js, Angular, Vue, Flutter, React Native, Swift, Android, and JavaScript.\nConfigure AWS for local development\nLearn how to set up your AWS account and configure it locally for use with Amplify.\nManual installation\nLearn how to get started with AWS Amplify Gen 2 by manually installing.\nConnect to AWS resources\nYou can use Amplify client libraries to connect directly to your AWS resources\nGen 2 for Gen 1 customers\nLearn how to set up your AWS account and configure it locally for use with Amplify."
  },
  {
    "title": "FAQ - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/how-amplify-works/faq/",
    "html": "Next.js\n/\nHow Amplify works\n/\nFAQ\nFAQ\n\nIs there a way to upgrade an existing Amplify project from Gen 1 to Gen 2?\n\nWe are still actively developing migration tooling to aid in transitioning your project from Gen 1 to Gen 2. Until then, we recommend you continue working with your Gen 1 Amplify project. We’ve put together a Gen 1 vs. Gen 2 feature support matrix here. We remain committed to supporting both Gen 1 and Gen 2 for the foreseeable future. For new projects, we recommend adopting Gen 2 to take advantage of its enhanced capabilities. Meanwhile, customers on Gen 1 will continue to receive support for high-priority bugs and essential security updates.\n\nIf I have a Gen 1 app, can I use Gen 2 in it?\n\nAmplify Gen 1 and Gen 2 follow different architectural and tooling paradigms, which was necessary to address common customer feedback from Gen 1. You will need to use our upcoming migration tooling to move from a Gen 1 to Gen 2 app. You cannot use Amplify Gen 1 (Studio/CLI) in the same app as Gen 2.\n\nShould I use Amplify Gen 1 or Gen 2 in new apps?\n\nIf you're building a new app, we recommend you use Amplify Gen 2.\n\nDoes Amplify Gen 2 support DataStore?\n\nAmplify Gen 2 supports GraphQL APIs without DataStore. We will release migration support for moving DataStore Gen 1 apps to Gen 2.\n\nWhat programming languages does Amplify Gen 2 support?\n\nAmplify Gen 2 supports a wide range of programming languages for client-side development. This includes dedicated client-side libraries for JavaScript, TypeScript, Dart, Java, Kotlin, and Swift. For backend development, Amplify Gen 2 uses TypeScript.\n\nIn Gen 1, Amplify offered a set of use case categories for building applications (for example, Authentication, Analytics, API, DataStore, Geo, and Predictions). Are those same categories available in Gen 2?\n\nAmplify Gen 2 offers built-in support for Auth, Data, Storage, and Functions. Other use cases can be implemented in Amplify Gen 2 as well using AWS Cloud Development Kit (AWS CDK) constructs which there is documentation for under the respective category name.\n\nCan I use Gen 2 with a JavaScript frontend that doesn't use TypeScript?\n\nYes. Amplify Gen 2's TypeScript backend definition works with JavaScript frontends. In addition, you still get an end-to-end typed data fetching experience even with a pure JavaScript frontend. See Generate a Data client for the recommended JavaScript client code.\n\nWhat if we want to add a feature like AI/ML or Amazon Location Service to our application in Gen 2?\n\nBecause Amplify builds on the AWS Cloud Development Kit (AWS CDK), any AWS services supported by the CDK can be added to your app using custom resources and L2/L1 AWS CDK constructs.\n\nWhat happens once my application grows too big and I want to do more configuration with my application (add more features, other AWS services, etc.)?\n\nYou can stay with Amplify no matter how big your application grows. Amplify is layered on top of the AWS CDK and AWS CloudFormation. These provide a standardized way of interacting with AWS, so you can add any AWS service supported by CDK to your Amplify app. You can also override Amplify-generated configuration of your resources using the CDK. You can use any deployment pipeline you choose if you want more control over your CI.\n\nHow much does it cost to operate Amplify Gen2?\n\nYou can read all about Amplify's pricing on our pricing page.\n\nWhich Amplify JavaScript version is compatible with Gen 2?\n\nAmplify JavaScript version 6.2.0 and above is compatible with backends created by Amplify Gen 2."
  },
  {
    "title": "Concepts - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/how-amplify-works/concepts/",
    "html": "Next.js\n/\nHow Amplify works\n/\nConcepts\nConcepts\n\nAWS Amplify Gen 2 uses a TypeScript-based, code-first developer experience (DX) for defining backends. The Gen 2 DX offers a unified Amplify developer experience with hosting, backend, and UI-building capabilities and a code-first approach. Amplify empowers frontend developers to deploy cloud infrastructure by simply expressing their app’s data model, business logic, authentication, and authorization rules completely in TypeScript. Amplify automatically configures the correct cloud resources and removes the requirement to stitch together underlying AWS services.\n\nCapabilities\n\nYou can use Amplify for end-to-end fullstack development.\n\nBuild fullstack apps with TypeScript\n\nWith the Gen 2 DX, you can provision backend infrastructure by authoring TypeScript. In the following diagram, the box at the bottom (outlined in pink), highlights the main difference in how you provision infrastructure compared to Gen 1. In Gen 1, you would use Studio's console or the CLI to provision infrastructure; in Gen 2, you author TypeScript code in files following a file-based convention (such as amplify/auth/resource.ts or amplify/auth/data.ts). With TypeScript types and classes for resources, you gain strict typing and IntelliSense in Visual Studio Code to prevent errors. A breaking change in the backend code immediately reflects as a type error in the co-located frontend code. The file-based convention follows the \"convention over configuration\" paradigm—you know exactly where to look for resource definitions when you group them by type in separate files.\n\nFaster local development\n\nPer-developer cloud sandbox environments are optimized for faster iterations. Each developer on a team gets an isolated cloud development environment against which they can test their changes. These cloud sandbox environments are meant for local development only, but they deploy high-fidelity AWS backends while you build. Depending on the workflow, iterative updates are now deployed up to 8X faster than Gen 1 deployments. In the diagram below, four developers are able to work on fullstack features independently without disrupting each other's environments.\n\nFullstack Git-based environments\n\nAll shared environments (such as production, staging, gamma) map 1:1 to Git branches in your repository. New features can be tested in ephemeral environments with pull request previews (or feature branches) before they are merged into production. Unlike the Gen 1 experience, which requires users to configure a number of steps in the CLI or Console to set up a fullstack environment, the Gen 2 experience is zero-config. Because of our code-first approach, the Git repository is always the source of truth for the state of the fullstack app—all backend resources are defined as code for reproducibility and portability across branches. This, along with central management of environment variables and secrets, simplifies the promotion workflow from lower to upper environments.\n\nUnified management console\n\nAll branches can be managed in the new Amplify console. The Amplify Gen 2 console provides a single place for you to manage your builds, hosting settings (such as custom domains), deployed resources (such as data browser or user management), and environment variables and secrets. Even though you can access deployed resources directly in other AWS service consoles, the Amplify console will offer a first-party experience for the categories almost every app needs—data, auth, storage, and functions. For example, with Data, Amplify offers an API playground and a data manager (coming soon) with relationship building, seed data generation, and file upload capabilities.\n\nBuild an app\nData\n\nThe @aws-amplify/backend library offers a TypeScript-first Data library for setting up fully typed real-time APIs (powered by AWS AppSync GraphQL APIs) and NoSQL databases (powered by Amazon DynamoDB tables). After you generate an Amplify backend, you will have an amplify/data/resource.ts file, which will contain your app's data schema. The defineData function turns the schema into a fully functioning data backend with all the boilerplate handled automatically.\n\nThe schema-based approach is an evolution of the Amplify GraphQL API in Gen 1. It offers several benefits, including dot completion, IntelliSense, and type validation.\n\nA data model for a chat app may look something like this, for example:\n\nCopy\ncode example\nconst schema = a.schema({\n  Chat: a.model({\n    name: a.string(),\n    message: a.hasMany('Message', 'chatId'),\n  }),\n  Message: a.model({\n    text: a.string(),\n    chat: a.belongsTo('Chat', 'chatId'),\n    chatId: a.id()\n  }),\n});\n\nOn your app's frontend, you can use the generateClient function, which provides a typed client instance, making it easy to integrate CRUD (create, read, update, delete) operations for your models in your application code.\n\nGen 2 automatically generates your types without the explicit codegen step that was part of Gen 1.\n\nCopy\ncode example\n// generate your data client using the Schema from your backend\nconst client = generateClient<Schema>();\n\n\n// list all messages\nconst { data } = await client.models.Message.list();\n\n\n// create a new message\nconst { errors, data: newMessage } = await client.models.Message.create({\n  text: 'My message text'\n});\nAuth\n\nAuth works similarly to data. You can configure the authentication settings you want for your app in amplify/auth/resource.ts. If you want to change the verification email's subject line, you can change out the default generated code with the following:\n\namplify/auth/resource.ts\nCopy\namplify/auth/resource.ts code example\nexport const auth = defineAuth({\n  loginWith: {\n    email: {\n      verificationEmailSubject: 'Welcome 👋 Verify your email!'\n    }\n  }\n});\n\nYou can customize your authentication flow with customized sign-in and registration flows, multi-factor authentication (MFA), and third-party social providers. Amplify deploys an Amazon Cognito instance in your AWS account when you add auth to your app.\n\nThen, you could use the Amplify Authenticator component or the client libraries to add user flows.\n\nCopy\ncode example\nimport { withAuthenticator } from '@aws-amplify/ui-react';\n\n\nfunction App({ signOut, user }) {\n  return (\n    <>\n      <h1>Hello {user.username}</h1>\n      <button onClick={signOut}>Sign out</button>\n    </>\n  );\n}\n\n\nexport default withAuthenticator(App);\nUI building\n\nAmplify makes it easy to quickly build web app user interfaces using the UI component library, Figma-to-code generation, and CRUD form-generation capabilities. Learn more.\n\nConnecting to AWS beyond Amplify\nAdd any AWS resource\n\nGen 2 is layered on top of AWS Cloud Development Kit (CDK)—the Data and Auth capabilities in @aws-amplify/backend wrap L3 AWS CDK constructs. As a result, extending the resources generated by Amplify does not require any special configuration. The following example adds Amazon Location Services by adding a file: amplify/custom/maps/resource.ts.\n\nCopy\ncode example\nimport { CfnOutput, Stack, StackProps } from 'aws-cdk-lib';\nimport * as locations from 'aws-cdk-lib/aws-location';\nimport { Construct } from 'constructs';\n\n\nexport class LocationMapStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n\n    // Create the map resource\n    const map = new locations.CfnMap(this, 'LocationMap', {\n      configuration: {\n        style: 'VectorEsriStreets' // map style\n      },\n      description: 'My Location Map',\n      mapName: 'MyMap'\n    });\n\n\n    new CfnOutput(this, 'mapArn', {\n      value: map.attrArn,\n      exportName: 'mapArn'\n    });\n  }\n}\n\nThis is then included in the amplify/backend.ts file so it gets deployed as part of your Amplify app.\n\nCopy\ncode example\nimport { Backend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource';\nimport { data } from './data/resource';\nimport { LocationMapStack } from './locationMapStack/resource';\n\n\nconst backend = new Backend({\n  auth,\n  data\n});\n\n\nnew LocationMapStack(\n  backend.getStack('LocationMapStack'),\n  'myLocationResource',\n  {}\n);\nConnect to existing resources\n\nAmplify is designed to work with your existing AWS resources and configurations. For example, you can use Amplify's pre-built authentication UI components with an existing Amazon Cognito user pool you created and configured separately. Or you can display images and files from an existing Amazon S3 bucket in your app's user interface by integrating with Amplify Storage.\n\nAmplify's libraries provide an interface to leverage your existing AWS services so that you can adopt Amplify's capabilities incrementally into your current workflows, without disrupting your existing backend infrastructure.\n\nNext steps\n\nNow that you have a conceptual understanding of AWS Amplify's capabilities, complete the quickstart tutorial to put it into action in an app."
  },
  {
    "title": "How Amplify works - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/how-amplify-works/",
    "html": "Next.js\n/\nHow Amplify works\nHow Amplify works\nConcepts\nLearn about the Amplify fullstack TypeScript DX\nFAQ\nFrequently asked questions about the code-first DX."
  },
  {
    "title": "Amplify Docs - AWS Amplify Gen 2 Documentation",
    "url": "https://docs.amplify.aws/nextjs/",
    "html": "Amplify Documentation for Next.js\n\nAWS Amplify is everything frontend developers need to develop and deploy cloud-powered fullstack applications without hassle. Easily connect your frontend to the cloud for data modeling, authentication, storage, serverless functions, SSR app deployment, and more.\n\nGet started\nToggle getting started guides navigation\nHow Amplify Works\nBuild fullstack apps with your framework of choice\n\nYou can use AWS Amplify with popular web and mobile frameworks like JavaScript, Flutter, Swift, and React. Build, connect, and host fullstack apps on AWS. Get started by selecting your preferred framework.\n\nReact\nNext.js\nAngular\nVue\nJavaScript\nReact Native\nFlutter\nAndroid\nSwift\nFeatures\nCode-first DX\n\nThe fullstack TypeScript developer experience lets you focus on your app code instead of infrastructure.\n\nFullstack Git deployments\n\nDeploy your frontend and backend together on every code commit. Your Git branch is the source of truth.\n\nFaster local development\n\nPer-developer cloud sandbox environments let you quickly iterate during development.\n\nDevelop\nTypeScript-first fullstack experience\nWrite TypeScript across your app's frontend and backend. Get schema validation, dot completion, and end-to-end types while you code.\nReal-time data for modern apps\nSync frontend state to real-time backend updates. Just write TypeScript without thinking about WebSockets.\nAuthn and authz for secure apps\nChoose the auth strategy (such as passwords, social, email links) and control data access based on users and groups.\nAuto-generate CRUD forms wired to data\nMap CRUD forms to your data model with form-level validations and error states built in.\nDeploy\nSSR/SSG/ISR hosting support\nDeploy Next.js, Nuxt, React, Vue.js, Angular (and more) apps by simply connecting your Git repository.\nFaster iterations with per-developer sandboxes\nPer-developer cloud sandboxes provide high fidelity and faster deployment times to make local iteration quick.\nZero-config fullstack branches\nFullstack deployments from your Git branch. Autodeploy Git branches to set up staging, development, and production environments.\nGUI to manage your data\nManage your app data, users and groups, and files in a single console.\nCustomize\nAdd any AWS service with CDK\nExtend or customize with the AWS CDK to access 200+ AWS services.\nBring your own pipelines\nUse your own pipelines to set up cross-account or multi-region, stage-based deployments.\nMonorepo and multi-repo support\nEnable support for all types of fullstack team workflows: monorepos, micro frontends, multi-repos, and more.\namplify/backend.ts\nCopy\namplify/backend.ts code example\nimport * as sns from 'aws-cdk-lib/aws-sns';\nimport * as sqs from 'aws-cdk-lib/aws-sqs';\nimport { defineBackend } from '@aws-amplify/backend';\nimport { auth } from './auth/resource.js';\nimport { data } from './data/resource.js';\n\n\nconst backend = defineBackend({\n  auth,\n  data\n});\n\n\nconst customResourceStack = backend.createStack('MyCustomResources');\n\n\nnew sqs.Queue(customResourceStack, 'CustomQueue');\nnew sns.Topic(customResourceStack, 'CustomTopic');"
  }
]