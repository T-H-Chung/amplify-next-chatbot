Title: Telemetry - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/reference/telemetry/
HTML Content:
Next.js
/
Reference
/
Telemetry
Telemetry

Amplify Gen 2 collects anonymous telemetry data about general usage of the CLI. Participation is optional, and you may opt out by using ampx configure telemetry disable.

Your decision to opt out is stored for your user, meaning all Amplify apps you work with on that computer will not send telemetry data.

How do I opt out?

You may opt out by using the configure telemetry disable command from the root of your Amplify app:

Terminal
Copy
Terminal code example
npx ampx configure telemetry disable

You can opt back in to the program by running the following from the root of your Amplify app:

Terminal
Copy
Terminal code example
npx ampx configure telemetry enable

In the event you would like to disable telemetry on a one-time basis, you can opt out by defining an environment variable:

Terminal
Copy
Terminal code example
export AMPLIFY_DISABLE_TELEMETRY=1

--------------------------------------------------------------------------------

Title: IAM Permissions Boundary - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/reference/permissions-boundary/
HTML Content:
Next.js
/
Reference
/
IAM Permissions Boundary
IAM Permissions Boundary

To set the maximum permissions that can be granted to IAM Roles created by Amplify, configure a permissions boundary for the AWS environment (i.e. AWS account & region). Then, Amplify-generated IAM roles can perform only the actions that are allowed by both the roles’ policies and permissions boundary.

The IAM permissions boundary will apply to all IAM Roles created by Amplify. This includes the "auth role" assumed by users that log into the app and the "unauth role" assumed by guest users. It also applies to Lambda execution roles, Cognito user group roles, and any role configured in a custom resource stack.

The IAM Policy to be used as a permissions boundary must be configured outside of Amplify. A permissions boundary is an IAM Policy. This is usually part of an AWS Organization rule or some other corporate governance requirement. Once you have created an IAM Policy to use as a permissions boundary, copy the IAM Policy ARN for the next steps.

Set up a permissions boundary in an AWS environment
Terminal
Copy
Terminal code example
cdk bootstrap --custom-permissions-boundary <iam-policy-arn>

The cdk bootstrap command is a one-time operation that configures the AWS account and region for CDK deployments. Once executed, users can continue to utilize Amplify commands (e.g. sandbox) without interruption. Any custom IAM permissions boundary set by cdk bootstrap will be automatically applied to the roles created by Amplify.

Check this guide to learn more about bootstrapping

--------------------------------------------------------------------------------

Title: IAM policy - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/reference/iam-policy/
HTML Content:
Next.js
/
Reference
/
IAM policy
IAM policy
Branch deployments

Branch deployments require the AmplifyBackendDeployFullAccess managed policy to be able to deploy backend resources during a fullstack deployment. When connecting your project through the console, a role with this policy attached will be automatically created for you.

Cloud sandbox deployments

Sandbox deployments, by design, use local credentials to deploy resources. You need to ensure that the local profile has the AmplifyBackendDeployFullAccess policy attached to it.

--------------------------------------------------------------------------------

Title: Cross-account deployments - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/deploy-and-host/fullstack-branching/cross-account-deployments/
HTML Content:
Next.js
/
Deployment
/
Fullstack workflows
/
Cross-account deployments
Cross-account deployments

This guide walks you through how to create a trunk-based, multi-region deployment pipeline for applications built using AWS Amplify Gen 2. We will be using Amazon CodeCatalyst and AWS Amplify Hosting in this guide, but you can choose any CI/CD provider.

Note: You can deploy this custom pipeline either in the us-west-2 or eu-west-1 Regions, as Amazon CodeCatalyst is currently only available in those two AWS Regions.

Step 1: Set up an Amazon CodeCatalyst space

Please refer to this Amazon CodeCatalyst guide for a detailed step-by-step walkthrough to set up your space.

Step 2: Deploy a fullstack Amplify Gen 2 app
Use our Next.js starter template to create a repository in your GitHub account.
Sign in to the AWS Management Console.
Navigate to the Amplify console and select Create new app.
Select the next-pages-template repository, then select Next.
Review the details on the Create Git Repository page, then select Save and deploy.
Done! You have successfully deployed a fullstack Gen 2 app. You can review the status of the app deployment in the Amplify console.

Step 3: Update build specification

Add the npx ampx generate outputs --branch $AWS_BRANCH --app-id $AWS_APP_ID command to the build spec and comment out the npx ampx pipeline-deploy --branch $AWS_BRANCH --app-id $AWS_APP_ID command. ampx pipeline-deploy runs a script to deploy backend updates, while ampx generate outputs fetches the latest amplify_outputs.json for the specified environment.

Step 4: Disable automatic builds on the branch

You can configure Amplify to disable automatic builds on every code commit. Navigate to the app in the Amplify console. Under App settings, select Branch settings. From the Branches section, select the branch and then choose Disable auto build from the Actions dropdown menu.

Step 5: Create an incoming webhook

You can set up an incoming webhook to trigger a build without committing code to your Git repository. Use the Amplify Console to create an incoming webhook.

Navigate to the app, under Hosting > Build settings select Create webhook. Provide a name for the webhook and select the target branch to build on incoming webhook requests.

Next, select the webhook and copy the curl command which will be used to trigger a build for the app.

Step 6: Create a new Amazon CodeCatalyst project

Please refer to this Amazon CodeCatalyst guide for a detailed step-by-step walkthrough to create a new project.

Note: When creating your project, select the next-pages-template GitHub repository, which we used to deploy the app in Step 2.

Step 7: Set up the resources in a different or target AWS account

To achieve a cross-account deployment, you will need to implement Steps 1 through 6 outlined previously in this guide in a different AWS account (for example, production account).

Step 8: Add the target AWS account to the CodeCatalyst space

Navigate to the CodeCatalyst space created as part of Step 1, select Settings, and then select AWS accounts. Add the target AWS account ID (Step 7) to it and select Associate AWS account.

You will also need to create an IAM role in the target AWS account which will be assumed by the staging environment to perform actions and deploy resources in the production environment. As a best practice, we recommend attaching the AmplifyBackendDeployFullAccess AWS managed policy to the IAM role as it contains all the required permissions to deploy Gen 2 resources in your account. You can learn more about adding IAM roles to account connections in the CodeCatalyst documentation.

Step 9: Create a workflow in the Amazon CodeCatalyst project

A workflow is an automated procedure that describes how to build, test, and deploy your code as part of a continuous integration and continuous delivery (CI/CD) system. You can learn more about workflows in the Amazon CodeCatalyst User Guide.

Within the CodeCatalyst project, navigate to the CI/CD feature and select Workflows.
Select Create workflow.
Choose the next-pages-template GitHub repository and the branch main from the dropdown menu.
Next, select Create.

Once you create the workflow, you should see a yaml editor in the CodeCatalyst console.

Switch the experience in the console to the Visual editor. Select the Actions button to see a list of workflow actions that you can add to your workflow.

Add the Build action to the workflow and select the Add variable button in the Inputs section. Add the following environment variables to it:

AWS_APP_ID_STAGING: amplify app id for staging app
AWS_APP_ID_PRODUCTION: amplify app id for production app
AWS_BRANCH: git branch name

Add another Build action to the workflow and select the Depends on button in the Inputs section. From the dropdown menu, select the name of the previous build action to set up the pipeline.

Next, select the Configuration section and add the following information to each of the build actions:

Environment information (optional): staging, production, etc.
AWS account connection: your account connection
Role: role setup with your account connection

You will then need to add the following shell commands to each of the build actions:

Terminal
Copy
Terminal code example
// This environment variable is required to run the pipeline-deploy command in a non Amplify CI environment
- Run: export CI=1


// Perform a clean install of the dependencies
- Run: npm ci


// Deploy the backend for your Amplify Gen 2 app
- Run: npx ampx pipeline-deploy --branch $AWS_BRANCH --app-id $AWS_APP_ID


// Trigger frontend build using incoming webhooks
- Run: if [ $AWS_BRANCH = "main" ]; then curl -X POST -d {} "`webhookUrl`&operation=startbuild" -H "Content-Type:application/json"; fi

You can now run Validate to ensure your workflow definition yaml file is valid. Lastly, select Commit to save your changes.

Note: Since workflows are saved as commits, and this workflow has a code push trigger enabled, committing the workflow will automatically start a new workflow run.

Next, you can review the result of the workflow run from the Runs tab:

Done! You have successfully set up a custom cross-account pipeline to deploy your frontend and backend for apps built using Amplify Gen 2. To summarize, this custom pipeline will enable you to deploy your backend initially with your staging environment using ampx pipeline-deploy in the CodeCatalyst workflow and ampx generate outputs will generate the amplify_outputs.json file for the main branch. Amplify Hosting will not deploy backend resources as part of the build and instead will use the deployed backend resources from the main branch. Once the staging environment deploys successfully, a similar process will be followed to deploy your production environment in a different AWS account.

PREVIOUS
Custom pipelines

--------------------------------------------------------------------------------

Title: CDK constructs - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/reference/cdk-constructs/
HTML Content:
Next.js
/
Reference
/
CDK constructs
CDK constructs

Constructs—the basic building blocks of AWS Cloud Development Kit (AWS CDK) apps—abstract away the complexity of configuring cloud resources, so you can concentrate on your application code. In the following sections, we summarize the available Amplify backend constructs.

Amplify Data

The official AmplifyData construct can be found on Construct Hub.

This package provides a Level 3 (L3) CDK construct wrapping the behavior of the Amplify GraphQL API. This enables quick development and iteration of AppSync APIs that support the Amplify GraphQL directives.

For more information on data modeling, visit the data-modeling documentation.

Amplify Auth

The official AmplifyAuth construct can be found on the npm registry.

--------------------------------------------------------------------------------

Title: Reference - Next.js - AWS Amplify Gen 1 Documentation
URL: https://docs.amplify.aws/gen1/nextjs/reference/
HTML Content:
Reference

--------------------------------------------------------------------------------

Title: About amplify_outputs.json - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/reference/amplify_outputs/
HTML Content:
Next.js
/
Reference
/
About amplify_outputs.json
About amplify_outputs.json

In Amplify Gen 2, the CLI will generate an amplify_outputs.json file with your backend's outputs such as your Data endpoint and Auth metadata. This file -- also known as the "client configuration file" -- is used to configure the client libraries in order to interact with your backend resources. Locally, this file is created while using ampx sandbox. In Amplify's CI/CD, this is created automatically for you based on the current Amplify app ID and git branch.

You can also manually create this file for a specified Amplify app ID and branch, or an AWS CloudFormation stack name with ampx generate outputs.

Extending Amplify outputs file

The amplify_outputs.json file is not just a static artifact; it is designed to be extendable to suit the evolving needs of your application. By leveraging the addOutput method from your backend, you can programmatically add configurations. This is particularly useful for customizing outputs that are not directly exposed through the Amplify constructs or for dynamically adjusting your app's configuration in response to changes in your backend strategy.

Overriding Amplify-managed configurations on amplify_outputs.json is not supported.

One common scenario where extending the configuration becomes handy is when you need to add custom outputs or extend existing configurations without manual file edits.

Consider a scenario where you want to add output parameters in your amplify_outputs.json that specify an S3 bucket and its region that your application will use for storing files.

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import { data } from "./data/resource";


const backend = defineBackend({
  auth, 
  data, 
});


backend.addOutput({
  storage: {
    aws_region: "us-east-1",
    bucket_name: "my-externally-managed-bucket",
  },
});

In your frontend end application, you can configure Amplify as follows:

src/index.ts
Copy
src/index.ts code example
import { Amplify } from "aws-amplify";
import outputs from "@/amplify_outputs.json";


Amplify.configure(outputs);
Custom configuration

In addition to extending existing configurations, you can also add custom output parameters to your amplify_outputs.json. This is useful for surfacing arbitrary outputs, values from custom CDK resources, or any other information that might be necessary for your application's logic or configuration.

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import { data } from "./data/resource";


const backend = defineBackend({
  auth, 
  data, 
});


backend.addOutput({
  custom: {
    api_id: "restAPIId",
    api_endpoint: "https://api.example.com",
    api_name: "restApiName",
  },
});

In your frontend application, you can access these custom configurations as follows:

src/index.ts
Copy
src/index.ts code example
import { Amplify } from "aws-amplify";
import outputs from "@/amplify_outputs.json";


Amplify.configure(outputs);
const currentConfig = Amplify.getConfig(); 
Amplify.configure({
  ...currentConfig,
  API: {
    REST: {
      [outputs.custom.api_name]: {
        endpoint: outputs.custom.api_endpoint,
        region: "us-east-1",
      },
    },
  },
});
Schema reference

The Amplify outputs file is defined using a JSON schema. You can find this schema in the aws-amplify/amplify-backend repository.

{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://amplify.aws/2024-02/outputs-schema.json",
  "title": "AWS Amplify Backend Outputs",
  "description": "Config format for Amplify Gen 2 client libraries to communicate with backend services.",
  "type": "object",
  "additionalProperties": false,
  "properties": {
    "$schema": {
      "description": "JSON schema",
      "type": "string"
    },
    "version": {
      "description": "Version of this schema",
      "const": "1"
    },
    "analytics": {
      "description": "Outputs manually specified by developers for use with frontend library",
      "type": "object",
      "additionalProperties": false,
      "properties": {
        "amazon_pinpoint": {
          "type": "object",
          "additionalProperties": false,
          "properties": {
            "aws_region": {
              "description": "AWS Region of Amazon Pinpoint resources",
              "$ref": "#/$defs/aws_region"
            },
            "app_id": {
              "type": "string"
            }
          },
          "required": [
            "aws_region",
            "app_id"
          ]
        }
      }
    },
    "auth": {
      "description": "Outputs generated from defineAuth",
      "type": "object",
      "additionalProperties": false,
      "properties": {
        "aws_region": {
          "description": "AWS Region of Amazon Cognito resources",
          "$ref": "#/$defs/aws_region"
        },
        "user_pool_id": {
          "description": "Cognito User Pool ID",
          "type": "string"
        },
        "user_pool_client_id": {
          "description": "Cognito User Pool Client ID",
          "type": "string"
        },
        "identity_pool_id": {
          "description": "Cognito Identity Pool ID",
          "type": "string"
        },
        "password_policy": {
          "description": "Cognito User Pool password policy",
          "type": "object",
          "additionalProperties": false,
          "properties": {
            "min_length": {
              "type": "integer",
              "minimum": 6,
              "maximum": 99
            },
            "require_numbers": {
              "type": "boolean"
            },
            "require_lowercase": {
              "type": "boolean"
            },
            "require_uppercase": {
              "type": "boolean"
            },
            "require_symbols": {
              "type": "boolean"
            }
          }
        },
        "oauth": {
          "type": "object",
          "additionalProperties": false,
          "properties": {
            "identity_providers": {
              "description": "Identity providers set on Cognito User Pool",
              "type": "array",
              "items": {
                "type": "string",
                "enum": [
                  "GOOGLE",
                  "FACEBOOK",
                  "LOGIN_WITH_AMAZON",
                  "SIGN_IN_WITH_APPLE"
                ]
              },
              "minItems": 0,
              "uniqueItems": true
            },
            "domain": {
              "description": "Domain used for identity providers",
              "type": "string"
            },
            "scopes": {
              "type": "array",
              "items": {
                "type": "string"
              },
              "minItems": 0,
              "uniqueItems": true
            },
            "redirect_sign_in_uri": {
              "description": "URIs used to redirect after signing in using an identity provider",
              "type": "array",
              "items": {
                "type": "string"
              },
              "minItems": 1,
              "uniqueItems": true
            },
            "redirect_sign_out_uri": {
              "description": "URIs used to redirect after signing out",
              "type": "array",
              "items": {
                "type": "string"
              },
              "minItems": 1,
              "uniqueItems": true
            },
            "response_type": {
              "type": "string",
              "enum": [
                "code",
                "token"
              ]
            }
          },
          "required": [
            "identity_providers",
            "domain",
            "scopes",
            "redirect_sign_in_uri",
            "redirect_sign_out_uri",
            "response_type"
          ]
        },
        "standard_required_attributes": {
          "description": "Cognito User Pool standard attributes required for signup",
          "type": "array",
          "items": {
            "$ref": "#/$defs/amazon_cognito_standard_attributes"
          },
          "minItems": 0,
          "uniqueItems": true
        },
        "username_attributes": {
          "description": "Cognito User Pool username attributes",
          "type": "array",
          "items": {
            "type": "string",
            "enum": [
              "email",
              "phone_number",
              "username"
            ]
          },
          "minItems": 1,
          "uniqueItems": true
        },
        "user_verification_types": {
          "type": "array",
          "items": {
            "type": "string",
            "enum": [
              "email",
              "phone_number"
            ]
          }
        },
        "unauthenticated_identities_enabled": {
          "type": "boolean",
          "default": true
        },
        "mfa_configuration": {
          "type": "string",
          "enum": [
            "NONE",
            "OPTIONAL",
            "REQUIRED"
          ]
        },
        "mfa_methods": {
          "type": "array",
          "items": {
            "enum": [
              "SMS",
              "TOTP"
            ]
          }
        }
      },
      "required": [
        "aws_region",
        "user_pool_id",
        "user_pool_client_id"
      ]
    },
    "data": {
      "description": "Outputs generated from defineData",
      "type": "object",
      "additionalProperties": false,
      "properties": {
        "aws_region": {
          "$ref": "#/$defs/aws_region"
        },
        "url": {
          "description": "AppSync endpoint URL",
          "type": "string"
        },
        "model_introspection": {
          "description": "generated model introspection schema for use with generateClient",
          "type": "object"
        },
        "api_key": {
          "type": "string"
        },
        "default_authorization_type": {
          "$ref": "#/$defs/aws_appsync_authorization_type"
        },
        "authorization_types": {
          "type": "array",
          "items": {
            "$ref": "#/$defs/aws_appsync_authorization_type"
          }
        }
      },
      "required": [
        "aws_region",
        "url",
        "default_authorization_type",
        "authorization_types"
      ]
    },
    "geo": {
      "description": "Outputs manually specified by developers for use with frontend library",
      "type": "object",
      "additionalProperties": false,
      "properties": {
        "aws_region": {
          "description": "AWS Region of Amazon Location Service resources",
          "$ref": "#/$defs/aws_region"
        },
        "maps": {
          "description": "Maps from Amazon Location Service",
          "type": "object",
          "additionalProperties": false,
          "properties": {
            "items": {
              "type": "object",
              "additionalProperties": false,
              "propertyNames": {
                "description": "Amazon Location Service Map name",
                "type": "string"
              },
              "patternProperties": {
                ".*": {
                  "$ref": "#/$defs/amazon_location_service_config"
                }
              }
            },
            "default": {
              "type": "string"
            }
          },
          "required": [
            "items",
            "default"
          ]
        },
        "search_indices": {
          "description": "Location search (search by places, addresses, coordinates)",
          "type": "object",
          "additionalProperties": false,
          "properties": {
            "items": {
              "type": "array",
              "uniqueItems": true,
              "minItems": 1,
              "items": {
                "description": "Actual search name",
                "type": "string"
              }
            },
            "default": {
              "type": "string"
            }
          },
          "required": [
            "items",
            "default"
          ]
        },
        "geofence_collections": {
          "description": "Geofencing (visualize virtual perimeters)",
          "type": "object",
          "additionalProperties": false,
          "properties": {
            "items": {
              "type": "array",
              "uniqueItems": true,
              "minItems": 1,
              "items": {
                "description": "Geofence name",
                "type": "string"
              }
            },
            "default": {
              "type": "string"
            }
          },
          "required": [
            "items",
            "default"
          ]
        }
      },
      "required": [
        "aws_region"
      ]
    },
    "notifications": {
      "type": "object",
      "description": "Outputs manually specified by developers for use with frontend library",
      "additionalProperties": false,
      "properties": {
        "aws_region": {
          "$ref": "#/$defs/aws_region"
        },
        "amazon_pinpoint_app_id": {
          "type": "string"
        },
        "channels": {
          "type": "array",
          "items": {
            "$ref": "#/$defs/amazon_pinpoint_channels"
          },
          "minItems": 1,
          "uniqueItems": true
        }
      },
      "required": [
        "aws_region",
        "amazon_pinpoint_app_id",
        "channels"
      ]
    },
    "storage": {
      "type": "object",
      "description": "Outputs generated from defineStorage",
      "additionalProperties": false,
      "properties": {
        "aws_region": {
          "$ref": "#/$defs/aws_region"
        },
        "bucket_name": {
          "type": "string"
        }
      },
      "required": [
        "aws_region",
        "bucket_name"
      ]
    },
    "custom": {
      "description": "Outputs generated from backend.addOutput({ custom: <config> })",
      "type": "object"
    }
  },
  "required": [
    "version"
  ],
  "$defs": {
    "aws_region": {
      "type": "string"
    },
    "amazon_cognito_standard_attributes": {
      "description": "Amazon Cognito standard attributes for users -- https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-settings-attributes.html",
      "type": "string",
      "enum": [
        "address",
        "birthdate",
        "email",
        "family_name",
        "gender",
        "given_name",
        "locale",
        "middle_name",
        "name",
        "nickname",
        "phone_number",
        "picture",
        "preferred_username",
        "profile",
        "sub",
        "updated_at",
        "website",
        "zoneinfo"
      ]
    },
    "aws_appsync_authorization_type": {
      "description": "List of supported auth types for AWS AppSync",
      "type": "string",
      "enum": [
        "AMAZON_COGNITO_USER_POOLS",
        "API_KEY",
        "AWS_IAM",
        "AWS_LAMBDA",
        "OPENID_CONNECT"
      ]
    },
    "amazon_location_service_config": {
      "type": "object",
      "additionalProperties": false,
      "properties": {
        "style": {
          "description": "Map style",
          "type": "string"
        }
      }
    },
    "amazon_pinpoint_channels": {
      "description": "supported channels for Amazon Pinpoint",
      "type": "string",
      "enum": [
        "IN_APP_MESSAGING",
        "FCM",
        "APNS",
        "EMAIL",
        "SMS"
      ]
    }
  }
}

--------------------------------------------------------------------------------

Title: Project structure - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/reference/project-structure/
HTML Content:
Next.js
/
Reference
/
Project structure
Project structure

Amplify Gen 2 backends are defined using TypeScript, and enable you to collocate resources depending on their function. For example, you can author a post confirmation trigger for Amazon Cognito that creates a UserProfile model right next to your auth's resource file.

When you create your first Amplify project using npm create amplify@latest, it will automatically set up the scaffolding for Data and Authentication resources:

Copy
code example
├── amplify/
│   ├── auth/
│   │   └── resource.ts
│   ├── data/
│   │   └── resource.ts
│   ├── backend.ts
│   └── package.json
├── node_modules/
├── .gitignore
├── package-lock.json
├── package.json
└── tsconfig.json

As your project grows and you build out your backend, the structure of your project may look like the following:

Copy
code example
├── amplify/
│   ├── auth/
│   │   ├── custom-message/
│   │   │   ├── custom-message.tsx
│   │   │   ├── handler.ts
│   │   │   ├── package.json
│   │   │   └── resource.ts
│   │   ├── post-confirmation.ts
│   │   ├── pre-sign-up.ts
│   │   ├── resource.ts
│   │   └── verification-email.tsx
│   ├── data/
│   │   ├── resolvers/
│   │   │   ├── list-featured-posts.ts
│   │   │   └── list-top-10-posts.ts
│   │   ├── resource.ts
│   │   └── schema.ts
│   ├── jobs/
│   │   ├── monthly-report/
│   │   │   ├── handler.ts
│   │   │   └── resource.ts
│   │   ├── process-featured-posts/
│   │   │   ├── handler.py
│   │   │   ├── requirements.txt
│   │   │   └── resource.ts
│   │   └── store-top-10-posts/
│   │       ├── handler.ts
│   │       └── resource.ts
│   ├── storage/
│   │   ├── photos/
│   │   │   ├── resource.ts
│   │   │   └── trigger.ts
│   │   └── reports/
│   │       └── resource.ts
│   ├── backend.ts
│   └── package.json
├── node_modules/
├── .gitignore
├── package-lock.json
├── package.json
└── tsconfig.json

Backend resources are defined in resource files using the define* helpers:

amplify/auth/resource.ts
Copy
amplify/auth/resource.ts code example
import { defineAuth } from '@aws-amplify/backend';


export const auth = defineAuth({
  loginWith: {
    email: true
  }
});

After the resources are defined, they are set up on the backend:

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';


defineBackend({
  auth,
  data
});

You can extend backends by using the AWS Cloud Development Kit (AWS CDK), which is installed by default as part of the create-amplify workflow. With the CDK, you can build using any AWS service, such as an Amazon S3 bucket that authenticated users have read and write access to. To get started with the CDK, add it to your backend:

amplify/backend.ts
Copy
amplify/backend.ts code example
import * as s3 from 'aws-cdk-lib/aws-s3';
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';


const backend = defineBackend({
  auth,
  data
});


// create the bucket and its stack
const bucketStack = backend.getStack('BucketStack');
const bucket = new s3.Bucket(bucketStack, 'Bucket', {
  blockPublicAccess: s3.BlockPublicAccess.BLOCK_ALL
});


// allow any authenticated user to read and write to the bucket
const authRole = backend.auth.resources.authenticatedUserIamRole;
bucket.grantReadWrite(authRole);


// allow any guest (unauthenticated) user to read from the bucket
const unauthRole = backend.auth.resources.unauthenticatedUserIamRole;
bucket.grantRead(unauthRole);
Next steps
Learn the concepts
Learn how to add AWS services to your backend

--------------------------------------------------------------------------------

Title: CLI commands - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/reference/cli-commands/
HTML Content:
Next.js
/
Reference
/
CLI commands
CLI commands

This page serves as a reference for commands found in the @aws-amplify/backend-cli package.

All commands can be prefixed with AWS CLI environment variables to change the AWS account behavior with Amplify Gen 2 commands.

npx ampx sandbox

Sandbox enables you to develop your backend alongside your frontend's development server. Run npx ampx sandbox to deploy to your personal cloud sandbox, this command will automatically watch for changes in the amplify/ folder, and redeploy each time you save a file.

Options
--dir-to-watch (string) - Directory to watch for file changes. All subdirectories and files will be included. Defaults to the amplify directory.
--exclude (string[]) - An array of paths or glob patterns to ignore. Paths can be relative or absolute and can either be files or directories.
--identifier (string) - An optional name to distinguish between different sandbox environments. Default is the name of the system user executing the process
--outputs-out-dir (string) - A path to a directory where the client config file is written. If not provided, defaults to the working directory of the current process.
--outputs-format (string) - Format in which the client config file is written (choices: json, dart).
--outputs-version (string) - Version of the configuration. Version 0 represents classic amplify-cli config file amplify-configuration and 1 represents newer config file amplify_outputs (choices: 0, 1).
--profile (string) - An AWS profile name.
--stream-function-logs (boolean) - Whether to stream function execution logs. (default: false)
--logs-filter (string[]) - Regex pattern to filter logs from only matched functions. E.g. to stream logs for a function, specify it's name, and to stream logs from all functions starting with auth specify 'auth' (default: Stream all logs)
--logs-out-file (string) - File to append the streaming logs. The file is created if it does not exist. (default: stdout)
Usage
Terminal
Copy
Terminal code example
npx ampx sandbox
Use with an alternate profile

You can use the --profile flag to run sandbox with an AWS profile other than default:

Terminal
Copy
Terminal code example
npx ampx sandbox --profile my-other-profile

Additionally, you can use AWS CLI environment variables to specify a different profile:

Terminal
Copy
Terminal code example
AWS_PROFILE=my-other-profile ampx sandbox
Use with an alternate Region

Use AWS environment variables to deploy to a Region other than your AWS profile's configured Region:

Terminal
Copy
Terminal code example
AWS_REGION=us-west-2 ampx sandbox
Use with mobile applications

For mobile applications, you will need to set the output directory and format of the generated configuration file, specifically amplify_outputs.json:

Terminal
Copy
Terminal code example
# for Android
npx ampx sandbox --outputs-out-dir app/src/main/res
Terminal
Copy
Terminal code example
# for Swift/iOS
npx ampx sandbox
Terminal
Copy
Terminal code example
# for Flutter
npx ampx sandbox --outputs-format dart --outputs-out-dir lib
npx ampx sandbox delete

Delete your personal cloud sandbox. This should only be used if you have an active cloud sandbox that you opted to not delete when exiting npx ampx sandbox.

Options
--name (string) - An optional name to distinguish between different sandbox environments. Default is the name in your package.json.
--profile (string) - An AWS profile name.
-y, --yes (boolean) - Do not ask for confirmation before deleting the sandbox environment.
Usage
Terminal
Copy
Terminal code example
npx ampx sandbox delete
npx ampx sandbox secret

Manage backend secrets used with your personal cloud sandbox.

Options
--profile (string) - An AWS profile name.
Usage
Terminal
Copy
Terminal code example
npx ampx sandbox secret
Using with an alternate AWS profile

You can use the --profile flag to run sandbox with an AWS profile other than default:

Terminal
Copy
Terminal code example
npx ampx sandbox secret list --profile my-other-profile

Additionally, you can use AWS environment variables to specify a different profile:

Terminal
Copy
Terminal code example
AWS_PROFILE=my-other-profile ampx sandbox secret list
Creating a secret

Create secrets for use with your personal cloud sandbox by using sandbox secret set:

Terminal
Copy
Terminal code example
npx ampx sandbox secret set LOGINWITHAMAZON_CLIENT_ID

This is how you configure secrets to be retrieved and used within your backend using secret().

Removing a secret

If you want to remove a secret you previously set, use sandbox secret remove:

Terminal
Copy
Terminal code example
npx ampx sandbox secret remove LOGINWITHAMAZON_CLIENT_ID
Listing secrets

List all available secrets for your personal sandbox in the default AWS profile and Region:

Terminal
Copy
Terminal code example
npx ampx sandbox secret list
Get a secret and view its details

You can view an existing secret and its details, such as the current version and when it was last updated:

Terminal
npx ampx sandbox secret get LOGINWITHAMAZON_CLIENT_ID
 name: LOGINWITHAMAZON_CLIENT_ID
 version: 1
 value: ****
 lastUpdated: Fri Nov 17 2023 12:00:00 GMT-0800 (Pacific Standard Time)
npx ampx generate

Generate is not intended to be used standalone; however, it does offer a few subcommands to generate information or code that is supplemental to your frontend development.

Each of the following generate subcommands require either a CloudFormation stack name or an existing Amplify App ID and corresponding git branch:

Terminal
Copy
Terminal code example
# with CloudFormation stack name
npx ampx generate <subcommand> --stack <cloudformation-stack-name>
Terminal
Copy
Terminal code example
# with Amplify App ID and git branch
npx ampx generate <subcommand> --app-id <app-id> --branch <git-branch-name>
npx ampx generate outputs

Generate the backend outputs file (e.g. amplify_outputs.json) for your frontend application to consume. This is intended to be used to manually generate a configuration file for an environment other than your personal cloud sandbox. For example, you might use it if you would like to verify something your coworker is seeing in their cloud sandbox, or to demonstrate frontend changes locally using a pre-existing "staging" branch.

Options

In addition to the required options noted in ampx generate:

--profile (string) - An AWS profile name.
--format (string) - The format into which the configuration should be exported (choices: json, dart).
--out-dir (string) - A path to the directory where config is written. If not provided, it defaults to the working directory of the current process.
--outputs-version (string) - Version of the configuration. Version 0 represents classic amplify-cli config file amplify-configuration and 1 represents newer config file amplify_outputs (choices: 0, 1).
Usage

As mentioned above, you can specify a team member's cloud sandbox CloudFormation stack:

Terminal
Copy
Terminal code example
npx ampx generate outputs --stack amplify-nextamplifygen2-josef-sandbox-ca85e1081b
Use with mobile applications

Similar to sandbox, you can specify an alternate outputs file format by using --format:

Terminal
Copy
Terminal code example
npx ampx generate outputs --stack amplify-nextamplifygen2-josef-sandbox-ca85e1081b
npx ampx generate graphql-client-code

Generate GraphQL statements and types for your frontend application to consume.

Options

The available parameters for npx ampx generate graphql-client-code are:

Required parameters:

Stack identifier
--stack(string) - A stack name that contains an Amplify backend.
Project identifier
--app-id(string) - The Amplify App ID of the project.
--branch(string) - A git branch of the Amplify project.

Optional parameters:

--out(string) - Specifies the path to the directory where the config is written. If not provided, defaults to the current process working directory.
--format(string) (choices: modelgen, graphql-codegen, introspection) - Specifies the format of the GraphQL client code to be generated.
--model-target (string) (choices: java, swift, javascript, typescript, dart) - Specifies the modelgen export target. Only applies when the --format parameter is set to modelgen.
--statement-target(string) (choices: javascript, graphql, flow, typescript, angular) - Specifies the graphql-codegen statement export target. Only applies when the --format parameter is set to graphql-codegen.
--type-target(string) (choices: json, swift, typescript, flow, scala, flow-modern, angular) - Specifies the optional graphql-codegen type export target. Only applies when the --format parameter is set to graphql-codegen.
--all(boolean)- Shows hidden options.
--profile(string) - Specifies an AWS profile name.
--debug (boolean) - Print debug logs to the console.
--help(boolean) - Displays help information about the command.
Usage
Generate GraphQL client code using the Amplify App ID and branch.
Terminal
Copy
Terminal code example
npx ampx generate graphql-client-code --app-id <your-amplify-app-id>	--branch staging
Generate GraphQL client code for a branch that is connected to Amplify

Sometimes you want to test your latest local changes with the backend of another deployed branch. If you want to generate the GraphQL client code file(s) for the latest deployment of another branch, you can run the following command:

Terminal
Copy
Terminal code example
npx ampx generate graphql-client-code --branch staging
Generate codegen for CDK app using a joint "AmplifyBackendStack" construct

Assume you have deployed your Amplify project with the CDK construct. You will need to remember your app's project name (designated as the second parameter in your CDK construct) and stack name (designated as part of your npx cdk deploy context)

lib/stack.ts
Copy
lib/stack.ts code example
import { Construct } from 'constructs';
import { App, Backend } from 'aws-cdk-lib/aws-amplify';


export class MyAmplifyStack extends cdk.Stack {
  constructor(scope: cdk.Construct, id: string, props?: cdk.StackProps) {
    super(scope, id, props);


    new Backend(this, "Backend", { /* ... */ });
  }
}
Deployment command for CDK project
Terminal
Copy
Terminal code example
npx cdk deploy

Run Amplify codegen command to generate GraphQL codegen:

Terminal
Copy
Terminal code example
npx ampx generate graphql-client-code --stack Backend --platform ts --out ./src
Generate codegen in specific language and format
Terminal
Copy
Terminal code example
npx ampx generate graphql-client-code --format modelgen --type-target angular
Supported GraphQL client code combinations:
Format	Platform	Codegen command in Amplify CLI	Command in Amplify Gen2	Default generated file/path
Introspection schema	Amplify Javascript	N/A	npx ampx generate graphql-client-code --format introspection	<path_to_app>/
GraphQL codegen	Amplify Javascript	amplify codegen	npx ampx generate graphql-client-code --format graphql-codegen --statement-target javascript --out <path_to_app>/src/graphql/	<path_to_app>/src/graphql/
Modelgen	Amplify Javascript	amplify codegen model	npx ampx generate graphql-client-code --format modelgen --model-target javascript --out <path_to_app>/src/models/	<path_to_app>/src/models/
Modelgen	Amplify Android	amplify codegen model	npx ampx generate graphql-client-code --format modelgen --model-target java --out <path_to_app/src/main/java/>	<path_to_app>/src/main/java/com/amplifyframework/datastore/generated/model
Modelgen	Amplify Swift	amplify codegen model	npx ampx generate graphql-client-code --format modelgen --model-target swift --out <path_to_swift_project>/AmplifyModels	<path_to_swift_project>/AmplifyModels
Modelgen	Amplify Flutter	amplify codegen model	npx ampx generate graphql-client-code --format modelgen --model-target dart --out <path_to_flutter_project>/AmplifyModels	<path_to_flutter_project>/AmplifyModels
npx ampx generate forms

Generate React form components derived from your backend data models for your frontend application to consume.

Options
--stack(string) - A stack name that contains an Amplify backend.
--branch (string) - Name of the git branch being deployed.
--app-id (string) - The app id of the target Amplify app.
--out-dir (string) - A path to directory where generated forms are written. Defaults to the ./ui-components directory.
--models (array) - Model name to generate.
--profile (string) - An AWS profile name.
Usage
Terminal
Copy
Terminal code example
npx ampx generate forms --branch $BRANCH_NAME --app-id $AWS_APP_ID --out-dir ./src
npx ampx info

Generates information on system, binaries, npm packages, and environment variables for troubleshooting Amplify issues.

Terminal
Copy
Terminal code example
npx ampx info

This command will print system information as follows:

Terminal
Copy
Terminal code example
System:
  OS: macOS 14.3.1
  CPU: (10) arm64 Apple M1 Pro
  Memory: 165.89 MB / 32.00 GB
  Shell: /opt/homebrew/bin/fish
Binaries:
  Node: 20.12.2 - ~/Library/Caches/fnm_multishells/1063_1714573452292/bin/node
  Yarn: 1.22.19 - ~/Library/Caches/fnm_multishells/1063_1714573452292/bin/yarn
  npm: 10.5.0 - ~/Library/Caches/fnm_multishells/1063_1714573452292/bin/npm
  pnpm: 9.0.5 - ~/Library/Caches/fnm_multishells/1063_1714573452292/bin/pnpm
NPM Packages:
  @aws-amplify/backend: 1.0.0
  @aws-amplify/backend-cli: 1.0.1
  aws-amplify: 6.2.0
  aws-cdk: 2.139.1
  aws-cdk-lib: 2.139.1
  typescript: 5.4.5
AWS environment variables:
  AWS_PROFILE = amplify-admin
  AWS_STS_REGIONAL_ENDPOINTS = regional
  AWS_NODEJS_CONNECTION_REUSE_ENABLED = 1
  AWS_SDK_LOAD_CONFIG = 1
No CDK environment variables
npx ampx pipeline-deploy

Deploys the Amplify project in a CI/CD pipeline for a specified Amplify app and branch.

Options
--branch (string) - Name of the git branch being deployed.
--app-id (string) - The app id of the target Amplify app.
--outputs-out-dir (string) - A path to a directory where the client config file is written. If not provided, defaults to the working directory of the current process.
--outputs-version (string) - Version of the configuration. Version 0 represents classic amplify-cli config file amplify-configuration and 1 represents newer config file amplify_outputs (choices: 0, 1).
Usage
Terminal
Copy
Terminal code example
npx ampx pipeline-deploy --branch $BRANCH_NAME --app-id $AWS_APP_ID

--------------------------------------------------------------------------------

Title: Custom pipelines - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/deploy-and-host/fullstack-branching/custom-pipelines/
HTML Content:
Next.js
/
Deployment
/
Fullstack workflows
/
Custom pipelines
Custom pipelines

While building with Amplify CI/CD offers benefits such as zero-config setup, fullstack previews, centralized secrets management, Amplify Gen 2 makes it easy to integrate fullstack CI/CD into your custom pipelines (for example, AWS CodePipeline, Amazon CodeCatalyst, GitHub Actions, and more).

Set up backend deployments

You can set up your backend deployments using the following steps:

Create an Amplify app by connecting a fullstack Gen 2 branch from your Git repository. This is a one time setup as for subsequent deployments, we will be using a custom pipeline.

Disable Auto-build for your branch. This will ensure code commits to your branch will not trigger a build.

Update the Amplify build specification file to add npx ampx generate outputs --branch $AWS_BRANCH --app-id $AWS_APP_ID and comment out the pipeline-deploy script. ampx pipeline-deploy runs a script to deploy backend updates, while ampx generate outputs fetches the latest amplify_outputs.json for the specified environment.

Now go to your pipeline provider and update the build settings to include the following:
Run npm ci.
Run export CI=1 to tell the deployment script that is a CI environment.
Run npx ampx pipeline-deploy --branch BRANCH_NAME --app-id AMPLIFY_APP_ID. BRANCH_NAME refers to the branch you're deploying. AMPLIFY_APP_ID is the Amplify App ID. To locate the App ID for your backend application, navigate to the Amplify console and select your backend-app. On the Overview page, the App ID is displayed under the project name.

The example below demonstrates how you would set up the build-spec when using Amazon CodeCatalyst.

Copy
code example
Actions:
  Build_82:
    # Identifies the action. Do not modify this value.
    Identifier: aws/build@v1.0.0
    # Specifies the source and/or artifacts to pass to the action as input.
    Inputs:
      # Optional
      Sources:
        - WorkflowSource # This specifies that the action requires this Workflow as a source
      Variables:
        - Name: BRANCH_NAME
          Value: main
        - Name: AMPLIFY_APP_ID
          Value: #####
    Configuration:
      # Required - Steps are sequential instructions that run shell commands
      Steps:
        - Run: export CI=1
        - Run: npm ci
        - Run: npx ampx pipeline-deploy --branch $BRANCH_NAME --app-id $AMPLIFY_APP_ID
Trigger a git push to your branch. Your build logs should show that there is an AWS CloudFormation deployment underway.
Set up frontend deployments

If you want to complete the fullstack CI/CD setup, we have to build, deploy, and host the frontend in addition to the backend.

Use the Amplify Console to create an incoming webhook.

Navigate to the frontend app, under Hosting > Build settings select Create webhook. Provide a name for the webhook and select the target branch to build on incoming webhook requests.

Next, select the webhook and copy the curl command which will be used to trigger a build for the frontend app.

Now update your custom-pipeline build settings to include the curl command to trigger a frontend build after the pipeline-deploy succeeds. Using the same Amazon CodeCatalyst example above, this step includes:
Copy
code example
Configuration:
      # Required - Steps are sequential instructions that run shell commands
      Steps:
        - Run: export CI=1
        - Run: npm ci
        - Run: npx ampx pipeline-deploy --branch $BRANCH_NAME --app-id $AMPLIFY_APP_ID
        - Run: if [ $BRANCH_NAME = "main" ]; then curl -X POST -d {}
            "https://webhooks.amplify.us-west-2.amazonaws.com/prod/webhooks?id=WEBHOOK-ID&token=TOKEN&operation=startbuild"
            -H "Content-Type:application/json"; fi
This should trigger a build in your Amplify app. Amplify CI will build and first generate the amplify_outputs.json for the branch and then build, deploy, and host the frontend.
PREVIOUS
Fullstack previews
NEXT
Cross-account deployments

--------------------------------------------------------------------------------

Title: Fullstack previews - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/deploy-and-host/fullstack-branching/pr-previews/
HTML Content:
Next.js
/
Deployment
/
Fullstack workflows
/
Fullstack previews
Fullstack previews

With fullstack previews, you can set up ephemeral fullstack environments on every pull request. This allows you to test features in isolation from production. Once fullstack previews are enabled, your typical workflow would look like the following diagram:

Your main (production branch) and featureA branch are deployed on Amplify.
You and your team work on featureA until it's ready.
The featureA branch is updated to main HEAD and then a pull request to main is opened.
The pull request preview is deployed on Amplify and available at pr-1.appid.amplifyapp.com.
Once the pull request is merged into main, the request is closed and the fullstack environment is also automatically torn down.
Prerequisites

Before you get started, make sure you have the following:

A fullstack Amplify app deployed
Ensure that your git repository is private. For security purposes, fullstack previews are disabled for public repositories with Amplify backend templates.
Enable fullstack previews

To enable fullstack web previews for your Amplify app, follow these steps:

Login to the Amplify console and select your app.

Navigate to Hosting > Previews. Select the main branch and click on Edit settings. 

Click on the Pull request previews toggle button and choose Confirm to enable previews. 

Done! You have successfully enabled previews on the production branch. 

Ship updates to the dev branch. Now, when you create a pull request for the main branch, Amplify will build and deploy your fullstack PR and provide you with a preview URL. 

For GitHub repositories only, you can access your preview URL directly on the pull request from the Amplify Hosting's bot comment:

After the pull request is merged or closed, the preview URL is deleted and any ephemeral fullstack environment is also deleted.

Share backend resources across Preview branches

Fullstack previews allow teams a way to preview changes from pull requests before merging code to a production branch. Pull requests let you tell others about changes you’ve pushed to a branch in a repository and the changes can be reviewed by accessing the preview URL. When previews are enabled on a git branch, by default every pull request created against the git branch creates an ephemeral fullstack environment.

In some instances, you may not want to deploy new resources for every preview branch. For example, you might want all your preview branches to point to the backend resources deployed by the dev branch so you can reuse seed data, users, and groups.

To achieve this, you can update your app build settings to reuse backend resources across your preview branches. In the Amplify console, select your app on the All apps page. From the App overview page, select Hosting > Build settings to view your app's build specification YAML file.

Update the build settings for the backend phase to run npx ampx generate outputs --branch dev app-id $AWS_APP_ID to generate the amplify_outputs.json file for all preview branches. After this update, any new deployed preview branches will not deploy backend resources as part of the build and instead will use the deployed backend resources from the dev branch.

amplify.yml
version: 1
backend:
    phases:
        build:
            commands:
                - 'npm ci --cache .npm --prefer-offline'
                - 'echo $AWS_BRANCH'
                - |
Copy
highlighted code example
                  case "${AWS_BRANCH}" in
                      main)
                          echo "Deploying main branch..."
                          npx ampx pipeline-deploy --branch $AWS_BRANCH --app-id $AWS_APP_ID
                          ;;
                      dev)
                          echo "Deploying dev branch..."
                          npx ampx pipeline-deploy --branch $AWS_BRANCH --app-id $AWS_APP_ID
                          ;;
                      pr-*)
                          echo "Deploying pull request branch..."
                          npx ampx generate outputs --branch dev --app-id $AWS_APP_ID 
                          ;;
                      *)
                          echo "Deploying to staging branch..."
                          npx ampx generate outputs --branch staging --app-id $AWS_APP_ID 
                          ;;
                  esac
frontend:
    phases:
        build:
            commands:
                - 'npm run build'
    artifacts:
        baseDirectory: .amplify-hosting
        files:
            - '**/*'
    cache:
        paths:
            - .next/cache/**/*
            - .npm/**/*
            - node_modules/**/*
PREVIOUS
Monorepo setup
NEXT
Custom pipelines

--------------------------------------------------------------------------------

Title: Separate frontend and backend teams - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/deploy-and-host/fullstack-branching/mono-and-multi-repos/
HTML Content:
Next.js
/
Deployment
/
Fullstack workflows
/
Separate frontend and backend teams
Separate frontend and backend teams

You might have different frontend and backend teams that maintain their own repositories. With Amplify Gen 2, you can deploy repositories that have backend-only code, so frontend and backend teams can operate independently of each other.

Deploy the backend app

Run mkdir backend-app && cd backend-app && npm create amplify@latest to set up a backend-only Amplify project. Commit the code to a Git provider of your choice.

Connect the backend-app in the new console. Navigate to the Amplify console and select Create new app.

When you connect the repository, notice the only auto-detected framework is Amplify.

Once you choose Save and deploy, your backend project will build.

Deploy the frontend app
Now let's set up the frontend app and connect to the deployed backend.
Terminal
Copy
Terminal code example
npm create next-app@14 -- multi-repo-example --typescript --eslint --no-app --no-src-dir --no-tailwind --import-alias '@/*'
Install Amplify dependencies.
Terminal
Copy
Terminal code example
cd multi-repo-example
npm add @aws-amplify/backend-cli aws-amplify @aws-amplify/ui-react
To connect to the deployed backend, run the following command. To locate the App ID for your backend application, navigate to the Amplify console and select your backend-app. On the Overview page, the App ID is displayed under the project name.
Terminal
Copy
Terminal code example
npx ampx generate outputs --branch main --app-id <your-backend-app-id>

This will generate the amplify_outputs.json file that contains all the information about your backend at the root of your project.

To validate that your frontend can connect to the backend, add the Authenticator login form to your app.
pages/_app.tsx
Copy
pages/_app.tsx code example
import { withAuthenticator } from '@aws-amplify/ui-react';
import { Amplify } from 'aws-amplify';
import outputs from '@/amplify_outputs.json';
import '@aws-amplify/ui-react/styles.css';
import '@/styles/globals.css';
import type { AppProps } from 'next/app';


// configure the Amplify client library with the configuration generated by `ampx sandbox`
Amplify.configure(outputs);


function App({ Component, pageProps }: AppProps) {
  return <Component {...pageProps} />;
}


export default withAuthenticator(App);
Let's also add an amplify.yml build-spec to our repository.
Copy
code example
version: 1
backend:
  phases:
    build:
      commands:
        - npm ci --cache .npm --prefer-offline
        - npx ampx generate outputs --branch main --app-id BACKEND-APPID
frontend:
  phases:
    build:
      commands:
        - npm run build
  artifacts:
    baseDirectory: .next
    files:
      - '**/*'
  cache:
    paths:
      - .next/cache/**/*
      - .npm/**/*
      - node_modules/**/*
Now let's deploy the app. In the Amplify console, choose Create new app. Connect the repository with the default settings. You should see that the build generates the output and does not deploy a frontend. Validate that your app is working fine.

Trigger a frontend build on backend updates

The ideal scenario is that the frontend automatically retrieves the latest updates from the backend every time there is a modification made to the backend code.

Use the Amplify Console to create an incoming webhook.

Navigate to the multi-repo-example app, under Hosting > Build settings select Create webhook. Provide a name for the webhook and select the target branch to build on incoming webhook requests.

Next, select the webhook and copy the curl command which will be used to trigger a build for the multi-repo-example app.

Now update the build settings for the backend-app to include the curl command to trigger a frontend build any time there are changes to the backend.
amplify.yml
Copy
amplify.yml code example
version: 1
backend:
  phases:
    build:
      commands:
        - npm ci --cache .npm --prefer-offline
        - npx ampx pipeline-deploy --branch $AWS_BRANCH --app-id $AWS_APP_ID
frontend:
  phases:
    build:
      commands:
        - mkdir ./dist && touch ./dist/index.html
        - curl -X POST -d {} "https://webhooks.amplify.ca-central-1.amazonaws.com/prod/webhooks?id=WEBHOOK-ID&token=TOKEN&operation=startbuild" -H "Content-Type:application/json"
  artifacts:
    baseDirectory: dist
    files:
      - '**/*'
  cache:
    paths:
      - node_modules/**/*
Sharing schema type definitions

If you're using Amplify Data, we recommend adding a paths entry in the tsconfig.json of your frontend app that points to the amplify/data/resource.ts file in your backend app to easily access your schema type definitions from your frontend apps.

First, cone your backend repo into the same parent directory as your frontend app, then add the following entry:

tsconfig.json
Copy
tsconfig.json code example
{
  "compilerOptions": {
    "paths": {
      "@/data-schema": ["../backend-app/amplify/data/resource"]
    }
  }
}

You can then import the Schema type from this path in your frontend code to get code completion and strong typing for your API calls:

apps/admin-dashboard/page.tsx
Copy
apps/admin-dashboard/page.tsx code example
import { generateClient } from "aws-amplify/data";
import type { Schema } from "@/data-schema";


const client = generateClient<Schema>();


const createTodo = async () => {
  await client.models.Todo.create({
    content: window.prompt("Todo content?"),
    isDone: false,
  });
}
PREVIOUS
Share resources across branches
NEXT
Monorepo setup

--------------------------------------------------------------------------------

Title: Monorepo setup - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/deploy-and-host/fullstack-branching/monorepos/
HTML Content:
Next.js
/
Deployment
/
Fullstack workflows
/
Monorepo setup
Monorepo setup

Some teams choose a monorepo approach, or single repositories that contain multiple packages or components to simplify the deployment process for shared libraries and components. Without a monorepo, you have to deploy each package individually, keep track of package versions and dependencies across packages, and ensure version compatibility. This can become exponentially more complex as the number of packages grows. With a monorepo, all packages and dependencies are contained within a single repository.

Amplify Gen 2 supports monorepo workflows for fullstack builds with monorepo tools such as Nx and yarn workspaces. When building with Gen 2, we recommend creating the amplify/ folder in a shared workspace. We will use the following example for this guide:

Copy
code example
├── apps/
│   ├── admin-dashboard/
│   │   ├── next.config.mjs
│   │   └── package.json
│   └── marketing-site/
│       ├── astro.config.mjs
│       └── package.json
├── packages/
│   └── my-shared-backend/
│       ├── amplify/
│       │   ├── auth/
│       │   │   └── resource.ts
│       │   ├── data/
│       │   │   └── resource.ts
│       │   └── backend.ts
│       |── package.json
        └── tsconfig.json
└── package.json

Monorepos require a slightly different setup. We are going to deploy 3 Amplify apps:

my-shared-backend
admin-dashboard
marketing-site
Deploy backend app

The first app, my-shared-backend, will be the only app that updates changes to the backend. The other apps will only run frontend builds that point to the shared backend.

To get started, deploy the shared backend Amplify app. With Gen 2, you can now setup backend-only CI/CD apps. Navigate to the Amplify console and select Create new app.

Once you connect your repository, select your monorepo project. Check the box that says My app is a monorepo and enter the path to your amplify backend.

Your build settings should be automatically detected. Save and deploy.
Deploy frontend apps
For the frontend apps, connect the frontend projects in the Amplify console separately, and update the build commands to include:
Terminal
Copy
Terminal code example
npx ampx generate outputs --branch main --app-id BACKEND-APP-ID
To locate the App ID for your backend application, navigate to the Amplify console and select your backend-app. On the Overview page, the App ID is displayed under the project name.
Terminal
Copy
Terminal code example
npx ampx generate outputs --branch main --app-id BACKEND-APP-ID
Sharing schema type definitions

If you're using Amplify Data, we recommend adding a paths entry in your tsconfig.json file that points to the amplify/data/resource.ts file to easily access your schema type definitions from your frontend apps.

tsconfig.json
Copy
tsconfig.json code example
{
  "compilerOptions": {
    "paths": {
      "@/data-schema": ["./packages/my-shared-backend/amplify/data/resource"]
    }
  }
}

You can then import the Schema type from this path in your frontend code to get code completion and strong typing for your API calls:

apps/admin-dashboard/page.tsx
Copy
apps/admin-dashboard/page.tsx code example
import { generateClient } from "aws-amplify/data";
import type { Schema } from "@/data-schema";


const client = generateClient<Schema>();


const createTodo = async () => {
  await client.models.Todo.create({
    content: window.prompt("Todo content?"),
    isDone: false,
  });
}
PREVIOUS
Separate frontend and backend teams
NEXT
Fullstack previews

--------------------------------------------------------------------------------

Title: Secrets and environment vars - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/deploy-and-host/fullstack-branching/secrets-and-vars/
HTML Content:
Next.js
/
Deployment
/
Fullstack workflows
/
Secrets and environment vars
Secrets and environment vars

Amplify Gen 2 offers centralized management of secrets and environment variables for all fullstack branches. Secrets allow you to securely configure environment-specific values like social sign-in keys, function environment variables, function secrets, and other sensitive data needed by your application across environments.

FAQ
How is this different from Amplify Gen 1?
Set secrets

You can set secrets for your fullstack branch deployments or your local dev server.

Branch environment

You can add secrets for branch deployments in the Amplify console. From the App home page, navigate to Hosting > Secrets, and then choose the Manage secrets button. You can add a secret key or value that applies to all deployed branches or just specific branches.

Secrets are stored in AWS Systems Manager Parameter Store under the following naming conventions:

Secrets that apply to all branches: /amplify/shared/<app-id>/<secret-key>
Secrets that apply to a specific branch: /amplify/<app-id>/<branchname>/<secret-key>
Local environment

Secrets set in a sandbox do not show up in the Amplify console. You can view them in the AWS Parameter Store console.

When testing features locally, you might want to test with real secrets. You can add secrets while running the cloud sandbox with the following command:

Terminal
Copy
Terminal code example
npx ampx sandbox secret set foo
? Enter secret value: ###
Done!


> npx ampx sandbox secret set bar
? Enter secret value: ###
Done!
Access secrets

Once you have set a secret, you can access the values in code by calling the secret() function. The following example shows how to set up social sign-in with authentication in your app. Depending on your environment, Amplify will automatically load the correct secret value with no extra configuration.

Copy
code example
import { defineAuth, secret } from '@aws-amplify/backend';


export const auth = defineAuth({
  loginWith: {
    email: true,
    externalProviders: {
      facebook: {
        clientId: secret('foo'),
        clientSecret: secret('bar')
      }
    }
  }
});
Remove secrets

When deleting branch environments or sandbox environments, you need to manually delete the secrets as well.

Branch environment

Secrets that are used in branch deployments can be managed directly in the Amplify console. You can remove them under Secret management by choosing Remove.

Local environment

To remove a secret in your local environment, run the following command in your terminal:

Terminal
Copy
Terminal code example
npx ampx sandbox secret remove foo
Set environment variables

Environment variables work like key-value pairs to help manage configurable settings across different deployment environments, including development, staging, and production. Unlike secrets, which store sensitive data, environment variables are typically nonconfidential and are used for controlling application behavior in different environments. Another key difference is that environment variables are stored and managed by the Amplify managed service. You can set environment variables in the Amplify console (view the AWS Amplify Hosting User Guide for detailed instructions).

Access environment variables

You can enable access to environment variables for your fullstack branch deployments or your local dev server.

Branch environment

You can manage your branch environment access through the Amplify console.

First, create an environment variable in the Amplify console (in this example, you will name it REACT_APP_TEST_VARIABLE)

Next, navigate to the Build Settings in console (or to the amplify.yml file) and update the build settings to pipe the environment variable into a file. Here is an example of writing it into an .env file:

amplify.yml
build:
  commands:
Copy
highlighted code example
    - echo "REACT_APP_TEST_VARIABLE=$REACT_APP_TEST_VARIABLE" >> .env
    - npm run build

With the implementation above, the environment variable is written in a .env file. However, you can write it to any file depending on your platform.

For Flutter, you can still use .env with an external package or generate your configuration file in Dart or JSON format.
For Android, you can use Build Configurations or Gradle variables.
For iOS, you can update your plist file with the necessary code or create a configuration file in JSON format.

Now the .env can access the environment variable through process.env in your client code:

Copy
code example
console.log('REACT_APP_TEST_VARIABLE', process.env.REACT_APP_TEST_VARIABLE);
Local environment

When working on your local machine, you must manually load the sandbox's environment variables. First, add the environment variable in your .env.local file. Then, a library such as @dotenvx/dotenvx can load the environment variables, which you can then reference with process.env.

PREVIOUS
Fullstack branch deployments
NEXT
Share resources across branches

--------------------------------------------------------------------------------

Title: Share resources across branches - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/deploy-and-host/fullstack-branching/share-resources/
HTML Content:
Next.js
/
Deployment
/
Fullstack workflows
/
Share resources across branches
Share resources across branches

In some instances, you may not want to deploy new resources for every branch. For example, you might want all your feature branches to point to the backend resources deployed by the dev branch so you can reuse seed data, users, and groups.

You can update your app build settings to share resources across branches. From the Amplify console, go to your App overview page, select Build settings under the Hosting for viewing your app's build specification YAML file.

Update the build settings for the backend phase to run npx ampx generate outputs --branch dev app-id $AWS_APP_ID to generate the amplify_outputs.json file for all branches other than main or dev. After this update, any new deployed branches will not deploy backend resources as part of the build and instead will use the deployed backend resources from the dev branch. Update the build settings for the backend phase to run npx ampx generate outputs --branch dev app-id $AWS_APP_ID to generate the amplify_outputs.json file for all branches other than main or dev. After this update, any new deployed branches will not deploy backend resources as part of the build and instead will use the deployed backend resources from the dev branch.

amplify.yml
Copy
amplify.yml code example
version: 1
backend:
    phases:
        build:
            commands:
                - 'npm ci --cache .npm --prefer-offline'
                - 'echo $AWS_BRANCH'
                - |
                  case "${AWS_BRANCH}" in
                      main)
                          echo "Deploying main branch..."
                          npx ampx pipeline-deploy --branch $AWS_BRANCH --app-id $AWS_APP_ID
                          ;;
                      dev)
                          echo "Deploying dev branch..."
                          npx ampx pipeline-deploy --branch $AWS_BRANCH --app-id $AWS_APP_ID
                          ;;
                      pr-*)
                          echo "Deploying pull request branch..."
                          npx ampx generate outputs --branch previews --app-id $AWS_APP_ID
                          ;;
                      *)
                          echo "Deploying to staging branch..."
                          npx ampx generate outputs --branch dev --app-id $AWS_APP_ID
                          ;;
                  esac
frontend:
    phases:
        build:
            commands:
                - 'npm run build'
    artifacts:
        baseDirectory: .next
        files:
            - '**/*'
    cache:
        paths:
            - .next/cache/**/*
            - .npm/**/*
            - node_modules/**/*
PREVIOUS
Secrets and environment vars
NEXT
Separate frontend and backend teams

--------------------------------------------------------------------------------

Title: Fullstack branch deployments - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/deploy-and-host/fullstack-branching/branch-deployments/
HTML Content:
Next.js
/
Deployment
/
Fullstack workflows
/
Fullstack branch deployments
Fullstack branch deployments

Amplify code-first DX (Gen 2) offers fullstack branch deployments that allow you to automatically deploy infrastructure and application code changes from feature branches. This enables testing changes in an isolated environment before merging to the main branch.

Set up feature branch deployments

After you've deployed your first branch, you can manually connect more, but the recommended workflow is to use the branch auto-detection feature.

Log in to the Amplify console and choose your app.

Navigate to App settings > Branch settings, select Edit and enable Branch auto-detection and Branch auto-disconnection. The following video uses the default settings, which will connect any branch in your repo automatically. Branch auto-disconnection will ensure that if you delete a branch from your repository, the branch will also be deleted.

You can also define a pattern to connect only certain branches. For example, setting dev, staging, and feature/* will automatically connect all three branch types. Your dev and staging branches, as well as any branch that begins with feature/, will be connected.

Push a commit to your feature/A and staging branches that match the pattern. You should start seeing deployments on the console page. You will now have three fullstack branches deployed.

Promote changes to production

In Gen 2, promoting changes to production follows the normal Git-based workflow.

Make a change in your feature/A branch.
Terminal
Copy
Terminal code example
git checkout -b feature/A


## make some edits to your code


git commit --am "New data model to track comments for todos added"


git push origin feature/A
Submit a pull request to your main branch. Once your team has validated the changes, merge the pull request to main. This will initiate a build on your main branch and update any frontend or backend resources that you changed.
Generate client config

You can generate the config for a branch environment by running:

For Web and React Native, generating the config with the default format and output directory.

Terminal
Copy
Terminal code example
npx ampx generate outputs --app-id <your-amplify-app-id> --branch <your-git-branch-name> --out-dir <path/to/config>
NEXT
Secrets and environment vars

--------------------------------------------------------------------------------

Title: Fullstack workflows - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/deploy-and-host/fullstack-branching/
HTML Content:
Next.js
/
Deployment
/
Fullstack workflows
Fullstack workflows
Fullstack branch deployments
Use fullstack branch deployments to test changes from feature branches.
Secrets and environment vars
Manage secrets and environment variables across your fullstack branch and local dev environments.
Share resources across branches
Update app build settings to share resources across branches.
Separate frontend and backend teams
Set up multiple repositories with the Amplify CI/CD pipeline.
Monorepo setup
Set up monorepos with the Amplify CI/CD pipeline.
Fullstack previews
Set up ephemeral fullstack environments with pull request previews.
Custom pipelines
Set up fullstack CI/CD in a custom pipeline.
Cross-account deployments
Set up a cross-account deployment pipeline powered by Amazon CodeCatalyst and AWS Amplify Hosting.

--------------------------------------------------------------------------------

Title: Sandbox features - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/deploy-and-host/sandbox-environments/features/
HTML Content:
Next.js
/
Deployment
/
Cloud sandbox environments
/
Sandbox features
Sandbox features

Sandbox environments include additional features for managing secrets, deploying multiple sandboxes, config generation, and client codegen for your Amplify app.

Secure secrets in your sandbox

Secrets set in a sandbox do not show up in the Amplify Console. You can view them in the AWS Systems Manager (SSM) Parameter Store console.

Amplify Gen 2 offers secure secret storage to manage sensitive data like API keys and database credentials. Secrets are similar to environment variables, but they are encrypted AWS Systems Manager Parameter Store key value pairs. Secrets are stored in AWS Parameter Store under the /amplify prefix.

Set secrets

You can add secrets to your sandbox environment using the following command:

Copy
code example
npx ampx sandbox secret set foo
? Enter secret value: ###
Done!


npx ampx sandbox secret set bar
? Enter secret value: ###
Done!

After these commands, your sandbox will have two secrets named foo and bar.

List secrets

You can list all of the secret names available in your sandbox environment with the following command:

Copy
code example
npx ampx sandbox secret list
 - foo
 - bar
Retrieve a secret

Note: This will print a secret value in plain text to the terminal. Do not use this command anywhere that terminal logs may be stored (such as CI/CD jobs).

To show the value of a secret, run the following command.

Copy
code example
npx ampx sandbox secret get foo
name: foo
version: 1
value: abc123
lastUpdated: Mon Nov 13 2023 22:19:12 GMT-0800 (Pacific Standard Time)
Remove secrets

To remove a secret from from the sandbox, run the following command in your terminal:

Copy
code example
npx ampx sandbox secret remove foo
Reference secrets

Once you have set a secret, you can reference the secret in your backend definition using the secret() function. The following example shows how to set up social sign-in with authentication in your app. Depending on your environment, Amplify will automatically load the correct secret value.

import { defineAuth, secret } from '@aws-amplify/backend';


export const auth = defineAuth({
  loginWith: {
    email: true,
    externalProviders: {
      facebook: {
Copy
highlighted code example
        clientId: secret('foo'),
        clientSecret: secret('bar')
      }
    }
  }
});

The secret() function does NOT retrieve the value of the secret. It places a reference to the secret value in the backend definition. The secret value is only resolved during deployment of your backend.

The secret() function can only be used in specific places in your backend definition such as configuring auth providers and function secrets.

To deploy a backend that uses secret() references via Amplify hosting, the secret values must be configured for the Amplify app or branch

Work with multiple AWS profiles

Sometimes you might have multiple AWS profiles set up locally. To run ampx sandbox secret commands, use the --profile flag to deploy to a specific profile. For example, let's say you have two AWS profiles set up locally—default and work. To add secrets to the sandbox in the work profile, run the following command in your terminal:

Copy
code example
npx ampx sandbox secret set foo --profile work
Work with multiple named sandboxes

Provisioning multiple sandboxes per app is possible but not recommended because managing multiple ephemeral environments for a single developer introduces complexity. With multiple sandboxes, it can be difficult to keep track of what code version or configuration is deployed where. Sticking to a single sandbox per developer keeps your workflows simpler.

You can create multiple sandboxes if you want to have different features or test environments available in different sandboxes. By default, your sandbox is named based on the local machine username. To override this name, use the --identifier option:

Copy
code example
npx ampx sandbox --identifier feature1sandbox

This will start a sandbox named feature1sandbox.

Once the deployment completes, exit sandbox and run the following command in the terminal:

Copy
code example
npx ampx sandbox --identifier feature2sandbox

After successful deployment, you will have two sandboxes feature1sandbox and feature2sandbox. You can switch between them but only one can be running at a time.

Secret management with named sandboxes

When working with multiple sandboxes, secrets must be configured for each one. All of the sandbox secret commands accept the --identifier argument to manage secrets for named sandboxes. For example, to add a secret to feature1sandbox, use:

Copy
code example
npx ampx sandbox --identifier feature1sandbox secret set baz
Stream function logs

Amplify offers the ability to stream function logs directly to your terminal or a file. Learn more about streaming function logs.

Generate client config

The client config, or amplify_outputs.json file, contains the configuration strings for interacting with AWS resources specific to an environment. The Amplify client libraries need the client config in order to use the library APIs to connect to backend resources. By default, the cloud sandbox generates the client configuration file at the root of the project (such as @/amplify_outputs.json). If you want to place the file at a different path (such as for a monorepo or Android app), run the following command in the terminal:

Terminal
Copy
Terminal code example
npx ampx sandbox --outputs-out-dir ./path/to/config --outputs-format ["json", "dart"]

Alternatively, if you want to generate the config for a branch environment to test against, run the following command in the terminal.

Copy
code example
npx ampx generate outputs --app-id <your-amplify-app-id> --branch main --format ["json", "dart"] --out-dir ./path/to/config
Deployment Environment

Alternatively, if you want to generate the config for a branch environment to test against, you can run the following command below in the terminal:

For Web and React Native, generating the config with the default format and output directory.

Terminal
Copy
Terminal code example
npx ampx generate outputs --app-id <app-id> --branch main
Generate client codegen

Amplify Gen 2 introduces a fully typed experience for data that no longer requires an explicit codegen step, unlike in Amplify Gen 1. You will only need this command if you are building a mobile app or have Gen 1 requirements.

Codegen generates native code for Swift (iOS), Java (Android), and JavaScript that represents your GraphQL API's data models. It can also generate GraphQL statements (queries, mutations, and subscriptions) so that you don't have to manually code them.

Once your sandbox completes a deployment, you can run the following command in the terminal to generate client code that is specific to your needs:

Copy
code example
npx ampx generate graphql-client-code
--format [choices: "modelgen", "graphql-codegen", "introspection"]
Delete a sandbox

You can delete a cloud sandbox environment in several ways:

Ctrl+C your sandbox and choose to delete resources.
Run npx ampx sandbox delete or npx ampx sandbox delete --name
Visit the Amplify console and delete sandboxes.
PREVIOUS
Use cloud sandbox in dev environment

--------------------------------------------------------------------------------

Title: Use cloud sandbox in dev environment - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/deploy-and-host/sandbox-environments/setup/
HTML Content:
Next.js
/
Deployment
/
Cloud sandbox environments
/
Use cloud sandbox in dev environment
Use cloud sandbox in dev environment

You can use a personal cloud sandbox environment that provides an isolated development space to rapidly build, test, and iterate on a fullstack app. Each developer on your team can use their own disposable sandbox environment connected to cloud resources.

Cloud sandbox environments are not intended for production workloads.

Create a new sandbox environment

You can set up a new sandbox environment on your machine once you have an Amplify app set up. If you have not yet created an Amplify Gen 2 app, visit the Quickstart.

First, open the terminal and run the following command:

Terminal
Copy
Terminal code example
npx ampx sandbox

When you deploy a cloud sandbox, Amplify creates an AWS CloudFormation stack following the naming convention of amplify-<app-name>-<$(whoami)>-sandbox in your AWS account with the resources configured in your amplify/ folder.

After a successful deployment, sandbox watches for file changes in your amplify/ folder and performs real-time updates to the associated CloudFormation stack. This functionality is built leveraging the hot swap capability of the AWS Cloud Development Kit (CDK).

Terminating a sandbox environment

After testing all the changes associated with the backend, you can terminate the sandbox session via Ctrl+c and can then choose whether you want to keep or delete all the resources in the sandbox environment.

Manage sandbox environments

You can view and manage all the sandbox environments for your team in the new Amplify console. This is useful for a team leader to audit all of the Amplify sandbox environments deployed within an account.

Choose Manage Sandboxes to get started:

You can then check the number, status, and last updates for sandbox environments across your team. You can also use the console to delete sandbox environments when no longer needed.

Best practices

Keep the following best practices in mind when working with cloud sandbox environments:

Sandboxes are identical in fidelity to your production environments.
Code changes are continuously deployed to your sandbox on every save for fast iterations.
Use sandboxes for experimentation and testing, not for production workloads.
Deploy one sandbox per Amplify app per developer to prevent conflicts.
Reset sandboxes occasionally to clear out unused resources and save costs.
NEXT
Sandbox features

--------------------------------------------------------------------------------

Title: Cloud sandbox environments - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/deploy-and-host/sandbox-environments/
HTML Content:
Next.js
/
Deployment
/
Cloud sandbox environments
Cloud sandbox environments
Use cloud sandbox in dev environment
Set up a cloud sandbox environment you can use with your frontend dev environment.
Sandbox features
Explore sandbox features such as secrets, client codegen, and config generation for mobile and cross-platform.

--------------------------------------------------------------------------------

Title: Manage form lifecycle - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-ui/formbuilder/lifecycle/
HTML Content:
Next.js
/
Build UI
/
Connected forms
/
Manage form lifecycle
Manage form lifecycle

Hook into the form's lifecycle events to customize user input before submission, run validations, or handle errors.

Initial state - The inputs are either empty or pre-populated based on a default value provided by you.

Use case: If your user clicks on the Clear or Reset button, they'll be brought back to this state.

onChange - Event when form data is changed by the user.

Use case: Use this to get the form data after every user input.

onValidate - Event hook for custom validations. This event triggers after onChange.

Use case: Use this to extend validation rules via code. onValidate also supports asynchronous validation rules, which enable you to validate the form input against external APIs.

onSubmit - Event when your user clicks the Submit button.

Use case: If your form is not connected to a data model, use set this event handler to retrieve the form data. If your form is connected to a data model, use this to customize the provided form data before they are saved to the cloud.

onSuccess - Event when saving form data to the cloud succeeds.

Use case: Use this to dismiss the form or reroute your user after a successful form submission. Only use this if your form is connected to a data model.

onError - Event when saving form data to the cloud fails.

Use case: Use this to log the error and investigate further if your validation rules need to be enhanced to catch input formatting issues. Only use this if your form is connected to a data model.

onCancel - Event when your user clicks on the Cancel button.

Use case: Use this to dismiss the form without saving the form data.

Get form data as your user inputs data - onChange

In some cases, you want to get the form data in real-time as the user is filling the form. The onChange event provides you the form data in the fields parameter.

Copy
code example
import { useState } from 'react'
import { HomeCreateForm } from './ui-components'


function App() {
  const [formData, setFormData] = useState()


  return (
    <HomeCreateForm onChange={fields => setFormData(fields)}/>
  )
}
Extend validation rules in code - onValidate

With the onValidate event, you can extend the validation rules in code. Learn more about How to add validation rules.

Handle form data submissions - onSubmit

onSubmit should be your default way to handle form submission. It is triggered every time the user clicks on the Submit action button.

You can use the onSubmit handler to customize the form data before they are saved to the cloud. The form data that's returned from the onSubmit handler will be saved to the cloud.

For example, if you want to trim all the string data before saving it:

Copy
code example
<HomeCreateForm
    onSubmit={(fields) => {
        const updatedFields = {}
        Object.keys(fields).forEach(key => {
            if (typeof fields[key] === 'string') {
                updatedFields[key] = fields[key].trim()
            } else {
                updatedFields[key] = fields[key]
            }
        })
        return updatedFields
    }}
/>
Handle form data successfully saving to the cloud - onSuccess

You can use the onSuccess handler to take an action after the form data has been successfully submitted. The example below hides the form after it has been successfully submitted.

Copy
code example
import { useState } from 'react'
import { HomeCreateForm } from './ui-components'


function App() {
  const [showForm, setShowForm] = useState(true)


  return (
    {showForm &&
      <HomeCreateForm onSuccess={() => {
        setShowForm(false) // Hide the form
      }}/>}
  )
}
Handle form submission errors - onError

You might encounter additional errors during the submit process. You can log these errors and present an alert to customers by using the onError handler.

Copy
code example
import { HomeCreateForm } from './ui-components'


function App() {
  return (
    <HomeCreateForm onError={(error) => {
      console.log(error)
    }}/>
  )
}
Handle user clicking on Cancel action button - onCancel

If the user clicks on the Cancel action button, you can use the onCancel event to hide the form or route the customer to another page.

Copy
code example
import { useState } from 'react'
import { HomeCreateForm } from './ui-components'


function App() {
  const [showForm, setShowForm] = useState(true)


  return (
    {showForm &&
      <HomeCreateForm onCancel={() => {
        setShowForm(false) // Hide the form
      }}/>}
  )
}
PREVIOUS
Validate form data

--------------------------------------------------------------------------------

Title: Deployment - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/deploy-and-host/
HTML Content:
Next.js
/
Deployment
Deployment
Frontend hosting
Host static and server-rendered web apps built with modern JS frameworks like Next.js, Vue, and React.
Cloud sandbox environments
Learn about sandbox development.
Fullstack workflows
Overview of fullstack branching capabilities.

--------------------------------------------------------------------------------

Title: Frontend hosting - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/deploy-and-host/hosting/
HTML Content:
Next.js
/
Deployment
/
Frontend hosting
Frontend hosting

AWS Amplify Hosting is a fully managed CI/CD and hosting service for fast, secure, and reliable static and server-side rendered apps that scale with your business. This service supports modern web frameworks such as React, Angular, Vue, Next.js, Nuxt.js, Gatsby, and more.

Because AWS Amplify Hosting is a fully managed service, its documentation lives on the AWS Documentation site. To learn about hosting features such as custom domains, redirects, and more, please visit the Hosting documentation.

View Hosting Docs

--------------------------------------------------------------------------------

Title: Figma-to-React - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-ui/figma-to-code/
HTML Content:
Next.js
/
Build UI
/
Figma-to-React
Figma-to-React

You can generate React code using the Amplify UI Figma file and the Amplify UI Builder plugin.

Step 1: Duplicate the Amplify UI Figma file

This file contains the following pages:

README: The README page explains how to use the Figma file to create new components, theme primitives, and customize layout and styling.
Theme: The theme page displays the theme values and design tokens Amplify UI uses to style the primitives. If you want to theme the primitives, use the AWS Amplify UI Builder Figma plugin to make changes to the theme. Any changes you make on the theme page itself will not be generated in code.
Primitives: Primitives are building-block components such as alerts, buttons, and badges. These primitives correspond to the Amplify UI primitives and get exported to code with all the primitive properties. This page is read-only. Changes to the primitives on this page will not be reflected in code that is generated.
My components: This page contains all of the custom components built using the primitives. Amplify provides dozens of components such as news feed, social media, and marketing hero components to get you started. Customize these to match your needs or build your own components.
Examples: This is for demonstration purposes only, to show designers how to use our components to build entire pages.

Please follow the README in our Figma file to learn how to create your components to optimize for code quality.

Step 2: Run the Amplify UI Builder Figma plugin in dev mode

After you duplicate the Figma file, you run the Amplify UI Builder figma plugin in dev mode or non-dev mode to generate Amplify UI React code.

Dev Mode
Turn on Figma dev mode in your Figma file.
Click on the Plugins tab.
Select the AWS Amplify UI Builder plugin.
Choose any layer in your file to get React code and a live preview of the generated code.
Non-dev Mode
Click on the Plugins tab.
Select the AWS Amplify UI Builder plugin.
Choose Download component code to download the React code for your components.

--------------------------------------------------------------------------------

Title: Validate form data - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-ui/formbuilder/validations/
HTML Content:
Next.js
/
Build UI
/
Connected forms
/
Validate form data
Validate form data

Sanitize user input by adding validation rules to your form. By default, Amplify generated forms infers a range of validation rules based on the data model. For example, given a data model with an AWSEmail field, the generated form input will automatically run an email validation rule.

Configurable validation rules

By default, the following validation rules are available for you to configure:

Input type	Configurable validation rule
String	- Start With
- End With
- Contain
- Does not contain
- Be less than N characters long
- Be at least N characters long

Int, Float	- Be greater than
- Be less than
- Be equal to

AWSDate, AWSTime, AWSDateTime	- Be before
- Be after

Automatically configured validation rules

For the types below, we automatically apply validation rules on form inputs:

AWSIPAddress: input value must be a valid IPv4 or IPv6 address.
AWSURL: input value must consist of a schema (http, mailto) and a path part. Path part can't contain two forward slashes (//).
AWSEmail: input value must be an email address in the format <local-part>@<domain-part>.
AWSJSON: input value must be a valid JSON.
AWSPhone: input value must be a phone number that can contain either spaces or hyphens to separate digit groups.
Add validation rules

Every form provides an onValidate event handler to provide additional validation rules via code. Return an object with validation functions for the fields you want to validate. In the example below, address must start with a number, otherwise return any existing auto-generated validation responses.

Copy
code example
<HomeCreateForm
  onValidate={{
    address: (value, validationResponse) => {
      const firstWord = value.split('')[0];
      if (!isNaN(str)) {
        // check if the first word is a number
        return {
          hasError: true,
          errorMessage: 'Address must start with a number'
        };
      }
      return validationResponse;
    }
  }}
/>

Note: the validation function must return a validation response of the following shape:

Copy
code example
type ValidationResponse = {
  hasError: boolean;
  errorMessage?: string;
};
Add validation rules for nested JSON data

Amplify generated forms can also produce nested JSON object. For example, you can create a new ProductForm component based on the following JSON object:

Copy
code example
{
  "name": "Piano",
  "price": {
    "maxDiscount": 0.15,
    "default": 999,
    "currency": "$"
  }
}

To add validation rules to the nested objects, pass in validation functions in the same nested structure as the data:

Copy
code example
<ProductForm
  onValidate={{
    price: {
      currency: (value, validationResponse) => {
        // Pass validation function to match the nested object
        const allowedCurrencies = ['$', '€', '￥', '₹'];
        if (!allowedCurrencies.includes(value)) {
          return {
            hasError: true,
            errorMessage: 'Currency must be either "$", "€", "￥", or "₹".'
          };
        }
        return validationResponse;
      }
    }
  }}
  onSubmit={(fields) => {
    /* handle form data submission */
  }}
/>
Call external APIs for asynchronous form validation

Sometimes your form needs to asynchronously validate an input with an external API or database before the form data is submitted.

Return a Promise in the onValidate prop to run an asynchronous validation rule. In the following example, we check with an external API if a real estate agent exist based on a given license number:

Copy
code example
<AgentContactForm
  onValidate={{
    licenseNumber: (value, validationResponse) => {
      // fetch calls an external API,
      // which ultimately returns a Promise<ValidationResponse>
      return fetch(`http://localhost:3000/api/agent/${value}`).then(
        (response) => {
          if (response.status !== 200) {
            return {
              // If the request failed, return a validation error
              hasError: true,
              errorMessage: 'No agent was not found with that license number.'
            };
          }
          return validationResponse;
        }
      );
    }
  }}
  onSubmit={(fields) => {
    /* Handle form submission */
  }}
/>
PREVIOUS
Configure special inputs
NEXT
Manage form lifecycle

--------------------------------------------------------------------------------

Title: Configure special inputs - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-ui/formbuilder/special-inputs/
HTML Content:
Next.js
/
Build UI
/
Connected forms
/
Configure special inputs
Configure special inputs
Storage Manager

Storage Manager fields allow your forms to accept file uploads, which are stored in an Amazon S3 bucket connected to your Amplify app. After uploading, that file's S3 key is stored in your data model, allowing for systematic retrieval using the Amplify JS library.

Prerequisites

In order to use the Storage Manager field, your Amplify app must have an Amplify app with Authentication and Storage enabled.

How it works

The Storage Manager input will allow users to select from files on their local device and upload them to an S3 bucket. Storage Manager automatically connects to your S3 bucket added as part of Amplify Storage.

Files are uploaded immediately upon selection, and an S3 key is generated. By default, Storage Manager will generate a unique S3 key based on the file uploaded. On form submission, Storage Manager will return the S3 key of the uploaded file as a String.

Adding it to your form

To use the StorageManager component with an autogenerated form you will first need a data model that has an attribute that is either a string or an array of strings (a.string().array() in amplify/data/resource.ts). Then make sure to run npx ampx generate forms after you update your data model.

Then go into the generated form JSX file you want to use the StorageManager, for example: ui-components/TodoCreateForm.jsx. If your attribute is an array of strings, look for an <ArrayField> with items={images} (if your attribute name is "images"). Remove that entire component and replace it with the StorageManager component like this:

ui-components/TodoCreateForm.jsx
Copy
ui-components/TodoCreateForm.jsx code example
// imports
import { StorageManager } from "@aws-amplify/ui-react-storage";
// import the processFile helper function which will create unique filenames based on the file contents
import { processFile } from "./utils";


//...
<StorageManager
  accessLevel="public"
  maxFileCount={10}
  acceptedFileTypes={['image/*']}
  processFile={processFile}
  onUploadSuccess={({key}) => {
    // assuming you have an attribute called 'images' on your data model that is an array of strings
    setImages(prevImages => [...prevImages, key])
  }}
  onFileRemove={({key}) => {
    setImages(prevImages => prevImages.filter(img => img !== key))
  }}
/>

If you want your data model to have only one image instead of an array of images, look for the <TextField> component with value={image} and replace it with the StorageManager component like this:

ui-components/TodoCreateForm.jsx
Copy
ui-components/TodoCreateForm.jsx code example
// imports
import { StorageManager } from "@aws-amplify/ui-react-storage";
// import the processFile helper function which will create unique filenames based on the file contents
import { processFile } from "./utils";


//...
<StorageManager
  accessLevel="public"
  maxFileCount={1}
  acceptedFileTypes={['image/*']}
  processFile={processFile}
  onUploadSuccess={({key}) => {
    // assuming you have an attribute called 'images' on your data model that is an array of strings
    setImage(key)
  }}
  onFileRemove={({key}) => {
    setImage(undefined)
  }}
/>

See the documentation for the StorageManager for all configuration options.

Unique S3 keys

If files with identical S3 keys are uploaded to the same path, S3 will overwrite those files. To prevent accidental overwriting of files, Storage Manager generates a unique S3 key by hashing the file contents. Uploading different files with the same name will not overwrite the original file.

However, if a form submitter uploads two identical files to the same path - even with different file names - Storage Manager will prevent file duplication in your S3 bucket.

File overwriting only occurs for identical S3 keys in the same path. If the File level access for your Storage Manager is set to private or protected, identical files uploaded by separate users will be saved separately.




If your File level access is set to public, identical files will overwrite each other.

PREVIOUS
Customize form inputs
NEXT
Validate form data

--------------------------------------------------------------------------------

Title: Customize form inputs - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-ui/formbuilder/customize/
HTML Content:
Next.js
/
Build UI
/
Connected forms
/
Customize form inputs
Customize form inputs

In this guide, you will learn how to customize connected forms that are generated by running npx ampx generate forms. Before you begin you will need:

Your cloud sandbox with an Amplify Data resource up and running (npx ampx sandbox)
A frontend application that has generated a connected form

All Amplify forms are built with the Amplify UI library. The generated form provides a mechanism to override properties for each individual input component, like TextField, TextAreaField, SelectField. You can override any props to those components with the overrides prop on the form component. For example, if you want to change the variation and label of the content field in the TodoCreateForm:

import TodoCreateForm from '@/ui-components/TodoCreateForm'


<TodoCreateForm
Copy
highlighted code example
  overrides={{
    content: {
      variation: 'quiet',
      label: 'Todo'
    }
  }}
/>

Note: We do not recommend overriding properties that are already set by the generated form. This could lead to unexpected behavior during runtime. Verify the set properties by navigating to the component in the src/ui-components/[your-form-component].jsx file.

You own updating the code directly for the generated form. Here's how you can customize the form.

Manually add form input field

You can manually add a form input connected to a data model to the generated form. For example, let's say you add a priority field to your data model. Make the following edits to the generated form:

src/ui-components/TodoCreateForm.js
// 1. Set initialValues
  const initialValues = {
    content: "",
Copy
highlighted code example
    priority: "" // Initial value for priority
  };


  // 2. State setup
  const [priority, setPriority] = React.useState(initialValues.priority);


  // 3. Update resetValues
  const resetStateValues = () => {
    .. // previous fields
Copy
highlighted code example
    setPriority(initialValues.priority)
    setErrors({});
  };


  // 4. Validation setup
  const validations = {
    content: [],
Copy
highlighted code example
    priority: [] // Assuming no special validations for now
  };


  // 5. Update form submission
   onSubmit={async (event) => {
        event.preventDefault();
        let modelFields = {
          ..,
Copy
highlighted code example
          priority
        };


  // 6. Add TextField
  <TextField
     label="Priority"
     isRequired={false}
     isReadOnly={false}
     value={priority}
     onChange={(e) => {
       let { value } = e.target;
       if (onChange) {
         const modelFields = {
           priority: value,
         };
         const result = onChange(modelFields);
         value = result?.priority ?? value;
       }
       if (errors.priority?.hasError) {
         runValidationTasks("priority", value);
       }
       setPriority(value);
     }}
     onBlur={() => runValidationTasks("priority", priority)}
     errorMessage={errors.priority?.errorMessage}
     hasError={errors.priority?.hasError}
     {...getOverrideProps(overrides, "priority")}
   />
Manually add option fields

Select Fields, Radio Group Fields, and Autocomplete Fields require a set of options for your users to choose from. For example, a "Status" input can only have the options "Not started", "In progress", and "Done". This would be identical to the above 6 steps, but in step 6 you would replace <TextField> with <SelectField>

src/ui-components/TodoCreateForm.js
Copy
src/ui-components/TodoCreateForm.js code example
// 6. Import <SelectField> component and add to form return
  <SelectField
    label="Label" 
    placeholder="Please select an option" 
    value={status} 
    onChange={(e) => {
      let { value } = e.target;
      if (onChange) {
          const modelFields = {
              status: value
          };
          const result = onChange(modelFields);
          value = result?.status ?? value;
      }
      if (errors.status?.hasError) {
          runValidationTasks("status", value);
      }
      setStatus(value);
      }} 
      onBlur={() => runValidationTasks("status", status)}
      errorMessage={errors.status?.errorMessage} 
      hasError={errors.status?.hasError} 
      {...getOverrideProps(overrides, "status")}
    >
      <option children="Not started" value="Not started" {...getOverrideProps(overrides, "statusOption0")}></option>
      <option children="In progress" value="In progress" {...getOverrideProps(overrides, "statusOption1")}></option>
      <option children="Done" value="Done" {...getOverrideProps(overrides, "statusOption2")}></option>
  </SelectField>
Configure form spacings (paddings and gaps)

Add spacing to your form and between inputs. Spacing values can either be a CSS length value (px, rem, em, %) or a reference to your theme object's spacing value (xss, medium, large).

import TodoCreateForm from '@/ui-components/TodoCreateForm'


<TodoCreateForm overrides={{
Copy
highlighted code example
  TodoCreateForm: {
    rowGap: 'xl',    // horizontal gap between inputs
    columnGap: 'xs', // vertical gap between inputs
    padding: 'xl',   // padding around form
  },
}} />
Customize label for Submit and Clear buttons

You can customize action button labels to better describe your form's use case, such as changing Submit to Create Todo.

import TodoCreateForm from '@/ui-components/TodoCreateForm'


<TodoCreateForm overrides={{
Copy
highlighted code example
  ClearButton: {
    children: 'Close'
  },
  SubmitButton: {
    children: 'Save todo'
  }
}} />
Toggle visibility for Submit and Clear buttons

You can customize the visibility of action buttons to better accommodate your form's use case.

import TodoCreateForm from '@/ui-components/TodoCreateForm'


<TodoCreateForm overrides={{
Copy
highlighted code example
  ClearButton: {
    display: 'none'
  },
  SubmitButton: {
    display: 'none'
  }
}} />

If you hide all form action buttons, you can still leverage the onChange event handler to self-manage the form lifecycle. This is useful for a form that updates data in real-time without explicit user confirmation.

import TodoCreateForm from '@/ui-components/TodoCreateForm'


<TodoCreateForm
Copy
highlighted code example
  onChange={(fields) => {
    console.log({ fields })
    // make sure you return fields!
    return fields
  }}
/>
NEXT
Configure special inputs

--------------------------------------------------------------------------------

Title: Connected forms - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-ui/formbuilder/
HTML Content:
Next.js
/
Build UI
/
Connected forms
Connected forms

Connected Forms are bound to a model in your app's data schema. Whenever a connected form is submitted, a record is automatically created or updated in the bound data model, with some or all of the form's input fields mapping to fields in the data model. Connected forms automatically work with any Amplify GraphQL API, and no onSubmit handling is required.

Generate forms

First, install the Amplify UI library.

Terminal
Copy
Terminal code example
npm add @aws-amplify/ui-react

To use connected forms, you first need to deploy a data model from your sandbox environment. We will use the same example as in the getting started tutorial. To get started run the following command from your project root:

Terminal
Copy
Terminal code example
npx ampx generate forms

This will generate create and update forms for each model defined in your schema in a folder called ui-components.

Terminal
Copy
Terminal code example
File written: ui-components/graphql/subscriptions.ts
File written: ui-components/graphql/mutations.ts
File written: ui-components/graphql/queries.ts
File written: ui-components/TodoCreateForm.jsx
File written: ui-components/TodoCreateForm.d.ts
File written: ui-components/TodoUpdateForm.jsx
File written: ui-components/TodoUpdateForm.d.ts
File written: ui-components/utils.js
File written: ui-components/index.js
Re-generating forms

In Gen 2, we automatically generate the form UI for you, which you can then customize and manage. If you decide to update your data model and need to regenerate the forms, please ensure you back up the original ui-components folder before executing the npx ampx generate forms command again.

Render React form in your app
In your application's entrypoint file (e.g. src/index.js for create-react-app or src/main.jsx for Vite), add the following imports and configuration
Copy
highlighted code example
import '@aws-amplify/ui-react/styles.css';
import { ThemeProvider } from '@aws-amplify/ui-react';
import { Amplify } from 'aws-amplify';


import outputs from './amplify_outputs.json';


Amplify.configure(outputs);
In your application's entrypoint file (e.g. src/main.jsx for Vite), wrap the <App /> component with the following:
Copy
code example
<ThemeProvider>
  <App />
</ThemeProvider>
Import your form by name. For a form named TodoCreateForm, you would use the following code:
Copy
code example
import { TodoCreateForm } from './ui-components';
Place your form in code. For a form named ProductCreateForm in a React project, you could use the following App code:
Copy
code example
function App() {
  return <TodoCreateForm />;
}


export default App;
Types of forms

All connected and unconnected forms are either a Create form or an Update form.

Create forms

Create forms render a form with empty inputs. If a create form is connected to a data model, will always generate a new record upon submission.

Update forms

Update forms expect an input value in order to pre-populate the form.

For update forms that are connected to a data model, you can use the id prop, or the model prop:

id prop: id string of the record you want to update. For example:
Copy
code example
<AuthorUpdateForm id="ac74af5c-3aab-4274-8f41-23e1e6576af5" />
Model prop: if your form is bound to a data model named Author, your form will have a prop named author as well, which can receive a record. For example:
Copy
code example
<AuthorUpdateForm author={authorRecord}>

--------------------------------------------------------------------------------

Title: Build UI - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-ui/
HTML Content:
Next.js
/
Build UI
Build UI

Amplify offers a UI Library that makes it easy to build web app user interfaces that are connected to the backend. Amplify UI offers:

Connected components that are designed to work seamlessly with AWS Amplify backend services, allowing you to quickly add common UX patterns for authentication, storage etc. without having to build them from scratch.
Tooling that generates React forms over data, and React components from Figma designs.
Connected forms
Generate React forms for creating and updating data in your Amplify data backend.
Figma-to-React
Generate React code directly inside Figma using Amplify UI.
Authenticator
The Authenticator is a connected component that adds complete authentication flows to your application with minimal boilerplate.
Storage Image
Storage Image is a connected component that simplifies the process of displaying images stored in an Amazon S3 bucket.
Storage Manager
Storage Manager is a connected component that facilitates operations such as uploading, downloading, listing, and deleting files from an Amazon S3 bucket.
Account Settings
Account Settings components are a set of standalone components that add user management flows to your application with minimal boilerplate. . .
Face Liveness
FaceLivenessDetector is a connected component that helps verify that only real users, not bad actors using spoofs, can access your services.

--------------------------------------------------------------------------------

Title: Use Amazon Q Developer with Amplify - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/q-developer/
HTML Content:
Next.js
/
Build & connect backend
/
Use Amazon Q Developer with Amplify
Use Amazon Q Developer with Amplify

Amazon Q Developer is a generative artificial intelligence (AI) powered conversational assistant that can help you understand, build, extend, and operate AWS applications. You can ask questions about AWS architecture, your AWS resources, best practices, documentation, support, and more. Amazon Q is constantly updating its capabilities so your questions get the most contextually relevant and actionable answers. When used in an integrated development environment (IDE), Amazon Q provides software development assistance. Amazon Q can chat about code, provide inline code completions, generate net new code, scan your code for security vulnerabilities, and make code upgrades and improvements, such as language updates, debugging, and optimizations.

Q Developer in the IDE provides inline code suggestions in real time. As you write code, Amazon Q automatically generates suggestions based on your existing code and comments. When you start typing out single lines of code or comments, Amazon Q makes suggestions based on your current and previous inputs. Inline suggestions are automatically enabled when you download the Amazon Q extension.

Setting up Q Developer

Amazon Q is available as an extension in Visual Studio Code and a plugin in JetBrains. Amazon Q is also available in the AWS Toolkit for Visual Studio. To get started, please visit Install Amazon Q Developer.

Use Q Developer - Inline code suggestions in your Amplify project

Amplify generates two folders in your backend directory, auth and data, which contain TypeScript AWS CDK definitions for each of these resources. We’ll build out the schema for our API through the help of Amazon Q Developer's inline code suggestion capabilities.

Step 1: Open amplify/data/resource.ts and comment out the default schema for Todo provided.

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
import { type ClientSchema, a, defineData } from "@aws-amplify/backend";


// ...


// const schema = a.schema({
//   Todo: a
//     .model({
//       content: a.string(),
//     })
//     .authorization(allow => [allow.publicApiKey()]),
// });


// ...

Step 2: In a new line below the commented schema, enter a comment to generate the schema using natural language. For example, generate a restaurant model with the following fields: id, name, description, address, image, rating, style. Rating can be a float value. Authorization should allow public. Press Enter for a new line and wait for Amazon Q Developer to generate inline code suggestion for your schema.

amplify/data/resource.ts
import { type ClientSchema, a, defineData } from "@aws-amplify/backend";


// ...


// const schema = a.schema({
//   Todo: a
//     .model({
//       content: a.string(),
//     })
//     .authorization(allow => [allow.publicApiKey()]),
// });


Copy
highlighted code example
// generate a restaurant model with the following fields: id, name, description, address, image, rating, style. Rating can be a float value. Authorization should allow public.


// ...

Step 3: Select the inline code suggestion generated by Amazon Q developer. The inline code suggestion feature assists you in defining the schema and hover over the output to select from other options.

Note: You can also trigger inline code suggestion feature by invoking Amazon Q Developer manually using Option+C keyboard shortcut in VS Code. For more commands, please refer to the Commands tab in the Amazon Q extension.

Step 4: Make any required changes to the schema and save the amplify/data/resource.ts file. This will trigger a sandbox deployment and your new data model will be deployed

--------------------------------------------------------------------------------

Title: Troubleshoot "Cannot find module $amplify/env/<function-name>" - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/troubleshooting/cannot-find-module-amplify-env/
HTML Content:
Next.js
/
Build & connect backend
/
Troubleshooting
/
Troubleshoot "Cannot find module $amplify/env/<function-name>"
Troubleshoot "Cannot find module $amplify/env/<function-name>"

When deploying a Amplify Gen 2 app, you may encounter the error message Cannot find module $amplify/env/<function-name> in your frontend build on Amplify Console. This error occurs when your framework tsconfig.json configuration picks up the amplify directory and tries to resolve it as a module. This module is a placeholder for environment variables that are injected at build time by Amplify. To resolve this error, you need to exclude the amplify directory.

To exclude the amplify directory in your tsconfig.json, add the following lines to the exclude section:

tsconfig.json
Copy
tsconfig.json code example
{
  "exclude": ["amplify/**/*"]
}

Amplify will perform type-checking on sandbox and pipeline-deploy using the tsconfig local to the Amplify backend amplify/tsconfig.json. If you'd like to extend your base configuration you can add it to the localized tsconfig.

Alternatively, if you work within a monorepo you can move your backend to its own package and export the Schema and outputs for ease of sharing with your other apps. For example, in your backend package's package.json

package.json
Copy
package.json code example
{
  "name": "my-backend",
  "private": true,
  "exports": {
    "./schema": "./amplify/data/resource.ts",
    "./outputs": "./amplify_outputs.json"
  }
}

--------------------------------------------------------------------------------

Title: Troubleshoot configuration errors - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/troubleshooting/library-not-configured/
HTML Content:
Next.js
/
Build & connect backend
/
Troubleshooting
/
Troubleshoot configuration errors
Troubleshoot configuration errors

If you are running into a missing configuration or NoCredentials error message and have called Amplify.configure in your project, your Amplify API is most likely being called before Amplify.configure. This can happen in a few different ways. Below are three possibilities you can check to troubleshoot this issue.

Check 1: Validate that Amplify.configure is called in the root of your project

Make sure you are calling Amplify.configure in the root file of your project. The root file of your app may be different depending on your frontend framework. The current default for some common frameworks are listed below (if you are not using TypeScript the ts and tsx extensions would be js and jsx):

Vue.js: src/main.ts
React: src/main.tsx
Angular: src/main.ts
Next.js Page Router: pages/_app.tsx or src/pages/_app.tsx
Nuxt: app.vue (Or in a plugins file, as recommended here.)

If you are using the Next.js App Router, you can follow the suggestions in our Next.js documentation for root-level configuration. Keep in mind that if you are calling any APIs at the module-level (i.e. at the top of your file) in any of the Child components, you may still run into this issue. Continue on the Check 2 if this is the case.

Check 2: Move module-level Amplify API invocations

When Amplify APIs are used outside of your application lifecycle, there is a risk that a JavaScript bundler may place that API call before Amplify.configure. Module-level function calls (calls at the top-level of a file), are generally evaluated in the order that they are imported.

Below is an example of code that will likely result in a missing configuration or NoCredentials error message:

index.ts
Copy
index.ts code example
import { Amplify } from 'aws-amplify';
import ComponentX from 'module-fetch-auth';


// fetchAuthSession() in ComponentX executed on import


Amplify.configure();


export default function App() {
  return (
    <div>
        <ComponentX />
    </div>
  );
}
module-fetch-auth.tsx
Copy
module-fetch-auth.tsx code example
import { fetchAuthSession } from 'aws-amplify/auth';


fetchAuthSession(); // Will throw "AuthUserPoolException: Auth UserPool not configured."


export default function ComponentX() {
  return (
    <div className="box">
      ...
    </div>
  );
}

This error can also happen when using Next.js Layouts and calling Amplify APIs in child components at the module-level (at the top of your file/module). See below for an example of this issue:

layout.tsx
Copy
layout.tsx code example
import ConfigureAmplifyClientSide from '@/ConfigureAmplifyClientSide';


export default function RootLayout({
  children,
}: {
  children: React.ReactNode;
}) {
  return (
    <html lang="en">
      <body className="container py-6">
        <>
          <ConfigureAmplifyClientSide />
          {children}
        </>
      </body>
    </html>
  );
}
ConfigureAmplifyClientSide.tsx
Copy
ConfigureAmplifyClientSide.tsx code example
import { Amplify } from "aws-amplify";


Amplify.configure(config, { ssr: true });


export default function ConfigureAmplifyClientSide() {
  return null;
}
page.tsx
Copy
page.tsx code example
import { fetchAuthSession } from "aws-amplify/auth";


// The layout calls configure, but fetchAuthSession ends up executing first
// Will throw "AuthUserPoolException: Auth UserPool not configured."
fetchAuthSession().then((session) => {
  console.log(session);
});


export default function HomePage() {
  return (
    <div className="box">
      ...
    </div>
  );
}

To fix this, we suggest moving all Amplify API calls to within the application lifecycle. For instance, if you are using React, you can use the useEffect hook for functions that should run before the app is loaded:

index.ts
Copy
index.ts code example
import { Amplify } from 'aws-amplify';
import ComponentX from 'module-fetch-auth';


Amplify.configure();


export default function App() {
  return (
    <div>
        <ComponentX />
    </div>
  );
}
module-fetch-auth.tsx
Copy
module-fetch-auth.tsx code example
import { type AuthSession, fetchAuthSession } from 'aws-amplify/auth';
import { useEffect, useState } from 'react';


export default function ComponentX() {
  const [session, setSession] = useState<AuthSession|undefined>();


  const getSession = async () => {
    try {
      const currentSession = await fetchAuthSession();
      setSession(currentSession);
    } catch (error: unknown) {
      console.log(error);
    }
  };


  useEffect(() => {
    getSession();
  }, []);


  return (
    <div className="box">
      ...
    </div>
  );
}
Check 3: Configure Amplify on each page of a multi-page app

If you are working in a multi-page app, you need to call Amplify.configure() for each page/route of your application. We recommend calling Amplify.configure in a common source file and importing it into each page.

--------------------------------------------------------------------------------

Title: Troubleshoot "Stack CDKToolkit already exists" - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/troubleshooting/stack-cdktoolkit-already-exists/
HTML Content:
Next.js
/
Build & connect backend
/
Troubleshooting
/
Troubleshoot "Stack CDKToolkit already exists"
Troubleshoot "Stack CDKToolkit already exists"

If you are deploying an Amplify Gen 2 app for the first time and have previously bootstrapped your AWS account to work with the AWS Cloud Development Kit (AWS CDK), and you encounter the following error in the Amplify Console:

Amplify Console
Build error!
Stack [CDKToolkit] already exists

You can mitigate by manually updating your CDKToolkit stack using the browser-based AWS CloudShell:

AWS CloudShell
Copy
AWS CloudShell code example
cdk bootstrap aws://$(aws sts get-caller-identity --query Account --output text)/$AWS_REGION

Or by running bootstrap using the AWS CDK CLI from your terminal:

Terminal
Copy
Terminal code example
npx aws-cdk@latest bootstrap aws://<your-aws-account-id>/<your-aws-region>

If you continue to experience this issue after applying the workaround noted above, please file an issue in the GitHub repository for Amplify Backend.

--------------------------------------------------------------------------------

Title: Troubleshooting - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/troubleshooting/
HTML Content:
Next.js
/
Build & connect backend
/
Troubleshooting
Troubleshooting
Troubleshoot configuration errors
Addressing missing configuration or NoCredentials error messages
Troubleshoot "Stack CDKToolkit already exists"
Addressing issues with upgrading CDKToolkit stacks
Troubleshoot "Cannot find module $amplify/env/<function-name>"
Addressing "Cannot find module $amplify/env/<function-name>" error message

--------------------------------------------------------------------------------

Title: Overriding resources - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/overriding-resources/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Overriding resources
Overriding resources

By using overrides, you may create a backend that the Amplify libraries or client config is unable to interpret properly. Always test changes in a staging environment.

When defining resources, you can access some underlying AWS Cloud Development Kit (CDK) construct properties to modify resource configurations. This allows you to customize backend resources beyond what is offered through the define* functions.

Overrides are defined in the amplify/backend.ts file after the defineBackend call has been made.

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';


const backend = defineBackend({
  auth,
  data
});


// overrides go here

The backend object exposes a resources property with objects for each of the components passed into the defineBackend function. Each of these resource objects exposes underlying L1 and L2 AWS CDK constructs that you can modify.

For example, here is how you can access the Cognito user pool that is created by defineAuth and set a custom removal policy on the resource.

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { UserPool } from 'aws-cdk-lib/aws-cognito';
import { RemovalPolicy } from 'aws-cdk-lib';


const backend = defineBackend({
  auth
});


const userPool = backend.auth.resources.userPool as UserPool;
userPool.applyRemovalPolicy(RemovalPolicy.RETAIN_ON_UPDATE_OR_DELETE);

Most L1 and L2 AWS CDK constructs that are used by the define* functions are accessible in this way.

Example - Grant access permissions between resources

Consider the case that we want to grant a function created by defineFunction access to call the Cognito user pool created by defineAuth. This can be accomplished with the following overrides.

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';
import { demoFunction } from './functions/demo-function/resource';
import { UserPool } from 'aws-cdk-lib/aws-cognito';
import { Function } from 'aws-cdk-lib/aws-lambda';


const backend = defineBackend({
  auth,
  data,
  demoFunction
});


const userPool = backend.auth.resources.userPool as UserPool;
const lambdaFunction = backend.demoFunction.resources.lambda as Function;


// grant the lambdaFunction read access to users
userPool.grant(lambdaFunction, 'cognito:GetUser', 'cognito:ListUsers');


// pass the Lambda the UserPool ID so that the Lambda can use it to make SDK calls
lambdaFunction.addEnvironment('USER_POOL_ID', userPool.userPoolId);
Example - Mutate synthesized CloudFormation

It's possible to reach all the way down to the raw CloudFormation to mutate properties using addPropertyOverride on an AWS CDK construct. To edit the password policies of the Cognito user pool in defineAuth, you can use the following code.

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';


const backend = defineBackend({
  auth
});


// override user pool password policies
backend.auth.resources.cfnResources.cfnUserPool.addPropertyOverride(
  'Policies',
  {
    PasswordPolicy: {
      MinimumLength: 10,
      RequireLowercase: true,
      RequireNumbers: true,
      RequireSymbols: true,
      RequireUppercase: true,
      TemporaryPasswordValidityDays: 20
    }
  }
);

Note the usage of auth.resources.cfnResources. This property exposes L1 CDK constructs that map one-to-one with the underlying CloudFormation properties.

The auth.resources.cfnResources.cfnUserPool property in the above example directly maps to the AWS::Cognito::UserPool CloudFormation resource.

This is different from auth.resources.userPool in the first example, which is an L2 CDK construct. These are constructs that provide a convenient interface around several related L1 constructs.

Example - Add tags to resources
amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';


const backend = defineBackend({
  auth,
  data
});


backend.data.resources.cfnResources.cfnGraphqlApi.addPropertyOverride('Tags', [
  {
    Key: 'graphqlapi-tag-1',
    Value: 'graphql-tag-value-1'
  },
  {
    Key: 'graphqlapi-tag-2',
    Value: 'graphql-tag-value-2'
  }
]);

For situations where you need even more customization of your app backend, see the documentation on custom resources.

PREVIOUS
Custom resources

--------------------------------------------------------------------------------

Title: Custom resources - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/custom-resources/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Custom resources
Custom resources

Custom resources allow you to integrate any AWS service into an Amplify backend. You are responsible for ensuring that your custom resources are secure, adhere to best practices, and work with the resources that Amplify creates for your app.

With Amplify Gen 2, you can add custom AWS resources to an Amplify app using the AWS Cloud Development Kit (AWS CDK), which is installed by default as part of the create-amplify workflow. The AWS CDK is an open source software development framework that defines your cloud application resources using familiar programming languages, such as TypeScript.

The AWS CDK can be used within an Amplify app to add custom resources and configurations beyond what Amplify supports out of the box. For example, a developer could use CDK to hook up a Redis cache, implement custom security rules, deploy containers on AWS Fargate, or use any other AWS service.

The infrastructure defined through the AWS CDK code is deployed along with the Amplify app backend. This provides the simplicity of Amplify combined with the flexibility of CDK for situations where you need more customization.

AWS CDK apps are composed of building blocks known as constructs, which are composed together to form stacks and apps. You can learn more in the Concepts section of the AWS Cloud Development Kit (AWS CDK) v2 Developer Guide.

With the Amplify code-first DX, you can add existing or custom CDK constructs to the backend of your Amplify app.

Adding an existing CDK construct

The AWS CDK comes with many existing constructs that can be directly added to your Amplify backend. For example, to add an Amazon Simple Queue Service (Amazon SQS) queue and an Amazon Simple Notification Service (Amazon SNS) topic to your backend, you can add the following to your amplify/backend.ts file.

amplify/backend.ts
Copy
amplify/backend.ts code example
import * as sns from 'aws-cdk-lib/aws-sns';
import * as sqs from 'aws-cdk-lib/aws-sqs';
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';


const backend = defineBackend({
  auth,
  data
});


const customResourceStack = backend.createStack('MyCustomResources');


new sqs.Queue(customResourceStack, 'CustomQueue');
new sns.Topic(customResourceStack, 'CustomTopic');

Note the use of backend.createStack(). This method instructs the backend to create a new CloudFormation Stack for your custom resources to live in. You can create multiple custom stacks and you can place multiple resources in any given stack.

Defining a CDK construct

Constructs are the basic building blocks of AWS CDK apps. A construct represents a "cloud component" and encapsulates everything AWS CloudFormation needs to create the component. Read more.

As shown above, you can use the existing AWS CDK constructs directly in an Amplify backend. However, you may find yourself repeating some patterns of common constructs. Custom constructs allow you to encapsulate common patterns into reusable components. This helps you implement best practices, accelerate development, and maintain consistency across applications.

A common use case is creating a custom notification construct that combines a Lambda function with Amazon SNS and Amazon Simple Email Service (Amazon SES).

This AWS CDK construct implements a decoupled notification system using Amazon SNS and Lambda. It allows publishing notification messages to an SNS topic from one Lambda function, and processing those messages asynchronously using a separate Lambda subscribed to the topic.

The key components are:

An Amazon SNS topic to receive notification messages
A Lambda function to publish messages to the Amazon SNS topic
A second Lambda subscribed to the topic that processes the messages and sends emails through Amazon SES

The publisher Lambda allows publishing a message containing the email subject, body text, and recipient address. The emailer Lambda retrieves messages from the SNS topic and handles sending the actual emails.

The CustomNotifications custom CDK construct can be defined as follows:

amplify/custom/CustomNotifications/resource.ts
Copy
amplify/custom/CustomNotifications/resource.ts code example
import * as url from 'node:url';
import { Runtime } from 'aws-cdk-lib/aws-lambda';
import * as lambda from 'aws-cdk-lib/aws-lambda-nodejs';
import * as sns from 'aws-cdk-lib/aws-sns';
import * as subscriptions from 'aws-cdk-lib/aws-sns-subscriptions';
import { Construct } from 'constructs';


// message to publish
export type Message = {
  subject: string;
  body: string;
  recipient: string;
};


type CustomNotificationsProps = {
  /**
   * The source email address to use for sending emails
   */
  sourceAddress: string;
};


export class CustomNotifications extends Construct {
  public readonly topic: sns.Topic;
  constructor(scope: Construct, id: string, props: CustomNotificationsProps) {
    super(scope, id);


    const { sourceAddress } = props;


    // Create SNS topic
    this.topic = new sns.Topic(this, 'NotificationTopic');


    // Create Lambda to publish messages to SNS topic
    const publisher = new lambda.NodejsFunction(this, 'Publisher', {
      entry: url.fileURLToPath(new URL('publisher.ts', import.meta.url)),
      environment: {
        SNS_TOPIC_ARN: this.topic.topicArn
      },
      runtime: Runtime.NODEJS_18_X
    });


    // Create Lambda to process messages from SNS topic
    const emailer = new lambda.NodejsFunction(this, 'Emailer', {
      entry: url.fileURLToPath(new URL('emailer.ts', import.meta.url)),
      environment: {
        SOURCE_ADDRESS: sourceAddress
      },
      runtime: Runtime.NODEJS_18_X
    });


    // Subscribe emailer Lambda to SNS topic
    this.topic.addSubscription(new subscriptions.LambdaSubscription(emailer));


    // Allow publisher to publish to SNS topic
    this.topic.grantPublish(publisher);
  }
}

The Lambda function code for the Publisher is:

amplify/custom/CustomNotifications/publisher.ts
Copy
amplify/custom/CustomNotifications/publisher.ts code example
// amplify/custom/CustomNotifications/publisher.ts
import { PublishCommand, SNSClient } from '@aws-sdk/client-sns';
import type { Handler } from 'aws-lambda';
import type { Message } from './resource';


const client = new SNSClient({ region: process.env.AWS_REGION });


// define the handler that will publish messages to the SNS Topic
export const handler: Handler<Message, void> = async (event) => {
  const { subject, body, recipient } = event;
  const command = new PublishCommand({
    TopicArn: process.env.TOPIC_ARN,
    Message: JSON.stringify({
      subject,
      body,
      recipient
    })
  });
  try {
    const response = await client.send(command);
    console.log('published', response);
  } catch (error) {
    console.log('failed to publish message', error);
    throw new Error('Failed to publish message', { cause: error });
  }
};

The Lambda function code for the Emailer is:

amplify/custom/CustomNotifications/emailer.ts
Copy
amplify/custom/CustomNotifications/emailer.ts code example
// amplify/custom/CustomNotifications/emailer.ts
import { SESClient, SendEmailCommand } from '@aws-sdk/client-ses';
import type { SNSHandler } from 'aws-lambda';
import type { Message } from './resource';


const sesClient = new SESClient({ region: process.env.AWS_REGION });


// define the handler to process messages from the SNS topic and send via SES
export const handler: SNSHandler = async (event) => {
  for (const record of event.Records) {
    const message: Message = JSON.parse(record.Sns.Message);


    // send the message via email
    await sendEmail(message);
  }
};


const sendEmail = async (message: Message) => {
  const { recipient, subject, body } = message;


  const command = new SendEmailCommand({
    Source: process.env.SOURCE_ADDRESS,
    Destination: {
      ToAddresses: [recipient]
    },
    Message: {
      Body: {
        Text: { Data: body }
      },
      Subject: { Data: subject }
    }
  });


  try {
    const result = await sesClient.send(command);
    console.log(`Email sent to ${recipient}: ${result.MessageId}`);
  } catch (error) {
    console.error(`Error sending email to ${recipient}: ${error}`);
    throw new Error(`Failed to send email to ${recipient}`, { cause: error });
  }
};

The CustomNotifications CDK construct can then be added to the Amplify backend one or more times, with different properties for each instance.

amplify/backend.ts
Copy
amplify/backend.ts code example
// amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';
import { CustomNotifications } from './custom/CustomNotifications/resource';


const backend = defineBackend({
  auth,
  data
});


const customNotifications = new CustomNotifications(
  backend.createStack('CustomNotifications'),
  'CustomNotifications',
  { sourceAddress: 'sender@example.com' }
);


backend.addOutput({
  custom: {
    topicArn: customNotifications.topic.topicArn,
    topicName: customNotifications.topic.topicName,
  },
});
Community CDK resources

The Construct Hub is a community-driven catalog of reusable infrastructure components. It is a place for developers to discover and share reusable patterns for AWS CDK, maintained by AWS.

In addition, the example projects using the AWS CDK repository contains a number of examples of reusable CDK constructs.

You can use these resources to create custom CDK constructs that can be used in your Amplify app.

PREVIOUS
Deletion protection and Backup resources
NEXT
Overriding resources

--------------------------------------------------------------------------------

Title: Deletion protection and Backup resources - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/deletion-backup-resources/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Deletion protection and Backup resources
Deletion protection and Backup resources

Deleting a Amplify sandbox with a resource enabled with deletion protection, the deploy process will fail and the resource will need to be manually deleted on the AWS console.

Using the AWS Cloud Development Kit (CDK) we can configure Amplify generated resource to enable deletion protection and backups on supported resources. For example, you can use AWS CDK to enable Point-in-time recovery for DynamoDB tables, or use AWS Backup as a advanced backup option.

Using underlying CDK construct properties you can modify resource configurations. This allows you to customize backend resources beyond what is offered via the define* functions.

Enabling deletion protection on a Auth resource

For example, if you would like to enable deletion protection on a Cognito user pool resource created by Amplify Auth.

amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';


const backend = defineBackend({
  auth,
  data
});


Copy
highlighted code example
const { cfnUserPool } = backend.auth.resources.cfnResources
cfnUserPool.deletionProtection = "ACTIVE";
Enabling Deletion protection on a Data resource

For example, if you would like to enable Deletion protection on all DynamoDB tables created by GraphQL API.

amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';


const backend = defineBackend({
  auth,
  data
});


Copy
highlighted code example
const { amplifyDynamoDbTables } = backend.data.resources.cfnResources;
for (const table of Object.values(amplifyDynamoDbTables)) {
  table.deletionProtectionEnabled = true;
}
Enabling Point-in-time recovery for DynamoDB tables

For example, enabling Point-in-time recovery for all the DynamoDB tables created by GraphQL API. By default Point-in-Time recovery retains backups for 35 days.

amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';


const backend = defineBackend({
  auth,
  data
});


Copy
highlighted code example
const { amplifyDynamoDbTables } = backend.data.resources.cfnResources;
for (const table of Object.values(amplifyDynamoDbTables)) {
  table.pointInTimeRecoveryEnabled = true;
}
Enabling Backups for DynamoDB tables

For example, if your DynamoDB tables requires backups that extend the default 35 days point-in-time recovery, AWS Backup service can be utilized to centralize and automate backups for DynamoDB tables. The example below outlines a backup plan configured to run daily at midnight, for all DynamoDB tables.

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend";
Copy
highlighted code example
import {
  BackupPlan,
  BackupPlanRule,
  BackupResource,
  BackupVault,
} from "aws-cdk-lib/aws-backup";
import { Schedule } from "aws-cdk-lib/aws-events";
import { Duration } from "aws-cdk-lib/core";
import { auth } from "./auth/resource";
import { data } from "./data/resource";


const backend = defineBackend({
  auth,
  data,
});


Copy
highlighted code example
const backupStack = backend.createStack("backup-stack");
const myTables = Object.values(backend.data.resources.tables);


const vault = new BackupVault(backupStack, "BackupVault", {
  backupVaultName: "backup-vault",
});


const plan = new BackupPlan(backupStack, "BackupPlan", {
  backupPlanName: "backup-plan",
  backupVault: vault,
});


plan.addRule(
  new BackupPlanRule({
    deleteAfter: Duration.days(60),
    ruleName: "backup-plan-rule",
    scheduleExpression: Schedule.cron({
      minute: "0",
      hour: "0",
      day: "*",
      month: "*",
      year: "*",
    }),
  })
);


plan.addSelection("BackupPlanSelection", {
  resources: myTables.map((table) => BackupResource.fromDynamoDbTable(table)),
  allowRestores: true,
});
PREVIOUS
PubSub
NEXT
Custom resources

--------------------------------------------------------------------------------

Title: Set up Amplify PubSub - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/pubsub/set-up-pubsub/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
PubSub
/
Set up Amplify PubSub
Set up Amplify PubSub

The AWS Amplify PubSub category provides connectivity with cloud-based message-oriented middleware. You can use PubSub to pass messages between your app instances and your app's backend creating real-time interactive experiences.

PubSub is available with AWS IoT and Generic MQTT Over WebSocket Providers.

With AWS IoT, AWS Amplify's PubSub automatically signs your HTTP requests when sending your messages.

AWS IoT

The default export for PubSub will sign requests according to Signature Version 4.

Make sure that the @aws-amplify/pubsub package has the same version number as the aws-amplify package in your package.json file.

To use in your app, import PubSub from the root export path:

Copy
code example
import { Amplify} from 'aws-amplify';
import { PubSub } from '@aws-amplify/pubsub';

Create a new instance for your endpoint and region in your configuration:

Copy
code example
// Apply plugin with configuration
const pubsub = new PubSub({
  region: '<YOUR-IOT-REGION>',
  endpoint:
    'wss://xxxxxxxxxxxxx.iot.<YOUR-IOT-REGION>.amazonaws.com/mqtt'
});

Find your aws_pubsub_endpoint by logging onto your AWS Console, choosing IoT Core from the list of services and then choosing Settings from the left navigation pane.

Step 1: Create IAM policies for AWS IoT

To use PubSub with AWS IoT, you will need to create the necessary IAM policies in the AWS IoT Console, and attach them to your Amazon Cognito Identity.

Go to IoT Core and choose Security from the left navigation pane, and then Policies from the dropdown menu. Next, click Create. The following myIoTPolicy policy will allow full access to all the topics.

Step 2: Attach your policy to your Amazon Cognito Identity

The next step is attaching the policy to your Cognito Identity.

You can retrieve the Cognito Identity Id of a logged in user with Auth Module:

Copy
code example
import { fetchAuthSession } from 'aws-amplify/auth';
fetchAuthSession().then((info) => {
  const cognitoIdentityId = info.identityId;
});

Then, you need to send your Cognito Identity Id to the AWS backend and attach myIoTPolicy. You can do this with the following AWS CLI command:

Copy
code example
aws iot attach-policy --policy-name 'myIoTPolicy' --target '<YOUR_COGNITO_IDENTITY_ID>'
Step 3: Allow the Amazon Cognito Authenticated Role to access IoT Services

For your Cognito Authenticated Role to be able to interact with AWS IoT it may be necessary to update its permissions, if you haven't done this before.
One way of doing this is to log to your AWS Console, select CloudFormation from the available services. Locate the parent stack of your solution: it is usually named <SERVICE-NAME>-<CREATION_TIMESTAMP>.
Select the Resources tab and tap on AuthRole Physical ID.
The IAM console will be opened in a new tab. Once there, tap on the button Attach Policies, then search AWSIoTDataAccess and AWSIoTConfigAccess, select them and tap on Attach policy.

If you are using Cognito Groups, the IAM role associated with that group also need the AWSIoTDataAccess and AWSIoTConfigAccess policies attached to it.

Failing to grant IoT related permissions to the Cognito Authenticated Role will result in errors similar to the following in your browser console: errorCode: 8, errorMessage: AMQJS0008I Socket closed.

Keeping track of your pubsub instances

In a real-world application, the code that sets up a pubsub instance (const pubsub = new PubSub(...)) will be used in multiple places. This means that the configuration will be separate from where your application publishes (pubsub.publish(...)) or subscribes (pubsub.subscribe(...)).

If you already know all the connections when deploying your application, you can export singleton instances for other parts of your application to easily import and use.

Example

./src/utils/pubsub.ts:

Copy
code example
import { PubSub } from '@aws-amplify/pubsub';
export const pubsub = new PubSub({...});

./src/components/LatestMessage.tsx:

Copy
code example
import { useState, useEffect } from 'react';
import { pubsub } from '../utils/pubsub';


export function LatestMessage() {
  const [message, setMessage] = useState<string>("");
  useEffect(() => {
    pubsub.subscribe({topics: ['messages']}).subscribe({
        next: (data) => {
          setMessage(data.msg);
        }
    });
  }, [])
  return <>{message}</>
}

This means you will maintain a single connection to the target endpoint without needing to pass the pubsub instance as a property through layers of components.

Third Party MQTT Providers

Import PubSub from the mqtt specific export path

Copy
code example
import { PubSub } from '@aws-amplify/pubsub/mqtt';

Create a new instance for your endpoint and region in your configuration:

Copy
code example
// Apply plugin with configuration
const pubsub = new PubSub({
  endpoint: 'wss://iot.eclipse.org:443/mqtt'
});

You can integrate any MQTT Over WebSocket provider with your app. Click here to learn more about MQTT Over WebSocket.

Only JSON serializable message payloads are currently supported for MQTT providers within PubSub. If you are attempting to use message payloads that are non-JSON serializable, consider transforming the payload into a format that aligns with the input type expected by MQTT.

PREVIOUS
Publish
NEXT
Subscribe and unsubscribe

--------------------------------------------------------------------------------

Title: Subscribe and unsubscribe - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/pubsub/subscribe/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
PubSub
/
Subscribe and unsubscribe
Subscribe and unsubscribe
Subscribe
Subscribe to a topic

In order to start receiving messages from your provider, you need to subscribe to a topic as follows;

Copy
code example
pubsub.subscribe({ topics: 'myTopic' }).subscribe({
  next: (data) => console.log('Message received', data),
  error: (error) => console.error(error),
  complete: () => console.log('Done')
});

Following events will be triggered with subscribe()

Event	Description
next	Triggered every time a message is successfully received for the topic
error	Triggered when subscription attempt fails
complete	Triggered when you unsubscribe from the topic
Subscribe to multiple topics

To subscribe for multiple topics, just pass a String array including the topic names:

Copy
code example
pubsub.subscribe({ topics: ['myTopic1', 'myTopic1'] }).subscribe({
  //...
});
Unsubscribe

To stop receiving messages from a topic, you can use unsubscribe() method:

Copy
code example
const sub1 = pubsub.subscribe({ topics: 'myTopicA' }).subscribe({
  next: (data) => console.log('Message received', data),
  error: (error) => console.error(error),
  complete: () => console.log('Done')
});


sub1.unsubscribe();
// You will no longer get messages for 'myTopicA'
Subscription connection status updates

Now that your application is setup and using pubsub subscriptions, you may want to know when the subscription is finally established, or reflect to your users when the subscription isn't healthy. You can monitor the connection state for changes via Hub.

Copy
code example
import { CONNECTION_STATE_CHANGE, ConnectionState } from '@aws-amplify/pubsub';
import { Hub } from 'aws-amplify/utils';


Hub.listen('pubsub', (data: any) => {
  const { payload } = data;
  if (payload.event === CONNECTION_STATE_CHANGE) {
    const connectionState = payload.data.connectionState as ConnectionState;
    console.log(connectionState);
  }
});
Connection states
Connected - Connected and working with no issues.
ConnectedPendingDisconnect - The connection has no active subscriptions and is disconnecting.
ConnectedPendingKeepAlive - The connection is open, but has missed expected keep alive messages.
ConnectedPendingNetwork - The connection is open, but the network connection has been disrupted. When the network recovers, the connection will continue serving traffic.
Connecting - Attempting to connect.
ConnectionDisrupted - The connection is disrupted and the network is available.
ConnectionDisruptedPendingNetwork - The connection is disrupted and the network connection is unavailable.
Disconnected - Connection has no active subscriptions and is disconnecting.
Connection issues and automated reconnection

Your application can lose connectivity for any number of reasons such as network outages or when the device is put to sleep. Your subscriptions will automatically reconnect when it becomes possible to do so.

While offline, your application will miss messages and will not automatically catch up when reconnection happens. Depending on your usecase, you may want take action to catch up when your app comes back online.

Copy
code example
const fetchRecentData = () => {
  // Retrieve recent data from some sort of data storage service
}


let priorConnectionState: ConnectionState;


Hub.listen("pubsub", (data: any) => {
  const { payload } = data;
  if (
    payload.event === CONNECTION_STATE_CHANGE
  ) {


    if (priorConnectionState === ConnectionState.Connecting && payload.data.connectionState === ConnectionState.Connected) {
      fetchRecentData();
    }
    priorConnectionState = payload.data.connectionState;
  }
});


pubsub.subscribe('myTopic').subscribe({
  next: data => // Process incoming messages
})
PREVIOUS
Set up Amplify PubSub

--------------------------------------------------------------------------------

Title: Publish - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/pubsub/publish/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
PubSub
/
Publish
Publish

To send a message to a topic, use publish() method with your topic name and the message:

Copy
code example
await pubsub.publish({ topics: 'myTopic1', message: { msg: 'Hello to all subscribers!' } });

If multiple providers are defined in your app you can pass the message to a specific provider:

Copy
code example
await pubsub.publish({ 
  topics: 'myTopic1',
  message: { msg: 'Hello to all subscribers!' },
  options: { provider: 'AWSIoTProvider' }
});

You can also publish a message to multiple topics:

Copy
code example
await pubsub.publish({ topics: ['myTopic1','myTopic2'], message: { msg: 'Hello to all subscribers!' } });
NEXT
Set up Amplify PubSub

--------------------------------------------------------------------------------

Title: PubSub - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/pubsub/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
PubSub
PubSub
Set up Amplify PubSub
Learn more about how you can use PubSub to pass messages between your app instances and your app’s backend creating real-time interactive experiences.
Subscribe and unsubscribe
Learn more about how to subscribe to and unsubscribe from topics using Amplify's PubSub category
Publish
Learn more about how to publish a message using the PubSub category in Amplify

--------------------------------------------------------------------------------

Title: Interact with bots - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/interactions/chatbot/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Interactions
/
Interact with bots
Interact with bots
Send messages to bot

You can send a text message to chatbot backend with send() command. The method returns a promise that includes the chatbot response.

src/App.tsx
Copy
src/App.tsx code example
import { Interactions } from '@aws-amplify/interactions';


const userInput = "I want to reserve a hotel for tonight";


// Provide a bot name and user input
const response = await Interactions.send({
  botName: "TheBotName",
  message: userInput
});


// Log chatbot response
console.log(response.message);
Display end of chat message

You can use onComplete() method to register a function to catch errors or chatbot confirmations when the session successfully ends.

src/App.tsx
Copy
src/App.tsx code example
import { Interactions } from '@aws-amplify/interactions';


Interactions.onComplete({
  botName: "TheBotName",
  callback: (error?: Error, completion?: {[key: string]: any}) => {
     if (error) {
        alert('bot conversation failed');
     } else if (completion) {
        console.debug('done: ' + JSON.stringify(completion, null, 2));
        alert('Trip booked. Thank you! What would you like to do next?');
     }
  }
});
PREVIOUS
Set up Amplify Interactions

--------------------------------------------------------------------------------

Title: Set up Amplify Interactions - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/interactions/set-up-interactions/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Interactions
/
Set up Amplify Interactions
Set up Amplify Interactions

AWS Amplify Interactions enables AI-powered chatbots in your web or mobile apps. You can use Interactions to configure your backend chatbot provider and to integrate a chatbot UI into your app with just a single line of code.

Interactions with AWS

AWS Amplify supports Amazon Lex as the default chatbots service. Amazon Lex supports creating conversational bots with the same deep learning technologies that power Amazon Alexa.

Setup AWS LexV2 bot

You can create an Amazon Lex V2 chatbot in Amazon Lex console. To create your bot, follow the steps shown in Amazon Lex V2 Developer Guide.

Update your IAM Policy

Amazon Lex service requires an IAM policy in order to use the interactions APIs (remember to replace the template with real value):

Copy
code example
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": ["lex:RecognizeText", "lex:RecognizeUtterance"],
      "Resource": "arn:aws:lex:<your-app-region>:<your-account-id>:bot-alias/<your-bot-id>/<your-bot-alias-id>"
    }
  ]
}
Configure your frontend

Add the aws-amplify and interactions package to your project:

Terminal
Copy
Terminal code example
npm add --save @aws-amplify/interactions aws-amplify

Make sure that the @aws-amplify/interactions package has the same version number as the aws-amplify package in your package.json file.

Configure Amplify

Import and load the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point. For example, App.js (Expo) or index.js (React Native CLI).

src/index.js
Copy
src/index.js code example
import { Amplify } from 'aws-amplify';
import outputs from '../amplify_outputs.json';


Amplify.configure(outputs);
Amplify.configure({
  ...Amplify.getConfig(),
  Interactions: {
    LexV2: {
      '<your-bot-name>': {
        aliasId: '<your-bot-alias-id>',
        botId: '<your-bot-id>',
        localeId: '<your-bot-locale-id>',
        region: '<your-bot-region>'
      }
    }
  }
});

Make sure you call Amplify.configure as early as possible in your application’s life-cycle. A missing configuration or NoCredentials error is thrown if Amplify.configure has not been called before other Amplify JavaScript APIs. Review the Library Not Configured Troubleshooting guide for possible causes of this issue.

NEXT
Interact with bots

--------------------------------------------------------------------------------

Title: Interactions - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/interactions/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Interactions
Interactions
Set up Amplify Interactions
AWS Amplify Interactions category enables AI-powered chatbots in your web or mobile apps. You can use Interactions to configure your backend chatbot provider and to integrate a chatbot UI into your app with just a single line of code.
Interact with bots
Learn more about how to integrate chat bot interactions into your application using Amplify.

--------------------------------------------------------------------------------

Title: Interpret sentiment - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/predictions/interpret-sentiment/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
AI/ML Predictions
/
Interpret sentiment
Interpret sentiment

Note: Make sure to complete the getting started section first, where you will set up the IAM roles with the right policy actions

Working with the API

Analyze text to find key phrases, sentiment (positive, negative, neutral), or the syntax (pronouns, verbs, etc.). You can also find entities in the text such as names or places, or perform language detection.

Copy
code example
import { Predictions } from '@aws-amplify/predictions';


const result = await Predictions.interpret({
  text: {
    source: {
      text: textToInterpret,
    },
    type: 'ALL'
  }
})
PREVIOUS
Label objects in an image

--------------------------------------------------------------------------------

Title: Label objects in an image - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/predictions/label-image/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
AI/ML Predictions
/
Label objects in an image
Label objects in an image

Note: Make sure to complete the getting started section first, where you will set up the IAM roles with the right policy actions

Working with the API

Detect labels, such if an image has a desk or a chair in it

Copy
code example
import { Predictions } from '@aws-amplify/predictions';


Predictions.identify({
  labels: {
    source: {
      file
    },
    type: 'LABELS'
  }
})
  .then((response) => {
    const { labels } = response;
    labels.forEach((object) => {
      const { name, boundingBoxes } = object;
    });
  })
  .catch((err) => console.log({ err }));

Detect unsafe content in an image

Copy
code example
import { Predictions } from '@aws-amplify/predictions';


const { unsafe } = await Predictions.identify({
  labels: {
    source: {
      file
    },
    type: 'UNSAFE'
  }
})

For both labels and unsafe content

Copy
code example
import { Predictions } from '@aws-amplify/predictions';


const { labels, unsafe } = await Predictions.identify({
  labels: {
    source: {
      file
    },
    type: 'ALL'
  }
})
PREVIOUS
Identify entities from images
NEXT
Interpret sentiment

--------------------------------------------------------------------------------

Title: Identify text - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/predictions/identify-text/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
AI/ML Predictions
/
Identify text
Identify text

Note: Make sure to complete the getting started section first, where you will set up the IAM roles with the right policy actions

Working with the API

Detect text in an input image. Input can be sent directly from the browser or an Amazon S3 key from project bucket.

Copy
code example
import { Predictions } from '@aws-amplify/predictions';


const response = await Predictions.identify({
  text: {
    source: {
      file
    }
  }
});
Identify image stored in Amazon S3
Copy
code example
import { Predictions } from '@aws-amplify/predictions';


const response = await Predictions.identify({
  text: {
    source: {
      key: pathToPhoto,
    }
  }
})

The following options are independent of which source is specified. For demonstration purposes we will reference a file but it can be an S3 Key as well. Predictions.identify({text : {...}}) can detect unstructured text PLAIN, structured text from tables TABLE or text from forms FORM.

Identify plain text

For detecting plain text, you can see the whole detected text, the lines detected, the position of each line of text, and each word.

Copy
code example
import { Predictions } from '@aws-amplify/predictions';


const response = await Predictions.identify({
  text: {
    source: {
      file
    },
    format: 'PLAIN'
  }
});


const {
  text: {
    fullText, // String
    lines, // Array of String ordered from top to bottom
    linesDetailed /* Array of objects that contains
        text, // String
        boundingBox: {
          width, // ratio of overall image width
          height, // ratio of overall image height
          left, // left coordinate as a ratio of overall image width
          top // top coordinate as a ratio of overall image height
        },
        polygon // Array of { x, y } coordinates as a ratio of overall image width and height
        */,
    words // Array of objects that contains { text, boundingBox, polygon}
  }
} = response;
Identify structured forms

For detecting structured forms (documents, tables, etc.) from an image, keyValues will return a string of the entity found in the image as well as metadata such as selected checkboxes or the relative location in the image using a boundingBox.

Copy
code example
import { Predictions } from '@aws-amplify/predictions';


const response = await Predictions.identify({
  text: {
    source: {
      file
    },
    format: 'FORM'
  }
});


const {
  text: {
    // same as PLAIN +
    keyValues // Array of { key: string, value: { text: string, selected: boolean}, polygon, boundingBox }
  }
} = response;

For example the below image would return keyValues with "Test" or "Checked" as a key, and true since they are selected. The location of these elements would be returned in the boundingBox value.

Identify structured tables

For detecting structured tables from an image

Copy
code example
import { Predictions } from '@aws-amplify/predictions';


const response = await Predictions.identify({
  text: {
    source: {
      file
    },
    format: 'TABLE'
  }
});


const {
  text: {
    // same as PLAIN +
    tables: [
      {
        size: { rows, columns },
        table // Matrix Array[ Array ] of size rows
        // each element of the array contains { text, boundingBox, polygon, selected, rowSpan, columnSpan}
      }
    ]
  }
} = response;

For detecting tables and forms on the image just select format "ALL"

Copy
code example
import { Predictions } from '@aws-amplify/predictions';


const { text } = await Predictions.identify({
  text: {
    source: {
      file
    },
    format: 'ALL'
  }
});
PREVIOUS
Translate language
NEXT
Identify entities from images

--------------------------------------------------------------------------------

Title: Identify entities from images - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/predictions/identify-entity/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
AI/ML Predictions
/
Identify entities from images
Identify entities from images

Note: Make sure to complete the getting started section first, where you will set up the IAM roles with the right policy actions

Working with the API

Predictions.identify({entities: {...}}) => Promise<> Detects entities from an image and potentially related information such as position, faces, and landmarks. Can also identify celebrities and entities that were previously added. This function returns a Promise that returns an object with the entities that was identified.

Input can be sent directly from the browser (using File object or ArrayBuffer object) or an Amazon S3 key from project bucket.

Detect entities directly from image uploaded from the browser. (File object)

Copy
code example
import { Predictions } from '@aws-amplify/predictions';


const response = await Predictions.identify({
  entities: {
    source: {
      file,
    },
  }
});

Detect entities directly from image binary from the browser. (ArrayBuffer object) This technique is useful when you have base64 encoded binary image data, for example, from a webcam source.

Copy
code example
import { Predictions } from '@aws-amplify/predictions';


const response = await Predictions.identify({
  entities: {
    source: {
      bytes: imageArrayBuffer,
    },
  }
});

From Amazon S3 key

Copy
code example
import { Predictions } from '@aws-amplify/predictions';


const response = await Predictions.identify({
  entities: {
    source: {
      key: pathToPhoto,
      level: 'guest' | 'private' | 'protected', //optional, default is the configured on Storage category
    },
  }
});

The following options are independent of which source is specified. For demonstration purposes it will be used file but it can be used S3 Key as well.

Detecting bounding box of faces from an image with its landmarks (eyes, mouth, nose).

Copy
code example
import { Predictions } from '@aws-amplify/predictions';


const { entities } = await Predictions.identify({
  entities: {
    source: {
      file,
    },
  }
})
for (const { boundingBox, landmarks } of entities) {
  const { 
    width, // ratio of overall image width
    height, // ratio of overall image height
    left, // left coordinate as a ratio of overall image width
    top // top coordinate as a ratio of overall image height
  } = boundingBox;
  
  for (const landmark of landmarks) {
    const {
      type, // string "eyeLeft", "eyeRight", "mouthLeft", "mouthRight", "nose"
      x, // ratio of overall image width
      y // ratio of overall image height
    } = landmark;
  }
}

Detecting celebrities on an image. It will return only celebrities the name and urls with related information.

Copy
code example
import { Predictions } from '@aws-amplify/predictions';


const { entities } = await Predictions.identify({
  entities: {
    source: {
      file,
    },
    celebrityDetection: true // boolean. It will only show detected celebrities 
  }
})


for (const { boundingBox, landmarks, metadata } of entities) {
  const { 
    name,
    urls 
  } = metadata; // celebrity info
  
  // ...
}
.catch(err => console.log({ err }));

Detecting entities from previously uploaded images (e.g. Advanced Configuration for Identify Entities)

Copy
code example
import { Predictions } from '@aws-amplify/predictions';


const { entities } = await Predictions.identify({
  entities: {
    source: {
      file,
    },
    collection: true
  }
})


for (const { boundingBox, metadata } of entities) {
  const {
    width, // ratio of overall image width
    height, // ratio of overall image height
    left, // left coordinate as a ratio of overall image width
    top // top coordinate as a ratio of overall image height
  } = boundingBox;
  const { externalImageId } = metadata; // this is the object key on S3 from the original image
}
PREVIOUS
Identify text
NEXT
Label objects in an image

--------------------------------------------------------------------------------

Title: Set up Predictions - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/predictions/set-up-predictions/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
AI/ML Predictions
/
Set up Predictions
Set up Predictions
Set up the backend

To enable Predictions we need to set up the appropriate IAM policy for Roles in your Cognito Identity Pool in order to use an appropriate feature. Additionally, we need to use the addOutput method to patch the custom Predictions resource to the expected output configuration.

Note: In the following example, we configure the policy to enable all supported ML capabilities. Ensure to include only the actions & resources relevant to your specific use cases. To learn more, check the docs of Amazon Translate, Amazon Polly, Amazon Transcribe, Amazon Rekognition, Amazon Textract, and Amazon Comprehend.

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import { Stack } from "aws-cdk-lib";
import { PolicyStatement } from "aws-cdk-lib/aws-iam";


const backend = defineBackend({
  auth,
});


// Configure a policy for the required use case.
// The actions included below cover all supported ML capabilities
backend.auth.resources.unauthenticatedUserIamRole.addToPrincipalPolicy(
  new PolicyStatement({
    actions: [
      "translate:TranslateText",
      "polly:SynthesizeSpeech",
      "transcribe:StartStreamTranscriptionWebSocket",
      "comprehend:DetectSentiment",
      "comprehend:DetectEntities",
      "comprehend:DetectDominantLanguage",
      "comprehend:DetectSyntax",
      "comprehend:DetectKeyPhrases",
      "rekognition:DetectFaces",
      "rekognition:RecognizeCelebrities",
      "rekognition:DetectLabels",
      "rekognition:DetectModerationLabels",
      "rekognition:DetectText",
      "rekognition:DetectLabel",
      "rekognition:SearchFacesByImage",      
      "textract:AnalyzeDocument",
      "textract:DetectDocumentText",
      "textract:GetDocumentAnalysis",
      "textract:StartDocumentAnalysis",
      "textract:StartDocumentTextDetection",
    ],
    resources: ["*"],
  })
);


backend.addOutput({
  custom: {
    Predictions: {
      convert: {
        translateText: {
          defaults: {
            sourceLanguage: "en",
            targetLanguage: "es",
          },
          proxy: false,
          region: Stack.of(backend.auth.resources.unauthenticatedUserIamRole)
            .region,
        },
        speechGenerator: {
          defaults: {
            voiceId: "Ivy",
          },
          proxy: false,
          region: Stack.of(backend.auth.resources.unauthenticatedUserIamRole)
            .region,
        },
        transcription: {
          defaults: {
            language: "en-US",
          },
          proxy: false,
          region: Stack.of(backend.auth.resources.unauthenticatedUserIamRole)
            .region,
        },
      },
      identify: {
        identifyEntities: {
          defaults: {
            collectionId: "default",
            maxEntities: 10,
          },
          celebrityDetectionEnabled: true,
          proxy: false,
          region: Stack.of(backend.auth.resources.unauthenticatedUserIamRole)
            .region,
        },
        identifyLabels: {
          defaults: {
            type: "ALL",
          },
          proxy: false,
          region: Stack.of(backend.auth.resources.unauthenticatedUserIamRole)
            .region,
        },
        identifyText: {
          defaults: {
            format: "ALL",
          },
          proxy: false,
          region: Stack.of(backend.auth.resources.unauthenticatedUserIamRole)
            .region,
        },
      },
      interpret: {
        interpretText: {
          defaults: {
            type: "ALL",
          },
          proxy: false,
          region: Stack.of(backend.auth.resources.unauthenticatedUserIamRole)
            .region,
        },
      },
    },
  },
});
Install Amplify Libraries

To install the Amplify library to use predictions features, run the following commands in your project's root folder:

Terminal
Copy
Terminal code example
npm add aws-amplify
Configure the frontend

Import and load the configuration file in your app. It is recommended you add the Amplify configuration step to your app's root entry point. For example main.ts in React and Angular.

src/main.ts
Copy
src/main.ts code example
import { Predictions } from "aws-amplify/predictions";
import outputs from "./amplify_outputs.json";


Amplify.configure(outputs);


Amplify.configure({
  ...Amplify.getConfig(),
  Predictions: config.custom.Predictions,
});
NEXT
Text to speech

--------------------------------------------------------------------------------

Title: Translate language - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/predictions/translate/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
AI/ML Predictions
/
Translate language
Translate language

Note: Make sure to complete the getting started section first, where you will set up the IAM roles with the right policy actions

Working with the API

Translate text from one source language to a destination language.

Copy
code example
import { Predictions } from '@aws-amplify/predictions';


const result = await Predictions.convert({
  translateText: {
    source: {
      text: textToTranslate,
      language : "es"
    },
    targetLanguage: "en"
  }
})

To view the complete list of supported languages refer to Supported languages and language codes.

PREVIOUS
Transcribe audio to text
NEXT
Identify text

--------------------------------------------------------------------------------

Title: Transcribe audio to text - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/predictions/transcribe-audio/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
AI/ML Predictions
/
Transcribe audio to text
Transcribe audio to text

Note: Make sure to complete the getting started section first, where you will set up the IAM roles with the right policy actions

Working with the API

You can transcribe a PCM Audio byte buffer to Text, such as a recording from microphone.

Copy
code example
import { Predictions } from '@aws-amplify/predictions';


const { transcription } = await Predictions.convert({
  transcription: {
    source: {
      bytes
    }
  }
})

To view the complete list of all the supported languages and language specific features refer to the supported languages list. The language data input type has to support streaming for it to work with Amplify Predictions.

PREVIOUS
Text to speech
NEXT
Translate language

--------------------------------------------------------------------------------

Title: Text to speech - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/predictions/text-to-speech/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
AI/ML Predictions
/
Text to speech
Text to speech

Note: Make sure to complete the getting started section first, where you will set up the IAM roles with the right policy actions

Working with the API

Generate an audio buffer for playback from a text input.

Copy
code example
import { Predictions } from '@aws-amplify/predictions';


const result = await Predictions.convert({
  textToSpeech: {
    source: {
      text: textToGenerateSpeech
    },
    voiceId: "Amy" 
  }
})

To view the complete list of voiceId options refer to Voices in Amazon Polly.

PREVIOUS
Set up Predictions
NEXT
Transcribe audio to text

--------------------------------------------------------------------------------

Title: AI/ML Predictions - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/predictions/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
AI/ML Predictions
AI/ML Predictions

Amplify provides provides a solution for using AI and ML cloud services to enhance your application. Some supported use cases:

Convert text to speech
Transcribe audio to text
Translate text from one language to another
Identify text from an image
Identify entities from an image
Identify real world objects from an image
Interpret text

Predictions is broadly organized into 3 key use cases - Identify, Convert, and Interpret - which are available in the client API as well as CLI workflows.

Identify will find text (words, tables, pages from a book), entities (faces and/or celebrities) from images. You can also identify real world landmarks or objects such as chairs, desks, etc. which are referred to as “labels” from images.
Convert allows you to translate text from one source language to a target language. You can also generate speech audio from text input. Lastly, you can take an audio input and transcribe it using a websocket stream.
Interpret allows you to analyze text for language, entities (places, people), key phrases, sentiment (positive, neutral, negative), and syntax (pronouns, verbs, adjectives).

Some common use cases are listed below, as well as an advanced workflow which allows you to perform dynamic image indexing from a connected s3 bucket.

Predictions comes with built-in support for Amazon Translate, Amazon Polly, Amazon Transcribe, Amazon Rekognition, Amazon Textract, and Amazon Comprehend.

Set up Predictions
Get started with integrating ML capabilities into your application using Amplify
Text to speech
Learn how to integrate text-to-speech capabilities into your application using Amplify.
Transcribe audio to text
Learn more about how to transcribe audio to text (also known as speech-to-text) for your application using Amplify
Translate language
Learn more about how to integrate translation capabilities for your application using Amplify
Identify text
Learn how to identify text from images and documents in your application using AWS Amplify.
Identify entities from images
Learn how to identify entities from an image using Amplify.
Label objects in an image
Learn more about how to detect labels in an image using Amplify. For example you can detect if an image has objects such as chairs, desks etc.
Interpret sentiment
Learn how to determine key phrases, sentiment, language, syntax, and entities from text using Amplify.

--------------------------------------------------------------------------------

Title: Use existing AWS resources - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/rest-api/existing-resources/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
API (REST)
/
Use existing AWS resources
Use existing AWS resources

Existing Amazon API Gateway resources can be used with the Amplify Libraries by calling Amplify.configure() with the API Gateway API name and options. Note, you will need to supply the full resource configuration and library options objects when calling Amplify.configure(). The following example shows how to configure additional API Gateway resources to an existing Amplify application:

Copy
code example
import { Amplify } from 'aws-amplify';
import outputs from '../amplify_outputs.json';
Amplify.configure(outputs):


const existingConfig = Amplify.getConfig();


// Add existing resource to the existing configuration.
Amplify.configure({
  ...existingConfig,
  API: {
    ...existingConfig.API,
    REST: {
      ...existingConfig.API?.REST,
      YourAPIName: {
        endpoint:
          'https://abcdefghij1234567890.execute-api.us-east-1.amazonaws.com/stageName',
        region: 'us-east-1' // Optional
      }
    }
  }
});
YourAPIName: Friendly name for the API
endpoint: The HTTPS endpoint of the API
region: AWS Region where the resources are provisioned. If not specified, the region will be inferred from the endpoint.

Note that before you can add an AWS resource to your application, the application must have the Amplify libraries installed. If you need to perform this step, see Install Amplify Libraries.

PREVIOUS
Test the REST API

--------------------------------------------------------------------------------

Title: Test the REST API - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/rest-api/test-api/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
API (REST)
/
Test the REST API
Test the REST API
Test the API from the terminal

If unauthenticated guest users have access to your REST API you can test it from the terminal using curl. curl is a command-line tool that lets you transfer data to and from a server using various protocols.

Curl is available in many distributions including Mac, Windows and Linux. Follow the install instructions in the docs.

Mac and Linux
Windows
GET method example
Terminal
Copy
Terminal code example
curl <your-api-endpoint>/<your-api-stage>/items
POST method example
Terminal
Copy
Terminal code example
curl -H "Content-Type: application/json" -d '{"name":"item-1"}' <your-api-endpoint>/<your-api-stage>/items
Test the API with API Gateway console

Let's test your new REST API using the route below with HTTP Method GET and path /items?limit=10 which includes a limit query string parameter.

Terminal
GET /items?limit=10
Sign in to the API Gateway console
Choose the myRestApi REST API
In the Resources pane, choose the method you want to test. Select GET right under /items.
Terminal
/                        
|_ /items               Main resource. Eg: /items  
  GET                   Methods  
  DELETE  
  PUT  
  POST  
  OPTIONS               Allow pre-flight requests in CORS by browser  
    |_ /{proxy+}         Proxy resource. Eg: /items/, /items/id, items/object/{id}  
    ANY                  Includes methods: DELETE, GET, HEAD, OPTIONS, PATCH, POST, PUT  
    OPTIONS              Allow pre-flight requests in CORS by browser
In the Method Execution pane, select TEST. Choose the GET method and add limit=10 to the query string {items} field.
Choose Test to run the test for GET /items?limit=10. The following information will be displayed: request, status, latency, response body, response headers and logs.
Terminal
Request
/items
Latency
111
Status
200
Response body
"Hello from myFunction!"
Response headers
{
  "Access-Control-Allow-Headers": "*",
  "Access-Control-Allow-Origin": "*",
  "X-Amzn-Trace-Id": "Root=1-661eee4b-f400fbebc6cfe65c3dadebcd;Parent=189f175e8de8d3a7;Sampled=0;lineage=c22c6ce1:0"
}
Log
Execution log for request 9bd9d8dc-95e2-494b-be1b-716393f83c49
Tue Apr 16 21:31:55 UTC 2024 : Starting execution for request: 9bd9d8dc-95e2-494b-be1b-716393f83c49
Tue Apr 16 21:31:55 UTC 2024 : HTTP Method: GET, Resource Path: /items
Tue Apr 16 21:31:55 UTC 2024 : Method request path: {}
Tue Apr 16 21:31:55 UTC 2024 : Method request query string: {}
Tue Apr 16 21:31:55 UTC 2024 : Method request headers: {}
Tue Apr 16 21:31:55 UTC 2024 : Method request body before transformations: 
Tue Apr 16 21:31:55 UTC 2024 : Endpoint request URI: https://lambda.us-east-1.amazonaws.com/2015-03-31/functions/arn:aws:lambda:us-east-1:[TRUNCATED:function:amplify-nextamplifygen2-y-testfunctionlambdaC407E8-zttuHxtL6x0V/invocations
Tue Apr 16 21:31:55 UTC 2024 : Endpoint request headers: {X-Amz-Date=20240416T213155Z, x-amzn-apigateway-api-id=bnyiitr69a, Accept=application/json, User-Agent=AmazonAPIGateway_bnyiitr69a, Host=lambda.us-east-1.amazonaws.com, X-Amz-Content-Sha256=246bd274ab578bc88286bd20a7371b0f08a1ec8cc2c8cacffb41e60430254c82, X-Amzn-Trace-Id=Root=1-661eee4b-f400fbebc6cfe65c3dadebcd, x-amzn-lambda-integration-tag=9bd9d8dc-95e2-494b-be1b-716393f83c49, Authorization=*********************************************************************************************************************************************************************************************************************************************************************************************************************************************bc00f2, X-Amz-Source-Arn=arn:aws:execute-api:us-east-1:[TRUNCATED]:bnyiitr69a/test-invoke-stage/GET/items, X-Amz-Security-Token= [TRUNCATED]
Tue Apr 16 21:31:55 UTC 2024 : Endpoint request body after transformations: {"resource":"/items","path":"/items","httpMethod":"GET","headers":null,"multiValueHeaders":null,"queryStringParameters":null,"multiValueQueryStringParameters":null,"pathParameters":null,"stageVariables":null,"requestContext":{"resourceId":"1m3yhu","resourcePath":"/items","httpMethod":"GET","extendedRequestId":"WVorzEQzoAMFubg=","requestTime":"16/Apr/2024:21:31:55 +0000","path":"/items","accountId":"[TRUNCATED]
","protocol":"HTTP/1.1","stage":"test-invoke-stage","domainPrefix":"testPrefix","requestTimeEpoch":1713303115234,"requestId":"9bd9d8dc-95e2-494b-be1b-716393f83c49","identity":{"cognitoIdentityPoolId":null,"cognitoIdentityId":null,"apiKey":"test-invoke-api-key","principalOrgId":null,"cognitoAuthenticationType":null,"userArn":"arn:aws:iam::[TRUNCATED]:user/ykethan","apiKeyId":"test-invoke-api-key-id","userAgent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36","accountId":"05364941472 [TRUNCATED]
Tue Apr 16 21:31:55 UTC 2024 : Sending request to https://lambda.us-east-1.amazonaws.com/2015-03-31/functions/arn:aws:lambda:us-east-1:[TRUNCATED]
:function:amplify-nextamplifygen2-y-testfunctionlambdaC407E8-zttuHxtL6x0V/invocations
Tue Apr 16 21:31:55 UTC 2024 : Received response. Status: 200, Integration latency: 108 ms
Tue Apr 16 21:31:55 UTC 2024 : Endpoint response headers: {Date=Tue, 16 Apr 2024 21:31:55 GMT, Content-Type=application/json, Content-Length=135, Connection=keep-alive, x-amzn-RequestId=67cfbdff-46cf-4355-8475-50a22e1f3234, x-amzn-Remapped-Content-Length=0, X-Amz-Executed-Version=$LATEST, X-Amzn-Trace-Id=root=1-661eee4b-f400fbebc6cfe65c3dadebcd;parent=189f175e8de8d3a7;sampled=0;lineage=c22c6ce1:0}
Tue Apr 16 21:31:55 UTC 2024 : Endpoint response body before transformations: {"statusCode":200,"headers":{"Access-Control-Allow-Origin":"*","Access-Control-Allow-Headers":"*"},"body":"\"Hello from myFunction!\""}
Tue Apr 16 21:31:55 UTC 2024 : Method response body after transformations: "Hello from myFunction!"
Tue Apr 16 21:31:55 UTC 2024 : Method response headers: {Access-Control-Allow-Origin=*, Access-Control-Allow-Headers=*, X-Amzn-Trace-Id=Root=1-661eee4b-f400fbebc6cfe65c3dadebcd;Parent=189f175e8de8d3a7;Sampled=0;lineage=c22c6ce1:0}
Tue Apr 16 21:31:55 UTC 2024 : Successfully completed execution
Tue Apr 16 21:31:55 UTC 2024 : Method completed with status: 200
PREVIOUS
Delete data
NEXT
Use existing AWS resources

--------------------------------------------------------------------------------

Title: Update data - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/rest-api/update-data/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
API (REST)
/
Update data
Update data
PUT requests

To create or update a item via the API endpoint:

Copy
code example
import { put } from 'aws-amplify/api';


async function updateItems() {
  try {
    const Item = { name: 'My first Item', message: 'Hello world!' };
    const restOperation = put({
      apiName: 'myRestApi',
      path: 'items/1',
      options: {
        body: Item
      }
    });
    const response = await restOperation.response;
    console.log('PUT call succeeded: ', response);
  } catch (error) {
    console.log('PUT call failed: ', JSON.parse(error.response.body));
  }
}
PREVIOUS
Post data
NEXT
Delete data

--------------------------------------------------------------------------------

Title: Delete data - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/rest-api/delete-data/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
API (REST)
/
Delete data
Delete data
DELETE requests

To delete an item via the API endpoint:

Copy
code example
import { del } from 'aws-amplify/api';


async function deleteItem() {
  try {
    const restOperation = del({
      apiName: 'myRestApi',
      path: 'items/1'
    });
    await restOperation.response;
    console.log('DELETE call succeeded');
  } catch (e) {
    console.log('DELETE call failed: ', JSON.parse(e.response.body));
  }
}
PREVIOUS
Update data
NEXT
Test the REST API

--------------------------------------------------------------------------------

Title: Post data - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/rest-api/post-data/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
API (REST)
/
Post data
Post data
POST Requests

Send a POST request with a JSON body.

Copy
code example
import { post } from 'aws-amplify/api';


async function postItem() {
  try {
    const restOperation = post({
      apiName: 'myRestApi',
      path: 'items',
      options: {
        body: {
          message: 'Mow the lawn'
        }
      }
    });


    const { body } = await restOperation.response;
    const response = await body.json();


    console.log('POST call succeeded');
    console.log(response);
  } catch (error) {
    console.log('POST call failed: ', JSON.parse(error.response.body));
  }
}
PREVIOUS
Fetch data
NEXT
Update data

--------------------------------------------------------------------------------

Title: Fetch data - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/rest-api/fetch-data/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
API (REST)
/
Fetch data
Fetch data

To invoke an endpoint, you need to set input object with required apiName option and optional headers, queryParams, and body options. API status code response > 299 are thrown as an ApiError instance. The error instance provides name and message properties parsed from the response.

GET requests
Copy
code example
import { get } from 'aws-amplify/api';


async function getItem() {
  try {
    const restOperation = get({ 
      apiName: 'myRestApi',
      path: 'items' 
    });
    const response = await restOperation.response;
    console.log('GET call succeeded: ', response);
  } catch (error) {
    console.log('GET call failed: ', JSON.parse(error.response.body));
  }
}
Accessing response payload

You can consume the response payload by accessing the body property of the response object. Depending on the use case and the content type of the body, you can consume they payload in string, blob, or JSON.

Copy
code example
// ...
const { body } = await restOperation.response;
// consume as a string:
const str = await body.text();
// OR consume as a blob:
const blob = await body.blob();
// OR consume as a JSON:
const json = await body.json();

You can not consume the response payload more than once.

Access HTTP response from errors

The REST API handler may throw an ApiError error instance. If the error is caused by an HTTP response with a non-2xx status code, the error instance will provide a response property. The response property contains following properties:

statusCode: HTTP status code
headers: HTTP response headers
body: HTTP response body as a string

The following example shows how to access the HTTP response from an ApiError instance, so that you can handle the error response from your REST API endpoint:

Copy
code example
import { ApiError, get } from 'aws-amplify/api';


try {
  const restOperation = get({ 
    apiName: 'myRestApi',
    path: 'items' 
  });
  await restOperation.response;
} catch (error) {
  if (error instanceof ApiError) {
    if (error.response) {
      const { 
        statusCode, 
        headers, 
        body 
      } = error.response;
      console.error(`Received ${statusCode} error response with payload: ${body}`);
    }
    // Handle API errors not caused by HTTP response.
  }
  // Handle other errors.
}
PREVIOUS
Define authorization rules
NEXT
Post data

--------------------------------------------------------------------------------

Title: Set up Amplify HTTP API - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/rest-api/set-up-http-api/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
API (REST)
/
Set up Amplify HTTP API
Set up Amplify HTTP API

Using the AWS Cloud Development Kit (AWS CDK), you can configure Amplify Functions as resolvers for routes of an HTTP API powered by Amazon API Gateway.

Set up HTTP API with Lambda Function

To get started, create a new directory and a resource file, amplify/functions/api-function/resource.ts. Then, define the function with defineFunction:

amplify/functions/api-function/resource.ts
Copy
amplify/functions/api-function/resource.ts code example
import { defineFunction } from "@aws-amplify/backend";


export const myApiFunction = defineFunction({
  name: "api-function",
});

Then, create the corresponding handler file, amplify/functions/api-function/handler.ts, file with the following contents:

amplify/functions/api-function/handler.ts
Copy
amplify/functions/api-function/handler.ts code example
import type { APIGatewayProxyHandlerV2 } from "aws-lambda";


export const handler: APIGatewayProxyHandlerV2 = async (event) => {
  console.log("event", event);
  return {
    statusCode: 200,
    // Modify the CORS settings below to match your specific requirements
    headers: {
      "Access-Control-Allow-Origin": "*", // Restrict this to domains you trust
      "Access-Control-Allow-Headers": "*", // Specify only the headers you need to allow
    },
    body: JSON.stringify("Hello from api-function!"),
  };
};

Next, using the AWS CDK, create an HTTP API in your backend file:

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from "@aws-amplify/backend";
import { Stack } from "aws-cdk-lib";
import {
  CorsHttpMethod,
  HttpApi,
  HttpMethod,
} from "aws-cdk-lib/aws-apigatewayv2";
import {
  HttpIamAuthorizer,
  HttpUserPoolAuthorizer,
} from "aws-cdk-lib/aws-apigatewayv2-authorizers";
import { HttpLambdaIntegration } from "aws-cdk-lib/aws-apigatewayv2-integrations";
import { Policy, PolicyStatement } from "aws-cdk-lib/aws-iam";
import { myApiFunction } from "./functions/api-function/resource";
import { auth } from "./auth/resource";
import { data } from "./data/resource";


const backend = defineBackend({
  auth,
  data,
  myApiFunction,
});


// create a new API stack
const apiStack = backend.createStack("api-stack");


// create a IAM authorizer
const iamAuthorizer = new HttpIamAuthorizer();


// create a User Pool authorizer
const userPoolAuthorizer = new HttpUserPoolAuthorizer(
  "userPoolAuth",
  backend.auth.resources.userPool,
  {
    userPoolClients: [backend.auth.resources.userPoolClient],
  }
);


// create a new HTTP Lambda integration
const httpLambdaIntegration = new HttpLambdaIntegration(
  "LambdaIntegration",
  backend.myApiFunction.resources.lambda
);


// create a new HTTP API with IAM as default authorizer
const httpApi = new HttpApi(apiStack, "HttpApi", {
  apiName: "myHttpApi",
  corsPreflight: {
    // Modify the CORS settings below to match your specific requirements
    allowMethods: [
      CorsHttpMethod.GET,
      CorsHttpMethod.POST,
      CorsHttpMethod.PUT,
      CorsHttpMethod.DELETE,
    ],
    // Restrict this to domains you trust
    allowOrigins: ["*"],
    // Specify only the headers you need to allow
    allowHeaders: ["*"],
  },
  createDefaultStage: true,
});


// add routes to the API with a IAM authorizer and different methods
httpApi.addRoutes({
  path: "/items",
  methods: [HttpMethod.GET, HttpMethod.PUT, HttpMethod.POST, HttpMethod.DELETE],
  integration: httpLambdaIntegration,
  authorizer: iamAuthorizer,
});


// add a proxy resource path to the API
httpApi.addRoutes({
  path: "/items/{proxy+}",
  methods: [HttpMethod.ANY],
  integration: httpLambdaIntegration,
  authorizer: iamAuthorizer,
});


// add the options method to the route
httpApi.addRoutes({
  path: "/items/{proxy+}",
  methods: [HttpMethod.OPTIONS],
  integration: httpLambdaIntegration,
});


// add route to the API with a User Pool authorizer
httpApi.addRoutes({
  path: "/cognito-auth-path",
  methods: [HttpMethod.GET],
  integration: httpLambdaIntegration,
  authorizer: userPoolAuthorizer,
});


// create a new IAM policy to allow Invoke access to the API
const apiPolicy = new Policy(apiStack, "ApiPolicy", {
  statements: [
    new PolicyStatement({
      actions: ["execute-api:Invoke"],
      resources: [
        `${httpApi.arnForExecuteApi("*", "/items")}`,
        `${httpApi.arnForExecuteApi("*", "/items/*")}`,
        `${httpApi.arnForExecuteApi("*", "/cognito-auth-path")}`,
      ],
    }),
  ],
});


// attach the policy to the authenticated and unauthenticated IAM roles
backend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(apiPolicy);
backend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(apiPolicy);


// add outputs to the configuration file
backend.addOutput({
  custom: {
    API: {
      [httpApi.httpApiName!]: {
        endpoint: httpApi.url,
        region: Stack.of(httpApi).region,
        apiName: httpApi.httpApiName,
      },
    },
  },
});
Install Amplify Libraries

Use the package manager of your choice to install the Amplify JavaScript library. For example, with npm:

Terminal
Copy
Terminal code example
npm add aws-amplify
Initialize Amplify API

To initialize the Amplify API category you need to configure Amplify with Amplify.configure().

Import and load the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point. For example src/main.ts:

pages/_app.tsx
Copy
pages/_app.tsx code example
import { Amplify } from 'aws-amplify';
import outputs from '@/amplify_outputs.json';


Amplify.configure(outputs);
const existingConfig = Amplify.getConfig();
Amplify.configure({
  ...existingConfig,
  API: {
    ...existingConfig.API,
    REST: outputs.custom.API,
  },
});

Make sure you call Amplify.configure as early as possible in your application’s life-cycle. A missing configuration or NoCredentials error is thrown if Amplify.configure has not been called before other Amplify JavaScript APIs. Review the Library Not Configured Troubleshooting guide for possible causes of this issue.

PREVIOUS
Set up Amplify REST API
NEXT
Define authorization rules

--------------------------------------------------------------------------------

Title: Set up Amplify REST API - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/rest-api/set-up-rest-api/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
API (REST)
/
Set up Amplify REST API
Set up Amplify REST API

Using the AWS Cloud Development Kit (AWS CDK), you can configure Amplify Functions as resolvers for routes of a REST API powered by Amazon API Gateway.

Set up REST API with Lambda Function

Create a new directory and a resource file, amplify/functions/api-function/resource.ts. Then, define the function with defineFunction:

amplify/functions/api-function/resource.ts
Copy
amplify/functions/api-function/resource.ts code example
import { defineFunction } from "@aws-amplify/backend";


export const myApiFunction = defineFunction({
  name: "api-function",
});

Create the corresponding handler file, amplify/functions/api-function/handler.ts, file with the following contents:

amplify/functions/api-function/handler.ts
Copy
amplify/functions/api-function/handler.ts code example
import type { APIGatewayProxyHandler } from "aws-lambda";


export const handler: APIGatewayProxyHandler = async (event) => {
  console.log("event", event);
  return {
    statusCode: 200,
    // Modify the CORS settings below to match your specific requirements
    headers: {
      "Access-Control-Allow-Origin": "*", // Restrict this to domains you trust
      "Access-Control-Allow-Headers": "*", // Specify only the headers you need to allow
    },
    body: JSON.stringify("Hello from myFunction!"),
  };
};

Use the AWS CDK to create an REST API resource powered by Amazon API Gateway.

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from "@aws-amplify/backend";
import { Stack } from "aws-cdk-lib";
import {
  AuthorizationType,
  CognitoUserPoolsAuthorizer,
  Cors,
  LambdaIntegration,
  RestApi,
} from "aws-cdk-lib/aws-apigateway";
import { Policy, PolicyStatement } from "aws-cdk-lib/aws-iam";
import { myApiFunction } from "./functions/api-function/resource";
import { auth } from "./auth/resource";
import { data } from "./data/resource";


const backend = defineBackend({
  auth,
  data,
  myApiFunction,
});


// create a new API stack
const apiStack = backend.createStack("api-stack");


// create a new REST API
const myRestApi = new RestApi(apiStack, "RestApi", {
  restApiName: "myRestApi",
  deploy: true,
  deployOptions: {
    stageName: "dev",
  },
  defaultCorsPreflightOptions: {
    allowOrigins: Cors.ALL_ORIGINS, // Restrict this to domains you trust
    allowMethods: Cors.ALL_METHODS, // Specify only the methods you need to allow
    allowHeaders: Cors.DEFAULT_HEADERS, // Specify only the headers you need to allow
  },
});


// create a new Lambda integration
const lambdaIntegration = new LambdaIntegration(
  backend.myApiFunction.resources.lambda
);


// create a new resource path with IAM authorization
const itemsPath = myRestApi.root.addResource("items", {
  defaultMethodOptions: {
    authorizationType: AuthorizationType.IAM,
  },
});


// add methods you would like to create to the resource path
itemsPath.addMethod("GET", lambdaIntegration);
itemsPath.addMethod("POST", lambdaIntegration);
itemsPath.addMethod("DELETE", lambdaIntegration);
itemsPath.addMethod("PUT", lambdaIntegration);


// add a proxy resource path to the API
itemsPath.addProxy({
  anyMethod: true,
  defaultIntegration: lambdaIntegration,
});


// create a new Cognito User Pools authorizer
const cognitoAuth = new CognitoUserPoolsAuthorizer(apiStack, "CognitoAuth", {
  cognitoUserPools: [backend.auth.resources.userPool],
});


// create a new resource path with Cognito authorization
const booksPath = myRestApi.root.addResource("cognito-auth-path");
booksPath.addMethod("GET", lambdaIntegration, {
  authorizationType: AuthorizationType.COGNITO,
  authorizer: cognitoAuth,
});


// create a new IAM policy to allow Invoke access to the API
const apiRestPolicy = new Policy(apiStack, "RestApiPolicy", {
  statements: [
    new PolicyStatement({
      actions: ["execute-api:Invoke"],
      resources: [
        `${myRestApi.arnForExecuteApi("*", "/items", "dev")}`,
        `${myRestApi.arnForExecuteApi("*", "/items/*", "dev")}`,
        `${myRestApi.arnForExecuteApi("*", "/cognito-auth-path", "dev")}`,
      ],
    }),
  ],
});


// attach the policy to the authenticated and unauthenticated IAM roles
backend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(
  apiRestPolicy
);
backend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(
  apiRestPolicy
);


// add outputs to the configuration file
backend.addOutput({
  custom: {
    API: {
      [myRestApi.restApiName]: {
        endpoint: myRestApi.url,
        region: Stack.of(myRestApi).region,
        apiName: myRestApi.restApiName,
      },
    },
  },
});
Install Amplify Libraries

Use the package manager of your choice to install the Amplify JavaScript library. For example, with npm:

Terminal
Copy
Terminal code example
npm add aws-amplify
Initialize Amplify API

To initialize the Amplify API category you need to configure Amplify with Amplify.configure().

Import and load the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point. For example index.js in React or main.ts in Angular.

pages/_app.tsx
Copy
pages/_app.tsx code example
import { Amplify } from 'aws-amplify';
import outputs from '@/amplify_outputs.json';


Amplify.configure(outputs);
const existingConfig = Amplify.getConfig();
Amplify.configure({
  ...existingConfig,
  API: {
    ...existingConfig.API,
    REST: outputs.custom.API,
  },
});

Make sure you call Amplify.configure as early as possible in your application’s life-cycle. A missing configuration or NoCredentials error is thrown if Amplify.configure has not been called before other Amplify JavaScript APIs. Review the Library Not Configured Troubleshooting guide for possible causes of this issue.

NEXT
Set up Amplify HTTP API

--------------------------------------------------------------------------------

Title: Define authorization rules - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/rest-api/customize-authz/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
API (REST)
/
Define authorization rules
Define authorization rules

When determining the authorization mode for your REST endpoint, there are a few customizations you can do.

IAM Authorization

By default, the API will be using IAM authorization and the requests will be signed for you automatically. IAM authorization has two modes: one using an unauthenticated role, and one using an authenticated role. When the user has not signed in, the unauthenticated role is used by default. Once the user has signed in, the authenticate role is used, instead.

API Key

If you want to configure a public REST API, you can set an API key in Amazon API Gateway or create one using the CDK construct. Then, you can set the API key header in the API configuration which will be applied to all requests.

Copy
code example
Amplify.configure(outputs, {
  API: {
    REST: {
      headers: async () => {
        return { 'X-Api-Key': apiKey };
      }
    }
  }
});
Cognito User Pool Authorization

You can use the access token from configured Cognito User Pool to authenticate against REST endpoint. The JWT token can be retrieved from the Auth category.

Copy
code example
import { fetchAuthSession } from 'aws-amplify/auth'


const session = await fetchAuthSession();
const token = session.tokens?.idToken

Then you need to set the Authorization header in the API category configuration. The following example shows how to set the Authorization header for all requests.

Copy
code example
Amplify.configure(outputs, {
  API: {
    REST: {
      headers: async () => {
        return { Authorization: authToken };
      }
    }
  }
});

For more details on how to configure the API Gateway with the custom authorization, see this

Note related to use of Access Token or ID Token

The ID Token contains claims about the identity of the authenticated user such as name, email, and phone_number. On the Amplify Authentication category you can retrieve the Id Token using:

Copy
code example
const session = await fetchAuthSession();
const token = session.tokens?.idToken

The Access Token contains scopes and groups and is used to grant access to authorized resources. This is a tutorial for enabling custom scopes. You can retrieve the Access Token using

Copy
code example
const session = await fetchAuthSession();
const token = session.tokens?.accessToken
Custom Authorization Token

If you want to use a custom authorization token, you can set the token in the API category configuration. The custom authorization token will be applied to all requests.

Copy
code example
Amplify.configure(outputs, {
  API: {
    REST: {
      headers: async () => {
        return { Authorization: customAuthToken };
      }
    }
  }
});
Setting Authorization Headers per Request

Alternatively, you can set the authorization headers per request. For example, if you want to use a custom header named Authorization for a specific REST request, you can set the following configuration:

Copy
code example
async function updateItem() {
  await del({
    apiName: 'myRestApi',
    path: 'items/1',
    options: {
      headers: {
        Authorization: authToken
      }
    }
  }).response;
}
PREVIOUS
Set up Amplify HTTP API
NEXT
Fetch data

--------------------------------------------------------------------------------

Title: Create an in-app messaging campaign on AWS Console - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/in-app-messaging/create-campaign/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
In-App Messaging
/
Create an in-app messaging campaign on AWS Console
Create an in-app messaging campaign on AWS Console

As an alternative to writing AWS Cloud Development Kit (CDK) code, you can use the AWS console to create a campaign that sends messages through any single channel that is supported by Amazon Pinpoint: Mobile Push, In-App, Email, SMS or Custom channels. Learn how to create a campaign using Amazon Pinpoint to continue integrating in-app messages in your app with Amplify.

Login to the AWS Console, and Search for Pinpoint.

Click on your project from the list of available project. Your project name would be the name you provided when you created the pinpoint project using CDK.

Click on Campaigns from the left navigation menu, and then click on Create a campaign

Add a name to your campaign, and keep the following options as follows and then click Next:

Campaign type: Standard campaign
Channel: In-App messaging
set prioritization: Fairly important

Click on the Create a segment radio button, add a name for your segment, and then click Next.

You can add as many segments as needed to the campaign. For this quickstart, you can use Include any audiences under the Segment group 1 section.
You can add a criteria to your segments to ensure that audiences that satisfy that criteria can receive the in-app message.
If you see an error message titled Segment might include multiple channels, click I understand to proceed.

Click on the Create a new in-app message radio button.

You have the ability to customize the following attributes of the in-app message:

Layout: Which includes all of the different messaging layout options.
Header: Title of the in-app message, including the text color/alignment.
Message: The body of the Message, including the text color/alignment.
Background: Control the background color of the in-app message.
Image URL: Add an image to be displayed as part of the in-app message body.
Primary button: Allows the addition of a button to add functionality to the in-app message.
Secondary button: Allows the addition of an extra button for additional functionality.
Custom Data: Allows the in-app message to pass additional data to the frontend app once it is triggered by an event.

For this tutorial you can create a simple message as shown below. Customers in your application will see the same message once the event is triggered.

Once you have finished customizing your in-app message, click on Next.
Under Trigger events, add the name of the analytics trigger that will be sent from your frontend app.
You have the ability to customize the trigger to allow only certain attributes or metrics that are passed with the analytics event to trigger the in-app message. (Optional)

By default, the number of messages shown per session is 1. You can update this threshold during campaign setup.

Review your campaign, and then click on Launch campaign.

Your campaign is now setup, and you are ready to start integrating the In-App Messaging functionality into your app.

Note: Campaign start time must be at least 15 minutes in future. In-app messages can only be synced to local device once the campaign becomes active (status should be "In Progress" in the campaigns screen of the Pinpoint console).

PREVIOUS
Resolve conflicts

--------------------------------------------------------------------------------

Title: API (REST) - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/rest-api/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
API (REST)
API (REST)
Set up Amplify REST API
The API category provides a solution for making HTTP requests to REST API endpoints. The API library can be used for creating signed requests against Amazon API Gateway when the API Gateway Authorization is set to AWS_IAM or Cognito User Pools.
Set up Amplify HTTP API
The API category provides a solution for making HTTP requests to HTTP API endpoints. The API library can be used for creating signed requests against Amazon API Gateway when the API Gateway Authorization is set to AWS_IAM or Cognito User Pools.
Define authorization rules
Learn more about how to define authorization rules for Amplify's REST API capabilities
Fetch data
Using the GET API REST in Amplify
Post data
Using Post, Put, etc. in Amplify
Update data
Using Post, Put, etc. in Amplify
Delete data
Using the Delete API REST in Amplify
Test the REST API
Learn how you can test the REST API from the terminal, with Amplify Mock, or with the API Gateway console.
Use existing AWS resources
Configure the Amplify Libraries to use existing Amazon API Gateway resources by referencing them in your configuration.

--------------------------------------------------------------------------------

Title: Resolve conflicts - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/in-app-messaging/resolve-conflicts/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
In-App Messaging
/
Resolve conflicts
Resolve conflicts

In the rare case where an event is sent and meets the criteria set forth by multiple in-app messages, the library needs to decide which message to return. If such a conflict should arise, In-App Messaging will choose a message by:

Sorting the messages in order of campaign expiration
Returning the top message sorted (the closest message to expiry)

However, this may not be how you wish to resolve such conflicts so you may want to set your own conflict handler.

src/index.js
Copy
src/index.js code example
import { setConflictHandler } from 'aws-amplify/in-app-messaging';


/**
 * Regardless of your conflict resolution strategy the handler must always accept
 * an array of in-app messages and return a single in-app message.
 */
const myConflictHandler = (messages) => {
  // Return a random message
  const randomIndex = Math.floor(Math.random() * messages.length);
  return messages[randomIndex];
};


setConflictHandler(myConflictHandler);
PREVIOUS
Respond to interaction events
NEXT
Create an in-app messaging campaign on AWS Console

--------------------------------------------------------------------------------

Title: Respond to interaction events - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/in-app-messaging/respond-interaction-events/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
In-App Messaging
/
Respond to interaction events
Respond to interaction events

Your code can respond with additional behavior to your users interacting with in-app messages by adding interaction event listeners.

Message received

Add onMessageReceived listeners to respond to an in-app message being received from the library as the result of an event matching the criteria of a synced in-app message. This is required if you are implementing a custom UI so that your UI can respond to event-triggered campaign messages but you may also find it helpful to listen for these messages for any other reason your application requires.

src/index.js
Copy
src/index.js code example
import { onMessageReceived } from 'aws-amplify/in-app-messaging';


const myMessageReceivedHandler = (message) => {
  // Do something with the received message
};


const listener = onMessageReceived(myMessageReceivedHandler);


listener.remove(); // Remember to remove the listener when it is no longer needed
Message displayed

Add onMessageDisplayed listeners to respond to an in-app message being displayed to your user.

src/index.js
Copy
src/index.js code example
import { onMessageDisplayed } from 'aws-amplify/in-app-messaging';


const myMessageDisplayedHandler = (message) => {
  // Do something with the displayed message
};


const listener = onMessageDisplayed(myMessageDisplayedHandler);


listener.remove(); // Remember to remove the listener when it is no longer needed
Message dismissed

Add onMessageDismissed listeners to respond to an in-app message being dismissed by your user.

src/index.js
Copy
src/index.js code example
import { onMessageDismissed } from 'aws-amplify/in-app-messaging';


const myMessageDismissedHandler = (message) => {
  // Do something with the dismissed message
};


const listener = onMessageDismissed(myMessageDismissedHandler);


listener.remove(); // Remember to remove the listener when it is no longer needed
Message action taken

Add onMessageActionTaken listeners to respond to an action being taken on an in-app message. Typically, this means that the user has tapped or clicked a button on an in-app message.

src/index.js
Copy
src/index.js code example
import { onMessageActionTaken } from 'aws-amplify/in-app-messaging';


const myMessageActionTakenHandler = (message) => {
  // Do something with the message action was taken against
};


const listener = onMessageActionTaken(myMessageActionTakenHandler);


listener.remove(); // Remember to remove the listener when it is no longer needed
Notifying listeners

If you are using the Amplify In-App Messaging UI, interaction events notifications are already wired up for you. However, if you are implementing your own UI, it is highly recommended to notify listeners of interaction events through your UI code so that the library can take further actions prescribed by the installed provider (for example, automatically recording corresponding Analytics events).

src/index.js
Copy
src/index.js code example
import { notifyMessageInteraction } from 'aws-amplify/in-app-messaging';


const message = {
  // In-app message that you want to record an interaction on
}


/**
 * Interaction events that can be notified correspond to their respective listeners:
 *    'messageReceived'
 *    'messageDisplayed'
 *    'messageDismissed'
 *    'messageActionTaken'
 */
notifyMessageInteraction({ message, type: 'messageDisplayed' });
PREVIOUS
Identify a user
NEXT
Resolve conflicts

--------------------------------------------------------------------------------

Title: Identify a user - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/in-app-messaging/identify-user/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
In-App Messaging
/
Identify a user
Identify a user

To fully harness the potential of In-App Messaging, you must segment and target your In-App Messaging campaigns to specific user subsets. By identifying users with additional information, including their device demographics, location and any attributes of your choosing, you will be able to display intelligent, targeted in-app messages to the right users.

src/index.js
Copy
src/index.js code example
import { identifyUser } from 'aws-amplify/in-app-messaging';


await identifyUser({
  userId: '', // E.g. user-id
  userProfile: {
    email: '', // E.g. example@service.com
    name: '', // E.g. name-of-the-user
    plan: '' // E.g. plan-they-subscribe-to
    customProperties: {
      // E.g. hobbies: ['cooking', 'knitting'],
    },
    demographic: {
      appVersion: '',
      locale: '', // E.g. en_US
      make: '', // E.g. Apple
      model: '', // E.g. iPhone
      modelVersion: '', // E.g. 13
      platform: '', // E.g. iOS
      platformVersion: '', // E.g. 15
      timezone: '' // E.g. Americas/Los_Angeles
    },
    location: {
      city: '', // E.g. Seattle
      country: '', // E.g. US,
      postalCode: '', // E.g. 98121
      region: '', // E.g. WA
      latitude: 0.0,
      longitude: 0.0
    },
    metrics: {
      // E.g. logins: 157
    },
  },
});
Identify a user with Amazon Pinpoint

When using identifyUser with Amazon Pinpoint, in addition to the other user info properties you can configure the address, optOut, and userAttributes properties under options.

src/index.js
Copy
src/index.js code example
import { identifyUser } from 'aws-amplify/in-app-messaging';


await identifyUser({
  userId: '', // E.g. user-id
  options: {
    address: '' // E.g. A device token or email address
    optOut: ''  // Either ALL or NONE
    userAttributes: {
      // E.g. interests: ['soccer', 'shoes'],
    }
  },
});
PREVIOUS
Clear messages
NEXT
Respond to interaction events

--------------------------------------------------------------------------------

Title: Clear messages - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/in-app-messaging/clear-messages/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
In-App Messaging
/
Clear messages
Clear messages

Once messages have been synced to your user's device, clearMessages() can be used to clear the synced messages.

src/index.js
Copy
src/index.js code example
import { clearMessages } from 'aws-amplify/in-app-messaging';


await clearMessages();

Note: If your app has authentication implemented, we recommend calling clearMessages() in between user log-ins to remove messages targeted for specific user segments. This is especially important if you anticipate your application will be used in shared device scenarios.

PREVIOUS
Display messages
NEXT
Identify a user

--------------------------------------------------------------------------------

Title: Display messages - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/in-app-messaging/display-messages/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
In-App Messaging
/
Display messages
Display messages

In-app messages are displayed when an In-App Messaging or analytics event is sent and matches the criteria defined by your active In-App Messaging campaigns.

Analytics event

Now that messages have been synced to your users' devices, Amplify In-App Messaging will allow you to start displaying them with Amplify Analytics events with no additional integration steps. Any events you record or are already recording using the Analytics' record API are automatically picked up and processed by In-App Messaging. If the event matches the attributes and criteria defined in an in-app message, that message will be displayed.

src/index.js
Copy
src/index.js code example
import { record } from 'aws-amplify/analytics';


record({
  name: 'first_event',
  attributes: { color: 'red' },
  metrics: { quantity: 10 }
});

If the event name, attributes, and metrics match those set forth by one of your In-App Messaging campaigns, you should see the in-app message displayed in your app.

In-App Messaging events

In addition to or instead of Amplify Analytics events, you can also dispatch In-App Messaging events to trigger an in-app message display programmatically.

src/index.js
Copy
src/index.js code example
import { dispatchEvent } from 'aws-amplify/in-app-messaging';


dispatchEvent({
  name: 'first_event',
  attributes: { color: 'red' },
  metrics: { quantity: 10 }
});

If the event name, attributes, and metrics match those set forth by one of your In-App Messaging campaigns, you should see the in-app message displayed in your app.

PREVIOUS
Sync messages
NEXT
Clear messages

--------------------------------------------------------------------------------

Title: Sync messages - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/in-app-messaging/sync-messages/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
In-App Messaging
/
Sync messages
Sync messages

To trigger messages, you must sync them from your In-App Messaging campaigns to your users' devices. These messages are then triggered with an analytics or In-App Messaging event. You can control when and how often this sync is performed.

src/index.js
Copy
src/index.js code example
import { syncMessages } from 'aws-amplify/in-app-messaging';


await syncMessages();

Note: Syncing messages will always overwrite existing messages currently on the user's device so that they are always up to date when the sync is performed.

PREVIOUS
Integrate your application
NEXT
Display messages

--------------------------------------------------------------------------------

Title: Set up in-app messaging - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/in-app-messaging/set-up-in-app-messaging/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
In-App Messaging
/
Set up in-app messaging
Set up in-app messaging

Amplify allows interacting with In-App Messaging APIs, enabling you to send messages to your app users. In-App Messaging is a powerful tool to engage with your users and provide them with relevant information. A campaign is a messaging initiative that engages a specific audience segment. A campaign sends tailored messages according to a schedule that you define. You can use the AWS Cloud Development Kit (AWS CDK) to create a campaign that sends messages through any single channel that is supported by Amazon Pinpoint: Mobile Push, In-App, Email, SMS or Custom channels.

The following is an example utilizing the AWS CDK to create the In-App Messaging resource powered by Amazon Pinpoint. Note: there are no official hand-written (L2) constructs for this service yet.

Note: Campaign start time must be at least 15 minutes in future. In-app messages can only be synced to local device once the campaign becomes active (Status should be "In Progress" in the campaigns screen of the Pinpoint console).

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import {
  CfnApp,
  CfnCampaign,
  CfnSegment,
} from "aws-cdk-lib/aws-pinpoint";
import { Policy, PolicyStatement } from "aws-cdk-lib/aws-iam";
import { Stack } from "aws-cdk-lib/core";




const backend = defineBackend({
  auth, 
  data,
  // additional resources 
});


const inAppMessagingStack = backend.createStack("inAppMessaging-stack");


// create a Pinpoint app
const pinpoint = new CfnApp(inAppMessagingStack, "Pinpoint", {
  name: "myPinpointApp",
});


// create a segment 
const mySegment = new CfnSegment(inAppMessagingStack, "Segment", {
  applicationId: pinpoint.ref,
  name: "mySegment",
});


// create a campaign with event and in-app message template
new CfnCampaign(inAppMessagingStack, "Campaign", {
  applicationId: pinpoint.ref,
  name: "MyCampaign",
  segmentId: mySegment.attrSegmentId,
  schedule: {
    // ensure the start and end time are in the future
    startTime: "2024-02-23T14:39:34Z", 
    endTime: "2024-02-29T14:32:40Z",
    frequency: "IN_APP_EVENT",
    eventFilter: {
      dimensions: {
        eventType: {
          dimensionType: "INCLUSIVE",
          values: ["my_first_event"],
        },
      },
      filterType: "ENDPOINT",
    },
  },


  messageConfiguration: {
    inAppMessage: {
      layout: "TOP_BANNER",
      content: [
        {
          // define the content of the in-app message
          bodyConfig: {
            alignment: "CENTER",
            body: "This is an example in-app message.",
            textColor: "#FFFFFF",
          },
          backgroundColor: "#000000",
          headerConfig: {
            alignment: "CENTER",
            header: "Welcome!",
            textColor: "#FFFFFF",
          },
          // optionally, define buttons, images, etc.
        },
      ],
    },
  },
});


//create an IAM policy to allow interacting with Pinpoint in-app messaging
const pinpointPolicy = new Policy(inAppMessagingStack, "PinpointPolicy", {
  policyName: "PinpointPolicy",
  statements: [
    new PolicyStatement({
      actions: [
        "mobiletargeting:GetInAppMessages",
        "mobiletargeting:UpdateEndpoint",
        "mobiletargeting:PutEvents",
      ],
      resources: [pinpoint.attrArn + "/*", pinpoint.attrArn],
    }),
  ],
});


// apply the policy to the authenticated and unauthenticated roles
backend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(pinpointPolicy);
backend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(pinpointPolicy);


// patch the custom Pinpoint resource to the expected output configuration
backend.addOutput({
  notifications: {
    amazon_pinpoint_app_id: pinpoint.ref,
    aws_region: Stack.of(pinpoint).region,
    channels: ["IN_APP_MESSAGING"],
  },
});
Install Amplify Libraries

First, install the aws-amplify library:

Terminal
Copy
Terminal code example
npm add aws-amplify
Initialize In-App Messaging

To finish setting up your application with Amplify, you need to configure it using the configure API. Next, to interact with In-App Messaging APIs, you need to first initialize In-App Messaging by calling the initializeInAppMessaging API directly imported from the in-app-messaging sub-path. This is required to be called as early as possible in the app lifecycle.

index.tsx
Copy
index.tsx code example
import { Amplify } from 'aws-amplify';
import { initializeInAppMessaging } from 'aws-amplify/in-app-messaging';
import outputs from '@/amplify_outputs.json';


Amplify.configure(outputs);
initializeInAppMessaging();

Make sure you call Amplify.configure as early as possible in your application’s life-cycle. A missing configuration or NoCredentials error is thrown if Amplify.configure has not been called before other Amplify JavaScript APIs.

References

Amazon Pinpoint Construct Library

NEXT
Integrate your application

--------------------------------------------------------------------------------

Title: Integrate your application - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/in-app-messaging/integrate-application/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
In-App Messaging
/
Integrate your application
Integrate your application
Install Amplify UI for React

Although Amplify In-App Messaging can be used as a standalone JavaScript library, this guide will show you how to use it together with Amplify UI, which currently supports integration with React and React Native, to get started quickly.

Learn more about Amplify In-App Messaging UI and how to fully unlock its capabilities here: Amplify UI for In-App Messaging

Terminal
Copy
Terminal code example
npm add @aws-amplify/ui-react @aws-amplify/ui-react-notifications
Integrate Amplify UI

Amplify UI provides a Higher-Order Component for ease of integrating the In-App Messaging UI with your application. Simply wrap your application root component in, for example, App.js.

src/App.js
Copy
src/App.js code example
import { withInAppMessaging } from '@aws-amplify/ui-react-notifications';


import '@aws-amplify/ui-react/styles.css';


const App = () => (
  {/* Your application code */}
);


export default withInAppMessaging(App);

Below is an example of what your entry file should look like:

src/index.js
Copy
src/index.js code example
import React, { useEffect } from 'react';
import {
  initializeInAppMessaging,
  syncMessages,
  dispatchEvent
} from 'aws-amplify/in-app-messaging';
import { Button, View } from '@aws-amplify/ui-react';
import { withInAppMessaging } from '@aws-amplify/ui-react-notifications';
import { record } from 'aws-amplify/analytics';
import '@aws-amplify/ui-react/styles.css';
import outputs from '../amplify_outputs.json';


Amplify.configure(outputs);
initializeInAppMessaging();


// To display your in-app message, make sure this event name matches one you created
// in an In-App Messaging campaign!
const myFirstEvent = { name: 'my_first_event' };


const App = () => {
  useEffect(() => {
    // Messages from your campaigns need to be synced from the backend before they
    // can be displayed. You can trigger this anywhere in your app. Here you are
    // syncing just once when this component (your app) renders for the first time.
    syncMessages();
  }, []);


  return (
    <View>
      {/* This button has an example of an analytics event triggering the in-app message. */}
      <Button
        onClick={() => {
          record(myFirstEvent);
        }}
      >
        Record Analytics Event
      </Button>


      {/* This button has an example of an In-app Messaging event triggering the in-app message.*/}
      <Button
        onClick={() => {
          dispatchEvent(myFirstEvent);
        }}
      >
        Send In-App Messaging Event
      </Button>
    </View>
  );
};


export default withInAppMessaging(App);

You can now build and run your app in your terminal. If you click on one of the buttons shown in the above example, the in-app message you defined in the Pinpoint console should be displayed in your app.

PREVIOUS
Set up in-app messaging
NEXT
Sync messages

--------------------------------------------------------------------------------

Title: Use Amazon Location Service SDK - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/geo/amazon-location-sdk/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Geo
/
Use Amazon Location Service SDK
Use Amazon Location Service SDK

Amplify Geo provides solutions for common use cases with Amazon Location Service but for any functionality that is not currently supported by Amplify Geo you can access the Amazon Location Service SDK directly.

Follow this guide to get started with the aws-sdk for Amazon Location Service using Amplify Auth credentials.

Overview

In this tutorial, we’ll go over the following:

Setting up the AWS SDK JavaScript v3 package for the Amazon Location Service SDK calls with Amplify auth.
Code examples using the Amazon Location Service SDK.
Installing SDK dependencies

The first step to using the SDKs in the client is to install the necessary dependencies with the following command:

Terminal
Copy
Terminal code example
npm add @aws-sdk/client-location
Connecting your app to Amazon Location Service

In the following procedure, you’ll connect your app to the Amazon Location Service APIs.

To connect your app to the Amazon Location Service

In your React App, open src/App.js file, and call the following function to initialize the Amazon Location Service client:

Copy
code example
import { Amplify } from 'aws-amplify';
import { fetchAuthSession } from 'aws-amplify/auth';
import {
  LocationClient,
  AssociateTrackerConsumerCommand
} from '@aws-sdk/client-location';
import outputs from '../amplify_outputs.json';
Amplify.configure(outputs);


const createClient = async () => {
  const session = await fetchAuthSession();
  const client = new LocationClient({
    credentials: session.credentials,
    region: amplifyconfig.aws_project_region
  });
  return client;
};

You’ve now successfully connected your app to the Amazon Location Service.

Using the Amazon Location Service APIs

In order to access Amazon Location Service APIs, ensure you've provisioned resources and configured your app using the instructions in either Amplify Geo Maps docs or the Amazon Location Service console.

You can check out the Amazon Location API Reference documentation for a complete list of supported features.

Example: Getting Device Position

This example requires you to have first provisioned a Tracker resource using the Amazon Location Service console.

The following code details how to use the Amazon Location Service APIs to update a device position and get a device position using the tracker you just created:

Copy
code example
// UpdateDevicePosition API
const params = {
  TrackerName: 'trackerId',
  Updates: [
    {
      DeviceId: 'deviceId',
      Position: [-122.431297, 37.773972],
      SampleTime: new Date()
    }
  ]
};
const command = new BatchUpdateDevicePositionCommand(params);
client.send(command, (err, data) => {
  if (err) console.error(err);
  if (data) console.log(data);
});


// GetDevicePosition API
const client = await createClient();
const params = {
  TrackerName: 'trackerId',
  DeviceId: 'deviceId'
};
const command = new GetDevicePositionCommand(params);
client.send(command, (err, data) => {
  if (err) console.error(err);
  if (data) console.log(data);
});
PREVIOUS
Migrate from Google Maps

--------------------------------------------------------------------------------

Title: In-App Messaging - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/in-app-messaging/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
In-App Messaging
In-App Messaging
Set up in-app messaging
Learn how to get started with in-app messaging.
Integrate your application
Learn how to integrate your application with In-app Messaging.
Sync messages
Learn how to sync in-app messages to your user's local device. Synced messages will be displayed when a matching event is triggered.
Display messages
Learn how in-app messages are displayed when an In-App Messaging or analytics event is sent and matches the criteria set forth by your active In-App Messaging campaigns.
Clear messages
Learn more about how to clear synced in-app messages from the user's device.
Identify a user
Learn how to segment and target your In-App Messaging campaigns to specific user subsets.
Respond to interaction events
Learn how to respond with additional behavior to your users interacting with in-app messages by adding interaction event listeners.
Resolve conflicts
Learn how to resolve conflicts when an event is sent and meets the criteria set forth by multiple in-app messages.
Create an in-app messaging campaign on AWS Console
Create a new Pinpoint campaign and configure it to be used with your Amplify project.

--------------------------------------------------------------------------------

Title: Migrate from Google Maps - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/geo/google-migration/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Geo
/
Migrate from Google Maps
Migrate from Google Maps

Are you using Google Maps or another similar Map Provider and would like to switch over to using Amplify Geo or Amazon Location Service? This tutorial will show you how to take your existing Google Maps APIs and switch over to using Amplify Geo.

Getting Started

Amplify Geo provides APIs for using location based functionality. Under the hood Amplify uses Amazon Location Service and is designed to work with open source mapping library MapLibre.

This guide assumes that you are already familiar with the Google Maps JavaScript API and with front-end web development concepts including HTML, CSS, and JavaScript.

To complete this tutorial, you will need:

Amplify Geo
A text editor
Key differences between Amplify Geo and Google Maps
Coordinates Conventions

A key difference to notice between using Amplify Geo and Google Maps is with Google Maps Platform their convention for specifying coordinates is [lat, lng]. When migrating over to Amplify Geo the order is swapped to be [lng, lat]. This was done to match the geojson spec which is also used by MapLibre.

Authorization

When using Google Maps Platform or other similar services like Mapbox you will first be prompted to go to the Google Cloud Console to set up APIs and create an API key where you will then use the API key when requesting the Google Maps JS API. With Amplify Geo you will instead setup Amplify Auth and the MapView component will read the auth configuration from the amplify_outputs.json file. Behind the scenes Amplify Auth uses Amazon Cognito to set up client credentials with access to Location Service and Geo will use those credentials when making any location related API calls. More information on setting Amplify Auth and Geo can be found below in the Setting Up Amplify section.

Create a webpage
Open your text editor and create a new file called index.html.
Paste the following code into the file to set up the framework for a webpage with a map.
Copy
code example
<!DOCTYPE html>
<html>


<head>
    <meta charset="utf-8">
    <title>Display a map on a webpage</title>
    <meta name="viewport" content="initial-scale=1,maximum-scale=1,user-scalable=no">
    <!-- Import MapLibre  -->
    <script src="https://cdn.amplify.aws/packages/maplibre-gl/1.15.2/maplibre-gl.js"
        integrity="sha384-rwYfkmAOpciZS2bDuwZ/Xa/Gog6jXem8D/whm3wnsZSVFemDDlprcUXHnDDUcrNU" crossorigin="anonymous"
        referrerpolicy="no-referrer"></script>
    <link href="https://cdn.amplify.aws/packages/maplibre-gl/1.15.2/maplibre-gl.css" rel="stylesheet"
        integrity="sha384-DrPVD9GufrxGb7kWwRv0CywpXTmfvbKOZ5i5pN7urmIThew0zXKTME+gutUgtpeD" crossorigin="anonymous"
        referrerpolicy="no-referrer">
    </link>
    <!-- Import Amplify  -->
    <script src="https://cdn.amplify.aws/packages/core/5.0.5/aws-amplify-core.min.js" 
        integrity="sha384-eM2urkpomL9SRm/kuPHZG3XPEItAiUAAyotT/AqlhSus8iAqs/EfHaYy1Jn5ih7K" crossorigin="anonymous"
        referrerpolicy="no-referrer"></script>
    <script src="https://cdn.amplify.aws/packages/auth/5.0.5/aws-amplify-auth.min.js"
        integrity="sha384-H25CFLYd7YHa1Oib73fs3kJN36VhaHHkLjo4AhGrhJ4HuKam05pg2/0t2MR6epun" crossorigin="anonymous"
        referrerpolicy="no-referrer"></script>
    <script src="https://cdn.amplify.aws/packages/geo/2.0.5/aws-amplify-geo.min.js"
        integrity="sha384-Esc9xx0X7ckb/yeYHuYsZGqBB4FwYr98NFHS3BRXLeRE/eB0uVrad2w+G6cGxYb5" crossorigin="anonymous"
        referrerpolicy="no-referrer"></script>
    <script src="https://cdn.amplify.aws/packages/maplibre-gl-js-amplify/1.5.0/maplibre-gl-js-amplify.umd.min.js"
        integrity="sha384-9kJyZavd3Jk6QzHeaLpugVonfZmZZZdixek6uglOwzKtZvDS9K3W4dshw1uswmlV" crossorigin="anonymous"
        referrerpolicy="no-referrer"></script>
    </link>


    <style>
        body {
            margin: 0;
            padding: 0;
        }


        #map {
            position: absolute;
            top: 0;
            bottom: 0;
            width: 100%;
        }
    </style>
</head>


<body>
    <div id="map"></div>
    <script type="module">
        import outputs from "../amplify_outputs.json" assert { type: "json" };
        const { Amplify } = aws_amplify_core;
        const { createMap } = AmplifyMapLibre;
        Amplify.configure(outputs);


        // Add code from below steps here
    </script>
</body>


</html>

This code imports the MapLibre GL JS library and CSS, one of the popular options for map rendering we recommend for use with Amplify Geo. In the HTML body you create a <div> element with an id of 'map' that will be the map's container. Finally in the script section you'll setup some Amplify configuration that is required for Amplify Geo to understand what Amplify AWS resources have been created.

Setting up Amplify
You will need to setup a Geo Map resources. Follow instructions for creating a map.
Once the workflow has completed you should have an amplify_outputs.json file in the same directory as your index.html file.
Save your index.html file.
Display a map

In this step we will show you how to add code to display a map in your application.

Amplify
Google Maps

With Amplify Geo and MapLibre you can add the following code to your index.html file inside the <script> tags, after the Amplify.configure command:

Copy
code example
const map = await createMap({
  container: document.getElementById('map'), // div ID
  center: [-122.4783, 37.8199], // initial coordinates [long, lat]
  zoom: 13 // initial zoom level, high number being more zoomed in
});

Save your HTML file and open it in a web browser to see your rendered map.

Display a marker

Here you will add a marker to your map

Amplify
Google Maps

With Amplify Geo and MapLibre you can do the following.

Copy
code example
const marker = new maplibregl.Marker().setLngLat([-122.4783, 37.8199]).addTo(map);

Save your changes and refresh your page and you should see a default blue marker icon on your map.

This example uses MapLibre's marker component to create a marker. To see more examples with markers on from MapLibre check the examples here.

Add a Popup

Now you can add a popup that displays information when a user clicks on a marker.

Amplify
Google Maps

With Amplify Geo and MapLibre you can do the following.

Copy
code example
const popup = new maplibregl.Popup().setHTML(
  `<h3>Golden Gate Bridge</h3><p>The hex code for the bridge's color is: #c0362c</p>`
);


const marker = new maplibregl.Marker()
  .setLngLat([-122.4783, 37.8199])
  .setPopup(popup)
  .addTo(map);

Save your changes and refresh your page and now when you click on the icon a popup should appear on the screen.

This example uses MapLibre's popup component to create a marker popup. To see more examples with popups on from MapLibre check the examples here.

Add a search component

Now we can try adding a search bar to your map which can return results and place markers on a map based on those results.

Amplify
Google Maps

With Amplify Geo and MapLibre you can do the following.

Copy
code example
const { createMap, createAmplifyGeocoder } = AmplifyMapLibre; // import from above updated to include createAmplifyGeocoder


const geocoder = createAmplifyGeocoder();
map.addControl(geocoder);

Save your changes and refresh your page and now when you should see a maplibre-gl-geocoder control in the top right corner of your map.

This example uses the MapLibre's geocoder component to create a search component. To see more options for our createAmplifyGeocoder utility function check out the docs here.

Add a stand alone search component

Now we can try adding a search bar without adding it to a map which can return results that you can use.

Amplify
Google Maps

With Amplify Geo and MapLibre you can do the following.

Copy
code example
// Create a div to hold the search component
const el = document.createElement("div");
el.setAttribute("id", "search");
document.body.appendChild(el);


// Create the geocoder component and append it to the div you created earlier
const geocoder = createAmplifyGeocoder();
document.getElementById("search").appendChild(geocoder.onAdd());

Save your changes and refresh your page and now when you should see a maplibre-gl-geocoder control in the div you created.

This example uses the MapLibre's geocoder component to create a search component. To see more options for our createAmplifyGeocoder utility function check out the docs here.

PREVIOUS
Use existing Amazon Location resources
NEXT
Use Amazon Location Service SDK

--------------------------------------------------------------------------------

Title: Use existing Amazon Location resources - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/geo/existing-resources/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Geo
/
Use existing Amazon Location resources
Use existing Amazon Location resources

To use existing Amazon Location Services resources with your Amplify backend or frontend application, use the addOutput method to surface backend resource outputs to the amplify_outputs.json file:

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from "@aws-amplify/backend"


const backend = defineBackend({})


backend.addOutput({
  geo: {
    aws_region: "<your-aws-region>",
    maps: {
      items: {
        "<your-friendly-map-name>": {
          name: "<your-map-name>",
          style: "<your-map-style>",
        },
      },
      default: "<your-friendly-map-name>",
    },
  },
})
Authorization permissions

To use your existing Amazon Location Service resources (i.e. maps and place indices) with Amplify Geo, you need to ensure your role has the right authorization permissions through Cognito.

Note: Here is a guide on Creating an Amazon Cognito identity pool for use with Amazon Location Service

There are two roles created by Cognito: an "authenticated role" that grants signed-in-user-level access and an "unauthenticated role" that allows unauthenticated access to resources. Attach the following policies for the appropriate resources and roles (Auth and/or Unauth). Replace {region}, {account-id}, and {enter Map/PlaceIndex name} with the correct items. Note that certain actions cannot be performed with unauthenticated access. The list of actions allowed for the Unauth role is in the Granting access to Amazon Location Service guide.

Copy
code example
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "GetTiles",
      "Effect": "Allow",
      "Action": [
        "geo:GetMapTile",
        "geo:GetMapSprites",
        "geo:GetMapGlyphs",
        "geo:GetMapStyleDescriptor"
      ],
      "Resource": "arn:aws:geo:<your-geo-region>:<your-account-id>:map/<your-map-name>"
    },
    {
      "Sid": "Search",
      "Effect": "Allow",
      "Action": [
        "geo:SearchPlaceIndexForPosition",
        "geo:SearchPlaceIndexForText"
      ],
      "Resource": "arn:aws:geo:<your-geo-region>:<your-account-id>:place-index/<your-index-name>"
    },
    {
      "Sid": "Geofence",
      "Effect": "Allow",
      "Action": [
        "geo:GetGeofence",
        "geo:PutGeofence",
        "geo:BatchPutGeofence",
        "geo:BatchDeleteGeofence",
        "geo:ListGeofences",
      ],
      "Resource": "arn:aws:geo:<your-geo-region>:<your-account-id>:geofence-collection/<your-collection-name>"
    }
  ]
}
Configure client library directly

You can first import and configure the generated amplify_outputs.json. You can then manually configure Amplify Geo like this:

Copy
code example
import { Amplify } from 'aws-amplify';
import outputs from '../amplify_outputs.json';


Amplify.configure(outputs);
Amplify.configure({
  ...Amplify.getConfig(),
  Geo: {
    LocationService: {
      maps: {
        items: {
          <your-map-name>: {
            // REQUIRED - Amazon Location Service Map resource name
            style: 'VectorEsriStreets' // REQUIRED - String representing the style of map resource
          }
        },
        default: '<your-preferred-default-map>' // REQUIRED - Amazon Location Service Map resource name to set as default
      },
      search_indices: {
        items: ['<your-geo-index>'], // REQUIRED - Amazon Location Service Place Index name
        default: '<your-default-index>' // REQUIRED - Amazon Location Service Place Index name to set as default
      },
      geofenceCollections: {
        items: ['<your-geo-collection>'], // REQUIRED - Amazon Location Service Geofence Collection name
        default: '<your-default-collection>' // REQUIRED - Amazon Location Service Geofence Collection name to set as default
      },
      region: '<your-geo-region>' // REQUIRED - Amazon Location Service Region
    }
  }
});

Now you can proceed to displaying a map or adding location search to your app.

PREVIOUS
Work with geofences
NEXT
Migrate from Google Maps

--------------------------------------------------------------------------------

Title: Work with geofences - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/geo/geofences/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Geo
/
Work with geofences
Work with geofences
Provisioning geofence resources

First, make sure you've provisioned a geofence collection resource and configured your app using the instructions in either Configure a geofence collection or Use existing Amazon Location Service resources and you have already setup displaying a map in your application.

Manage Geofences in Your Application

To add a geofence management component to your map, you can use the amplify-geofence-control.

Install the necessary dependencies with the following command:

Terminal
Copy
Terminal code example
npm add aws-amplify \
  @aws-amplify/geo \
  @aws-amplify/ui-react \
  @aws-amplify/ui-react-geo

Note: Make sure that aws-amplify @aws-amplify/geo version 6.0.0 or above are installed.

First, create a map onto which you want to add the geofence management component. See the guide on creating and displaying maps.

Then, import AmplifyGeofenceControl from "maplibre-gl-js-amplify", create a new instance of this control and add it to your MapLibre map instance.

Notes: To use Geofence Controls the user will need to be authenticated with the administrative Cognito user associated with the Geofence Collection you created. Below is an example using React and the Amplify Authenticator.

Javascript
React

Note: When using the existing maps implementation you can add the Geofence control to an existing map

Copy
code example
import { useEffect, useRef } from "react";
- import { createMap } from "maplibre-gl-js-amplify";
+ import { createMap, AmplifyGeofenceControl } from "maplibre-gl-js-amplify";
+ import { withAuthenticator } from "@aws-amplify/ui-react";
+ import "@aws-amplify/ui-react/styles.css";
+ import "maplibre-gl-js-amplify/dist/public/amplify-ctrl-geofence.css";
import "maplibre-gl/dist/maplibre-gl.css";


function Map() {
  const mapRef = useRef(null); // Reference to the map DOM element
  // Wrapping your code in a useEffect allows us to run initializeMap after the div has been rendered into the DOM
  useEffect(() => {
    let map;
    async function initializeMap() {
      // You only want to initialize the underlying maplibre map after the div has been rendered
      if (mapRef.current != null) {
        map = await createMap({
          container: mapRef.current,
          center: [-122.431297, 37.773972],
          zoom: 11,
        });
      }
+     const control = new AmplifyGeofenceControl()
+     map.addControl(control);
  }
  initializeMap();
    // Cleans up and maplibre DOM elements and other resources - https://maplibre.org/maplibre-gl-js/docs/API/classes/Map/#remove
    return function cleanup() {
      if (map != null) map.remove();
    };
  }, []);
 return (
   <div className="App">
     <div ref={mapRef} id="map" />
   </div>
 );
}


export default withAuthenticator(Map);

Note: Ensure that your package bundler (webpack, rollup, etc) is configured to handle css files. Check out the webpack documentation here.

Geofence API

If you are using a different mapping library or need a programmatic approach to managing geofences, the @aws-amplify/geo package provides methods for managing geofences, but not geofence collections.

First, you need to import Geo from the @aws-amplify/geo package.

Copy
code example
import { Geo } from '@aws-amplify/geo';
saveGeofences

saveGeofences is used to save geofences to your collection. It can take a single geofence or an array of geofences.

API
Copy
code example
Geo.saveGeofences(geofences, options) => Promise<SaveGeofenceResults>;
Parameters
geofences - can be a single geofence object, or an array of geofence objects to save to a collection.
options - optional options object for saving geofences
collectionName - the name of the collection to save geofences to.
Defaults to the default collection listed in your amplify_outputs.json file after provisioning a geofence collection resource.

Geofence objects must have the following properties:

geofenceId - a opaque and unique identifier for the geofence.
geometry - a geometry object that defines the geofence.
polygon - an array of arrays with [Longitude, Latitude] coordinates.

NOTE: Polygon arrays have a few requirements:

must have at least 4 vertices (i.e. 4 coordinate points)
the first and last point must be the same in order to complete the polygonal loop
vertices must be in counter-clockwise order
Return

The return from saveGeofences is a Promise that resolves to SaveGeofenceResults which contains both successes and errors for geofences that were successfully created or failed.

Each success object has the following properties:

geofenceId - the geofenceId of the geofence that was saved.
createTime - the time the geofence was created.
updateTime - the time the geofence was last updated.

Each error object has the following properties:

geofenceId - the geofenceId of the geofence that failed to be saved.
error - an error object
code - the error code
message - the error message
Example
Copy
code example
let saveGeofenceResults;
try {
  saveGeofenceResults = await Geo.saveGeofences({
    geofenceId: 'my-geofence',
    geometry: {
      polygon: [
        [-123.14695358276366, 49.290090146520434],
        [-123.1358814239502, 49.294960279811974],
        [-123.15021514892577, 49.29300108863353],
        [-123.14909934997559, 49.29132171993048],
        [-123.14695358276366, 49.290090146520434]
      ]
    }
  });
} catch (error) {
  // errors thrown by input validations of `saveGeofences`
  throw error;
}


if (saveGeofenceResults.errors.length > 0) {
  // error handling that are from the underlying API calls
  console.log(`Success count: ${saveGeofenceResults.successes.length}`);
  console.log(`Error count: ${saveGeofenceResults.errors.length}`);
}
getGeofence

geoGeofence is used to get a single geofence from a collection.

API
Copy
code example
Geo.getGeofence(geofenceId, options) => Promise<Geofence>;
Parameters
geofenceId - the id of the geofence to get.
options - optional options object for getting a geofence
collectionName - the name of the collection to get geofence from.
Defaults to the default collection listed in your amplify_outputs.json file after provisioning a geofence collection resource.
Return

The return from getGeofence is a Promise that resolves to a geofence object.

Example
Copy
code example
let responses;
try {
  response = await Geo.getGeofence('geofenceId');
} catch (error) {
  throw error;
}
listGeofences

listGeofences is used to get a list of geofences from a collection. It has pagination built in and will return 100 geofences per page.

API
Copy
code example
Geo.listGeofences(options) => Promise<ListGeofenceResults>;
Parameters
options - optional options object for saving geofences
nextToken - the pagination token for the next page of geofences.
if no token is given, it will return the first page of geofences.
collectionName - the name of the collection to save geofences to.
Defaults to the default collection listed in your amplify_outputs.json file after provisioning a geofence collection resource.
Return

Returns a Promise that resolves to an object with the following properties:

entries - an array of geofences
nextToken - the pagination token for the next page of geofences
Example
Copy
code example
let response;
try {
  response = await Geo.listGeofences();
  response.entries.forEach((geofence) => console.log(geofence.geofenceId));
} catch (error) {
  throw error;
}
deleteGeofences

deleteGeofences is used to delete a geofences from a collection. It can delete a single or multiple geofences at once.

API
Copy
code example
Geo.deleteGeofences(geofenceIds, options) => Promise<DeleteGeofencesResults>;
Parameters
geofenceIds - a single geofenceId or array of geofenceIds to delete
options - optional options object for saving geofences
collectionName - the name of the collection to save geofences to.
Defaults to the default collection listed in your amplify_outputs.json file after provisioning a geofence collection resource.
Return

The return from deleteGeofences is a Promise that resolves to an object with both successes and errors for geofences that were successfully deleted or not.

The success object is an array of geofenceIds that were successfully deleted.
The error object is an array of error objects that include the following properties:
geofenceId - the geofenceId of the geofence that failed to be deleted.
error - an error object
code - the error code
message - the error
Example
Copy
code example
let response;
try {
  response = await Geo.deleteGeofences(
    [
      "geofence1",
      "geofence2",
      "geofence3",
    ]
  )
catch (error) {
  // error handling from logic and validation issues within `deleteGeofences`
  throw error;
}


if(response.errors.length > 0){
  // error handling that are from the underlying API calls
  console.log(`Success count: ${response.successes.length}`);
  console.log(`Error count: ${response.errors.length}`);
}
PREVIOUS
Configure a geofence collection
NEXT
Use existing Amazon Location resources

--------------------------------------------------------------------------------

Title: Configure a geofence collection - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/geo/configure-geofencing/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Geo
/
Configure a geofence collection
Configure a geofence collection

A Geofence is a virtual perimeter for a real-world geographic area. A Geofence contains points or vertices that form a closed boundary, defining an area of interest. Geofence collections store one or multiple Geofences.

Setup a new Geofence Collection
amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from "@aws-amplify/backend";
import { Policy, PolicyStatement } from "aws-cdk-lib/aws-iam";
import { CfnGeofenceCollection } from "aws-cdk-lib/aws-location";
import { auth } from "./auth/resource";
import { data } from "./data/resource";


const backend = defineBackend({
  auth,
  data,
  // additional resources
});


const geoStack = backend.createStack("geo-stack");


// create a location services geofence collection
const myGeofenceCollection = new CfnGeofenceCollection(
  geoStack,
  "GeofenceCollection",
  {
    collectionName: "myGeofenceCollection",
    pricingPlan: "RequestBasedUsage",
    tags: [
      {
        key: "name",
        value: "myGeofenceCollection",
      },
    ],
  }
);


// create an IAM policy to allow interacting with geofence collection resource
const myGeofenceCollectionPolicy = new Policy(
  geoStack,
  "GeofenceCollectionPolicy",
  {
    policyName: "myGeofenceCollectionPolicy",
    statements: [
      new PolicyStatement({
        actions: [
          "geo:GetGeofence",
          "geo:PutGeofence",
          "geo:BatchPutGeofence",
          "geo:BatchDeleteGeofence",
          "geo:ListGeofences",
        ],
        resources: [myGeofenceCollection.attrArn],
      }),
    ],
  }
);


// apply the policy to the authenticated and unauthenticated roles
backend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(myGeofenceCollectionPolicy);
backend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(myGeofenceCollectionPolicy);


// patch the geofence collection resource to the expected output configuration
backend.addOutput({
  geo: {
    geofence_collections: {
      default: myGeofenceCollection.collectionName,
      items: [myGeofenceCollection.collectionName],
    },
  },
});
Geofence Collection Pricing Plan

The pricing plan for the Geofence Collection will be set to RequestBasedUsage. We advice you to go through the location service pricing along with the location service terms (82.5 section) to learn more about the pricing plan.

Group access

To scope access permissions based on Cognito User Groups

Create a Cognito User Pool Group
amplify/auth/resource.ts
Copy
amplify/auth/resource.ts code example
import { defineAuth } from '@aws-amplify/backend';


export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  groups: ["User"],
});
Add permissions to the Cognito User Pool Group role
amplify/backend.ts
Copy
amplify/backend.ts code example
const myGeofenceCollectionPolicy = new Policy(
  geoStack,
  "GeofenceCollectionPolicy",
  {
    policyName: "myGeofenceCollectionPolicy",
    statements: [
      new PolicyStatement({
        actions: [
          "geo:GetGeofence",
          "geo:PutGeofence",
          "geo:BatchPutGeofence",
          "geo:BatchDeleteGeofence",
          "geo:ListGeofences",
        ],
        resources: [myGeofenceCollection.attrArn],
      }),
    ],
  }
);


backend.auth.resources.groups["User"].role.attachInlinePolicy(myGeofenceCollectionPolicy);

Note: If you combine Auth/Guest user access and Individual Group access, users who are members of a group will only be granted the permissions of the group, and not the authenticated user permissions. The permissions apply to ALL Geofences in a collection. For example, If you add Read permission such as ListGeofences and GetGeofence to User Cognito group, ALL users added to that group will be able to read the properties of ALL Geofences in that Geofence collection.

Using the AWS SDK for Javascript

Alternatively, if you want to add users to an existing Cognito user pool group programmatically, you can use the AWS SDK for Javascript. Refer to the API documentation.

Note: After you have provisioned the Geofence Collection, depending on your application's use-case, you can also add Geofences to the provisioned Geofence Collection programmatically. Refer this API documentation for more information.

PREVIOUS
Work with location search
NEXT
Work with geofences

--------------------------------------------------------------------------------

Title: Work with maps - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/geo/maps/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Geo
/
Work with maps
Work with maps
Display a map

First, ensure you've provisioned an Amazon Location Service Map resource and configured your app using the instructions in either Set up map or Use existing resources guide.

Note: For React, you can use the Amplify React MapView component

To render a map, the MapLibre GL and the maplibre-gl-js-amplify libraries are required. MapLibre GL is an open source map rendering library and maplibre-gl-js-amplify library makes it easy to integrate MapLibre with Amplify Geo and handles Authentication.

Add the dependencies to your app:

Terminal
Copy
Terminal code example
npm add maplibre-gl maplibre-gl-js-amplify

Verify the following:

maplibre-gl-js-amplify version 4.0.0 or above is installed
Any package bundlers (webpack, rollup, etc) are configured to handle css files. Check out the webpack documentation here.

Import the library into your application:

Copy
code example
import { createMap } from 'maplibre-gl-js-amplify';
import 'maplibre-gl/dist/maplibre-gl.css';

Next, create and render the Map with the help of createMap.

Note: There must be a div with an id="map" on the DOM before making the call to createMap in this way.

Copy
code example
async function initializeMap() {
  const map = await createMap({
    container: 'map', // An HTML Element or HTML element ID to render the map in https://maplibre.org/maplibre-gl-js/docs/API/classes/Map/
    center: [-123.1187, 49.2819], // [Longitude, Latitude]
    zoom: 11
  });
}


initializeMap();

To render a map using a className or something other than the ID you can pass in a reference to the HTML Element itself.

Copy
code example
const element = document.getElementsByClassName("class")[0];


const map = await createMap({
    container: element,
    ...
})

The MapLibre canvas requires a defined height to display properly, otherwise you may end up with a blank screen where the map is supposed to be.

The amplify-map.css file has a few commonly used methods for setting the height of the map component. You can add some of the examples listed to your own styles or directly import amplify-map.css like so:

Copy
code example
import "maplibre-gl-js-amplify/dist/public/amplify-map.css";

To render a map using percentage based height you need to ensure that all ancestor elements to the map container have a height:

Copy
code example
html,
body,
#root {
  /* The ancestors of the map element */
  height: 100%;
}


#map {
  height: 50%;
}

Display markers on map

To display markers on a map, use the drawPoints function. drawPoints expects:

sourceName - specifies the layer on which the markers are rendered on. You can edit existing markers by passing the same sourceName
coordinate data - (longitude, latitude) the coordinate data of the markers to be displayed
a maplibre-gl-js Map - the map object on which to render the markers

First, import the drawPoints method in your app. Your import section should include look like this

Copy
code example
import { drawPoints } from 'maplibre-gl-js-amplify';

The drawPoints method returns ids of the source and layers used to display the markers on the map. These ids can be used for further customization through maplibre-gl-js source, paint, and layer options.

For more information about the parameters and options that can be used with drawPoints check the documentation here.

Next, use the following code snippet when you want to display the markers on the map. Add it to the initializeMap() function if you want the markers to show up on map load.

Copy
code example
map.on('load', function () {
  drawPoints(
    'mySourceName', // Arbitrary source name
    [
      {
        coordinates: [-122.483696, 37.833818], // [Longitude, Latitude]
        title: 'Golden Gate Bridge',
        address: 'A suspension bridge spanning the Golden Gate'
      },
      {
        coordinates: [-122.477, 37.8105] // [Longitude, Latitude]
      }
    ], // An array of coordinate data, an array of Feature data, or an array of [NamedLocations](https://github.com/aws-amplify/maplibre-gl-js-amplify/blob/main/src/types.ts#L8)
    map,
    {
      showCluster: true,
      unclusteredOptions: {
        showMarkerPopup: true
      },
      clusterOptions: {
        showCount: true
      }
    }
  );
});

Display different map styles

The getAvailableMaps API fetches information for all maps that are available to be displayed.

This is useful if you would like to give your users a variety of maps styles to choose from.

Copy
code example
import { Geo } from '@aws-amplify/geo';


Geo.getAvailableMaps();

The available maps are returned as an array with the following contents:

Copy
code example
//returns
[
  {
    mapName: 'myAmplifyGeoEsriStreetMap',
    style: 'VectorEsriStreets'
  },
  {
    mapName: 'myAmplifyGeoEsriTopographicMap',
    style: 'VectorEsriTopographic'
  }
];

You can resize and customize a map with the resize and setStyle functions:

Copy
code example
map.setStyle('myAmplifyGeoEsriTopographicMap'); // map name received from getAvailableMaps()
map.resize(); // forces the map to re-render
Removing a map from the DOM

When it's time to remove the map from the DOM, you can use the .remove method of the generated map. This will clean up and release all resources associated with the map (DOM elements, event bindings, web workers, and WebGL resources).

Copy
code example
map.remove();

After calling .remove(), you must not call any other methods on the map.

For React users:

Not removing the map on component unmount can cause memory leaks in your application. It's recommended to call .remove() in either the return function of a React useEffect hook or the componentWillUnmount lifecycle hook of a class component.

Add map to html website

To display a map on your html website, add the following scripts to your html webpage.

Copy
code example
<link href="https://cdn.amplify.aws/packages/maplibre-gl/1.15.2/maplibre-gl.css" rel="stylesheet" integrity="sha384-DrPVD9GufrxGb7kWwRv0CywpXTmfvbKOZ5i5pN7urmIThew0zXKTME+gutUgtpeD" crossorigin="anonymous" referrerpolicy="no-referrer"></link>
<script src="https://cdn.amplify.aws/packages/maplibre-gl/1.15.2/maplibre-gl.js" integrity="sha384-rwYfkmAOpciZS2bDuwZ/Xa/Gog6jXem8D/whm3wnsZSVFemDDlprcUXHnDDUcrNU" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script src="https://cdn.amplify.aws/packages/core/4.3.0/aws-amplify-core.min.js" integrity="sha384-7Oh+5w0l7XGyYvSqbKi2Q7SA5K640V5nyW2/LEbevDQEV1HMJqJLA1A00z2hu8fJ" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script src="https://cdn.amplify.aws/packages/auth/4.3.8/aws-amplify-auth.min.js" integrity="sha384-jfkXCEfYyVmDXYKlgWNwv54xRaZgk14m7sjeb2jLVBtUXCD2p+WU8YZ2mPZ9Xbdw" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script src="https://cdn.amplify.aws/packages/geo/1.1.0/aws-amplify-geo.min.js" integrity="sha384-TFMTyWuCbiptXTzvOgzJbV8TPUupG1rA1AVrznAhCSpXTIdGw82bGd8RTk5rr3nP" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script src="https://cdn.amplify.aws/packages/maplibre-gl-js-amplify/1.1.0/maplibre-gl-js-amplify.umd.min.js" integrity="sha384-7/RxWonKW1nM9zCKiwU9x6bkQTjldosg0D1vZYm0Zj+K/vUSnA3sOMhlRRWAtHPi" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

Next, add a div element with id map anywhere in your webpage where you want to render the map. Include the following code snippet to configure Amplify (update the amplify_outputs.json file path accordingly) and instantiate the map.

Copy
code example
<script type="module">
  import outputs from './amplify_outputs.json' assert { type: 'json' };
  const { Amplify } = aws_amplify_core;
  const { createMap } = AmplifyMapLibre;
  Amplify.configure(outputs);
  createMap({
    container: 'map',
    center: [-123.1187, 49.2819], // [Longitude, Latitude]
    zoom: 13
  });
</script>
Sample application
Copy
code example
<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <title>Display a map on a webpage</title>
        <meta name="viewport" content="initial-scale=1,maximum-scale=1,user-scalable=no">
        <link href="https://cdn.amplify.aws/packages/maplibre-gl/1.15.2/maplibre-gl.css" rel="stylesheet" integrity="sha384-DrPVD9GufrxGb7kWwRv0CywpXTmfvbKOZ5i5pN7urmIThew0zXKTME+gutUgtpeD" crossorigin="anonymous" referrerpolicy="no-referrer"></link>
        <script src="https://cdn.amplify.aws/packages/maplibre-gl/1.15.2/maplibre-gl.js" integrity="sha384-rwYfkmAOpciZS2bDuwZ/Xa/Gog6jXem8D/whm3wnsZSVFemDDlprcUXHnDDUcrNU" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
        <script src="https://cdn.amplify.aws/packages/core/5.0.5/aws-amplify-core.min.js" integrity="sha384-eM2urkpomL9SRm/kuPHZG3XPEItAiUAAyotT/AqlhSus8iAqs/EfHaYy1Jn5ih7K" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
        <script src="https://cdn.amplify.aws/packages/auth/5.0.5/aws-amplify-auth.min.js" integrity="sha384-H25CFLYd7YHa1Oib73fs3kJN36VhaHHkLjo4AhGrhJ4HuKam05pg2/0t2MR6epun" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
        <script src="https://cdn.amplify.aws/packages/geo/2.0.5/aws-amplify-geo.min.js" integrity="sha384-Esc9xx0X7ckb/yeYHuYsZGqBB4FwYr98NFHS3BRXLeRE/eB0uVrad2w+G6cGxYb5" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
        <script src="https://cdn.amplify.aws/packages/maplibre-gl-js-amplify/1.5.0/maplibre-gl-js-amplify.umd.min.js" integrity="sha384-9kJyZavd3Jk6QzHeaLpugVonfZmZZZdixek6uglOwzKtZvDS9K3W4dshw1uswmlV" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
        <style>
            body { margin: 0; padding: 0; }
            #map { position: absolute; top: 0; bottom: 0; width: 100%; }
        </style>
    </head>
    <body>
        <div id="map"></div>
        <script type="module">
            import outputs from "./amplify_outputs.json" assert { type: "json" };
            const { Amplify } = aws_amplify_core;
            const { createMap } = AmplifyMapLibre;
            Amplify.configure(outputs);
            createMap({
                container: "map",
                center: [-123.1187, 49.2819], // [Longitude, Latitude]
                zoom: 13,
            });
        </script>
    </body>
</html>
Map API's

If you want more information about the maps you currently have configured or want a way to switch between maps programmatically, the @aws-amplify/geo package provides API's that return more information about your currently provisioned maps.

First, you need to import Geo from the @aws-amplify/geo package.

Copy
code example
import { Geo } from '@aws-amplify/geo';
getAvailableMaps

getAvailableMaps will return the map resources you currently have provisioned in your Amplify project. You can switch between any of these different maps and display their different map styles.

API
Copy
code example
Geo.getAvailableMaps() => Promise<AmazonLocationServiceMapStyle[]>;
Parameters
N/A
Return

The return from getAvailableMaps is a Promise that resolves to AmazonLocationServiceMapStyle[] which is an array of mapName, style, and region.

Each object has the following properties:

mapName - name of the map you created.
style - the Amazon Location Service style used to create the map.
region - the AWS region the map is hosted in.

Note: When changing a map with Amplify and MapLibre the setStyle function should be called with the name of the Location Service map NOT the style. This is because the transformRequest function uses the Location Service map name to make a new request for map tile data.

Example
Copy
code example
const availableMaps = await Geo.getAvailableMaps();


map.setStyle(availableMaps[0].mapName);
getDefaultMap

getDefaultMap is used to get a the default map object.

API
Copy
code example
Geo.getDefaultMap() => Promise<AmazonLocationServiceMapStyle>;
Parameters
N/A
Return

The return from getDefaultMap is a Promise that resolves to a AmazonLocationServiceMapStyle object.

The object has the following properties:

mapName - name of the map you created.
style - the Amazon Location Service style used to create the map.
region - the AWS region the map is hosted in.
Example
Copy
code example
const defaultMap = await Geo.getDefaultMap();
PREVIOUS
Set up Amplify Geo
NEXT
Configure location search

--------------------------------------------------------------------------------

Title: Work with location search - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/geo/location-search/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Geo
/
Work with location search
Work with location search
Add location search functionality on a map

First, make sure you've provisioned a search index resource and configured your app using the instructions in either Configure Location Search or Use existing Amazon Location Service resources and you have already setup displaying a map in your application.

Note: For React, you can use the Amplify UI Location Search component to generate and display the search results.

To add a location search UI component to your map, you can use the maplibre-gl-geocoder library. maplibre-gl-js-amplify package makes it easy to integrate maplibre-gl-geocoder with Amplify Geo by exporting a utility function createAmplifyGeocoder() that returns an instance of maplibre-gl-geocoder with some pre-defined settings and supports all the options for customizing the UI component

Install the necessary dependencies with the following command:

Terminal
Copy
Terminal code example
npm add @maplibre/maplibre-gl-geocoder maplibre-gl@1 maplibre-gl-js-amplify

Note: Make sure that maplibre-gl-js-amplify version 4.0.0 or above is installed.

First, create a map onto which you want to add the location search UI component. See the guide on creating and displaying maps.

Then, use createAmplifyGeocoder() to get a new instance of MaplibreGeocoder and add the location search UI component to the map.

Note: Ensure that your package bundler (webpack, rollup, etc) is configured to handle css files. Check out the webpack documentation here.

Copy
code example
import { createMap, createAmplifyGeocoder } from "maplibre-gl-js-amplify";
import maplibregl from "maplibre-gl";
import "maplibre-gl/dist/maplibre-gl.css";
import "@maplibre/maplibre-gl-geocoder/dist/maplibre-gl-geocoder.css";
import "maplibre-gl-js-amplify/dist/public/amplify-geocoder.css"; // Optional CSS for Amplify recommended styling


async function initializeMap() {
    const el = document.createElement("div");
    el.setAttribute("id", "map");
    document.body.appendChild(el);


    const map = await createMap({
        container: "map",
        center: [-123.1187, 49.2819], // [Longitude, Latitude]
        zoom: 11,
    })


    map.addControl(createAmplifyGeocoder());
}


initializeMap();

Display the location search box outside the map

You can also use maplibre-gl-geocoder to display the location search UI component anywhere in your application, even outside the map.

To do so, extract the html element using function onAdd() and attach it anywhere in your DOM instead of adding it via the map's addControl() function.

Copy
code example
const geocoder = createAmplifyGeocoder();
document.getElementById("search").appendChild(geocoder.onAdd());

Customize Search Icons

You can customize the search icons used by the maplibre-gl-geocoder to use any image of your choosing. MapLibre markers require an HTMLElement when passing in custom images.

The following example puts an existing SVG icon into an HTMLElement before being passed to createAmplifyGeocoder which creates a maplibre-gl-geocoder.

Copy
code example
import myIcon from "./myIcon.svg" // relative path to your custom icon


const icon = new Image(100, 100);
icon.src = myIcon;


const geocoder = createAmplifyGeocoder({ showResultMarkers: { element: icon } });
map.addControl(geocoder);

Location-based search capabilities

Amplify Geo enables you to search for locations by text, addresses, or geo-coordinates.

Search by text, address, business name, city, and more

The Geo.searchByText() API enables you to search for places or points of interest by free-form text, such as an address, name, city, or region.

Copy
code example
import { Geo } from "@aws-amplify/geo"


Geo.searchByText("Amazon Go Store")

Customize your search results further by providing:

countries - to limit the search results to given countries (specified in ISO Alpha-3 country codes)
maxResults - to limit the maximum result set
biasPosition - to act as the search origination location
searchAreaConstraints - to limit the area to search inside of
searchIndexName - to use a different Location Service search index resource than the default

Note: Providing both biasPosition and searchAreaConstraints parameters simultaneously returns an error.

Copy
code example
const searchOptionsWithBiasPosition = {
  countries: string[], // Alpha-3 country codes
  maxResults: number, // 50 is the max and the default
  biasPosition: [
    longitude // number
    latitude // number,
  ], // Coordinates point to act as the center of the search
  searchIndexName: string, // the string name of the search index
}


const searchOptionsWithSearchAreaConstraints = {
  countries: ["USA"], // Alpha-3 country codes
  maxResults: 25, // 50 is the max and the default
  searchAreaConstraints: [SWLongitude, SWLatitude, NELongitude, NELatitude], // Bounding box to search inside of
  searchIndexName: string, // the string name of the search index
}


Geo.searchByText('Amazon Go Stores', searchOptionsWithBiasPosition)

This returns places and their coordinates that match the search constraints. A place can also have additional metadata as shown in the example below.

Copy
code example
// returns
[
  {
    geometry: {
      point:
        [
          -122.34014899999994, // Longitude point
          47.61609000000004 // Latitude point
        ],
    },
    addressNumber: "2131" // optional string for the address number alone
    country: "USA" // optional Alpha-3 country code
    label: "Amazon Go, 2131 7th Ave, Seattle, WA, 98121, USA" // Optional string
    municipality: "Seattle" // Optional string
    neighborhood: undefined // Optional string
    postalCode: "98121" // Optional string
    region: "Washington" // Optional string
    street: "7th Ave" // Optional string
    subRegion: "King County" // Optional string
  }
]
Search by coordinates

The Geo.searchByCoordinates() API is a reverse Geocoder that takes a coordinate point and returns information about what it finds at that point on the map. The returned object is the same shape as searchByText() API above.

Copy
code example
import { Geo } from "@aws-amplify/geo";


Geo.searchByCoordinates([longitudePoint, latitudePoint])

You can optionally limit your result set with the maxResults parameter or override the default search index with the searchIndexName parameter.

Copy
code example
const searchOptionsWithBiasPosition = {
  maxResults: number, // 50 is the max and the default
  searchIndexName: string, // the string name of the search index
}


Geo.searchByCoordinates([-122.3399573, 47.616179], searchOptionsWithBiasPosition)
Search for suggestions

The Geo.searchForSuggestions() API enables you to search for suggestions by free-form text, such as a place, address, city, or region.

Copy
code example
import { Geo } from "@aws-amplify/geo";


Geo.searchForSuggestions("Amazon Go Store")

Similar to Geo.searchByText() API, customize your search results further by providing:

countries - to limit the search results to given countries (specified in ISO Alpha-3 country codes)
maxResults - to limit the maximum result set
biasPosition - to act as the search origination location
searchAreaConstraints - to limit the area to search inside of
searchIndexName - to use a different Location Service search index resource than the default

Note: Providing both biasPosition and searchAreaConstraints parameters simultaneously returns an error.

Copy
code example
const searchOptionsWithBiasPosition = {
  countries: string[], // Alpha-3 country codes
  maxResults: number, // 50 is the max and the default
  biasPosition: [
    longitude // number
    latitude // number,
  ], // Coordinates point to act as the center of the search
  searchIndexName: string, // the string name of the search index
}


const searchOptionsWithSearchAreaConstraints = {
  countries: ["USA"], // Alpha-3 country codes
  maxResults: 25, // 50 is the max and the default
  searchAreaConstraints: [SWLongitude, SWLatitude, NELongitude, NELatitude], // Bounding box to search inside of
  searchIndexName: string, // the string name of the search index
}


Geo.searchForSuggestions('Amazon Go', searchOptionsWithBiasPosition)

This returns a list of suggestions (places and their respective placeId if available) that match the search constraints.

Copy
code example
// returns
[
  {
    text: "Amazon Go, 2131 7th Ave, Seattle, WA, 98121, USA",
    placeId: "8fd9d4c6-2527-4190-a7df-0dae352c9dc6"
  },
  {
    text: "Amazon Go, 1906 Terry Ave, Seattle, WA, 98101, USA",
    placeId: "5d04d071-dea2-4d86-bfce-86bd6a8f4787"
  }
]

In cases where placeId is not available on the list of suggestions as below, use searchByText to search for the selected place by text.

Copy
code example
Geo.searchForSuggestions("Amazon", { MaxResults: 5 })


// returns
[
  {
    text: "Amazon Go",
  },
  {
    text: "Amazon 4-star",
  }
]


Geo.searchByText('Amazon Go', { MaxResults: 5 })

This returns places and their coordinates that match the search text.

Search by PlaceId

The Geo.searchByPlaceId() API enables you to search for a place by a placeId, which is a unique opaque token for a place returned by the provider.

Copy
code example
import { Geo } from "@aws-amplify/geo";


Geo.searchByPlaceId(placeId)

You can optionally override the default search index with the searchIndexName parameter.

Copy
code example
const searchByPlaceIdOptions = {
  searchIndexName: string, // the string name of the search index
}


Geo.searchByPlaceId("8fd9d4c6-2527-4190-a7df-0dae352c9dc6", searchByPlaceIdOptions)

This returns a place with metadata as shown in the example below.

Copy
code example
// returns
{
  geometry: {
    point:
      [
        -122.34014899999994, // Longitude point
        47.61609000000004 // Latitude point
      ],
  },
  addressNumber: "2131" // optional string for the address number alone
  country: "USA" // optional Alpha-3 country code
  label: "Amazon Go, 2131 7th Ave, Seattle, WA, 98121, USA" // Optional string
  municipality: "Seattle" // Optional string
  neighborhood: undefined // Optional string
  postalCode: "98121" // Optional string
  region: "Washington" // Optional string
  street: "7th Ave" // Optional string
  subRegion: "King County" // Optional string
}
PREVIOUS
Configure location search
NEXT
Configure a geofence collection

--------------------------------------------------------------------------------

Title: Configure location search - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/geo/configure-location-search/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Geo
/
Configure location search
Configure location search

Amplify's geo category enables you to search by places, addresses, and coordinates in your app with "place index" resources.

Setup a new Location Search Index
amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend";
import { Policy, PolicyStatement } from "aws-cdk-lib/aws-iam";
Copy
highlighted code example
import { CfnMap, CfnPlaceIndex } from "aws-cdk-lib/aws-location";
import { auth } from "./auth/resource";
import { data } from "./data/resource";


const backend = defineBackend({
  auth,
  data,
  // additional resources
});


const geoStack = backend.createStack("geo-stack");


// create a location services map
const map = new CfnMap(geoStack, "Map", {
  mapName: "myMap",
  description: "Map",
  configuration: {
    style: "VectorEsriNavigation",
  },
  pricingPlan: "RequestBasedUsage",
  tags: [
    {
      key: "name",
      value: "myMap",
    },
  ],
});




// create an IAM policy to allow interacting with geo resource
const myGeoPolicy = new Policy(geoStack, "GeoPolicy", {
  policyName: "myGeoPolicy",
  statements: [
    new PolicyStatement({
      actions: [
        "geo:GetMapTile",
        "geo:GetMapSprites",
        "geo:GetMapGlyphs",
        "geo:GetMapStyleDescriptor",
      ],
      resources: [map.attrArn],
    }),
  ],
});


// apply the policy to the authenticated and unauthenticated roles
backend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(myGeoPolicy);
backend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(myGeoPolicy);


Copy
highlighted code example
// create a location services place index
const myIndex = new CfnPlaceIndex(geoStack, "PlaceIndex", {
  dataSource: "Here",
  dataSourceConfiguration: {
    intendedUse: "SingleUse",
  },
  indexName: "myPlaceIndex",
  pricingPlan: "RequestBasedUsage",
  tags: [
    {
      key: "name",
      value: "myPlaceIndex",
    },
  ],
});


// create a policy to allow access to the place index
const myIndexPolicy = new Policy(geoStack, "IndexPolicy", {
  policyName: "myIndexPolicy",
  statements: [
    new PolicyStatement({
      actions: [
        "geo:SearchPlaceIndexForPosition",
        "geo:SearchPlaceIndexForText",
        "geo:SearchPlaceIndexForSuggestions",
        "geo:GetPlace",
      ],
      resources: [myIndex.attrArn],
    }),
  ],
});


// attach the policy to the authenticated and unauthenticated IAM roles
backend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(myIndexPolicy);
backend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(myIndexPolicy);


// patch the place index resource to the expected output configuration
backend.addOutput({
  geo: {
    aws_region: geoStack.region,
    maps: {
      items: {
        [map.mapName]: {
          style: "VectorEsriNavigation",
        },
      },
      default: map.mapName,
    },
Copy
highlighted code example
    search_indices: {
      default: myIndex.indexName,
      items: [myIndex.indexName],
    },
  },
});
Location Search Index Pricing Plan

The pricing plan for Search Index will be set to RequestBasedUsage. We advice you to go through the location service pricing along with the location service terms (82.5 section) to learn more about the pricing plan.

Advanced Settings

You can optionally configure the data provider and result storage location for your location search index.

Location Search data provider

You can select a data provider as the source for geocoding, reverse geocoding and searches. Each provider gathers and curates their data using different means. They may also have varying expertise in different regions of the world. The available data providers of geospatial data are shown. To learn more about data providers, please refer this location service documentation.

Here – For additional information about HERE Technologies, see Here guide.
Esri – For additional information about Esri, see Esri guide.

Note: If your application is tracking or routing assets you use in your business (such as delivery vehicles or employees), you may only use HERE as your geolocation provider. See section 82 of the AWS service terms for more details.

Location Search result storage location

You can specify how the results of a search operation will be stored by the caller.

SingleUse - specifies that the results won't be stored.
Storage - specifies that the result can be cached or stored in a database.

Refer this location service doc for more information.

PREVIOUS
Work with maps
NEXT
Work with location search

--------------------------------------------------------------------------------

Title: Set up Amplify Geo - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/geo/set-up-geo/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Geo
/
Set up Amplify Geo
Set up Amplify Geo

Amplify provides APIs and map UI components for maps and location search for your web apps.You can add maps and location search functionality to your app in just a few lines of code. The following is an example utilizing the AWS Cloud Development Kit (AWS CDK) to create a Geo resource powered by Amazon Location Services. But do note there are no official hand-written (L2) constructs for this service yet.

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from "@aws-amplify/backend";
import { Policy, PolicyStatement } from "aws-cdk-lib/aws-iam";
import { CfnMap } from "aws-cdk-lib/aws-location";
import { Stack } from "aws-cdk-lib/core";
import { auth } from "./auth/resource";
import { data } from "./data/resource";


const backend = defineBackend({
  auth,
  data,
  // additional resources
});


const geoStack = backend.createStack("geo-stack");


// create a location services map
const map = new CfnMap(geoStack, "Map", {
  mapName: "myMap",
  description: "Map",
  configuration: {
    style: "VectorEsriNavigation",
  },
  pricingPlan: "RequestBasedUsage",
  tags: [
    {
      key: "name",
      value: "myMap",
    },
  ],
});


// create an IAM policy to allow interacting with geo resource
const myGeoPolicy = new Policy(geoStack, "GeoPolicy", {
  policyName: "myGeoPolicy",
  statements: [
    new PolicyStatement({
      actions: [
        "geo:GetMapTile",
        "geo:GetMapSprites",
        "geo:GetMapGlyphs",
        "geo:GetMapStyleDescriptor",
      ],
      resources: [map.attrArn],
    }),
  ],
});


// apply the policy to the authenticated and unauthenticated roles
backend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(myGeoPolicy);
backend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(myGeoPolicy);


// patch the map resource to the expected output configuration
backend.addOutput({
  geo: {
    aws_region: geoStack.region,
    maps: {
      items: {
        [map.mapName]: {
          style: "VectorEsriNavigation",
        },
      },
      default: map.mapName,
    },
  },
});
Configure your application

To display a map in your application, you can use the Amplify React MapView component or the MapLibre GL with maplibre-gl-js-amplify libraries are required.

Install the necessary dependencies by running the following command:

Terminal
Copy
Terminal code example
npm add aws-amplify @aws-amplify/geo

Note: Make sure that version 6.0.0 or above is installed.

Import and load the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point.

pages/_app.js
Copy
pages/_app.js code example
import { Amplify } from 'aws-amplify';
import outputs from '@/amplify_outputs.json';
Amplify.configure(outputs);

Make sure you call Amplify.configure as early as possible in your application’s life-cycle. A missing configuration or NoCredentials error is thrown if Amplify.configure has not been called before other Amplify JavaScript APIs.

Notes:

If you want to use existing Amazon Location Service resources follow this guide instead.
If you want to use Amazon Location Service APIs not directly supported by Geo, use the escape hatch to access the Amazon Location Service SDK.
References

Location Construct Library

Map Pricing Plan

The pricing plan for the Map example is set to RequestBasedUsage. We advice you to go through the location service pricing along with the location service terms (82.5 section) to learn more about the pricing plan.

NEXT
Work with maps

--------------------------------------------------------------------------------

Title: Geo - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/geo/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Geo
Geo
Set up Amplify Geo
AWS Amplify Geo module provides a simple way to get map data, search for places, and reverse geocoding.
Work with maps
Working with map displays, APIs, and more.
Configure location search
Create and manage location search indices or place indices that are used to search for places in your application.
Work with location search
Use Amplify Geo to add location search and location-based search capabilities.
Configure a geofence collection
Create and manage collections of Geofences
Work with geofences
Provision and manage geofences in your application with Amplify Geo.
Use existing Amazon Location resources
Configure Amplify Geo to use existing Amazon Location Service resources by referencing them in your configuration.
Migrate from Google Maps
Migrate applications from Google Maps to Amplify Geo
Use Amazon Location Service SDK
For specialized use cases where Amplify does not provide the functionality, you can use the escape hatch to access a low-level client instance for Amazon Location Service.

--------------------------------------------------------------------------------

Title: Use existing AWS resources - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/analytics/existing-resources/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Analytics
/
Use existing AWS resources
Use existing AWS resources

To use existing Amazon Pinpoint resources with your Amplify backend or frontend application, use the addOutput method to surface backend resource outputs to the amplify_outputs.json file:

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from "@aws-amplify/backend"


const backend = defineBackend({})


backend.addOutput({
  analytics: {
    amazon_pinpoint: {
      aws_region: "<your-aws-region>",
      app_id: "<your-pinpoint-app-id>",
    },
  },
})
Configuring client library directly

Alternatively, you can configure the client library directly using Amplify.configure(). This manual setup enables you to use your existing Amazon Pinpoint resource in your app.

src/main.ts
Copy
src/main.ts code example
import { Amplify } from 'aws-amplify';


Amplify.configure({
  ...Amplify.getConfig(),
  Analytics: {
    ...Amplify.getConfig().Analytics,
    Pinpoint: {
      // REQUIRED -  Amazon Pinpoint App Client ID
      appId: 'XXXXXXXXXXabcdefghij1234567890ab',


      // REQUIRED -  Amazon service region
      region: 'us-east-1',


      // OPTIONAL - How many events can be buffered at once.
      bufferSize: 1000,


      // OPTIONAL - How many events will be flushed from the buffer per batch.
      flushSize: 100,


      // OPTIONAL - The interval in milliseconds to perform a buffer check and flush if necessary.
      flushInterval: 5000, // 5s


      // OPTIONAL - The limit for failed recording retries.
      resendLimit: 5
    }
  }
});
Update your IAM Policy

Amazon Pinpoint requires an AWS Identity and Access Management (IAM) policy in order to use the record and identifyUser APIs:

Copy
code example
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": ["mobiletargeting:UpdateEndpoint", "mobiletargeting:PutEvents"],
      "Resource": ["arn:aws:mobiletargeting:*:<your-account-id>:apps/<your-pinpoint-app-id>*"]
    }
  ]
}
PREVIOUS
Personalized recommendations

--------------------------------------------------------------------------------

Title: Personalized recommendations - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/analytics/personalize-recommendations/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Analytics
/
Personalized recommendations
Personalized recommendations

Amazon Personalize can create recommendations by using event data, historical data, or a combination of both. The event data can then be used to create recommendations.

To record event data, you need the following:

A dataset group
An event tracker.

For more information, see Record Events.

Installation and Configuration

After creating the Amazon Personalize dataset group, you need to add the personalize:PutEvents permission to your AWS Identity and Access Management (IAM) user roles.

An example IAM policy:

Copy
code example
{
  "Version": "2012-10-17",
  "Statement": [{
    "Effect": "Allow",
    "Action": "personalize:PutEvents",
    "Resource": "arn:aws:personalize:<your-aws-region>:<your-account-id>:event-tracker/<your-resource-name>"
  }]
}

You need the tracking ID of your event tracker. For more information, see Get a Tracking ID.

Configure Amazon Personalize:

src/index.js
Copy
src/index.js code example
import { Amplify } from 'aws-amplify';
Amplify.configure({
  ...Amplify.getConfig(),
  Analytics: {
    Personalize: {
      // REQUIRED - The trackingId to track the events
      trackingId: '<tracking-id>',
      // REQUIRED -  Amazon Personalize service region
      region: 'us-east-1',
      // OPTIONAL - The number of events to be deleted from the buffer when flushed.
      flushSize: 10,
      // OPTIONAL - The interval in milliseconds to perform a buffer check and flush if necessary.
      flushInterval: 5000 // 5s
    }
  }
});
Working with the API

You can use the Identify event type to track a user identity. This lets you connect a user to their actions and record traits about them. To identify a user, specify a unique identifier for the userId property. Consider the following user interactions when choosing when and how often to call record with the Identify eventType:

After a user registers.
After a user logs in.
When a user updates their information (For example, changing or adding a new address).
Upon loading any pages that are accessible by a logged-in user (optional).
Copy
code example
import { record } from 'aws-amplify/analytics/personalize';


record({
  eventType: 'Identify',
  properties: {
    userId: '<user-id>'
  }
});

You can send events to Amazon Personalize by calling the record operation. If you already use Identify to track end-user data, you can skip the userId, the SDK will fetch the userId based on current browser session. For information about the properties field, see Put Events.

Copy
code example
import { record } from 'aws-amplify/analytics/personalize';


record({
  eventType: '<event-type>',
  userId: '<user-id>', // optional
  properties: {
    itemId: '<item-id>',
    eventValue: '<event-value>'
  }
});

You can track iframe and HTML5 media types by using the MediaAutoTrack event type. MediaAutoTrack tracks all media events of the media DOM element that you bind to. MediaAutoTracker will automatically track Play, Pause, Ended, TimeWatched, and Resume in eventType. The duration of the event compared to the total length of the media is stored as a percentage value in eventValue.

Copy
code example
import { record } from 'aws-amplify/analytics/personalize';


record({
  eventType: 'MediaAutoTrack',
  userId: '<user-id>', // (optional)
  properties: {
    domElementId: 'media-dom-element-id',
    itemId: '<item-d>'
  }
});
Flush events

The recorded events are saved in a buffer and sent to the remote server periodically (You can tune it with the flushInterval option). If needed, you have the option to manually clear all the events from the buffer by using the 'flushEvents' API.

Copy
code example
import { flushEvents } from 'aws-amplify/analytics/personalize';


flushEvents();
PREVIOUS
Storing analytics data
NEXT
Use existing AWS resources

--------------------------------------------------------------------------------

Title: Storing analytics data - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/analytics/storing-data/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Analytics
/
Storing analytics data
Storing analytics data

The Amazon Data Firehose analytics provider allows you to send analytics data to an Amazon Data Firehose stream for reliably storing data.

Setup Firehose stream

The following is an example utilizing the AWS Cloud Development Kit (AWS CDK) to create the Analytics resource powered by Amazon Data Firehose.

Let's create a storage bucket to store the data from the Firehose stream.

amplify/storage/resource.ts
Copy
amplify/storage/resource.ts code example
import { defineStorage } from "@aws-amplify/backend";


// Define the S3 bucket resource
export const storage = defineStorage({
  name: "FirehoseDestinationBucket",
});

next, let's create the Firehose resource.

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import { storage } from "./storage/resource";
import { CfnDeliveryStream } from "aws-cdk-lib/aws-kinesisfirehose";
import { Stack } from "aws-cdk-lib/core";
import {
  Policy,
  PolicyStatement,
  Role,
  ServicePrincipal,
} from "aws-cdk-lib/aws-iam";


const backend = defineBackend({
  auth, 
  data,
  storage,
  // additional resources 
});


// Create a new stack for the Firehose resources
const firehoseStack = backend.createStack("firehose-stack");


// Access the S3 bucket resource
const s3Bucket = backend.storage.resources.bucket;


// Create a new IAM role for the Firehose
const firehoseRole = new Role(firehoseStack, "FirehoseRole", {
  assumedBy: new ServicePrincipal("firehose.amazonaws.com"),
});


// Grant the Firehose role read/write permissions to the S3 bucket
s3Bucket.grantReadWrite(firehoseRole);


// Create a new Firehose delivery stream
const myFirehose = new CfnDeliveryStream(firehoseStack, "MyFirehose", {
  deliveryStreamType: "DirectPut",
  s3DestinationConfiguration: {
    bucketArn: s3Bucket.bucketArn,
    roleArn: firehoseRole.roleArn,
  },
  deliveryStreamName: "myFirehose",
});


// Create a new IAM policy to allow users to write to the Firehose
const firehosePolicy = new Policy(firehoseStack, "FirehosePolicy", {
  statements: [
    new PolicyStatement({
      actions: ["firehose:PutRecordBatch"],
      resources: [myFirehose.attrArn],
    }),
  ],
});


// Attach the policy to the authenticated and unauthenticated IAM roles
backend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(firehosePolicy);
backend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(firehosePolicy);
Installation and Configuration

Ensure you have setup IAM permissions for firehose:PutRecordBatch.

Example IAM policy for Amazon Data Firehose:

Copy
code example
{
  "Version": "2012-10-17",
  "Statement": [{
    "Effect": "Allow",
    "Action": "firehose:PutRecordBatch",
    // replace the template fields
    "Resource": "arn:aws:firehose:<your-aws-region>:<your-aws-account-id>:deliverystream/<your-stream-name>"
  }]
}

Configure Firehose:

src/index.js
Copy
src/index.js code example
import { Amplify } from 'aws-amplify';


Amplify.configure({
  ...Amplify.getConfig(),
  Analytics: {
    KinesisFirehose: {
      // REQUIRED -  Amazon Kinesis Firehose service region
      region: 'us-east-1',


      // OPTIONAL - The buffer size for events in number of items.
      bufferSize: 1000,


      // OPTIONAL - The number of events to be deleted from the buffer when flushed.
      flushSize: 100,


      // OPTIONAL - The interval in milliseconds to perform a buffer check and flush if necessary.
      flushInterval: 5000, // 5s


      // OPTIONAL - The limit for failed recording retries.
      resendLimit: 5
    }
  }
});
Storing data

You can send a data to a Firehose stream with the standard record method. Any data is acceptable and streamName is required:

src/index.js
Copy
src/index.js code example
import { record } from 'aws-amplify/analytics/kinesis-firehose';


record({
  data: {
    // The data blob to put into the record
  },
  streamName: 'myFirehose'
});
Flush events

The recorded events are saved in a buffer and sent to the remote server periodically (You can tune it with the flushInterval option). If needed, you have the option to manually clear all the events from the buffer by using the 'flushEvents' API.

src/index.js
Copy
src/index.js code example
import { flushEvents } from 'aws-amplify/analytics/kinesis-firehose';


flushEvents();
PREVIOUS
Streaming analytics data
NEXT
Personalized recommendations

--------------------------------------------------------------------------------

Title: Streaming analytics data - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/analytics/streaming-data/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Analytics
/
Streaming analytics data
Streaming analytics data

The Amazon Kinesis analytics provider allows you to send analytics data to an Kinesis stream for real-time processing.

Setup Kinesis stream

The following is an example utilizing the AWS Cloud Development Kit (AWS CDK) to create the Analytics resource powered by Amazon Kinesis.

amplify/backend.ts
Copy
amplify/backend.ts code example
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import { Policy, PolicyStatement } from "aws-cdk-lib/aws-iam";
import { Stream } from "aws-cdk-lib/aws-kinesis";
import { Stack } from "aws-cdk-lib/core";


const backend = defineBackend({
  auth, 
  data,
  // additional resources 
});


// create a new stack for the Kinesis stream
const kinesisStack = backend.createStack("kinesis-stack");


// create a new Kinesis stream with one shard
const kinesisStream = new Stream(kinesisStack, "KinesisStream", {
  streamName: "myKinesisStream",
  shardCount: 1,
});


// create a new policy to allow PutRecords to the Kinesis stream
const kinesisPolicy = new Policy(kinesisStack, "KinesisPolicy", {
  statements: [
    new PolicyStatement({
      actions: ["kinesis:PutRecords"],
      resources: [kinesisStream.streamArn],
    }),
  ],
});


// apply the policy to the authenticated and unauthenticated roles
backend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(kinesisPolicy);
backend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(kinesisPolicy);
Installation and Configuration

If you did not use the CLI, ensure you have setup IAM permissions for kinesis:PutRecords.

Example IAM policy for Amazon Kinesis:

Copy
code example
{
  "Version": "2012-10-17",
  "Statement": [{
    "Effect": "Allow",
    "Action": "kinesis:PutRecords",
    "Resource": "arn:aws:kinesis:<your-aws-region>:<your-aws-account-id>:stream/<your-stream-name>" // replace the template fields
  }]
}

For more information visit the Amazon Kinesis Developer Documentation.

Configure Kinesis:

src/index.js
Copy
src/index.js code example
// Configure the plugin after adding it to the Analytics module
import { Amplify } from 'aws-amplify';


Amplify.configure({
  ...Amplify.getConfig(),
  Analytics: {
    Kinesis: {
      // REQUIRED -  Amazon Kinesis service region
      region: 'us-east-1',


      // OPTIONAL - The buffer size for events in number of items.
      bufferSize: 1000,


      // OPTIONAL - The number of events to be deleted from the buffer when flushed.
      flushSize: 100,


      // OPTIONAL - The interval in milliseconds to perform a buffer check and flush if necessary.
      flushInterval: 5000, // 5s


      // OPTIONAL - The limit for failed recording retries.
      resendLimit: 5
    }
  }
});
Stream data

You can send a data to a Kinesis stream with the standard record() method:

src/index.js
Copy
src/index.js code example
import { record } from 'aws-amplify/analytics/kinesis';


record({
  data: {
    // The data blob to put into the record
  },
  partitionKey: 'myPartitionKey',
  streamName: 'myKinesisStream'
});
Flush events

The recorded events are saved in a buffer and sent to the remote server periodically (You can tune it with the flushInterval option). If needed, you have the option to manually clear all the events from the buffer by using the 'flushEvents' API.

src/index.js
Copy
src/index.js code example
import { flushEvents } from 'aws-amplify/analytics/kinesis';


flushEvents();
PREVIOUS
Enable and disable analytics
NEXT
Storing analytics data

--------------------------------------------------------------------------------

Title: Automatically track sessions - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/analytics/auto-track-sessions/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Analytics
/
Automatically track sessions
Automatically track sessions

Analytics auto tracking helps you to automatically track user behaviors like sessions' start/stop, page view change and web events like clicking or mouseover.

Session Tracking

You can track the session both in a web app or a React Native app by using Analytics. A web session can be defined in different ways. To keep it simple, we define a web session as being active when the page is not hidden and inactive when the page is hidden. A session in a React Native app is active when the app is in the foreground and inactive when the app is in the background.

For example:

src/index.js
Copy
src/index.js code example
import { configureAutoTrack } from 'aws-amplify/analytics';


configureAutoTrack({
  // REQUIRED, turn on/off the auto tracking
  enable: true,
  // REQUIRED, the event type, it's one of 'event', 'pageView' or 'session'
  type: 'session',
  // OPTIONAL, additional options for the tracked event.
  options: {
    // OPTIONAL, the attributes of the event
    attributes: {
      customizableField: 'attr'
    }
  }
});

By default, when the page/app transitions to the foreground, the Analytics module will send an event to the Amazon Pinpoint Service.

Copy
code example
{
  "eventType": "_session_start",
  "attributes": {
    "customizableField": "attr"
  }
}

This behavior can be disabled by calling configureAutoTrack:

src/index.js
Copy
src/index.js code example
import { configureAutoTrack } from 'aws-amplify/analytics';


configureAutoTrack({
  enable: false,
  type: 'session'
});
Page View Tracking

Use this feature to track the most frequently viewed page/url in your webapp. It automatically sends events containing url information when a page is visited.

This behavior can be enabled by calling configureAutoTrack:

src/index.js
Copy
src/index.js code example
import { configureAutoTrack } from 'aws-amplify/analytics';


configureAutoTrack({
  // REQUIRED, turn on/off the auto tracking
  enable: true,
  // REQUIRED, the event type, it's one of 'event', 'pageView' or 'session'
  type: 'pageView',
  // OPTIONAL, additional options for the tracked event.
  options: {
    // OPTIONAL, the attributes of the event
    attributes: {
      customizableField: 'attr'
    },


    // OPTIONAL, the event name. By default, this is 'pageView'
    eventName: 'pageView',


    // OPTIONAL, the type of app under tracking. By default, this is 'multiPageApp'.
    // You will need to change it to 'singlePage' if your app is a single-page app like React
    appType: 'multiPageApp',


    // OPTIONAL, provide the URL for the event.
    urlProvider:  () => {
      // the default function
      return window.location.origin + window.location.pathname;
    }
  }
});

This behavior can be disabled by calling configureAutoTrack:

src/index.js
Copy
src/index.js code example
import { configureAutoTrack } from 'aws-amplify/analytics';


configureAutoTrack({
  enable: false,
  type: 'pageView'
});
Page Event Tracking

Use page event tracking to track user interactions with specific elements on a page. Attach the specified selectors to your DOM element and turn on the auto tracking.

This behavior can be enabled by calling configureAutoTrack:

src/index.js
Copy
src/index.js code example
import { configureAutoTrack } from 'aws-amplify/analytics';


configureAutoTrack({
  // REQUIRED, turn on/off the auto tracking
  enable: true,
  // REQUIRED, the event type, it's one of 'event', 'pageView' or 'session'
  type: 'event',
  // OPTIONAL, additional options for the tracked event.
  options: {
    // OPTIONAL, the attributes of the event
    attributes: {
      customizableField: 'attr'
    },
    // OPTIONAL, events you want to track. By default, this is 'click'
    events: ['click'],


    // OPTIONAL, the prefix of the selectors. By default, this is 'data-amplify-analytics-'
    // Per https://www.w3schools.com/tags/att_global_data.asp, always start
    // the prefix with 'data' to avoid collisions with the user agent
    selectorPrefix: 'data-amplify-analytics-'
  }
});

For example:

Copy
code example
<!-- you want to track this button and send an event when it is clicked -->
<button
  data-amplify-analytics-on="click"
  data-amplify-analytics-name="click"
  data-amplify-analytics-attrs="attr1:attr1_value,attr2:attr2_value"
/>

When the button above is clicked, an event will be sent automatically. This is equivalent to doing:

Copy
code example
<script>
  import { record } from 'aws-amplify/analytics';
  var sendEvent = function() {
    record({
      name: 'click',
      attributes: {
        attr: 'attr', // the default ones
        attr1: attr1_value, // defined in the button component
        attr2: attr2_value // defined in the button component
      }
    });
  };
</script>
<button onclick="sendEvent()" />

This behavior can be disabled by calling configureAutoTrack:

src/index.js
Copy
src/index.js code example
import { configureAutoTrack } from 'aws-amplify/analytics';


configureAutoTrack({
  enable: false,
  type: 'event'
});

Note: Amplify doesn't capture location automatically. Instead, you can add the location information in the default config when you configure Analytics or while updating the end point.

PREVIOUS
Identify user
NEXT
Enable and disable analytics

--------------------------------------------------------------------------------

Title: Enable and disable analytics - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/analytics/enable-disable/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Analytics
/
Enable and disable analytics
Enable and disable analytics
Disable Analytics

Analytics are enabled by default when you configure it in your app. To disable Analytics in your app use the disable function:

src/index.js
Copy
src/index.js code example
import { disable } from 'aws-amplify/analytics';


disable();
Enable Analytics

To enable analytics you can use the enable function in your app:

src/index.js
Copy
src/index.js code example
import { enable } from 'aws-amplify/analytics';


enable();
PREVIOUS
Automatically track sessions
NEXT
Streaming analytics data

--------------------------------------------------------------------------------

Title: Identify user - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/analytics/identify-user/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Analytics
/
Identify user
Identify user

This API sends information about the current user to Amazon Pinpoint.

Additional information such as the user's name, email, location, and device can be included by specifying the UserProfile. Custom attributes can also be included by setting UserProfile.customProperties.

If the user was signed in through signIn you can retrieve the current user's ID as shown below:

src/index.js
Copy
src/index.js code example
import { identifyUser } from 'aws-amplify/analytics';
import { getCurrentUser } from 'aws-amplify/auth';


const location = {
  latitude: 47.606209,
  longitude: -122.332069,
  postalCode: '98122',
  city: 'Seattle',
  region: 'WA',
  country: 'USA'
};


const customProperties = {
  plan: ['plan'],
  phoneNumber: ['+11234567890'],
  age: ['25']
};


const userProfile = {
  location,
  name: 'username',
  email: 'name@example.com',
  customProperties
};


async function sendUserData() {
  const user = await getCurrentUser();


  identifyUser({
    userId: user.userId,
    userProfile
  });
}

Sending user information allows you to associate a user to their user profile and activities or actions in your app. The user's actions and attributes can also tracked across devices and platforms by using the same userId.

Some scenarios for identifying a user and their associated app activities are:

When a user completes app sign up
When a user completes sign in process
When a user launches your app
When a user modifies or updates their user profile
PREVIOUS
Record events
NEXT
Automatically track sessions

--------------------------------------------------------------------------------

Title: Set up Amplify Analytics - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/analytics/set-up-analytics/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Analytics
/
Set up Amplify Analytics
Set up Amplify Analytics

Amplify enables you to collect analytics data for your app. In order to use Analytics, you will enable Amazon Kinesis or Amazon Pinpoint using the AWS Cloud Development Kit (AWS CDK). The Analytics category uses Amazon Cognito identity pools to identify users in your app. Cognito allows you to receive data from authenticated, and unauthenticated users in your app.

Set up Analytics backend

Use the AWS CDK to create an analytics resource powered by Amazon Pinpoint.

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from "@aws-amplify/backend"
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import { Policy, PolicyStatement } from "aws-cdk-lib/aws-iam";
import { CfnApp } from "aws-cdk-lib/aws-pinpoint";
import { Stack } from "aws-cdk-lib/core";


const backend = defineBackend({
  auth,
  data,
  // additional resources
});


const analyticsStack = backend.createStack("analytics-stack");


// create a Pinpoint app
const pinpoint = new CfnApp(analyticsStack, "Pinpoint", {
  name: "myPinpointApp",
});


// create an IAM policy to allow interacting with Pinpoint
const pinpointPolicy = new Policy(analyticsStack, "PinpointPolicy", {
  policyName: "PinpointPolicy",
  statements: [
    new PolicyStatement({
      actions: ["mobiletargeting:UpdateEndpoint", "mobiletargeting:PutEvents"],
      resources: [pinpoint.attrArn + "/*"],
    }),
  ],
});


// apply the policy to the authenticated and unauthenticated roles
backend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(pinpointPolicy);
backend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(pinpointPolicy);


// patch the custom Pinpoint resource to the expected output configuration
backend.addOutput({
  analytics: {
    amazon_pinpoint: {
      app_id: pinpoint.ref,
      aws_region: Stack.of(pinpoint).region,
    }
  },
});
Install Amplify Libraries

First, install the aws-amplify library:

Terminal
Copy
Terminal code example
npm add aws-amplify
Initialize Amplify Analytics

Import and load the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point.

pages/_app.tsx
Copy
pages/_app.tsx code example
import { Amplify } from 'aws-amplify';
import { record } from 'aws-amplify/analytics';
import outputs from '@/amplify_outputs.json';


Amplify.configure({
  ...Amplify.getConfig(),
  Analytics: amplifyconfig.Analytics,
});

Next Steps:

Congratulations! Now that you have Analytics' backend provisioned and Analytics library installed. Check out the following links to see Amplify Analytics use cases:

Record Events
Track Sessions
Identify User
References

Amazon Pinpoint Construct Library

NEXT
Record events

--------------------------------------------------------------------------------

Title: Record events - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/analytics/record-events/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Analytics
/
Record events
Record events
Recording Custom Events

To record custom events call the record API:

src/index.js
Copy
src/index.js code example
import { record } from 'aws-amplify/analytics';


record({
  name: 'albumVisit',
});

Analytics events are buffered in memory and periodically sent to the service and not saved locally between application sessions. If the session is ended before a buffered event is sent, it will be lost. Use the flushEvents API to manually send buffered events to the service.

Record a Custom Event with Attributes

The record API lets you add additional attributes to an event. For example, to record artist information with an albumVisit event:

src/index.js
Copy
src/index.js code example
import { record } from 'aws-amplify/analytics';


record({
  name: 'albumVisit',
  attributes: { genre: '', artist: '' },
});

Recorded events will be buffered and periodically sent to Amazon Pinpoint.

Record Engagement Metrics

Metrics can also be added to an event:

src/index.js
Copy
src/index.js code example
import { record } from 'aws-amplify/analytics';


record({
  name: 'albumVisit',
  metrics: { minutesListened: 30 },
});

Metric values must be a Number type such as a float or integer.

The Amazon Pinpoint event count updates in minutes after recording your event.

However, it can take upwards of 30 minutes for the event to display in the Filter section, and for its custom attributes to appear in Amazon Pinpoint.

Flush events

The recorded events are saved in a buffer and sent to the remote server periodically. If needed, you have the option to manually clear all the events from the buffer by using the 'flushEvents' API.

src/index.js
Copy
src/index.js code example
import { flushEvents } from 'aws-amplify/analytics';


flushEvents();
PREVIOUS
Set up Amplify Analytics
NEXT
Identify user

--------------------------------------------------------------------------------

Title: Next.js App Router (Server Components) - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/server-side-rendering/nextjs-app-router-server-components/
HTML Content:
Next.js
/
Build & connect backend
/
Server-Side Rendering
/
Next.js App Router (Server Components)
Next.js App Router (Server Components)

This Quickstart guide will walk you through how to build a task list application with TypeScript, Next.js App Router with Server Components, and React. If you are new to these technologies, we recommend you go through the official React, Next.js, and TypeScript tutorials first.

Prerequisites

Before you get started, make sure you have the following installed:

Node.js v18.17 or later
npm v9 or later
git v2.14.1 or later

You will also need to create an AWS account. Note that AWS Amplify is part of the AWS Free Tier.

Create a project

First, you will need to create a new Next.js app. The following command will create a Next.js app in a directory called next-amplify-gen2 that uses the App Router.

Copy
code example
npm create next-app@14 -- next-amplify-gen2 --typescript --eslint --app --no-src-dir --no-tailwind --import-alias '@/*'
cd next-amplify-gen2

The easiest way to get started with AWS Amplify is through npm with create-amplify.

Copy
code example
npm create amplify@latest
? Where should we create your project? (.) # press enter

Running this command will scaffold a lightweight Amplify project in your current project with the following files:

Copy
code example
├── amplify/
│   ├── auth/
│   │   └── resource.ts
│   ├── data/
│   │   └── resource.ts
│   ├── backend.ts
│   └── package.json
├── node_modules/
├── .gitignore
├── package-lock.json
├── package.json
└── tsconfig.json
Start local dev server

Let's start a local dev server for your app development. For the frontend, run npm run dev to spin up a localhost dev server with the default Next.js template.

Copy
code example
npm run dev

Now configure your AWS account to use Amplify. Note: If you already have an AWS profile with credentials on your local machine, and you have configured the corresponding AWS profile with the AmplifyBackendDeployFullAccess permission policy, you can skip this step.

For the backend, we're going to start a cloud sandbox environment. Amplify gives every developer a personal cloud sandbox environment that provides isolated development spaces to rapidly build, test, and iterate. When you're working with a team, each developer will have their own personal cloud sandbox. In a new terminal window, run the following command:

Copy
code example
npx ampx sandbox
Do not use cloud sandbox environments in production.

You should now have these two commands running concurrently in different terminal windows.

Build a backend

Next, we will add data and auth capabilities to the app. In Amplify Gen 2, the resource.ts files are where you define the corresponding backend resource and details about it.

Add data

create-amplify provides the scaffolding of a amplify/data/resource.ts file, which is ready to deploy.

See the complete amplify/data/resources.ts

Step 1: Open amplify/data/resource.ts and update it to add a done field of type boolean and a priority field of enum with a value of ['low', 'medium', 'high']. We've removed the default comments to shorten the code below for the next few examples.

amplify/data/resource.ts
import { type ClientSchema, a, defineData } from '@aws-amplify/backend';


// ...


const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
Copy
highlighted code example
      done: a.boolean(),
      priority: a.enum(['low', 'medium', 'high'])
    })
    .authorization(allow => [allow.owner(), allow.publicApiKey().to(['read'])]),
});


// ...

Once you save your changes to the data model, they will be deployed in seconds to your cloud sandbox.

The Todo data model is defined with authorization rules to allow the person who creates the Todo instance (the owner) to perform all actions on the data they own. We are also allowing all page viewers, including unauthenticated users, to read data.

Note: These authorization rules can be modified using a chain of methods as defined by default. For example, we could remove the .to(['read']) and allow all visitors to perform all actions on data or add permissions for signed-in users or users who belong to user groups such as Admin. You can learn more about all options for authorization in the Customize your auth rules section of the docs.

Step 2: Remove public access by deleting the allow.publicApiKey().to(['read']) authorization rule. Your authorization rule will look like the code below:

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
// ...


.authorization(allow => [allow.owner()]),


// ...

Below the schema declaration, you will see the defineData function, which receives our schema and authorization configuration as arguments. The default configuration is for an apiKey to enable public access.

Step 3: Update the defaultAuthorizationMode to userPool so that the default is to use user authentication.

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
// ...


export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: 'userPool'
  }
});
Add authentication

Now let's work on our authentication configuration. Similar to the data/resource.ts we just worked on, the auth/resource.ts file has code to define our authentication configuration. In this case, we are setting the authentication method to log in with email.

See the complete amplify/auth/resources.ts

Let's customize the subject of the verification email sent to users after they sign up for our app. There is only one step to complete.

Open amplify/auth/resource.ts and update it to add a subject line by defining an object with email authentication properties referencing the code below:

amplify/auth/resource.ts
// amplify/auth/resource.ts
import { defineAuth } from '@aws-amplify/backend';


export const auth = defineAuth({
  loginWith: {
Copy
highlighted code example
   email: {
     verificationEmailSubject: 'Welcome! Verify your email!'
   },
  }
});
The Data and Auth resource files are imported into the amplify/backend.ts file which serves as the entry point to the Amplify backend for all resources used in this app. It is shown below, but there are no modifications needed to complete this quickstart.
amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';


defineBackend({
  auth,
  data
});
Build UI

Let's add UI that connects to the backend data and auth resources.

Configure Amplify Client Side

First, install the Amplify UI component library:

Copy
code example
npm add @aws-amplify/ui-react

Next, create a components folder in the root of your project and copy the contents below to a file called ConfigureAmplify.tsx.

components/ConfigureAmplify.tsx
Copy
components/ConfigureAmplify.tsx code example
// components/ConfigureAmplify.tsx
"use client";


import { Amplify } from "aws-amplify";


import outputs from "@/amplify_outputs.json";


Amplify.configure(outputs, { ssr: true });


export default function ConfigureAmplifyClientSide() {
  return null;
}

Update app/layout.tsx to import and render <ConfigureAmplifyClientSide />. This client component will configure Amplify for client pages in our application.

app/layout.tsx
Copy
app/layout.tsx code example
// app/layout.tsx
import "@aws-amplify/ui-react/styles.css";
import type { Metadata } from "next";
import { Inter } from "next/font/google";
import "./globals.css";


import ConfigureAmplifyClientSide from "@/components/ConfigureAmplify";


const inter = Inter({ subsets: ["latin"] });


export const metadata: Metadata = {
  title: "Create Next App",
  description: "Generated by create next app",
};


export default function RootLayout({
  children,
}: {
  children: React.ReactNode;
}) {
  return (
    <html lang="en">
      <body className={inter.className}>
        <ConfigureAmplifyClientSide />
        {children}
      </body>
    </html>
  );
}
Configure Amplify Server Side

First, install the Amplify Next.js adapter:

Copy
code example
npm add @aws-amplify/adapter-nextjs

Next, create a utils/amplify-utils.ts file from the root of the project and paste the code below. runWithAmplifyServerContext, cookiesClient, and AuthGetCurrentUserServer are declared here and will be used to gain access to Amplify assets from the server.

utils/amplify-utils.ts
Copy
utils/amplify-utils.ts code example
// utils/amplify-utils.ts
import { cookies } from "next/headers";


import { createServerRunner } from "@aws-amplify/adapter-nextjs";
import { generateServerClientUsingCookies } from "@aws-amplify/adapter-nextjs/api";
import { getCurrentUser } from "aws-amplify/auth/server";


import { type Schema } from "@/amplify/data/resource";
import outputs from "@/amplify_outputs.json";


export const { runWithAmplifyServerContext } = createServerRunner({
  config: outputs,
});


export const cookiesClient = generateServerClientUsingCookies<Schema>({
  config: outputs,
  cookies,
});


export async function AuthGetCurrentUserServer() {
  try {
    const currentUser = await runWithAmplifyServerContext({
      nextServerContext: { cookies },
      operation: (contextSpec) => getCurrentUser(contextSpec),
    });
    return currentUser;
  } catch (error) {
    console.error(error);
  }
}
Add server authentication routes

First, create a client-side Login component in the components folder that will be wrapped in withAuthenticator. If the user is logged in, they will be redirected to the index route; otherwise, the Amplify UI Authenticator component will be rendered.

components/Login.tsx
Copy
components/Login.tsx code example
// components/Login.tsx
"use client";


import { withAuthenticator } from "@aws-amplify/ui-react";
import { AuthUser } from "aws-amplify/auth";
import { redirect } from "next/navigation";
import { useEffect } from "react";


function Login({ user }: { user?: AuthUser }) {
  useEffect(() => {
    if (user) {
      redirect("/");
    }
  }, [user]);
  return null;
}


export default withAuthenticator(Login);

Next, create a new route under app/login/page.tsx to render the Login component.

app/login/page.tsx
Copy
app/login/page.tsx code example
// app/login/page.tsx


import Login from "@/components/Login";


export default function LoginPage() {
  return <Login />;
}
Custom <Authenticator> example

Finally, create a Logout component to be used later.

components/Logout.tsx
Copy
components/Logout.tsx code example
// components/Logout.tsx


"use client";


import { signOut } from "aws-amplify/auth";
import { useRouter } from "next/navigation";


export default function Logout() {
  const router = useRouter();


  return (
    <button
      onClick={async () => {
        await signOut();
        router.push("/login");
      }}
      className="px-2 bg-white text-black"
    >
      Sign out
    </button>
  );
}

Note: If using Amplify UI Social Providers, set the callbackUrls for the /login route when configuring social sign-in for your Gen 2 backend, as shown below.

amplify/auth/resource.ts
Copy
amplify/auth/resource.ts code example
import { defineAuth, secret } from '@aws-amplify/backend';


export const auth = defineAuth({
  loginWith: {
    externalProviders: {
      // ...
      callbackUrls: [
        'http://localhost:3000/login',
        'https://mywebsite.com/login'
      ],
      logoutUrls: ['http://localhost:3000/logout', 'https://mywebsite.com/logout']
    }
  }
});
Add middleware for server-side redirect

Create middleware.ts in the root of the project with the contents below.

This middleware runs fetchAuthSession wrapped in runWithAmplifyServerContext and will redirect to /login when a user is not logged in.

middleware.ts
Copy
middleware.ts code example
// middleware.ts
import { NextRequest, NextResponse } from "next/server";


import { fetchAuthSession } from "aws-amplify/auth/server";


import { runWithAmplifyServerContext } from "@/utils/amplify-utils";


export async function middleware(request: NextRequest) {
  const response = NextResponse.next();


  const authenticated = await runWithAmplifyServerContext({
    nextServerContext: { request, response },
    operation: async (contextSpec) => {
      try {
        const session = await fetchAuthSession(contextSpec, {});
        return session.tokens !== undefined;
      } catch (error) {
        console.log(error);
        return false;
      }
    },
  });


  if (authenticated) {
    return response;
  }


  return NextResponse.redirect(new URL("/login", request.url));
}


export const config = {
  matcher: [
    /*
     * Match all request paths except for the ones starting with:
     * - api (API routes)
     * - _next/static (static files)
     * - _next/image (image optimization files)
     * - favicon.ico (favicon file)
     * - login
     */
    "/((?!api|_next/static|_next/image|favicon.ico|login).*)",
  ],
};

Run your application with npm run dev and navigate to http://localhost:3000. You should now see the authenticator, which is already configured and ready for your first sign-up! Create a new user account, confirm the account through email, and then sign in.

View list of to-do items

Now, let's display data on our app's frontend.

The code below uses the cookiesClient to provide access to the Todo model defined in the backend.

Modify your app's home page file, app/page.tsx, with the following code:

app/page.tsx
Copy
app/page.tsx code example
// app/page.tsx


import { cookiesClient } from "@/utils/amplify-utils";


async function App() {
  const { data: todos } = await cookiesClient.models.Todo.list();


  return (
    <>
      <h1>Hello, Amplify 👋</h1>
      <ul>
        {todos && todos.map((todo) => <li key={todo.id}>{todo.content}</li>)}
      </ul>
    </>
  );
}


export default App;

Once you save the file and navigate back to http://localhost:3000, you should see "Hello, Amplify" with a blank page for now because you have only an empty list of to-dos.

Create a new to-do item

Let's update the component to have a form for prompting the user for the title for creating a new to-do list item and run the addTodo method on form submission. In a production app, the additional fields of the Todo model would be added to the form.

After creating a to-do, revalidatePath is run to clear the Next.js cache for this route to instantly update the results from the server without a full page reload.

app/page.tsx
Copy
app/page.tsx code example
// app/page.tsx


import { revalidatePath } from "next/cache";


import { AuthGetCurrentUserServer, cookiesClient } from "@/utils/amplify-utils";


import Logout from "@/components/Logout";


async function App() {
  const user = await AuthGetCurrentUserServer();
  const { data: todos } = await cookiesClient.models.Todo.list();


  async function addTodo(data: FormData) {
    "use server";
    const title = data.get("title") as string;
    await cookiesClient.models.Todo.create({
      content: title,
      done: false,
      priority: "medium",
    });
    revalidatePath("/");
  }


  return (
    <>
      <h1>Hello, Amplify 👋</h1>
      {user && <Logout />}
      <form action={addTodo}>
        <input type="text" name="title" />
        <button type="submit">Add Todo</button>
      </form>


      <ul>
        {todos && todos.map((todo) => <li key={todo.id}>{todo.content}</li>)}
      </ul>
    </>
  );
}


export default App;
Terminate dev server

Go to localhost in the browser to make sure you can now log in and create and list to-dos. You can end your development session by shutting down the frontend dev server and cloud sandbox. The sandbox prompts you to delete your backend resources. While you can retain your backend, we recommend deleting all resources so you can start clean again next time.

Deploy and host a fullstack branch

Now that your app is working, let's deploy it to a shared fullstack branch so you can share the project with your team. Amplify offers a fully managed hosting service with CI/CD built in, making it easy to set up production and staging environments with Git branches. In Gen 2, every Git branch in your repository maps 1:1 to a fullstack branch in Amplify.

Create remote Git repository

If you already have your project remotely hosted in a Git repository, you can skip this step. Otherwise, navigate to your preferred Git provider, and add your project to a new repository. Amplify supports GitHub, AWS CodeCommit, GitLab, and Bitbucket.

Connect branch in the Amplify console
To get started with Gen 2, log in to the Amplify console and navigate to your preferred AWS Region. (The Amplify console is available in 19 AWS Regions).
From the Public Preview banner, choose Try Amplify Gen 2.

In the Git provider screen, choose Option 2: Start with an existing app. Connect the repository you just deployed and pick a branch.

Review all of your settings to ensure everything is set up correctly. Choose Save and deploy to deploy your web app.

Manage fullstack branch

The new Amplify console gives you a central place to manage your branches, hosting settings, CI/CD builds, and backend resources. Even though you can access backend resources directly from AWS service consoles, the Amplify console offers built-in user and data administration.

--------------------------------------------------------------------------------

Title: Server-Side Rendering - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/server-side-rendering/
HTML Content:
Next.js
/
Build & connect backend
/
Server-Side Rendering
Server-Side Rendering

This guide walks through how to use Amplify Auth and Data APIs from Next.js server-side runtimes.

Before you begin:

Follow the Next.js App Router tutorial
Install the Amplify Next.js adapter

To use Amplify APIs server-side, you need to install the Amplify Next.js adapter in addition to the Amplify libraries:

Terminal
Copy
Terminal code example
npm add aws-amplify @aws-amplify/adapter-nextjs
Configure Amplify APIs for server-side usage

You will need to create a runWithAmplifyServerContextRunner function to use Amplify APIs on the server-side of your Next.js app.

You can create an amplifyServerUtils.ts file under a utils folder in your codebase. In this file, you will import the Amplify backend outputs from the amplify_outputs.json file that is generated by the Amplify CLI, and use the createServerRunner function to create the runWithAmplifyServerContextRunner function.

For example, the utils/amplifyServerUtils.ts file may contain the following content:

Copy
code example
import { createServerRunner } from '@aws-amplify/adapter-nextjs';
import outputs from '@/amplify_outputs.json';


export const { runWithAmplifyServerContext } = createServerRunner({
  config: outputs
});

You can use the exported runWithAmplifyServerContext function to call Amplify APIs within isolated request contexts. You can review examples under the Calling Amplify category APIs on the server side section.

TIP: You only need to call the createServerRunner function once and reuse the runWithAmplifyServerContext function throughout.

Configure Amplify library for client-side usage

When you use the Amplify library on the client-side of your Next.js app, you will need to configure Amplify by calling the Amplify.configure as you would to use Amplify in a single-page application.

NOTE: To use the Amplify library on the client side in a Next.js app, you will need to set ssr to true when calling Amplify.configure. This instructs the Amplify library to store tokens in the cookie store of a browser. Cookies will be sent along with requests to your Next.js server for authentication.

Copy
code example
'use client';


import outputs from '@/amplify_outputs.json';
import { Amplify } from 'aws-amplify';


Amplify.configure(outputs, {
  ssr: true // required when using Amplify with Next.js
});


export default function RootLayoutThatConfiguresAmplifyOnTheClient({
  children
}: {
  children: React.ReactNode;
}) {
  return children;
}

To avoid repetitive calls to Amplify.configure, you can call it once in a top-level client-side rendered layout component.

Learn more
Configure Amplify in a Next.js App Router application
Authentication with Next.js server-side runtime

You can use the Amplify Auth category APIs to sign up and sign in your end users on the client side. When you set ssr: true when calling Amplify.configure, the Amplify library uses cookies to store tokens which will be sent along with HTTP requests to your Next.js app server.

Manage Auth session with the Next.js Middleware

You can use the fetchAuthSession API to check the auth sessions that are attached to the incoming requests in the middleware of your Next.js app to protect your routes. For example:

Copy
code example
import { fetchAuthSession } from 'aws-amplify/auth/server';
import { NextRequest, NextResponse } from 'next/server';
import { runWithAmplifyServerContext } from '@/utils/amplifyServerUtils';


export async function middleware(request: NextRequest) {
  const response = NextResponse.next();


  const authenticated = await runWithAmplifyServerContext({
    nextServerContext: { request, response },
    operation: async (contextSpec) => {
      try {
        const session = await fetchAuthSession(contextSpec);
        return (
          session.tokens?.accessToken !== undefined &&
          session.tokens?.idToken !== undefined
        );
      } catch (error) {
        console.log(error);
        return false;
      }
    }
  });


  if (authenticated) {
    return response;
  }


  return NextResponse.redirect(new URL('/sign-in', request.url));
}


export const config = {
  matcher: [
    /*
     * Match all request paths except for the ones starting with:
     * - api (API routes)
     * - _next/static (static files)
     * - _next/image (image optimization files)
     * - favicon.ico (favicon file)
     */
    '/((?!api|_next/static|_next/image|favicon.ico|sign-in).*)'
  ]
};

In this example, if the incoming request is not associated with a valid user session the request will be redirected to the /sign-in route.

NOTE: When calling fetchAuthSession with a response context, it will send the refreshed tokens (if any) back to the client via the Set-Cookie header in the response.

Calling Amplify category APIs on the server side

For the Auth categories to use Amplify APIs on the server in your Next.js app, you will need to:

Import the API from the /server sub path.
Use the runWithAmplifyServerContext helper function created by calling the createServerRunner function exported from @aws-amplify/adapter-nextjs to call the Amplify API in an isolated server context.

For the GraphQL API category, review Connect to data from Server-side Runtimes.

NOTE: A subset of Amplify APIs can now be called on the server side of a Next.js app. These APIs are exported from the /server sub paths. See the full list of supported APIs.

Note: If you use the Amplify server-side APIs in a server action and encounter the following error running next build:

./node_modules/@aws-amplify/core/node_modules/@aws-crypto/sha256-js/build/module/index.js + 12 modules

Cannot get final name for export 'fromUtf8' of ./node_modules/@smithy/util-utf8/dist-es/index.js

You can add the following to your next.config.js:

next.config.js
/** @type {import('next').NextConfig} */
const nextConfig = {
Copy
highlighted code example
  experimental: {
    serverComponentsExternalPackages: ['@aws-crypto'],
  },
};

See Next.js documentation on serverComponentsExternalPackages for more details.

With Next.js App Router
Dynamic rendering in React server component

Dynamic rendering is based on a user session extracted from an incoming request.

Copy
code example
import { cookies } from 'next/headers';
import { getCurrentUser } from 'aws-amplify/auth/server';
import { runWithAmplifyServerContext } from '@/utils/amplifyServerUtils';


// This page always dynamically renders per request
export const dynamic = 'force-dynamic';


export default async function AuthGetCurrentUserServer() {
  try {
    const currentUser = await runWithAmplifyServerContext({
      nextServerContext: { cookies },
      operation: (contextSpec) => getCurrentUser(contextSpec)
    });


    return (
      <AuthFetchResult
        description="The API is called on the server side."
        data={currentUser}
      />
    );
  } catch (error) {
    console.error(error);
    return <p>Something went wrong...</p>;
  }
}
Static rendering in React server component

Static rendering does not require a user session, so you can specify the nextServerContext parameter as null. This is useful for some use cases; for example, when you are using the Storage API with guest access (if you have enabled it in your backend).

Copy
code example
import { getUrl } from 'aws-amplify/storage/server';
import Image from 'next/image';
import { runWithAmplifyServerContext } from '@/utils/amplifyServerUtils';


// Re-render this page every 60 minutes
export const revalidate = 60 * 60; // in seconds


export default async function StaticallyRenderedPage() {
  try {
    const splashUrl = await runWithAmplifyServerContext({
      nextServerContext: null,
      operation: (contextSpec) =>
        getUrl(contextSpec, {
          key: 'splash.png'
        })
    });


    return (
      <Image
        src={splashUrl.url.toString()}
        alt="Splash Image"
        width={500}
        height={500}
      />
    );
  } catch (error) {
    console.error(error);
    return <p>Something went wrong...</p>;
  }
}

NOTE: The URL returned by the getUrl API expires in the above example. You may want to specify the revalidate parameter to rerender the page as required to ensure the URL gets regenerated.

In Route Handlers

In route handlers require implementing an API route that enables GET /apis/get-current-user.

Copy
code example
import { getCurrentUser } from 'aws-amplify/auth/server';
import { cookies } from 'next/headers';
import { NextResponse } from 'next/server';
import { runWithAmplifyServerContext } from '@/utils/amplifyServerUtils';


export async function GET() {
  const user = await runWithAmplifyServerContext({
    nextServerContext: { cookies },
    operation: (contextSpec) => getCurrentUser(contextSpec)
  });


  return NextResponse.json({ user });
}

When you call fetch('/apis/get-current-user') it returns a payload that contains the user data for the current signed-in user.

With Next.js Pages Router
In getServerSideProps

The following example extracts current user data from the request and provides them to a page react component via its props.

Copy
code example
export const getServerSideProps: GetServerSideProps = async ({ req, res }) => {
  const currentUser = await runWithAmplifyServerContext({
    nextServerContext: { request: req, response: res },
    operation: (contextSpec) => getCurrentUser(contextSpec)
  });


  return { props: { currentUser } };
};
In getStaticProps

Similar to static rendering with the App Router, you can pass null as the value of the nextServerContext parameter to use the Amplify Storage API with guest access.

Copy
code example
export async function getStaticProps() {
  const splashUrl = await runWithAmplifyServerContext({
    nextServerContext: null,
    operation: (contextSpec) => getUrl(contextSpec, { key: 'splash.png' })
  });


  return {
    props: { imageUrl: splashUrl.url.toString() },
    revalidate: (splashUrl.expiresAt.getTime() - Date.now()) / 1000 // in seconds
  };
}
Supported APIs for Next.js server-side usage

All APIs that support use on the server are exported from the aws-amplify/<category>/server sub paths. You must use these APIs for any server-side use cases.

Category	APIs	Server (Node.js) Amplify Hosting/Vercel	Vercel Edge Runtime (middleware)
Auth	fetchAuthSession	✅	✅
Auth	fetchUserAttributes	✅	✅
Auth	getCurrentUser	✅	✅
Data	generateServerClientUsingCookies	✅	
Data	generateServerClientUsingReqRes	✅	
Storage	getUrl	✅	
Storage	getProperties	✅	
Storage	list	✅	
Storage	remove	✅	
Storage	copy	✅	

--------------------------------------------------------------------------------

Title: Analytics - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/analytics/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
/
Analytics
Analytics
Set up Amplify Analytics
The Analytics category enables you to collect analytics data for your app. The Analytics category comes with built-in support for Amazon Pinpoint and Amazon Kinesis (Kinesis support is currently only available in the Amplify JavaScript library). The Analytics category uses Amazon Cognito Identity pools to identify users in your App. Cognito allows you to receive data from authenticated, and unauthenticated users in your App.
Record events
Learn how to record analytics events using Amplify.
Identify user
Use the Amplify analytics plugin to inform Pinpoint about your users.
Automatically track sessions
The Amplify analytics plugin records when an application opens and closes. This session information can be viewed either from your local computer’s terminal or the AWS Console for Pinpoint.
Enable and disable analytics
Learn how to enable/disable analytics using Amplify.
Streaming analytics data
The Amazon Kinesis analytics provider allows you to send analytics data to an Amazon Kinesis stream for real-time processing.
Storing analytics data
The Amazon Data Firehose analytics provider allows you to send analytics data to an Amazon Data Firehose stream for reliably storing data.
Personalized recommendations
Amazon Personalize can create recommendations by using event data, historical data, or a combination of both. The event data can then be used to create recommendations.
Use existing AWS resources
Configure the Amplify Libraries to use existing Amazon Pinpoint resources by referencing them in your configuration.

--------------------------------------------------------------------------------

Title: Add any AWS service - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/add-aws-services/
HTML Content:
Next.js
/
Build & connect backend
/
Add any AWS service
Add any AWS service
Analytics
Learn how to set Analytics resource powered by Pinpoint
Geo
Modern, interactive maps with location markers and location search.
In-App Messaging
Learn how to set up In-App Messaging resource powered by Pinpoint
API (REST)
A straightforward and secure solution for making HTTP requests using REST APIs
AI/ML Predictions
Learn how to set up AI/ML Predictions
Interactions
Automate customer workflows by enlisting the help of conversational chatbots powered by deep learning technologies
PubSub
The AWS Amplify PubSub category provides connectivity with cloud-based message-oriented middleware. You can use PubSub to pass messages between your app instances and its backend creating real-time interactive experiences.
Deletion protection and Backup resources
Learn how to enable deletion protection and backup on resources.
Custom resources
Learn how to write custom resources with the AWS CDK.
Overriding resources
Learn how to override resources.

--------------------------------------------------------------------------------

Title: Modify Amplify-generated Lambda resources with CDK - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/functions/modify-resources-with-cdk/
HTML Content:
Next.js
/
Build & connect backend
/
Functions
/
Modify Amplify-generated Lambda resources with CDK
Modify Amplify-generated Lambda resources with CDK

Amplify Functions utilize the NodejsFunction construct from the AWS Cloud Development Kit (CDK). The underlying resources can be modified, overridden, or extended using CDK after setting the resource on your backend.

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from '@aws-amplify/backend';
import { myFunction } from './functions/my-function';


const backend = defineBackend({
  myFunction
})


// CDK constructs can be accessed via
backend.myFunction.resources


// where the Lambda function can be found on
backend.myFunction.resources.lambda

The Lambda resource available is a representation of IFunction.

Adding IAM Policies

To learn how to add IAM policies to a Function's execution role, visit the documentation for granting access to other resources.

PREVIOUS
Examples

--------------------------------------------------------------------------------

Title: S3 Upload confirmation - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/functions/examples/s3-upload-confirmation/
HTML Content:
Next.js
/
Build & connect backend
/
Functions
/
Examples
/
S3 Upload confirmation
S3 Upload confirmation

You can use defineStorage and defineFunction to create a function trigger to confirm uploading a file.

To get started, install the @types/aws-lambda package, which contains types for different kinds of Lambda handlers, events, and responses.

Terminal
Copy
Terminal code example
npm add --save @types/aws-lambda

Update your storage definition to define the onUpload trigger as below:

amplify/storage/resource.ts
Copy
amplify/storage/resource.ts code example
import { defineFunction, defineStorage } from "@aws-amplify/backend";


export const storage = defineStorage({
  name: 'myProjectFiles',
  triggers: {
    onUpload: defineFunction({
      entry: './on-upload-handler.ts'
    })
  }
});

Next, create a file named amplify/storage/on-upload-handler.ts and use the following code to log the object keys whenever an object is uploaded to the bucket. You can add your custom logic to this function as needed.

amplify/storage/on-upload-handler.ts
Copy
amplify/storage/on-upload-handler.ts code example
import type { S3Handler } from 'aws-lambda';


export const handler: S3Handler = async (event) => {
  const objectKeys = event.Records.map((record) => record.s3.object.key);
  console.log(`Upload handler invoked for objects [${objectKeys.join(', ')}]`);
};

Now, when you deploy your backend, this function will be invoked whenever an object is uploaded to the bucket.

PREVIOUS
DynamoDB Streams

--------------------------------------------------------------------------------

Title: DynamoDB Streams - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/functions/examples/dynamo-db-stream/
HTML Content:
Next.js
/
Build & connect backend
/
Functions
/
Examples
/
DynamoDB Streams
DynamoDB Streams

With AWS Lambda, you can seamlessly integrate various event sources, such as Amazon DynamoDB, Amazon SQS, and others, to trigger Lambda functions in response to real-time events. This feature enables you to build responsive, event-driven applications that react to changes in data or system state without the need for polling services.

In this guide, lets configure a Lambda function with an Amazon DynamoDB stream as an event source. The Lambda function is automatically triggered whenever an item is added, updated, or deleted from the table, enabling you to build real-time applications that react to changes in your data. In this example, we will use a Todo table created by a data model on the GraphQL API.

To get started, install the AWS Lambda Powertools Logger, which provides structured logging capabilities for your Lambda function, and the aws-lambda package, which is used to define the handler type.

Terminal
Copy
Terminal code example
npm add --save-dev @aws-lambda-powertools/logger @types/aws-lambda

Second, create a new directory and a resource file, amplify/functions/dynamoDB-function/resource.ts. Then, define the function with defineFunction:

amplify/functions/dynamoDB-function/resource.ts
Copy
amplify/functions/dynamoDB-function/resource.ts code example
import { defineFunction } from "@aws-amplify/backend";


export const myDynamoDBFunction = defineFunction({
  name: "dynamoDB-function",
});

Third, create the corresponding handler file, amplify/functions/dynamoDB-function/handler.ts, file with the following contents:

amplify/functions/dynamoDB-function/handler.ts
Copy
amplify/functions/dynamoDB-function/handler.ts code example
import type { DynamoDBStreamHandler } from "aws-lambda";
import { Logger } from "@aws-lambda-powertools/logger";


const logger = new Logger({
  logLevel: "INFO",
  serviceName: "dynamodb-stream-handler",
});


export const handler: DynamoDBStreamHandler = async (event) => {
  for (const record of event.Records) {
    logger.info(`Processing record: ${record.eventID}`);
    logger.info(`Event Type: ${record.eventName}`);


    if (record.eventName === "INSERT") {
      // business logic to process new records
      logger.info(`New Image: ${JSON.stringify(record.dynamodb?.NewImage)}`);
    }
  }
  logger.info(`Successfully processed ${event.Records.length} records.`);
  
  return {
    batchItemFailures: [],
  };
};

Lastly, create DynamoDB table as event source in the amplify/backend.ts file:

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from "@aws-amplify/backend";
import { StartingPosition } from "aws-cdk-lib/aws-lambda";
import { DynamoEventSource } from "aws-cdk-lib/aws-lambda-event-sources";
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import { myDynamoDBFunction } from "./functions/kinesis-function/resource";


const backend = defineBackend({
  auth,
  data,
  myDynamoDBFunction,
});


const eventSource = new DynamoEventSource(backend.data.resources.tables["Todo"], {
  startingPosition: StartingPosition.LATEST,
});


backend.myDynamoDBFunction.resources.lambda.addEventSource(eventSource);
PREVIOUS
Amazon Kinesis Data Streams
NEXT
S3 Upload confirmation

--------------------------------------------------------------------------------

Title: Custom message - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/functions/examples/custom-message/
HTML Content:
Next.js
/
Build & connect backend
/
Functions
/
Examples
/
Custom message
Custom message

You can use defineAuth and defineFunction to create an Amazon Cognito custom message AWS Lambda trigger thats sends an custom email or phone verification message, or a multi-factor authentication (MFA) code.

To get started, install @types/aws-lambda package that will be used to define the type of the handler:

Terminal
Copy
Terminal code example
npm add --save-dev @types/aws-lambda

Next, create a new directory and a resource file, amplify/auth/custom-message/resource.ts. Then, define the function with defineFunction:

amplify/auth/custom-message/resource.ts
Copy
amplify/auth/custom-message/resource.ts code example
import { defineFunction } from '@aws-amplify/backend';


export const customMessage = defineFunction({
  name: "custom-message",
});

Next, create the corresponding handler file, amplify/auth/custom-message/handler.ts, file with the following contents:

amplify/auth/custom-message/handler.ts
Copy
amplify/auth/custom-message/handler.ts code example
import type { CustomMessageTriggerHandler } from "aws-lambda";


export const handler: CustomMessageTriggerHandler = async (event) => {
  if (event.triggerSource === "CustomMessage_ForgotPassword") {
    const locale = event.request.userAttributes["locale"];
    if (locale === "en") {
      event.response.emailMessage = `Your new one-time code is ${event.request.codeParameter}`;
      event.response.emailSubject = "Reset my password";
    } else if (locale === "es") {
      event.response.emailMessage = `Tu nuevo código de un solo uso es ${event.request.codeParameter}`;
      event.response.emailSubject = "Restablecer mi contraseña";
    }
  }


  return event;
};

Lastly, set the newly created function resource on your auth resource:

amplify/auth/resource.ts
Copy
amplify/auth/resource.ts code example
import { defineAuth } from '@aws-amplify/backend';
import { customMessage } from "./custom-message/resource";


export const auth = defineAuth({
  // ...
  triggers: {
    customMessage,
  }
});

After deploying the changes, whenever a user with user attribute locale set to es attempts to reset a password they will receive an email with a one-time code in Spanish.

PREVIOUS
User attribute validation
NEXT
Google reCAPTCHA challenge

--------------------------------------------------------------------------------

Title: Google reCAPTCHA challenge - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/functions/examples/google-recaptcha-challenge/
HTML Content:
Next.js
/
Build & connect backend
/
Functions
/
Examples
/
Google reCAPTCHA challenge
Google reCAPTCHA challenge

You can use defineAuth and defineFunction to create an auth experience that requires a reCAPTCHA v3 token. This can be accomplished by leveraging Amazon Cognito's feature to define a custom auth challenge and 3 triggers:

Create auth challenge
Define auth challenge
Verify auth challenge response
Create auth challenge trigger

To get started, create the first of the three triggers, create-auth-challenge. This is the trigger responsible for creating the reCAPTCHA challenge after a password is verified.

amplify/auth/create-auth-challenge/resource.ts
Copy
amplify/auth/create-auth-challenge/resource.ts code example
import { defineFunction } from "@aws-amplify/backend"


export const createAuthChallenge = defineFunction({
  name: "create-auth-challenge",
})

After creating the resource file, create the handler with the following contents:

amplify/auth/create-auth-challenge/handler.ts
Copy
amplify/auth/create-auth-challenge/handler.ts code example
import type { CreateAuthChallengeTriggerHandler } from "aws-lambda"


export const handler: CreateAuthChallengeTriggerHandler = async (event) => {
  const { request, response } = event


  if (
    // session will contain 3 "steps": SRP, password verification, custom challenge
    request.session.length === 2 &&
    request.challengeName === "CUSTOM_CHALLENGE"
  ) {
    response.publicChallengeParameters = { trigger: "true" }
    response.privateChallengeParameters = { answer: "" }
    // optionally set challenge metadata
    response.challengeMetadata = "CAPTCHA_CHALLENGE"
  }


  return event
}
Define auth challenge trigger

Next, you will want to create the trigger responsible for defining the auth challenge flow, define-auth-challenge.

amplify/auth/define-auth-challenge/resource.ts
Copy
amplify/auth/define-auth-challenge/resource.ts code example
import { defineFunction } from "@aws-amplify/backend"


export const defineAuthChallenge = defineFunction({
  name: "define-auth-challenge",
})

After creating the resource file, create the handler with the following contents:

amplify/auth/define-auth-challenge/handler.ts
Copy
amplify/auth/define-auth-challenge/handler.ts code example
import type { DefineAuthChallengeTriggerHandler } from "aws-lambda"


export const handler: DefineAuthChallengeTriggerHandler = async (event) => {
  const { response } = event
  const [srp, password, captcha] = event.request.session


  // deny by default
  response.issueTokens = false
  response.failAuthentication = true


  if (srp?.challengeName === "SRP_A") {
    response.failAuthentication = false
    response.challengeName = "PASSWORD_VERIFIER"
  }


  if (
    password?.challengeName === "PASSWORD_VERIFIER" &&
    password.challengeResult === true
  ) {
    response.failAuthentication = false
    response.challengeName = "CUSTOM_CHALLENGE"
  }


  if (
    captcha?.challengeName === "CUSTOM_CHALLENGE" &&
    // check for the challenge metadata set in "create-auth-challenge"
    captcha?.challengeMetadata === "CAPTCHA_CHALLENGE" &&
    captcha.challengeResult === true
  ) {
    response.issueTokens = true
    response.failAuthentication = false
  }


  return event
}
Verify auth challenge response trigger

Lastly, create the trigger responsible for verifying the challenge response, which in this case is the reCAPTCHA token verification.

If you have not done so already, you will need to register your application and retrieve a reCAPTCHA secret key. This can then be configured for use with your cloud sandbox using:

Terminal
Copy
Terminal code example
npx ampx sandbox secret set GOOGLE_RECAPTCHA_SECRET_KEY
amplify/auth/verify-auth-challenge-response/resource.ts
Copy
amplify/auth/verify-auth-challenge-response/resource.ts code example
import { defineFunction, secret } from "@aws-amplify/backend"


export const verifyAuthChallengeResponse = defineFunction({
  name: "verify-auth-challenge-response",
  environment: {
    GOOGLE_RECAPTCHA_SECRET_KEY: secret("GOOGLE_RECAPTCHA_SECRET_KEY"),
  },
})

After creating the resource file, create the handler with the following contents:

amplify/auth/verify-auth-challenge-response/handler.ts
Copy
amplify/auth/verify-auth-challenge-response/handler.ts code example
import type { VerifyAuthChallengeResponseTriggerHandler } from "aws-lambda"
import { env } from "$amplify/env/verify-auth-challenge-response"


/**
 * Google ReCAPTCHA verification response
 * @see https://developers.google.com/recaptcha/docs/v3#site_verify_response
 */
type GoogleRecaptchaVerifyResponse = {
  // whether this request was a valid reCAPTCHA token for your site
  success: boolean
  // the score for this request (0.0 - 1.0)
  score: number
  // the action name for this request (important to verify)
  action: string
  // timestamp of the challenge load (ISO format yyyy-MM-dd'T'HH:mm:ssZZ)
  challenge_ts: string
  // the hostname of the site where the reCAPTCHA was solved
  hostname: string
  // optional error codes
  "error-codes"?: unknown[]
}


export const handler: VerifyAuthChallengeResponseTriggerHandler = async (
  event
) => {
  if (!event.request.challengeAnswer) {
    throw new Error("Missing challenge answer")
  }


  // https://developers.google.com/recaptcha/docs/verify#api_request
  const url = new URL("https://www.google.com/recaptcha/api/siteverify")
  const params = new URLSearchParams({
    secret: env.GOOGLE_RECAPTCHA_SECRET_KEY,
    response: event.request.challengeAnswer,
  })
  url.search = params.toString()


  const request = new Request(url, {
    method: "POST",
  })


  const response = await fetch(request)
  const result = (await response.json()) as GoogleRecaptchaVerifyResponse


  if (!result.success) {
    throw new Error("Verification failed", { cause: result["error-codes"] })
  }


  // indicate whether the answer is correct
  event.response.answerCorrect = result.success


  return event
}
Configure auth resource

Finally, import and set the three triggers on your auth resource:

amplify/auth/resource.ts
Copy
amplify/auth/resource.ts code example
import { defineAuth } from "@aws-amplify/backend"
import { createAuthChallenge } from "./create-auth-challenge/resource"
import { defineAuthChallenge } from "./define-auth-challenge/resource"
import { verifyAuthChallengeResponse } from "./verify-auth-challenge-response/resource"


/**
 * Define and configure your auth resource
 * @see https://docs.amplify.aws/gen2/build-a-backend/auth
 */
export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  triggers: {
    createAuthChallenge,
    defineAuthChallenge,
    verifyAuthChallengeResponse,
  },
})
PREVIOUS
Custom message
NEXT
Amazon Kinesis Data Streams

--------------------------------------------------------------------------------

Title: Amazon Kinesis Data Streams - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/functions/examples/kinesis-stream/
HTML Content:
Next.js
/
Build & connect backend
/
Functions
/
Examples
/
Amazon Kinesis Data Streams
Amazon Kinesis Data Streams

With AWS Lambda, you can seamlessly integrate various event sources, such as Amazon Kinesis, Amazon SQS, and others, to trigger Lambda functions in response to real-time events. This feature enables you to build responsive, event-driven applications that react to changes in data or system state without the need for polling services.

In this guide, let us configure a Lambda function with a Kinesis data stream as an event source. The Lambda function is automatically triggered whenever new data is published to the stream - whether you're processing streaming data, reacting to application events, or automating workflows.

To get started, install the AWS Lambda Powertools Logger, which provides structured logging capabilities for your Lambda function, and the aws-lambda package, which is used to define the handler type.

Terminal
Copy
Terminal code example
npm add @aws-lambda-powertools/logger @types/aws-lambda

Second, create a new directory and a resource file, amplify/functions/kinesis-function/resource.ts. Then, define the function with defineFunction:

amplify/functions/kinesis-function/resource.ts
Copy
amplify/functions/kinesis-function/resource.ts code example
import { defineFunction } from "@aws-amplify/backend";


export const myKinesisFunction = defineFunction({
  name: "kinesis-function",
});

Third, create the corresponding handler file, amplify/functions/kinesis-function/handler.ts, file with the following contents:

amplify/functions/kinesis-function/handler.ts
Copy
amplify/functions/kinesis-function/handler.ts code example
import type {
  KinesisStreamBatchResponse,
  KinesisStreamHandler,
  KinesisStreamRecordPayload,
} from "aws-lambda";
import { Buffer } from "node:buffer";
import { Logger } from "@aws-lambda-powertools/logger";


const logger = new Logger({
  logLevel: "INFO",
  serviceName: "kinesis-stream-handler",
});


export const handler: KinesisStreamHandler = async (
  event,
  context
): Promise<KinesisStreamBatchResponse> => {
  for (const record of event.Records) {
    try {
      logger.info(`Processed Kinesis Event - EventID: ${record.eventID}`);
      const recordData = await getRecordDataAsync(record.kinesis);
      logger.info(`Record Data: ${recordData}`);
    } catch (err) {
      logger.error(`An error occurred ${err}`);
      /*
      When processing stream data, if any item fails, returning the failed item's position immediately
      prompts Lambda to retry from this item forward, ensuring continuous processing without skipping data.
      */
      return {
        batchItemFailures: [{ itemIdentifier: record.kinesis.sequenceNumber }],
      };
    }
  }
  logger.info(`Successfully processed ${event.Records.length} records.`);
  return { batchItemFailures: [] };
};


async function getRecordDataAsync(
  payload: KinesisStreamRecordPayload
): Promise<string> {
  const data = Buffer.from(payload.data, "base64").toString("utf-8");
  await Promise.resolve(1); // Placeholder for an async process
  return data;
}

Lastly, create the Kinesis stream and add it as a event source in the amplify/backend.ts file:

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from "@aws-amplify/backend";
import { Stream } from "aws-cdk-lib/aws-kinesis";
import { StartingPosition } from "aws-cdk-lib/aws-lambda";
import { KinesisEventSource } from "aws-cdk-lib/aws-lambda-event-sources";
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import { myKinesisFunction } from "./functions/kinesis-function/resource";


const backend = defineBackend({
  auth,
  data,
  myKinesisFunction,
});


const kinesisStack = backend.createStack("kinesis-stack");


const kinesisStream = new Stream(kinesisStack, "KinesisStream", {
  streamName: "myKinesisStream",
  shardCount: 1,
});


const eventSource = new KinesisEventSource(kinesisStream, {
  startingPosition: StartingPosition.LATEST,
  reportBatchItemFailures: true,
});


backend.myKinesisFunction.resources.lambda.addEventSource(eventSource);

For examples on streaming analytics data to the Kinesis stream from your frontend, see the Streaming analytics data documentation.

PREVIOUS
Google reCAPTCHA challenge
NEXT
DynamoDB Streams

--------------------------------------------------------------------------------

Title: User attribute validation - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/functions/examples/user-attribute-validation/
HTML Content:
Next.js
/
Build & connect backend
/
Functions
/
Examples
/
User attribute validation
User attribute validation

You can use defineAuth and defineFunction to create a Cognito pre sign-up Lambda trigger that extends the behavior of sign-up to validate attribute values.

To get started, create a new directory and a resource file, amplify/auth/pre-sign-up/resource.ts. Then, define the function with defineFunction:

amplify/auth/pre-sign-up/resource.ts
Copy
amplify/auth/pre-sign-up/resource.ts code example
import { defineFunction } from '@aws-amplify/backend';


export const preSignUp = defineFunction({
  name: "pre-sign-up"
});

Next, create the corresponding handler file, amplify/auth/pre-sign-up/handler.ts, file with the following contents:

amplify/auth/pre-sign-up/handler.ts
Copy
amplify/auth/pre-sign-up/handler.ts code example
import type { PreSignUpTriggerHandler } from "aws-lambda"


function isOlderThan(date: Date, age: number) {
  const comparison = new Date()
  comparison.setFullYear(comparison.getFullYear() - age)
  return date.getTime() > comparison.getTime()
}


export const handler: PreSignUpTriggerHandler = async (event) => {
  const birthdate = new Date(event.request.userAttributes["birthdate"])


  // you must be 13 years or older
  if (!isOlderThan(birthdate, 13)) {
    throw new Error("You must be 13 years or older to use this site")
  }


  return event
}

Lastly, set the newly created function resource on your auth resource:

amplify/auth/resource.ts
Copy
amplify/auth/resource.ts code example
import { defineAuth } from '@aws-amplify/backend';
import { preSignUp } from './pre-sign-up/resource';


export const auth = defineAuth({
  // ...
  triggers: {
    preSignUp
  }
});

After deploying the changes, whenever a user attempts to sign up this handler will verify the submitter's age is above 13 years.

PREVIOUS
Override ID token claims
NEXT
Custom message

--------------------------------------------------------------------------------

Title: Override ID token claims - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/functions/examples/override-token/
HTML Content:
Next.js
/
Build & connect backend
/
Functions
/
Examples
/
Override ID token claims
Override ID token claims

You can use defineAuth and defineFunction to create an Amazon Cognito Pre token generation AWS Lambda trigger to override the token by adding a new claim or modifying the user's group membership.

To get started, install the aws-lambda package, which is used to define the handler type.

Terminal
Copy
Terminal code example
npm add --save-dev @types/aws-lambda

Create a new directory and a resource file, amplify/auth/pre-token-generation/resource.ts. Then, define the function with defineFunction:

amplify/auth/pre-token-generation/resource.ts
Copy
amplify/auth/pre-token-generation/resource.ts code example
import { defineFunction } from '@aws-amplify/backend';


export const preTokenGeneration = defineFunction({
  name: 'pre-token-generation',
});

Then, create the corresponding handler file, amplify/auth/post-confirmation/pre-token-generation/handler.ts, file with the following contents:

amplify/auth/pre-token-generation/handler.ts
Copy
amplify/auth/pre-token-generation/handler.ts code example
import type { PreTokenGenerationTriggerHandler } from "aws-lambda";


export const handler: PreTokenGenerationTriggerHandler = async (event) => {
  event.response = {
    claimsOverrideDetails: {
      groupOverrideDetails: {
        // This will add the user to the cognito group "amplify_group_1" 
        groupsToOverride: ["amplify_group_1"],
      },
      claimsToAddOrOverride: {
        // This will add the custom claim "amplfy_attribute" to the id token
        amplfy_attribute: "amplify_gen_2",
      },
    },
  };
  return event;
};

Lastly, set the newly created function resource on your auth resource:

amplify/auth/resource.ts
Copy
amplify/auth/resource.ts code example
import { defineAuth } from '@aws-amplify/backend';
import { preTokenGeneration } from './pre-token-generation/resource';


export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  triggers: {
    preTokenGeneration
  }
});

After deploying the changes, The idToken of the user will be modified as per the trigger above.

Copy
code example
{
  "cognito:groups": [
    "amplify_group_1"
  ],
  "email_verified": true,
  "iss": "...",
  "cognito:username": "...",
  "origin_jti": "...",
  "amplfy_attribute": "amplify_gen_2",
  "aud": "...",
}
PREVIOUS
Create a user profile record
NEXT
User attribute validation

--------------------------------------------------------------------------------

Title: Create a user profile record - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/functions/examples/create-user-profile-record/
HTML Content:
Next.js
/
Build & connect backend
/
Functions
/
Examples
/
Create a user profile record
Create a user profile record

You can use defineAuth and defineFunction to create a Cognito post confirmation Lambda trigger to create a profile record when a user is confirmed.

A user is "confirmed" when they verify their account. Typically this happens when the user confirms their email via the verification email. The post confirmation handler will not be triggered for federated sign-ins (i.e. social sign-in).

To get started, install the aws-lambda package, which is used to define the handler type.

Terminal
Copy
Terminal code example
npm add --save-dev @types/aws-lambda

Update the amplify/data/resource.ts file to define a data model for the user's profile:

Make sure to configure the authorization rule to allow the postConfirmation resource as highlighted below. Granting access to resources creates environment variables for your Function such as the GraphQL API endpoint. To learn more visit the environment variables and secrets documentation for Functions.

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
import { type ClientSchema, a, defineData } from "@aws-amplify/backend";
import { postConfirmation } from "../auth/post-confirmation/resource";


const schema = a
  .schema({
    UserProfile: a
      .model({
        email: a.string(),
        profileOwner: a.string(),
      })
      .authorization((allow) => [
        allow.ownerDefinedIn("profileOwner"),
      ]),
  })
  .authorization((allow) => [allow.resource(postConfirmation)]);
export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: "apiKey",
    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});

Create a new directory and a resource file, amplify/auth/post-confirmation/resource.ts. Then, define the Function with defineFunction:

amplify/auth/post-confirmation/resource.ts
Copy
amplify/auth/post-confirmation/resource.ts code example
import { defineFunction } from '@aws-amplify/backend';


export const postConfirmation = defineFunction({
  name: 'post-confirmation',
});

Run the command npx ampx sandbox to create the backend, then use the command below to generate GraphQL client code to call your data backend.

Note: We are working on bringing the end-to-end typed experience to connect to your data from within function resources without needing this step. If you'd like to provide feedback on the experience or want to have early access, join our Discord community.

Terminal
Copy
Terminal code example
npx ampx generate graphql-client-code --out <path-to-post-confirmation-handler-dir>/graphql

Then, create the corresponding handler file, amplify/auth/post-confirmation/handler.ts, file with the following contents:

amplify/auth/post-confirmation/handler.ts
Copy
amplify/auth/post-confirmation/handler.ts code example
import type { PostConfirmationTriggerHandler } from "aws-lambda";
import { type Schema } from "../../data/resource";
import { Amplify } from "aws-amplify";
import { generateClient } from "aws-amplify/data";
import { env } from "$amplify/env/post-confirmation";
import { createUserProfile } from "./graphql/mutations";


Amplify.configure(
  {
    API: {
      GraphQL: {
        endpoint: env.AMPLIFY_DATA_GRAPHQL_ENDPOINT,
        region: env.AWS_REGION,
        defaultAuthMode: "iam",
      },
    },
  },
  {
    Auth: {
      credentialsProvider: {
        getCredentialsAndIdentityId: async () => ({
          credentials: {
            accessKeyId: env.AWS_ACCESS_KEY_ID,
            secretAccessKey: env.AWS_SECRET_ACCESS_KEY,
            sessionToken: env.AWS_SESSION_TOKEN,
          },
        }),
        clearCredentialsAndIdentityId: () => {
          /* noop */
        },
      },
    },
  }
);


const client = generateClient<Schema>({
  authMode: "iam",
});


export const handler: PostConfirmationTriggerHandler = async (event) => {
  await client.graphql({
    query: createUserProfile,
    variables: {
      input: {
        email: event.request.userAttributes.email,
        profileOwner: `${event.request.userAttributes.sub}::${event.userName}`,
      },
    },
  });


  return event;
};

Lastly, set the newly created Function resource on your auth resource:

amplify/auth/resource.ts
Copy
amplify/auth/resource.ts code example
import { defineAuth } from '@aws-amplify/backend';
import { postConfirmation } from './post-confirmation/resource';


export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  triggers: {
    postConfirmation
  }
});

After deploying the changes, whenever a user signs up and verifies their account a profile record is automatically created.

PREVIOUS
Add user to group
NEXT
Override ID token claims

--------------------------------------------------------------------------------

Title: Add user to group - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/functions/examples/add-user-to-group/
HTML Content:
Next.js
/
Build & connect backend
/
Functions
/
Examples
/
Add user to group
Add user to group

You can use defineAuth and defineFunction to create a Cognito post confirmation Lambda trigger that extends the behavior to perform some action when a user is confirmed.

A user is "confirmed" when they verify their account. Typically this happens when the user confirms their email via the verification email. The post confirmation handler will not be triggered for federated sign-ins (i.e. social sign-in).

To get started, install the AWS SDK v3 package, which will be used to perform actions against your auth resource, and the @types/aws-lambda package, which is used to define the handler type:

Terminal
Copy
Terminal code example
npm add --save-dev @aws-sdk/client-cognito-identity-provider @types/aws-lambda

Next, create a new directory and a resource file, amplify/auth/post-confirmation/resource.ts. Then, define the Function with defineFunction:

amplify/auth/post-confirmation/resource.ts
Copy
amplify/auth/post-confirmation/resource.ts code example
import { defineFunction } from '@aws-amplify/backend';


export const postConfirmation = defineFunction({
  name: 'post-confirmation',
  // optionally define an environment variable for your group name
  environment: {
    GROUP_NAME: 'EVERYONE'
  }
});

After creating the Function definition you will need to:

create the EVERYONE group
grant access to your auth resource to ensure it can perform the addUserToGroup action
set the Function as the post confirmation trigger
amplify/auth/resource.ts
Copy
amplify/auth/resource.ts code example
import { defineAuth } from "@aws-amplify/backend";
import { postConfirmation } from "./post-confirmation/resource"


export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  groups: ["EVERYONE"],
  triggers: {
    postConfirmation,
  },
  access: (allow) => [
    allow.resource(postConfirmation).to(["addUserToGroup"]),
  ],
})

Then create the Function's corresponding handler file, amplify/auth/post-confirmation/handler.ts, file with the following contents:

amplify/auth/post-confirmation/handler.ts
Copy
amplify/auth/post-confirmation/handler.ts code example
import type { PostConfirmationTriggerHandler } from 'aws-lambda';
import {
  CognitoIdentityProviderClient,
  AdminAddUserToGroupCommand
} from '@aws-sdk/client-cognito-identity-provider';
import { env } from '$amplify/env/post-confirmation';


const client = new CognitoIdentityProviderClient();


// add user to group
export const handler: PostConfirmationTriggerHandler = async (event) => {
  const command = new AdminAddUserToGroupCommand({
    GroupName: env.GROUP_NAME,
    Username: event.userName,
    UserPoolId: event.userPoolId
  });
  const response = await client.send(command);
  console.log('processed', response.$metadata.requestId);
  return event;
};

After deploying the changes, whenever a user signs up and verifies their account they are automatically added to the group named "EVERYONE".

PREVIOUS
Email domain filtering
NEXT
Create a user profile record

--------------------------------------------------------------------------------

Title: Email domain filtering - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/functions/examples/email-domain-filtering/
HTML Content:
Next.js
/
Build & connect backend
/
Functions
/
Examples
/
Email domain filtering
Email domain filtering

You can use defineAuth and defineFunction to create a Cognito pre sign-up Lambda trigger that performs filtering based on the user's email address. This can allow or deny user signups based on their email address.

To get started, install the aws-lambda package, which is used to define the handler type.

Terminal
Copy
Terminal code example
npm add --save-dev @types/aws-lambda

Next, create a new directory and a resource file, amplify/auth/pre-sign-up/resource.ts. Then, define the Function with defineFunction:

amplify/auth/pre-sign-up/resource.ts
Copy
amplify/auth/pre-sign-up/resource.ts code example
import { defineFunction } from '@aws-amplify/backend';


export const preSignUp = defineFunction({
  name: 'pre-sign-up',
  // optionally define an environment variable for your filter
  environment: {
    ALLOW_DOMAIN: 'amazon.com'
  }
});

Next, create the corresponding handler file, amplify/auth/pre-sign-up/handler.ts, file with the following contents:

amplify/auth/pre-sign-up/handler.ts
Copy
amplify/auth/pre-sign-up/handler.ts code example
import type { PreSignUpTriggerHandler } from 'aws-lambda';
import { env } from '$amplify/env/pre-sign-up';


export const handler: PreSignUpTriggerHandler = async (event) => {
  const email = event.request.userAttributes['email'];


  if (!email.endsWith(env.ALLOW_DOMAIN)) {
    throw new Error('Invalid email domain');
  }


  return event;
};

Lastly, set the newly created Function resource on your auth resource:

amplify/auth/resource.ts
Copy
amplify/auth/resource.ts code example
import { defineAuth } from '@aws-amplify/backend';
import { preSignUp } from './pre-sign-up/resource';


export const auth = defineAuth({
  // ...
  triggers: {
    preSignUp
  }
});

After deploying the changes, whenever a user attempts to sign up without an amazon.com email address they will receive an error.

NEXT
Add user to group

--------------------------------------------------------------------------------

Title: Grant access to other resources - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/functions/grant-access-to-other-resources/
HTML Content:
Next.js
/
Build & connect backend
/
Functions
/
Grant access to other resources
Grant access to other resources

In order for Amplify Functions to interact with other resources they must be given access. There are two ways to grant Amplify Functions access to other resources:

Using the access property
Using the AWS Cloud Development Kit (CDK)
Using the access property

The access property is a property found in each of the define* functions for defining Amplify resources. It allows you specify the necessary actions using common language.

When you grant a function access to another resource in your Amplify backend (such as granting access to storage), it will configure environment variables for that function to make SDK calls to the AWS services it has access to. Those environment variables are typed and available as part of the env object.

Say you have a function that generates reports each month from your Data resource and needs to store the generated reports in Storage:

amplify/storage/resource.ts
Copy
amplify/storage/resource.ts code example
import { defineStorage } from '@aws-amplify/backend';
import { generateMonthlyReports } from '../functions/generate-monthly-reports/resource';


export const storage = defineStorage({
  name: 'myReports',
  access: (allow) => ({
    'reports/*': [
      allow.resource(generateMonthlyReports).to(['read', 'write', 'delete'])
    ]
  })
});

This access definition will add the environment variable myReports_BUCKET_NAME to the function. This environment variable can be accessed on the env object.

Here's an example of how it can be used to upload some content to S3.

amplify/functions/generate-monthly-reports/handler.ts
Copy
amplify/functions/generate-monthly-reports/handler.ts code example
import { S3Client, PutObjectCommand } from '@aws-sdk/client-s3';
import { env } from '$amplify/env/generate-monthly-reports';


const s3Client = new S3Client();


export const handler = async () => {
  const command = new PutObjectCommand({
    Bucket: env.myReports_BUCKET_NAME,
    Key: `reports/${new Date().toISOString()}.csv`,
    Body: new Blob([''], { type: 'text/csv;charset=utf-8;' })
  });


  await s3Client.send(command);
};
Using CDK

When permissions are needed to access resources beyond the capabilities of the access property, you must use CDK.

Functions are created with an execution role, which is an IAM role that contains policies that dictate what resources your Function can interact with when it executes. This role can be extended using the addToRolePolicy() method:

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend"
import * as iam from "aws-cdk-lib/aws-iam"
import * as sns from "aws-cdk-lib/aws-sns"
import { weeklyDigest } from "./functions/weekly-digest/resource"


const backend = defineBackend({
  weeklyDigest,
})


const weeklyDigestLambda = backend.weeklyDigest.resources.lambda


const topicStack = backend.createStack("WeeklyDigest")
const topic = new sns.Topic(topicStack, "Topic", {
  displayName: "digest",
})


Copy
highlighted code example
const statement = new iam.PolicyStatement({
  sid: "AllowPublishToDigest",
  actions: ["sns:Publish"],
  resources: [topic.topicArn],
})


weeklyDigestLambda.addToRolePolicy(statement)

However some constructs provide a grant* method to grant access to common policy actions. Revisiting the example above you can grant the same access with grantPublish:

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend"
import * as iam from "aws-cdk-lib/aws-iam"
import * as sns from "aws-cdk-lib/aws-sns"
import { weeklyDigest } from "./functions/weekly-digest/resource"


const backend = defineBackend({
  weeklyDigest,
})


const weeklyDigestLambda = backend.weeklyDigest.resources.lambda


const topicStack = backend.createStack("WeeklyDigest")
const topic = new sns.Topic(topicStack, "Topic", {
  displayName: "digest"
})


Copy
highlighted code example
topic.grantPublish(weeklyDigestLambda)
PREVIOUS
Streaming logs
NEXT
Examples

--------------------------------------------------------------------------------

Title: Examples - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/functions/examples/
HTML Content:
Next.js
/
Build & connect backend
/
Functions
/
Examples
Examples
Email domain filtering
Use an Auth Pre Signup trigger to allow or deny sign-ups based on email domains
Add user to group
Use an Auth Post Authentication trigger to automatically add new users to a group
Create a user profile record
Use an Auth Post Authentication trigger to automatically a user profile record
Override ID token claims
Use an Auth Pre token generation trigger to override ID token claims
User attribute validation
Validate user attributes with an Auth trigger
Custom message
Use an Auth custom message authentication trigger to customize the message sent to users
Google reCAPTCHA challenge
Leverage Google reCAPTCHA to protect against spam
Amazon Kinesis Data Streams
Create a Lambda event source for a Amazon Kinesis Data Stream to trigger Lambda functions in response to real-time events
DynamoDB Streams
Create a Lambda event source using Amazon DynamoDB Streams to trigger a Lambda function in response to real-time events.
S3 Upload confirmation
Use a trigger to confirm uploading files

--------------------------------------------------------------------------------

Title: Streaming logs - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/functions/streaming-logs/
HTML Content:
Next.js
/
Build & connect backend
/
Functions
/
Streaming logs
Streaming logs

Amplify enables you to stream logs from your Function directly to your terminal while running ampx sandbox. To get started, specify the --stream-function-logs option when starting sandbox:

Terminal
Copy
Terminal code example
npx ampx sandbox --stream-function-logs

Note: this feature is only available for Sandbox

Streaming Function logs directly to your terminal enable faster debug iterations, and greater insight into your Functions' executions.

Filtering

By default, Amplify will stream all of your Functions' logs. If you wish to only stream a subset of Functions you can specify a filter by Function name or a regular expression for Function names. For example, if you have a collection of Auth triggers where the Function names include "auth"

Terminal
Copy
Terminal code example
npx ampx sandbox --stream-function-logs --logs-filter auth

After you successfully deploy your personal cloud sandbox, start your frontend application, and sign up for the first time, you will see logs from your triggers' executions printed to the terminal where sandbox is running.

Terminal
> npx ampx sandbox --stream-function-logs --logs-filter auth
...


✨  Total time: 158.44s


[Sandbox] Watching for file changes...
File written: amplify_outputs.json
[auth-pre-sign-up] 3:36:34 PM INIT_START Runtime Version: nodejs:18.v30	Runtime Version ARN: arn:aws:lambda:us-east-1::runtime:f89c264158db39a1cfcbb5f9b3741413df1cfce4d550c9a475a67d923e19e2f4
[auth-pre-sign-up] 3:36:34 PM START RequestId: 685be2bd-5df1-4dd5-9eb1-24f5f6337f91 Version: $LATEST
[auth-pre-sign-up] 3:36:34 PM END RequestId: 685be2bd-5df1-4dd5-9eb1-24f5f6337f91
[auth-pre-sign-up] 3:36:34 PM REPORT RequestId: 685be2bd-5df1-4dd5-9eb1-24f5f6337f91	Duration: 4.12 ms	Billed Duration: 5 ms	Memory Size: 512 MB	Max Memory Used: 67 MB	Init Duration: 173.67 ms
[auth-post-confirmation] 3:38:40 PM INIT_START Runtime Version: nodejs:18.v30	Runtime Version ARN: arn:aws:lambda:us-east-1::runtime:f89c264158db39a1cfcbb5f9b3741413df1cfce4d550c9a475a67d923e19e2f4
[auth-post-confirmation] 3:38:40 PM START RequestId: fce69b9f-b257-4af8-8a6e-821f84a39ce7 Version: $LATEST
[auth-post-confirmation] 3:38:41 PM 2024-07-19T22:38:41.209Z	fce69b9f-b257-4af8-8a6e-821f84a39ce7	INFO	processed 412f8911-acfa-41c7-9605-fa0c40891ea9
[auth-post-confirmation] 3:38:41 PM END RequestId: fce69b9f-b257-4af8-8a6e-821f84a39ce7
[auth-post-confirmation] 3:38:41 PM REPORT RequestId: fce69b9f-b257-4af8-8a6e-821f84a39ce7	Duration: 264.38 ms	Billed Duration: 265 ms	Memory Size: 512 MB	Max Memory Used: 93 MB	Init Duration: 562.19 ms
[auth-pre-authentication] 3:38:41 PM INIT_START Runtime Version: nodejs:18.v30	Runtime Version ARN: arn:aws:lambda:us-east-1::runtime:f89c264158db39a1cfcbb5f9b3741413df1cfce4d550c9a475a67d923e19e2f4
[auth-pre-authentication] 3:38:41 PM START RequestId: 9210ca3a-1351-4826-8544-123684765710 Version: $LATEST
[auth-pre-authentication] 3:38:41 PM END RequestId: 9210ca3a-1351-4826-8544-123684765710
[auth-pre-authentication] 3:38:41 PM REPORT RequestId: 9210ca3a-1351-4826-8544-123684765710	Duration: 3.47 ms	Billed Duration: 4 ms	Memory Size: 512 MB	Max Memory Used: 67 MB	Init Duration: 180.24 ms
[auth-post-authentication] 3:38:42 PM INIT_START Runtime Version: nodejs:18.v30	Runtime Version ARN: arn:aws:lambda:us-east-1::runtime:f89c264158db39a1cfcbb5f9b3741413df1cfce4d550c9a475a67d923e19e2f4
[auth-post-authentication] 3:38:42 PM START RequestId: 60c1d680-ea24-4a8b-93de-02d085859140 Version: $LATEST
[auth-post-authentication] 3:38:42 PM END RequestId: 60c1d680-ea24-4a8b-93de-02d085859140
[auth-post-authentication] 3:38:42 PM REPORT RequestId: 60c1d680-ea24-4a8b-93de-02d085859140	Duration: 4.61 ms	Billed Duration: 5 ms	Memory Size: 512 MB	Max Memory Used: 68 MB	Init Duration: 172.66 ms
Writing to a file

By default, Amplify will print logs to the terminal where sandbox is running, however you can alternatively write logs to a file by specifying --logs-out-file:

Terminal
Copy
Terminal code example
npx ampx sandbox --stream-function-logs --logs-out-file sandbox.log

This can be combined with --logs-filter to create a log file of just your Auth-related Functions, for example:

Terminal
Copy
Terminal code example
npx ampx sandbox --stream-function-logs --logs-filter auth --logs-out-file sandbox-auth.log

However it cannot be combined multiple times to write logs to multiple files.

PREVIOUS
Scheduling Functions
NEXT
Grant access to other resources

--------------------------------------------------------------------------------

Title: Scheduling Functions - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/functions/scheduling-functions/
HTML Content:
Next.js
/
Build & connect backend
/
Functions
/
Scheduling Functions
Scheduling Functions

Amplify offers the ability to schedule Functions to run on specific intervals using natural language or cron expressions. To get started, specify the schedule property in defineFunction:

amplify/jobs/weekly-digest/resource.ts
Copy
amplify/jobs/weekly-digest/resource.ts code example
import { defineFunction } from "@aws-amplify/backend";


export const weeklyDigest = defineFunction({
  name: "weekly-digest",
  schedule: "every week",
});

Function schedules are powered by Amazon EventBridge rules, and can be leveraged to address use cases such as:

generating a "front page" of top-performing posts
generating a weekly digest of top-performing posts
generating a monthly report of warehouse inventory

Their handlers can be typed using the EventBridgeHandler type:

amplify/jobs/weekly-digest/handler.ts
Copy
amplify/jobs/weekly-digest/handler.ts code example
import type { EventBridgeHandler } from "aws-lambda";


export const handler: EventBridgeHandler = async (event) => {
  console.log("event", JSON.stringify(event, null, 2))
}

Note: AWS Lambda types can be installed with

Terminal
Copy
Terminal code example
npm install --save-dev @types/aws-lambda

Schedules can either be a single interval, or multiple intervals:

amplify/jobs/generate-report/resource.ts
Copy
amplify/jobs/generate-report/resource.ts code example
import { defineFunction } from "@aws-amplify/backend";


export const generateReport = defineFunction({
  name: "generate-report",
  schedule: ["every week", "every month", "every year"],
});

Schedules can also be defined to execute using minutes or hours with a shorthand syntax:

amplify/jobs/drink-some-water/resource.ts
Copy
amplify/jobs/drink-some-water/resource.ts code example
import { defineFunction } from "@aws-amplify/backend";


export const drinkSomeWater = defineFunction({
  name: "drink-some-water",
  schedule: "every 1h"
})

Or combined to create complex schedules:

amplify/jobs/remind-me/resource.ts
Copy
amplify/jobs/remind-me/resource.ts code example
import { defineFunction } from "@aws-amplify/backend";


export const remindMe = defineFunction({
  name: "remind-me",
  schedule: [
    // every sunday at midnight
    "every week",
    // every tuesday at 5pm
    "0 17 * * 2",
    // every wednesday at 5pm
    "0 17 * * 3",
    // every thursday at 5pm
    "0 17 * * 4",
    // every friday at 5pm
    "0 17 * * 5",
  ]
})
Using natural language

Schedules can be written using natural language, using terms you use every day. Amplify supports the following time periods:

day will always start at midnight
week will always start on Sunday at midnight
month will always start on the first of the month at midnight
year will always start on the first of the year at midnight
m for minutes
h for hours

Natural language expressions are prefixed with "every":

amplify/jobs/drink-some-water/resource.ts
Copy
amplify/jobs/drink-some-water/resource.ts code example
import { defineFunction } from "@aws-amplify/backend";


export const drinkSomeWater = defineFunction({
  name: "drink-some-water",
  schedule: "every 1h"
})
Using cron expressions

Schedules can be written using cron expressions.

amplify/jobs/remind-me/resource.ts
Copy
amplify/jobs/remind-me/resource.ts code example
import { defineFunction } from "@aws-amplify/backend";


export const remindMe = defineFunction({
  name: "remind-me-to-take-the-trash-out",
  schedule: [
    // every tuesday at 9am
    "0 9 * * 2",
    // every friday at 9am
    "0 9 * * 5",
  ]
})
PREVIOUS
Configure Functions
NEXT
Streaming logs

--------------------------------------------------------------------------------

Title: Configure Functions - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/functions/configure-functions/
HTML Content:
Next.js
/
Build & connect backend
/
Functions
/
Configure Functions
Configure Functions

defineFunction comes out-of-the-box with sensible but minimal defaults. The following options are provided to tweak the function configuration.

name

By default, functions are named based on the directory the defineFunction call is placed in. In the above example, defining the function in amplify/functions/my-demo-function/resource.ts will cause the function to be named my-demo-function by default.

If an entry is specified, then the name defaults to the basename of the entry path. For example, an entry of ./signup-trigger-handler.ts would cause the function name to default to signup-trigger-handler.

This optional property can be used to explicitly set the name of the function.

amplify/functions/my-demo-function/resource.ts
Copy
amplify/functions/my-demo-function/resource.ts code example
export const myDemoFunction = defineFunction({
  entry: './demo-function-handler.ts',
  name: 'overrideName' // explicitly set the name to override the default naming behavior
});
timeoutSeconds

By default, functions will time out after 3 seconds. This can be configured to any whole number of seconds up to 15 minutes.

amplify/functions/my-demo-function/resource.ts
export const myDemoFunction = defineFunction({
Copy
highlighted code example
  timeoutSeconds: 60 // 1 minute timeout
});
memoryMB

By default, functions have 512 MB of memory allocated to them. This can be configured from 128 MB up to 10240 MB. Note that this can increase the cost of function invocation. For more pricing information see here.

amplify/functions/my-demo-function/resource.ts
export const myDemoFunction = defineFunction({
Copy
highlighted code example
  memoryMB: 256 // allocate 256 MB of memory to the function.
});
runtime

Currently, only Node runtimes are supported by defineFunction. However, you can change the Node version that is used by the function. The default is the oldest Node LTS version that is supported by AWS Lambda (currently Node 18).

If you wish to use an older version of Node, keep an eye on the Lambda Node version deprecation schedule. As Lambda removes support for old Node versions, you will have to update to newer supported versions.

amplify/functions/my-demo-function/resource.ts
Copy
amplify/functions/my-demo-function/resource.ts code example
export const myDemoFunction = defineFunction({
  runtime: 20 // use Node 20
});
entry

By default, Amplify will look for your function handler in a file called handler.ts in the same directory as the file where defineFunction is called. To point to a different handler location, specify an entry value.

amplify/functions/my-demo-function/resource.ts
Copy
amplify/functions/my-demo-function/resource.ts code example
export const myDemoFunction = defineFunction({
  entry: './path/to/handler.ts' // this path should either be absolute or relative to the current file
});
PREVIOUS
Environment variables and secrets
NEXT
Scheduling Functions

--------------------------------------------------------------------------------

Title: Environment variables and secrets - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/functions/environment-variables-and-secrets/
HTML Content:
Next.js
/
Build & connect backend
/
Functions
/
Environment variables and secrets
Environment variables and secrets

Amplify Functions support setting environment variables and secrets on the environment property of defineFunction.

Note: do not store secret values in environment variables. Environment variables values are rendered in plaintext to the build artifacts located at .amplify/artifacts and may be emitted to CloudFormation stack event messages. To store secrets skip to the secrets section

Environment variables

Environment variables can be configured in defineFunction using the environment property.

amplify/functions/say-hello/resource.ts
Copy
amplify/functions/say-hello/resource.ts code example
import { defineFunction } from '@aws-amplify/backend';


export const sayHello = defineFunction({
  environment: {
    NAME: 'World'
  }
});

Any environment variables specified here will be available to the function at runtime.

Some environment variables are constant across all branches and deployments. But many environment values differ between deployment environments. Branch-specific environment variables can be configured for Amplify hosting deployments.

Suppose you created a branch-specific environment variable in hosting called "API_ENDPOINT" which had a different value for your "staging" vs "prod" branch. If you wanted that value to be available to your function you can pass it to the function using

amplify/functions/say-hello/resource.ts
Copy
amplify/functions/say-hello/resource.ts code example
export const sayHello = defineFunction({
  environment: {
    NAME: "World",
    API_ENDPOINT: process.env.API_ENDPOINT
  }
});
Accessing environment variables

Within your function handler, you can access environment variables using the normal process.env global object provided by the Node runtime. However, this does not make it easy to discover what environment variables will be available at runtime. Amplify generates an env symbol that can be used in your function handler and provides typings for all variables that will be available at runtime. Copy the following code to use it.

amplify/functions/say-hello/handler.ts
Copy
highlighted code example
import { env } from '$amplify/env/say-hello'; // the import is '$amplify/env/<function name>'


export const handler = async (event) => {
  // the env object has intellisense for all environment variables that are available to the function
  return `Hello, ${env.NAME}!`;
};
Learn more
Understanding the "env" symbol and how to manually configure your Amplify project to use it
Secrets

Sometimes it is necessary to provide a secret value to a function. For example, it may need a database password or an API key to perform some business use case. Environment variables should NOT be used for this because environment variable values are included in plaintext in the function configuration. Instead, secret access can be used.

Before using a secret in a function, you need to define a secret. After you have defined a secret, you can reference it in your function config.

amplify/functions/say-hello/resource.ts
Copy
amplify/functions/say-hello/resource.ts code example
import { defineFunction, secret } from '@aws-amplify/backend';


export const sayHello = defineFunction({
  environment: {
    NAME: "World",
    API_ENDPOINT: process.env.API_ENDPOINT,
    API_KEY: secret('MY_API_KEY') // this assumes you created a secret named "MY_API_KEY"
  }
});

You can use this secret value at runtime in your function the same as any other environment variable. However, you will notice that the value of the environment variable is not stored as part of the function configuration. Instead, the value is fetched when your function runs and is provided in memory.

amplify/functions/say-hello/handler.ts
Copy
amplify/functions/say-hello/handler.ts code example
import { env } from '$amplify/env/say-hello';


export const handler = async (event) => {
  const request = new Request(env.API_ENDPOINT, {
    headers: {
      // this is the value of secret named "MY_API_KEY"
      Authorization: `Bearer ${env.API_KEY}`
    }
  })
  // ...
  return `Hello, ${env.NAME}!`;
};
PREVIOUS
Set up a Function
NEXT
Configure Functions

--------------------------------------------------------------------------------

Title: Set up a Function - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/functions/set-up-function/
HTML Content:
Next.js
/
Build & connect backend
/
Functions
/
Set up a Function
Set up a Function

Amplify Functions are powered by AWS Lambda, and allow you to perform a wide variety of customization through self-contained functions. Functions can respond to events from other resources, execute some logic in-between events like an authentication flow, or act as standalone jobs. They are used in a variety of settings and use cases:

Authentication flow customizations (e.g. attribute validations, allowlisting email domains)
Resolvers for GraphQL APIs
Handlers for individual REST API routes, or to host an entire API
Scheduled jobs

To get started, create a new directory and a resource file, amplify/functions/say-hello/resource.ts. Then, define the Function with defineFunction:

amplify/functions/say-hello/resource.ts
Copy
amplify/functions/say-hello/resource.ts code example
import { defineFunction } from '@aws-amplify/backend';


export const sayHello = defineFunction({
  // optionally specify a name for the Function (defaults to directory name)
  name: 'say-hello',
  // optionally specify a path to your handler (defaults to "./handler.ts")
  entry: './handler.ts'
});

Next, create the corresponding handler file at amplify/functions/say-hello/handler.ts. This is where your function code will go.

amplify/functions/say-hello/handler.ts
Copy
amplify/functions/say-hello/handler.ts code example
import type { Handler } from 'aws-lambda';


export const handler: Handler = async (event, context) => {
  // your function code goes here
  return 'Hello, World!';
};

The handler file must export a function named "handler". This is the entry point to your function. For more information on writing functions, refer to the AWS documentation for Lambda function handlers using Node.js.

Lastly, this function needs to be added to your backend.

amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend';
Copy
highlighted code example
import { sayHello } from './functions/say-hello/resource';


defineBackend({
Copy
highlighted code example
  sayHello
});

Now when you run npx ampx sandbox or deploy your app on Amplify, it will include your Function.

To invoke your Function, we recommend adding your Function as a handler for a custom query with your Amplify Data resource. This will enable you to strongly type Function arguments and the return statement, and use this to author your Function's business logic. To get started, open your amplify/data/resource.ts file and specify a new query in your schema:

amplify/data/resource.ts
import { type ClientSchema, a, defineData } from "@aws-amplify/backend"
import { sayHello } from "../functions/say-hello/resource"


const schema = a.schema({
Copy
highlighted code example
  sayHello: a
    .query()
    .arguments({
      name: a.string().default("World"),
    })
    .returns(a.string())
    .handler(a.handler.function(sayHello)),
})


export type Schema = ClientSchema<typeof schema>


export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: "iam",
  },
})

Now you can use this query from the Schema export to strongly type your Function handler:

amplify/functions/say-hello/handler.ts
Copy
amplify/functions/say-hello/handler.ts code example
import type { Schema } from "../../data/resource"


export const handler: Schema["sayHello"]["functionHandler"] = async (event) => {
  // arguments typed from `.arguments()`
  const { name } = event.arguments
  // return typed from `.returns()`
  return `Hello, ${name}!`
}

Finally, use the data client to invoke your Function by calling its associated query.

src/main.ts
import type { Schema } from "./amplify/data/resource"
import { Amplify } from "aws-amplify"
import { generateClient } from "aws-amplify/api"
import outputs from "./amplify_outputs.json"


Amplify.configure(outputs)


const client = generateClient<Schema>()


Copy
highlighted code example
client.queries.sayHello({
  name: "Amplify",
})
Next steps

Now that you have completed setting up your first Function, you may also want to add some additional features or modify a few settings. We recommend you learn more about:

Environment variables and secrets
Grant access to other resources
Explore example use cases
Modifying underlying resources with CDK
NEXT
Environment variables and secrets

--------------------------------------------------------------------------------

Title: Functions - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/functions/
HTML Content:
Next.js
/
Build & connect backend
/
Functions
Functions
Set up a Function
Use AWS Lambda functions to perform tasks and customize workflows.
Environment variables and secrets
Learn how to configure and consume environment variables and secrets
Configure Functions
Learn how to configure functions
Scheduling Functions
Learn how to schedule functions to run at specific intervals
Streaming logs
Stream execution logs directly to your terminal while Sandbox is running
Grant access to other resources
Extend the capabilities of your Function by granting access to other resources
Examples
Example use cases for Amplify Functions
Modify Amplify-generated Lambda resources with CDK
Learn how to extend the underlying Function resources

--------------------------------------------------------------------------------

Title: Manage files with Amplify console - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/storage/manage-with-amplify-console/
HTML Content:
Next.js
/
Build & connect backend
/
Storage
/
Manage files with Amplify console
Manage files with Amplify console

The File storage page in the Amplify console provides a user-friendly interface for managing your application's backend file storage. It allows for efficient testing and management of your files.

If you have not yet created a storage resource, visit the Storage setup guide.

Access File storage

After you've deployed your storage resource, you can access the manager on Amplify Console.

Log in to the Amplify console and choose your app.
Select the branch you would like to access.
Select Storage from the left navigation bar.
To upload a file
On the Storage page, select the Upload button
Select the file you would like to upload and then select Done

Alternatively, you can Drag and drop a file onto the Storage page.

To delete a file
On the Storage page, select the file you want to delete.
Select the Actions dropdown and then select Delete.
To copy a file
On the Storage page, select the file you want to copy.
Select the Actions dropdown and then select Copy to.
Select or create the folder you want a copy of your file to be saved to.
Select Copy to copy your file to the selected folder.
To move a file
On the Storage page, select the file you want to move.
Select the Actions dropdown and then select Move to.
Select or create the folder you want to move your file to.
Select Move to move your file to the selected folder.
PREVIOUS
Use Amplify Storage with any S3 bucket

--------------------------------------------------------------------------------

Title: Use Amplify Storage with any S3 bucket - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/storage/use-with-custom-s3/
HTML Content:
Next.js
/
Build & connect backend
/
Storage
/
Use Amplify Storage with any S3 bucket
Use Amplify Storage with any S3 bucket

With Amplify Storage APIs, you can use your own S3 buckets instead of the Amplify-created ones.

Important: To utilize the storage APIs with an S3 bucket outside of Amplify, you must have Amplify Auth configured in your project.

Step 1 - Add necessary permissions to the S3 bucket

For the specific Amazon S3 bucket that you want to use with these APIs, you need to make sure that the associated IAM role has the necessary permissions to read and write data to that bucket.

To do this, go to Amazon S3 console > Select the S3 bucket > Permissions > Edit Bucket Policy.

The policy will look something like this

Copy
code example
{
	"Version": "2012-10-17",
	"Statement": [
		{
			"Sid": "Statement1",
			"Principal": { "AWS": "arn:aws:iam::<AWS-account-ID>:role/<role-name>" },
			"Effect": "Allow",
			"Action": [
				"s3:PutObject",
				"s3:GetObject",
				"s3:DeleteObject",
				"s3:ListBucket"
			],
			"Resource": [
				"arn:aws:s3:::<bucket-name>/*"
			]
		}
	]
}

Replace <AWS-account-ID> with your AWS account ID and <role-name> with the IAM role associated with your Amplify Auth setup. Replace <bucket-name> with the S3 bucket name.

You can refer to Amazon S3's Policies and Permissions documentation for more ways to customize access to the bucket.

Step 2 - Specify S3 bucket in Amplify's backend config

Next, use the addOutput method from the backend definition object to define a custom s3 bucket by specifying the name and region of the bucket in your amplify/backend.ts file.

Important

You cannot use both a storage backend configured through Amplify and a custom S3 bucket at the same time.

If you specify a custom S3 bucket, no sandbox storage resource will be created. The provided custom S3 bucket will be used, even in the sandbox environment.

Copy
code example
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';


const backend = defineBackend({
  auth,
  data,
});


Copy
highlighted code example
backend.addOutput({
  storage: {
    aws_region: "<region>",
    bucket_name: "<bucket-name>"
  },
});
Step 3 - Import latest amplify_outputs.json file

To ensure the local amplify_outputs.json file is up-to-date, you can run the npx ampx generate outputs command or download the latest amplify_outputs.json from the Amplify console as shown below.

Now that you've configured the necessary permissions, you can start using the storage APIs with your chosen S3 bucket.

PREVIOUS
Extend S3 resources
NEXT
Manage files with Amplify console

--------------------------------------------------------------------------------

Title: Extend S3 resources - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/storage/extend-s3-resources/
HTML Content:
Next.js
/
Build & connect backend
/
Storage
/
Extend S3 resources
Extend S3 resources
For Amplify-generated S3 resources

Amplify Storage generates Amazon S3 resources to offer storage features. You can access the underlying Amazon S3 resources to further customize your backend configuration by using the AWS Cloud Developer Kit (AWS CDK).

Example - Enable Transfer Acceleration

The following is an example of how you would enable Transfer Acceleration on the bucket (CDK documentation). In order to enable Transfer Acceleration on the bucket, you will have to unwrap the L1 CDK construct from the L2 CDK construct like the following.

Copy
highlighted code example
import * as s3 from 'aws-cdk-lib/aws-s3';
import { defineBackend } from '@aws-amplify/backend';
import { storage } from './storage/resource';


const backend = defineBackend({
  storage
});


Copy
highlighted code example
const s3Bucket = backend.storage.resources.bucket;


const cfnBucket = s3Bucket.node.defaultChild as s3.CfnBucket;


cfnBucket.accelerateConfiguration = {
  accelerationStatus: "Enabled" // 'Suspended' if you want to disable transfer acceleration
}

Read more about escape hatches in the CDK.

For Manually configured S3 resources

To make calls to your S3 bucket from your App, you need to set up a CORS Policy for your S3 bucket. This callout is only for manual configuration of your S3 bucket.

The following steps will set up your CORS Policy:

Go to Amazon S3 console and click on your project's userfiles bucket, which is normally named as [Bucket Name][Id]-dev. 
Click on the Permissions tab for your bucket. 
Click the edit button in the Cross-origin resource sharing (CORS) section. 
Make the Changes and click on Save Changes. You can add required metadata to be exposed in ExposeHeaders with x-amz-meta-XXXX format. 
Copy
code example
[
  {
    "AllowedHeaders": ["*"],
    "AllowedMethods": ["GET", "HEAD", "PUT", "POST", "DELETE"],
    "AllowedOrigins": ["*"],
    "ExposeHeaders": [
      "x-amz-server-side-encryption",
      "x-amz-request-id",
      "x-amz-id-2",
      "ETag",
      "x-amz-meta-foo"
    ],
    "MaxAgeSeconds": 3000
  }
]

Note: You can restrict the access to your bucket by updating AllowedOrigin to include individual domains.

PREVIOUS
Listen to storage events
NEXT
Use Amplify Storage with any S3 bucket

--------------------------------------------------------------------------------

Title: Listen to storage events - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/storage/lambda-triggers/
HTML Content:
Next.js
/
Build & connect backend
/
Storage
/
Listen to storage events
Listen to storage events

Function triggers can be configured to enable event-based workflows when files are uploaded or deleted. To add a function trigger, modify the defineStorage configuration.

First, in your storage definition, add the following:

amplify/storage/resource.ts
export const storage = defineStorage({
  name: 'myProjectFiles',
Copy
highlighted code example
  triggers: {
    onUpload: defineFunction({
      entry: './on-upload-handler.ts'
    }),
    onDelete: defineFunction({
      entry: './on-delete-handler.ts'
    })
  }
});

Then create the function definitions at amplify/storage/on-upload-handler.ts and amplify/storage/on-delete-handler.ts.

amplify/storage/on-upload-handler.ts
Copy
amplify/storage/on-upload-handler.ts code example
import type { S3Handler } from 'aws-lambda';


export const handler: S3Handler = async (event) => {
  const objectKeys = event.Records.map((record) => record.s3.object.key);
  console.log(`Upload handler invoked for objects [${objectKeys.join(', ')}]`);
};
amplify/storage/on-delete-handler.ts
Copy
amplify/storage/on-delete-handler.ts code example
import type { S3Handler } from 'aws-lambda';


export const handler: S3Handler = async (event) => {
  const objectKeys = event.Records.map((record) => record.s3.object.key);
  console.log(`Delete handler invoked for objects [${objectKeys.join(', ')}]`);
};

Note: The S3Handler type comes from the @types/aws-lambda npm package. This package contains types for different kinds of Lambda handlers, events, and responses.

Now, when you deploy your backend, these functions will be invoked whenever an object is uploaded or deleted from the bucket.

PREVIOUS
Copy files
NEXT
Extend S3 resources

--------------------------------------------------------------------------------

Title: Copy files - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/storage/copy-files/
HTML Content:
Next.js
/
Build & connect backend
/
Storage
/
Copy files
Copy files

Note: You can only copy files up to 5GB in a single operation

You can copy an existing file to a different path within the storage bucket using the copy API.

The copy method duplicates an existing file to a designated path and returns an object {path: 'destPath'} upon successful completion.

Copy
code example
import { copy } from 'aws-amplify/storage';


const copyFile = async () => {
  try {
    const response = await copy({
      source: {
        path: 'album/2024/1.jpg',
        // Alternatively, path: ({identityId}) => `album/{identityId}/1.jpg`
      },
      destination: {
        path: 'shared/2024/1.jpg',
        // Alternatively, path: ({identityId}) => `shared/{identityId}/1.jpg`
      },
    });
  } catch (error) {
    console.error('Error', err);
  }
};

Cross identity ID copying is only allowed if the destination path has the the right access rules to allow other authenticated users writing to it.

More copy options
Option	Type	Description	Reference Links
useAccelerateEndpoint	boolean	Whether to use accelerate endpoint.	Transfer Acceleration
PREVIOUS
Remove files
NEXT
Listen to storage events

--------------------------------------------------------------------------------

Title: Remove files - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/storage/remove-files/
HTML Content:
Next.js
/
Build & connect backend
/
Storage
/
Remove files
Remove files

Files can be removed from a storage bucket using the 'remove' API. If a file is protected by an identity Id, only the user who owns the file will be able to remove it.

Copy
code example
import { remove } from 'aws-amplify/storage';


try {
  await remove({ 
    path: 'album/2024/1.jpg',
    // Alternatively, path: ({identityId}) => `album/{identityId}/1.jpg`
  });
} catch (error) {
  console.log('Error ', error);
}
PREVIOUS
List file properties
NEXT
Copy files

--------------------------------------------------------------------------------

Title: List file properties - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/storage/list-files/
HTML Content:
Next.js
/
Build & connect backend
/
Storage
/
List file properties
List file properties

You can list files without having to download all the files. You can do this by using the list API from the Amplify Library for Storage. You can also get properties individually for a file using the getProperties API.

List Files
Copy
code example
import { list } from 'aws-amplify/storage';


const result = await list({
	path: 'photos/',
  // Alternatively, path: ({identityId}) => `album/{identityId}/photos/`
});

Note the trailing slash / - if you had requested list({ path : 'photos' }) it would also match against files like photos123.jpg alongside photos/123.jpg.

The format of the response will look similar to the below example:

Copy
code example
{
  items: [
    {
      path: "photos/123.jpg",
      eTag: "30074401292215403a42b0739f3b5262",
      lastModified: "Thu Oct 08 2020 23:59:31 GMT+0800 (Singapore Standard Time)",
      size: 138256
    },
    // ...
  ],
}

Manually created folders will show up as files with a size of 0, but you can also match keys against a regex like file.key.match(/\.[0-9a-z]+$/i) to distinguish files from folders. Since "folders" are a virtual concept in Amazon S3, any file may declare any depth of folder just by having a / in its name.

To access the contents and subpaths of a "folder", you have two options:

Request the entire path and parse the contents.
Use the subpathStrategy option to retrieve only the files within the specified path (i.e. exclude files under subpaths).
Get all nested files within a path

This retrieves all files and folders under a given path. You may need to parse the result to get only the files within the specified path.

Copy
code example
function processStorageList(response) {
  let files = [];
  let folders = new Set();
  response.items.forEach((res) => {
    if (res.size) {
      files.push(res);
      // sometimes files declare a folder with a / within then
      let possibleFolder = res.path.split('/').slice(0, -1).join('/');
      if (possibleFolder) folders.add(possibleFolder);
    } else {
      folders.add(res.path);
    }
  });
  return { files, folders };
}

If you need the files and folders in terms of a nested object instead (for example, to build an explorer UI), you could parse it recursively:

Copy
code example
function processStorageList(response) {
  const filesystem = {};
  // https://stackoverflow.com/questions/44759750/how-can-i-create-a-nested-object-representation-of-a-folder-structure
  const add = (source, target, item) => {
    const elements = source.split('/');
    const element = elements.shift();
    if (!element) return; // blank
    target[element] = target[element] || { __data: item }; // element;
    if (elements.length) {
      target[element] =
        typeof target[element] === 'object' ? target[element] : {};
      add(elements.join('/'), target[element], item);
    }
  };
  response.items.forEach((item) => add(item.path, filesystem, item));
  return filesystem;
}

This places each item's data inside a special __data key.

Excluding subpaths

In addition to using the list API to get all the contents of a path, you can also use it to get only the files within a path while excluding files under subpaths.

For example, given the following keys in your path you may want to return only the jpg object, and not the "vacation" subpath and its contents:

Copy
code example
photos/photo1.jpg
photos/vacation/

This can be accomplished with the subpathStrategy option:

src/main.ts
Copy
src/main.ts code example
import { list } from "aws-amplify/storage";
const result = await list({ 
  path: "photos/",
  options:{
    subpathStrategy: { strategy:'exclude' }
  }
});

The response will include only the objects within the photos/ path and will also communicate any excluded subpaths:

Copy
code example
{
    excludedSubpaths: [
      'photos/vacation/'
    ],
    items: [
      {
        path: "photos/photo1.jpg",
        eTag: "30074401292215403a42b0739f3b5262",
        lastModified: "Thu Oct 08 2020 23:59:31 GMT+0800 (Singapore Standard Time)",
        size: 138256
      },
    ]
}

The default delimiter character is '/', but this can be changed by supplying a custom delimiter:

src/main.ts
Copy
src/main.ts code example
const result = await list({
  // Path uses '-' character to organize files rather than '/'
  path: 'photos-',
  options: {
    subpathStrategy: {
      strategy: 'exclude',
      delimiter: '-'
    }
  }
});
More list options
Option	Type	Description
listAll	boolean	Set to true to list all files within the specified path
pageSize	number	Sets the maximum number of files to be return. The range is 0 - 1000
nextToken	string	Indicates whether the list is being continued on this bucket with a token
useAccelerateEndpoint	boolean	Whether to use accelerate endpoint.

Read more at Transfer Acceleration

If the pageSize is set lower than the total file size, a single list call only returns a subset of all the files. To list all the files with multiple calls, users can use the nextToken flag:

Copy
code example
import { list } from 'aws-amplify/storage';


const PAGE_SIZE = 20;
let nextToken = undefined;
//...
const loadNextPage = async () => {
  let response = await list({
    path: 'photos/',
    // Alternatively, path: ({ identityId }) => `album/{identityId}/photos/`
    pageSize: PAGE_SIZE,
    nextToken: nextToken
    }
  });
  if (response.nextToken) {
    nextToken = response.nextToken;
  } else {
    nextToken = undefined;
  }
  // render list items from response.items
};
Get File Properties

You can also view the properties of an individual file.

Copy
code example
import { getProperties } from 'aws-amplify/storage';


try {
  const result = await getProperties({
    path: 'album/2024/1.jpg'
    // Alternatively, path: ({ identityId }) => `album/{identityId}/1.jpg`
  });
  console.log('File Properties ', result);
} catch (error) {
  console.log('Error ', error);
}

The properties and metadata will look similar to the below example

Copy
code example
{
  path: "album/2024/1.jpg",
  contentType: "image/jpeg",
  contentLength: 6873,
  eTag: "\"56b32cf4779ff6ca3ba3f2d455fa56a7\"",
  lastModified: Wed Apr 19 2023 14:20:55 GMT-0700 (Pacific Daylight Time) {},
  metadata: { owner: 'aws' }
}
More getProperties options
Option	Type	Description
useAccelerateEndpoint	boolean	Whether to use accelerate endpoint.

To get the metadata in result for all APIs you have to configure user defined metadata in CORS.

Learn more about how to setup an appropriate CORS Policy.

PREVIOUS
Download files
NEXT
Remove files

--------------------------------------------------------------------------------

Title: Download files - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/storage/download-files/
HTML Content:
Next.js
/
Build & connect backend
/
Storage
/
Download files
Download files
Storage Image React UI Component

You can easily display images in your app by using the cloud-connected Storage Image React UI component. This component fetches images securely from your storage resource and displays it on the web page.

Terminal
Copy
Terminal code example
npm add @aws-amplify/ui-react-storage aws-amplify
Copy
code example
import { StorageImage } from '@aws-amplify/ui-react-storage';


export const DefaultStorageImageExample = () => {
  return <StorageImage alt="cat" path="your-path/cat.jpg" />;
};

Learn more about how you can further customize the UI component by referring to the Storage Image documentation.

To further customize your in-app experience, you can use the getUrl or downloadData API from the Amplify Library for Storage.

Note: Refer to the Transfer Acceleration documentation to learn how to enable transfer acceleration for storage APIs.

Get or download file from a URL

With the getUrl API, you can get a presigned URL which is valid for 900 seconds or 15 minutes by default. You can use this URL to create a download link for users to click on. The expiresAt property is a Date object that represents the time at which the URL will expire.

Copy
code example
import { getUrl } from 'aws-amplify/storage';


const linkToStorageFile = await getUrl({
  path: "album/2024/1.jpg",
  // Alternatively, path: ({identityId}) => `album/{identityId}/1.jpg`
  options: {
    validateObjectExistence?: false,  // defaults to false
    expiresIn?: 20 // validity of the URL, in seconds. defaults to 900 (15 minutes) and maxes at 3600 (1 hour)
    useAccelerateEndpoint: true; // Whether to use accelerate endpoint.
  },
});
console.log('signed URL: ', linkToStorageFile.url);
console.log('URL expires at: ', linkToStorageFile.expiresAt);

Inside your template or JSX code, you can use the url property to create a link to the file:

Copy
code example
<a href={linkToStorageFile.url.toString()} target="_blank" rel="noreferrer">
  {fileName} 
</a>

This function does not check if the file exists by default. As result, the signed URL may fail if the file to be downloaded does not exist.

More getUrl options
Option	Type	Description
useAccelerateEndpoint	boolean	Whether to use accelerate endpoint.

Read more at Transfer Acceleration
validateObjectExistence	boolean	Whether to head object to make sure the object existence before downloading. Defaults to false
expiresIn	number	Number of seconds till the URL expires.

The expiration time of the presigned url is dependent on the session and will max out at 1 hour.
Download to a file

Use the downloadData API to download the file locally.

Copy
code example
import { downloadData } from 'aws-amplify/storage';


// Downloads file content to memory
const { body, eTag } = await downloadData({
  path: "/album/2024/1.jpg",
  options: {
    // optional progress callback
    onProgress: (event) => {
      console.log(event.transferredBytes);
    }
    // optional bytes range parameter to download a part of the file, the 2nd MB of the file in this example
    bytesRange: {
      start: 1024,
      end: 2048
    }
  }
}).result;
Get the text value of downloaded File

You can get the value of file in any of the three formats: blob, json, or text. You can call the respective method on the body property to consume the set data in the respective format.

Copy
code example
import { downloadData } from 'aws-amplify/storage';


try {
  const downloadResult = await downloadData({
    path: "/album/2024/1.jpg"
  }).result;
  const text = await downloadResult.body.text();
  // Alternatively, you can use `downloadResult.body.blob()`
  // or `downloadResult.body.json()` get read body in Blob or JSON format.
  console.log('Succeed: ', text);
} catch (error) {
  console.log('Error : ', error);
}
Monitor download progress
Copy
code example
import { downloadData } from 'aws-amplify/storage';


// Download a file from S3 bucket
const { body, eTag } = await downloadData(
  {
    path: "/album/2024/1.jpg",
    options: {
      onProgress: (progress) {
        console.log(`Download progress: ${(progress.transferredBytes/progress.totalBytes) * 100}%`);
      }
    }
  }
).result;
Cancel download
Copy
code example
import { downloadData, isCancelError } from 'aws-amplify/storage';


const downloadTask = downloadData({ path: "/album/2024/1.jpg" });
downloadTask.cancel();
try {
  await downloadTask.result;
} catch (error) {
  if (isCancelError(error)) {
    // Handle error thrown by task cancellation.
  }
}
More download options
Option	Type	Description	Reference Links
useAccelerateEndpoint	boolean	Whether to use accelerate endpoint.	Transfer Acceleration
bytesRange	{ start: number; end:number; }	bytes range parameter to download a part of the file.	
onProgress	callback	Callback function tracking the upload/download progress.	
Frequently Asked Questions
downloadData is cached; if you have recently modified a file you may not get the latest version right away. You can pass in cacheControl: 'no-cache' to get the latest version.
downloadData only returns the latest cached version of the file; there is not yet an API to view prior versions.
Image compression or CloudFront CDN caching for your S3 buckets is not yet possible.
There is no API for Cognito Group-based access to files.
There is currently no API for getting the identityId of other users; you have to retrieve this from elsewhere before calling Storage.get.
PREVIOUS
Upload files
NEXT
List file properties

--------------------------------------------------------------------------------

Title: Upload files - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/storage/upload-files/
HTML Content:
Next.js
/
Build & connect backend
/
Storage
/
Upload files
Upload files

You can implement upload functionality in your app by either using the Storage Manager UI component or further customizing the upload experience using the upload API.

Storage Manager React UI Component

Upload files from your app in minutes by using the cloud-connected Storage Manager UI Component.

Terminal
Copy
Terminal code example
npm add @aws-amplify/ui-react-storage aws-amplify

Then, use the component in your app.

Copy
code example
import { StorageManager } from '@aws-amplify/ui-react-storage';
import '@aws-amplify/ui-react/styles.css';


export const DefaultStorageManagerExample = () => {
  return (
    <StorageManager
      acceptedFileTypes={['image/*']}
      path="public/"
      maxFileCount={1}
      isResumable
    />
  );
};

Learn more about how you can further customize the UI component by referring to the Storage Manager documentation.

Implement upload functionality

Note: Refer to the Transfer Acceleration documentation to learn how to enable transfer acceleration for storage APIs.

Upload from file

The following is an example of how you would upload a file from a file object, this could be retrieved from the local machine or a different source.

Copy
code example
import { uploadData } from "aws-amplify/storage";


const file = document.getElementById("file");
const upload = document.getElementById("upload");


upload.addEventListener("click", () => {
  const fileReader = new FileReader();
  fileReader.readAsArrayBuffer(file.files[0]);


  fileReader.onload = async (event) => {
    console.log("Complete File read successfully!", event.target.result);
    try {
      await uploadData({
                data: event.target.result, 
                path: file.files[0].name 
            });
    } catch (e) {
      console.log("error", e);
    }
  };
});
Upload from data

You can following this example if you have data saved in memory and would like to upload this data to the cloud.

Copy
code example
import { uploadData } from 'aws-amplify/storage';


try {
  const result = await uploadData({
    path: "album/2024/1.jpg",
    // Alternatively, path: ({identityId}) => `album/${identityId}/1.jpg`
    data: file,
    options: {
      onProgress // Optional progress callback.
    }
  }).result;
  console.log('Succeeded: ', result);
} catch (error) {
  console.log('Error : ', error);
}
Monitor upload progress

Monitor progress of upload by using the onProgress options

Copy
code example
import { uploadData } from 'aws-amplify/storage';


const monitorUpload = async () => {
  try {
    const result = await uploadData({
      path: "album/2024/1.jpg",
      // Alternatively, path: ({identityId}) => `album/${identityId}/1.jpg`
      data: file,
      options: {
        onProgress: ({ transferredBytes, totalBytes }) => {
          if (totalBytes) {
            console.log(
              `Upload progress ${Math.round(
                (transferredBytes / totalBytes) * 100
              )} %`
            );
          }
        },
      },
    }).result;
    console.log("Path from Response: ", result.path);
  } catch (error) {
    console.log("Error : ", error);
  }
}
Pause, resume, and cancel uploads

We have callback functions that support resuming, pausing, and cancelling uploadData requests.

Copy
code example
import { uploadData, isCancelError } from 'aws-amplify/storage';


// Pause, resume, and cancel a task
const uploadTask = uploadData({ path, data: file });
//...
uploadTask.pause();
//...
uploadTask.resume();
//...
uploadTask.cancel();
//...
try {
  await uploadTask.result;
} catch (error) {
  if (isCancelError(error)) {
    // Handle error thrown by task cancellation
  }
}
More upload options
Option	Type	Description
contentType	String	The default content-type header value of the file when downloading it.

Read more at Content-Type documentation
contentEncoding	String	The default content-encoding header value of the file when downloading it.

Read more at Content-Encoding documentation
contentDisposition	String	Specifies presentational information for the object.

Read more at Content-Disposition documentation
metadata	map<String>	A map of metadata to store with the object in S3.

Read more at S3 metadata documentation
useAccelerateEndpoint	boolean	Whether to use accelerate endpoint.

Read more at Transfer Acceleration

Uploads that were initiated over one hour ago will be cancelled automatically. There are instances (e.g. device went offline, user logs out) where the incomplete file remains in your Amazon S3 account. It is recommended to setup a S3 lifecycle rule to automatically cleanup incomplete upload requests.

MultiPart upload

Amplify will automatically perform an Amazon S3 multipart upload for objects that are larger than 5MB. For more information about S3's multipart upload, see Uploading and copying objects using multipart upload

PREVIOUS
Customize authorization rules
NEXT
Download files

--------------------------------------------------------------------------------

Title: Customize authorization rules - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/storage/authorization/
HTML Content:
Next.js
/
Build & connect backend
/
Storage
/
Customize authorization rules
Customize authorization rules

Customize authorization for your storage bucket by defining access to file paths for guests, authenticated users, and user groups. Access can also be defined for functions that require access to the storage bucket.

Refer to the following examples to understand how you can further customize authorization against different user types.

Access Types

Note: Paths in access definitions cannot have a '/' at the beginning of the string.

By default, all paths are denied to all types of users unless explicitly granted within defineStorage using the access callback as shown below.

Authentication is required to continue using Amplify Storage, please make sure you set it up if you haven't already - documentation to set up Auth.

Guest Users
Authenticated Users
User Groups
Owners
Functions

To grant all guest (i.e. not signed in) users of your application read access to files under media/, use the following access values.

amplify/storage/resource.ts
Copy
amplify/storage/resource.ts code example
export const storage = defineStorage({
  name: 'myProjectFiles',
  access: (allow) => ({
    'media/*': [
      allow.guest.to(['read']) // additional actions such as "write" and "delete" can be specified depending on your use case
    ]
  })
});
Access definition rules

There are some rules for the types of paths that can be specified at the same time in the storage access definition.

All paths must end with /*.
Only one level of nesting is allowed. For example, you can define access controls on media/* and media/albums/* but not on media/albums/photos/* because there are two other definitions along the same path.
Wildcards cannot conflict with the {entity_id} token. For example, you cannot have both media/* and media/{entity_id}/* defined because the wildcard in the first path conflicts with the {entity_id} token in the second path.
A path cannot be a prefix of another path with an {entity_id} token. For example media/* and media/albums/{entity_id}/* is not allowed.

When one path is a subpath of another, the permissions on the subpath always override the permissions from the parent path. Permissions are not "inherited" from a parent path. Consider the following access definition example:

Copy
code example
export const storage = defineStorage({
  name: 'myProjectFiles',
  access: (allow) => ({
    'media/*': [allow.authenticated.to(['read', 'write', 'delete'])],
    'media/profile-pictures/*': [allow.guest.to(['read'])],
    'media/albums/*': [allow.authenticated.to(['read'])],
    'other/*': [
      allow.guest.to(['read']),
      allow.authenticated.to(['read', 'write'])
    ]
  })
});

The access control matrix for this configuration is

	media/*	media/profile-pictures/*	media/albums/*	other/*
Authenticated Users	read, write, delete	NONE	read	read, write
Guest users	NONE	read	NONE	read

Authenticated users have access to read, write, and delete everything under media/* EXCEPT media/profile-pictures/* and media/albums/*. For those subpaths, the scoped down access overrides the access granted on the parent media/*

Available actions

When you configure access to a particular path, you can scope the access to one or more CRUDL actions.

Access	Corresponding Library APIs
read	getUrl, downloadData, list, and getProperties
get	getUrl and downloadData
list	list, and getProperties
write	uploadData, copy
delete	remove

Note: read is a combination of get and list access definitions and hence cannot be defined in the presence of get or list.

For Gen 1 public, protected, and private access pattern

To configure defineStorage in Amplify Gen 2 to behave the same way as the storage category in Gen 1, the following definition can be used.

amplify/storage/resource.ts
Copy
amplify/storage/resource.ts code example
export const storage = defineStorage({
  name: 'myProjectFiles',
  access: (allow) => ({
    'public/*': [
      allow.guest.to(['read']),
      allow.authenticated.to(['read', 'write', 'delete']),
    ],
    'protected/{entity_id}/*': [
      allow.authenticated.to(['read']),
      allow.entity('identity').to(['read', 'write', 'delete'])
    ],
    'private/{entity_id}/*': [
      allow.entity('identity').to(['read', 'write', 'delete'])
    ]
  })
});
PREVIOUS
Set up Storage
NEXT
Upload files

--------------------------------------------------------------------------------

Title: Set up Storage - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/storage/set-up-storage/
HTML Content:
Next.js
/
Build & connect backend
/
Storage
/
Set up Storage
Set up Storage

In this guide, you will learn how to set up storage in your Amplify app. You will set up your backend resources, and enable listing, uploading, and downloading files.

If you have not yet created an Amplify app, visit the quickstart guide.

Amplify Storage seamlessly integrates file storage and management capabilities into frontend web and mobile apps, built on top of Amazon Simple Storage Service (Amazon S3). It provides intuitive APIs and UI components for core file operations, enabling developers to build scalable and secure file storage solutions without dealing with cloud service complexities.

Building your storage backend

First, create a file amplify/storage/resource.ts. This file will be the location where you configure your storage backend. Instantiate storage using the defineStorage function and providing a name for your storage bucket. This name is a friendly name to identify your bucket in your backend configuration. Amplify will generate a unique identifier for your app using a UUID, the name attribute is just for use in your app.

amplify/storage/resource.ts
Copy
amplify/storage/resource.ts code example
import { defineStorage } from '@aws-amplify/backend';


export const storage = defineStorage({
  name: 'amplifyTeamDrive'
});

Import your storage definition in your amplify/backend.ts file that contains your backend definition. Add storage to defineBackend.

amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
Copy
highlighted code example
import { storage } from './storage/resource';


defineBackend({
  auth,
Copy
highlighted code example
  storage
});

Now when you run npx ampx sandbox or deploy your app on Amplify, it will configure an Amazon S3 bucket where your files will be stored. Before files can be accessed in your application, you must configure storage access rules.

To deploy these changes, commit them to git and push the changes upstream. Amplify's CI/CD system will automatically pick up the changes and build and deploy the updates.

Terminal
Copy
Terminal code example
git commit -am "add storage backend"
git push
Define File Path Access

By default, no users or other project resources have access to any files in the storage bucket. Access must be explicitly granted within defineStorage using the access callback.

The access callback returns an object where each key in the object is a file path and each value in the object is an array of access rules that apply to that path.

The following example shows you how you can set up your file storage structure for a generic photo sharing app. Here,

Guests have access to see all profile pictures and only the users that uploaded the profile picture can replace or delete them. Users are identified by their Identity Pool ID in this case i.e. identityID.
There's also a general pool where all users can submit pictures.

Learn more about customizing access to file path.

amplify/storage/resource.ts
Copy
amplify/storage/resource.ts code example
export const storage = defineStorage({
  name: 'amplifyTeamDrive',
  access: (allow) => ({
    'profile-pictures/{entity_id}/*': [
      allow.guest.to(['read']),
      allow.entity('identity').to(['read', 'write', 'delete'])
    ],
    'picture-submissions/*': [
      allow.authenticated.to(['read','write']),
      allow.guest.to(['read', 'write'])
    ],
  })
});
Connect your app code to the storage backend

The Amplify Storage library provides client APIs that connect to the backend resources you defined.

Configure Amplify in project

Import and load the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point. For example index.js in React or main.ts in Angular.

Copy
code example
import { Amplify } from 'aws-amplify';
import outputs from '../amplify_outputs.json';


Amplify.configure(outputs);

Make sure you call Amplify.configure as early as possible in your application’s life-cycle. A missing configuration or NoCredentials error is thrown if Amplify.configure has not been called before other Amplify JavaScript APIs.

Upload your first file

Next, let's a photo to the picture-submissions/ path.

Copy
code example
import { uploadData } from "aws-amplify/storage";


const file = document.getElementById("file");
const upload = document.getElementById("upload");


upload.addEventListener("click", () => {
  const fileReader = new FileReader();
  fileReader.readAsArrayBuffer(file.files[0]);


  fileReader.onload = async (event) => {
    console.log("Complete File read successfully!", event.target.result);
    try {
      await uploadData({
        data: event.target.result,
        path: `picture-submissions/${file.files[0].name}`
      });
    } catch (e) {
      console.log("error", e);
    }
  };
});
Manage files in Amplify console

After successfully publishing your storage backend and connecting your project with client APIs, you can manage files and folders in the Amplify console. You can perform on-demand actions like upload, download, copy, and more under the Storage tab in the console. Refer to Manage files in Amplify Console guide for additional information.

Conclusion

Congratulations! You finished the Set up Amplify Storage guide. In this guide, you set up and connected to backend resources, customized your file paths and access definitions, and connected your application to the backend to implement features like file uploads and downloads.

Next steps

Now that you have completed setting up storage in your Amplify app, you can proceed to add file management features to your app. You can use the following guides to implement upload and download functionality, or you can access more capabilities from the side navigation.

Upload Files
Download Files
NEXT
Customize authorization rules

--------------------------------------------------------------------------------

Title: Nuxt.js server runtime - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/connect-from-server-runtime/nuxtjs-server-runtime/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Connect to data from Server-side Runtimes
/
Nuxt.js server runtime
Nuxt.js server runtime

This guide walks through how you can connect to Amplify Data from Nuxt.js Server-side Runtime (SSR). For Nuxt.js applications, Amplify provides first-class support for Routing (Pages) , API Routes , and Middleware.

Before you begin, you will need:

A Nuxt.js application created
Deployed Amplify Data resources, or directly using AWS AppSync
Connect to Amplify Data from a Nuxt.js server runtime

Connecting to Amplify Data will include setting up the AmplifyAPIs Plugin with the runWithAmplifyServerContext adapter, using the useNuxtApp() composable, setting up the Amplify server context utility and then using the runAmplifyApi function to call the API in an isolated server context.

Step 1 - Set up the AmplifyAPIs Plugin

Nuxt 3 offers universal rendering by default, where your data fetching logic may be executed on both the client and server sides. Amplify offers APIs that are capable of running within a server context to support use cases such as server-side rendering (SSR) and static site generation (SSG), though Amplify's client-side APIs and server-side APIs of Amplify are slightly different. You can set up an AmplifyAPIs plugin to make your data fetching logic run smoothly across the client and server. To learn more about how to use Amplify categories APIs in server side rendering, refer to this documentation.

Create a plugins directory under the root of your Nuxt project.
Create two files 01.amplify-apis.client.ts and 01.amplify-apis.server.ts under the plugins directory.

In these files, you will register both client-specific and server-specific Amplify APIs that you will use in your Nuxt project as a plugin. You can then access these APIs via the useNuxtApp composable.

NOTE: The leading number in the files name indicate the plugin loading order, for more details see https://nuxt.com/docs/guide/directory-structure/plugins#registration-order. The .client and .server indicate the runtime that the logic contained in the file will run on, client or server. For details see: https://nuxt.com/docs/guide/directory-structure/plugins

Modify the 01.amplify-apis.client.ts file, with the following code:

Expand to view the code implementation

Next, modify the 01.amplify-apis.server.ts file, with the following code:

Expand to view the code implementation
Step 2 - Use the useNuxtApp() composable

Using the GraphQL API in ~/app.vue:

nuxt-amplify-gen2/app.vue
Copy
nuxt-amplify-gen2/app.vue code example
<script setup lang="ts">
import { Authenticator } from '@aws-amplify/ui-vue';
import '@aws-amplify/ui-vue/styles.css';
import { onMounted, ref } from 'vue';
import type { Schema } from '@/amplify/data/resource';


// create a reactive reference to the array of todos
const todos = ref<Schema['Todo']['type'][]>([]);


async function listTodos() {
 try {
    // `$Amplify` is generated by Nuxt according to the `provide` key in the plugins
    // fetch all todos
    const { data } = await useNuxtApp().$Amplify.GraphQL.client.models.Todo.list();
    todos.value = data;


  } catch (error) {
     console.error('Error fetching todos', error);
  }
}


// fetch todos when the component is mounted
onMounted(() => {
  listTodos();
});
</script>




<template>
  <Authenticator>
    <template v-slot="{ user, signOut }">
      <h1>Hello, Amplify 👋</h1>
        <ul>
          <li v-for="todo in todos" :key="todo.id">{{ todo.content }}</li>
        </ul>
      <button @click="signOut">Sign Out</button>
    </template>
  </Authenticator>
</template>

The app.vue file can be rendered on both the client and server sides by default. The useNuxtApp().$Amplify composable will pick up the correct implementation of 01.amplify-apis.client.ts and 01.amplify-apis.server.ts to use, depending on the runtime.

Only a subset of Amplify APIs are usable on the server side, and as the libraries evolve, amplify-apis.client and amplify-apis.server may diverge further. You can guard your API calls to ensure an API is available in the context where you use it. E.g., you can use if (process.client) to ensure that a client-only API isn't executed on the server.

Step 3 - Set up Amplify for API Routes

Following the specification of Nuxt, your API route handlers will live under ~/server, which is a separate environment from other parts of your Nuxt app; hence, the plugins created in the previous step are not usable here, and extra work is required.

Setup Amplify Server Context Utility
Create a utils directory under the server directory of your Nuxt project.
Create an amplifyUtils.ts file under the utils directory.

In this file, you will create a helper function to call Amplify APIs that are capable of running on the server side with context isolation. Modify the amplifyUtils.ts file, with the following code:

Expand to view the code implementation

Now, you can use the runAmplifyApi function to call Amplify APIs in an isolated server context. Create a new API route /api/current-user in the server directory and modify the current-user.ts file, with the following code:

nuxt-amplify-gen2/server/api/current-user.ts
Copy
nuxt-amplify-gen2/server/api/current-user.ts code example
import { getCurrentUser } from "aws-amplify/auth/server";
import { runAmplifyApi } from "~/server/utils/amplifyUtils";


export default defineEventHandler(async (event) => {
  const user = await runAmplifyApi(event, (contextSpec) =>
    getCurrentUser(contextSpec)
  );


  return user;
});

You can then fetch data from this API route, for example: fetch('http://localhost:3000/api/current-user')

PREVIOUS
Next.js server runtime

--------------------------------------------------------------------------------

Title: Storage - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/storage/
HTML Content:
Next.js
/
Build & connect backend
/
Storage
Storage
Set up Storage
Set up Amplify Storage for your project
Customize authorization rules
Define granular authorization rules for storage buckets
Upload files
Upload files using Amplify Storage
Download files
Download files using Amplify Storage
List file properties
Get list of files or file properties using Amplify Storage
Remove files
Remove files using Amplify Storage
Copy files
Copy files using Amplify Storage
Listen to storage events
Set up triggers on Storage events
Extend S3 resources
Extend configuration for S3 resources
Use Amplify Storage with any S3 bucket
You can use the Amplify Storage APIs against your own S3 bucket in your account.
Manage files with Amplify console
Manage your applications storage files with Amplify console

--------------------------------------------------------------------------------

Title: Optimistic UI - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/optimistic-ui/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Optimistic UI
Optimistic UI

Amplify Data can be used with TanStack Query to implement optimistic UI, allowing CRUD operations to be rendered immediately on the UI before the request roundtrip has completed. Using Amplify Data with TanStack additionally makes it easy to render loading and error states, and allows you to rollback changes on the UI when API calls are unsuccessful.

In the following examples we'll create a list view that optimistically renders newly created items, and a detail view that optimistically renders updates and deletes.

For more details on TanStack Query, including requirements, supported browsers, and advanced usage, see the TanStack Query documentation. For complete guidance on how to implement optimistic updates with TanStack Query, see the TanStack Query Optimistic UI Documentation. For more on Amplify Data, see the API documentation.

To get started, run the following command in an existing Amplify project with a React frontend:

Terminal
Copy
Terminal code example
# Install TanStack Query
npm i @tanstack/react-query @tanstack/react-query-devtools

Modify your Data schema to use this "Real Estate Property" example:

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
const schema = a.schema({
  RealEstateProperty: a.model({
    name: a.string().required(),
    address: a.string(),
  }).authorization(allow => [allow.guest()])
})


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: 'iam',
  },
});

Save the file and run npx ampx sandbox to deploy the changes to your backend cloud sandbox. For the purposes of this guide, we'll build a Real Estate Property listing application.

Next, at the root of your project, add the required TanStack Query imports, and create a client:

src/main.tsx
import React from 'react'
import ReactDOM from 'react-dom/client'
import App from './App.tsx'
import './index.css'
import { Amplify } from 'aws-amplify'
import outputs from '../amplify_outputs.json'
Copy
highlighted code example
import { QueryClient, QueryClientProvider } from "@tanstack/react-query";
import { ReactQueryDevtools } from "@tanstack/react-query-devtools";


Amplify.configure(outputs)


const queryClient = new QueryClient()


ReactDOM.createRoot(document.getElementById('root')!).render(
  <React.StrictMode>
Copy
highlighted code example
    <QueryClientProvider client={queryClient}>
      <App />
      <ReactQueryDevtools initialIsOpen={false} />
    </QueryClientProvider>
  </React.StrictMode>,
)

TanStack Query Devtools are not required, but are a useful resource for debugging and understanding how TanStack works under the hood. By default, React Query Devtools are only included in bundles when process.env.NODE_ENV === 'development', meaning that no additional configuration is required to exclude them from a production build. For more information on the TanStack Query Devtools, visit the TanStack Query Devtools docs

For the complete working example, including required imports and React component state management, see the Complete Example below.

How to use TanStack Query query keys with the Amplify Data API

TanStack Query manages query caching based on the query keys you specify. A query key must be an array. The array can contain a single string or multiple strings and nested objects. The query key must be serializable, and unique to the query's data.

When using TanStack to render optimistic UI with Amplify Data, you must use different query keys depending on the API operation. When retrieving a list of items, a single string is used (e.g. queryKey: ["realEstateProperties"]). This query key is also used to optimistically render a newly created item. When updating or deleting an item, the query key must also include the unique identifier for the record being deleted or updated (e.g. queryKey: ["realEstateProperties", newRealEstateProperty.id]).

For more detailed information on query keys, see the TanStack Query documentation.

Optimistically rendering a list of records

To optimistically render a list of items returned from the Amplify Data API, use the TanStack useQuery hook, passing in the Data API query as the queryFn parameter. The following example creates a query to retrieve all records from the API. We'll use realEstateProperties as the query key, which will be the same key we use to optimistically render a newly created item.

src/App.tsx
Copy
highlighted code example
import type { Schema } from '../amplify/data/resource'
import { generateClient } from 'aws-amplify/data'
import { useQuery } from '@tanstack/react-query'


const client = generateClient<Schema>();


function App() {
Copy
highlighted code example
  const {
    data: realEstateProperties,
    isLoading,
    isSuccess,
    isError: isErrorQuery,
  } = useQuery({
    queryKey: ["realEstateProperties"],
    queryFn: async () => {
      const response = await client.models.RealEstateProperty.list();


      const allRealEstateProperties = response.data;


      if (!allRealEstateProperties) return null;


      return allRealEstateProperties;
    },
  });
  // return ...
}
Optimistically rendering a newly created record

To optimistically render a newly created record returned from the Amplify Data API, use the TanStack useMutation hook, passing in the Amplify Data API mutation as the mutationFn parameter. We'll use the same query key used by the useQuery hook (realEstateProperties) as the query key to optimistically render a newly created item. We'll use the onMutate function to update the cache directly, as well as the onError function to rollback changes when a request fails.

import { generateClient } from 'aws-amplify/api'
import type { Schema } from '../amplify/data/resource'
Copy
highlighted code example
import { useQueryClient, useMutation } from '@tanstack/react-query'


const client = generateClient<Schema>()


function App() {
Copy
highlighted code example
  const queryClient = useQueryClient();


Copy
highlighted code example
  const createMutation = useMutation({
    mutationFn: async (input: { name: string, address: string }) => {
      const { data: newRealEstateProperty } = await client.models.RealEstateProperty.create(input)
      return newRealEstateProperty;
    },
    // When mutate is called:
    onMutate: async (newRealEstateProperty) => {
      // Cancel any outgoing refetches
      // (so they don't overwrite our optimistic update)
      await queryClient.cancelQueries({ queryKey: ["realEstateProperties"] });


      // Snapshot the previous value
      const previousRealEstateProperties = queryClient.getQueryData([
        "realEstateProperties",
      ]);


      // Optimistically update to the new value
      if (previousRealEstateProperties) {
        queryClient.setQueryData(["realEstateProperties"], (old: Schema["RealEstateProperty"]["type"][]) => [
          ...old,
          newRealEstateProperty,
        ]);
      }


      // Return a context object with the snapshotted value
      return { previousRealEstateProperties };
    },
    // If the mutation fails,
    // use the context returned from onMutate to rollback
    onError: (err, newRealEstateProperty, context) => {
      console.error("Error saving record:", err, newRealEstateProperty);
      if (context?.previousRealEstateProperties) {
        queryClient.setQueryData(
          ["realEstateProperties"],
          context.previousRealEstateProperties
        );
      }
    },
    // Always refetch after error or success:
    onSettled: () => {
      queryClient.invalidateQueries({ queryKey: ["realEstateProperties"] });
    },
  });
  // return ...
}
Querying a single item with TanStack Query

To optimistically render updates on a single item, we'll first retrieve the item from the API. We'll use the useQuery hook, passing in the get query as the queryFn parameter. For the query key, we'll use a combination of realEstateProperties and the record's unique identifier.

import { generateClient } from 'aws-amplify/data'
import type { Schema } from '../amplify/data/resource'
import { useQuery } from '@tanstack/react-query'


const client = generateClient<Schema>()


function App() {
  const currentRealEstatePropertyId = "SOME_ID"
Copy
highlighted code example
  const {
    data: realEstateProperty,
    isLoading,
    isSuccess,
    isError: isErrorQuery,
  } = useQuery({
    queryKey: ["realEstateProperties", currentRealEstatePropertyId],
    queryFn: async () => {
      if (!currentRealEstatePropertyId) { return }


      const { data: property } = await client.models.RealEstateProperty.get({
        id: currentRealEstatePropertyId,
      });
      return property;
    },
  });
}
Optimistically render updates for a record

To optimistically render Amplify Data updates for a single record, use the TanStack useMutation hook, passing in the update mutation as the mutationFn parameter. We'll use the same query key combination used by the single record useQuery hook (realEstateProperties and the record's id) as the query key to optimistically render the updates. We'll use the onMutate function to update the cache directly, as well as the onError function to rollback changes when a request fails.

When directly interacting with the cache via the onMutate function, the newRealEstateProperty parameter will only include fields that are being updated. When calling setQueryData, include the previous values for all fields in addition to the newly updated fields to avoid only rendering optimistic values for updated fields on the UI.

src/App.tsx
import { generateClient } from 'aws-amplify/data'
import type { Schema } from '../amplify/data/resource'
import { useQueryClient, useMutation } from "@tanstack/react-query";


const client = generateClient<Schema>()


function App() {
Copy
highlighted code example
  const queryClient = useQueryClient();


Copy
highlighted code example
   const updateMutation = useMutation({
    mutationFn: async (realEstatePropertyDetails: { id: string, name?: string, address?: string }) => {
      const { data: updatedProperty } = await client.models.RealEstateProperty.update(realEstatePropertyDetails);


      return updatedProperty;
    },
    // When mutate is called:
    onMutate: async (newRealEstateProperty: { id: string, name?: string, address?: string }) => {
      // Cancel any outgoing refetches
      // (so they don't overwrite our optimistic update)
      await queryClient.cancelQueries({
        queryKey: ["realEstateProperties", newRealEstateProperty.id],
      });


      await queryClient.cancelQueries({
        queryKey: ["realEstateProperties"],
      });


      // Snapshot the previous value
      const previousRealEstateProperty = queryClient.getQueryData([
        "realEstateProperties",
        newRealEstateProperty.id,
      ]);


      // Optimistically update to the new value
      if (previousRealEstateProperty) {
        queryClient.setQueryData(
          ["realEstateProperties", newRealEstateProperty.id],
          /**
           * `newRealEstateProperty` will at first only include updated values for
           * the record. To avoid only rendering optimistic values for updated
           * fields on the UI, include the previous values for all fields:
           */
          { ...previousRealEstateProperty, ...newRealEstateProperty }
        );
      }


      // Return a context with the previous and new realEstateProperty
      return { previousRealEstateProperty, newRealEstateProperty };
    },
    // If the mutation fails, use the context we returned above
    onError: (err, newRealEstateProperty, context) => {
      console.error("Error updating record:", err, newRealEstateProperty);
      if (context?.previousRealEstateProperty) {
        queryClient.setQueryData(
          ["realEstateProperties", context.newRealEstateProperty.id],
          context.previousRealEstateProperty
        );
      }
    },
    // Always refetch after error or success:
    onSettled: (newRealEstateProperty) => {
      if (newRealEstateProperty) {
        queryClient.invalidateQueries({
          queryKey: ["realEstateProperties", newRealEstateProperty.id],
        });
        queryClient.invalidateQueries({
          queryKey: ["realEstateProperties"],
        });
      }
    },
  });
}
Optimistically render deleting a record

To optimistically render a deletion of a single record, use the TanStack useMutation hook, passing in the delete mutation as the mutationFn parameter. We'll use the same query key combination used by the single record useQuery hook (realEstateProperties and the record's id) as the query key to optimistically render the updates. We'll use the onMutate function to update the cache directly, as well as the onError function to rollback changes when a delete fails.

src/App.tsx
import { generateClient } from 'aws-amplify/data'
import type { Schema } from '../amplify/data/resource'
import { useQueryClient, useMutation } from '@tanstack/react-query'


const client = generateClient<Schema>()


function App() {
Copy
highlighted code example
  const queryClient = useQueryClient();


Copy
highlighted code example
    const deleteMutation = useMutation({
    mutationFn: async (realEstatePropertyDetails: { id: string }) => {
      const { data: deletedProperty } = await client.models.RealEstateProperty.delete(realEstatePropertyDetails);
      return deletedProperty;
    },
    // When mutate is called:
    onMutate: async (newRealEstateProperty) => {
      // Cancel any outgoing refetches
      // (so they don't overwrite our optimistic update)
      await queryClient.cancelQueries({
        queryKey: ["realEstateProperties", newRealEstateProperty.id],
      });


      await queryClient.cancelQueries({
        queryKey: ["realEstateProperties"],
      });


      // Snapshot the previous value
      const previousRealEstateProperty = queryClient.getQueryData([
        "realEstateProperties",
        newRealEstateProperty.id,
      ]);


      // Optimistically update to the new value
      if (previousRealEstateProperty) {
        queryClient.setQueryData(
          ["realEstateProperties", newRealEstateProperty.id],
          newRealEstateProperty
        );
      }


      // Return a context with the previous and new realEstateProperty
      return { previousRealEstateProperty, newRealEstateProperty };
    },
    // If the mutation fails, use the context we returned above
    onError: (err, newRealEstateProperty, context) => {
      console.error("Error deleting record:", err, newRealEstateProperty);
      if (context?.previousRealEstateProperty) {
        queryClient.setQueryData(
          ["realEstateProperties", context.newRealEstateProperty.id],
          context.previousRealEstateProperty
        );
      }
    },
    // Always refetch after error or success:
    onSettled: (newRealEstateProperty) => {
      if (newRealEstateProperty) {
        queryClient.invalidateQueries({
          queryKey: ["realEstateProperties", newRealEstateProperty.id],
        });
        queryClient.invalidateQueries({
          queryKey: ["realEstateProperties"],
        });
      }
    },
  });
}
Loading and error states for optimistically rendered data

Both useQuery and useMutation return isLoading and isError states that indicate the current state of the query or mutation. You can use these states to render loading and error indicators.

In addition to operation-specific loading states, TanStack Query provides a useIsFetching hook. For the purposes of this demo, we show a global loading indicator in the Complete Example when any queries are fetching (including in the background) in order to help visualize what TanStack is doing in the background:

Copy
code example
function GlobalLoadingIndicator() {
  const isFetching = useIsFetching();
  return isFetching ? <div style={styles.globalLoadingIndicator}></div> : null;
}

For more details on advanced usage of TanStack Query hooks, see the TanStack documentation.

The following example demonstrates how to use the state returned by TanStack to render a loading indicator while a mutation is in progress, and an error message if the mutation fails. For additional examples, see the Complete Example below.

Copy
code example
<>
  {updateMutation.isError &&
  updateMutation.error instanceof Error ? (
    <div>An error occurred: {updateMutation.error.message}</div>
  ) : null}


  {updateMutation.isSuccess ? (
    <div>Real Estate Property updated!</div>
  ) : null}


  <button
    onClick={() =>
      updateMutation.mutate({
        id: realEstateProperty.id,
        address: `${Math.floor(
          1000 + Math.random() * 9000
        )} Main St`,
      })
    }
  >
    Update Address
  </button>
</>
Complete example
src/main.tsx
Copy
src/main.tsx code example
import React from 'react'
import ReactDOM from 'react-dom/client'
import App from './App.tsx'
import './index.css'
import { Amplify } from 'aws-amplify'
import outputs from '../amplify_outputs.json'
import { QueryClient, QueryClientProvider } from "@tanstack/react-query";
import { ReactQueryDevtools } from "@tanstack/react-query-devtools";


Amplify.configure(outputs)


export const queryClient = new QueryClient()


ReactDOM.createRoot(document.getElementById('root')!).render(
  <React.StrictMode>
    <QueryClientProvider client={queryClient}>
      <App />
      <ReactQueryDevtools initialIsOpen={false} />
    </QueryClientProvider>
  </React.StrictMode>,
)
src/App.tsx
Copy
src/App.tsx code example
import { generateClient } from 'aws-amplify/data'
import type { Schema } from '../amplify/data/resource'
import './App.css'
import { useIsFetching, useMutation, useQuery } from '@tanstack/react-query'
import { queryClient } from './main'
import { useState } from 'react'




const client = generateClient<Schema>({
  authMode: 'iam'
})


function GlobalLoadingIndicator() {
  const isFetching = useIsFetching();


  return isFetching ? <div style={styles.globalLoadingIndicator}></div> : null;
}




function App() {
  const [currentRealEstatePropertyId, setCurrentRealEstatePropertyId] =
  useState<string | null>(null);


  const {
    data: realEstateProperties,
    isLoading,
    isSuccess,
    isError: isErrorQuery,
  } = useQuery({
    queryKey: ["realEstateProperties"],
    queryFn: async () => {
      const response = await client.models.RealEstateProperty.list();


      const allRealEstateProperties = response.data;


      if (!allRealEstateProperties) return null;


      return allRealEstateProperties;
    },
  });


  const createMutation = useMutation({
    mutationFn: async (input: { name: string, address: string }) => {
      const { data: newRealEstateProperty } = await client.models.RealEstateProperty.create(input)
      return newRealEstateProperty;
    },
    // When mutate is called:
    onMutate: async (newRealEstateProperty) => {
      // Cancel any outgoing refetches
      // (so they don't overwrite our optimistic update)
      await queryClient.cancelQueries({ queryKey: ["realEstateProperties"] });


      // Snapshot the previous value
      const previousRealEstateProperties = queryClient.getQueryData([
        "realEstateProperties",
      ]);


      // Optimistically update to the new value
      if (previousRealEstateProperties) {
        queryClient.setQueryData(["realEstateProperties"], (old: Schema["RealEstateProperty"]["type"][]) => [
          ...old,
          newRealEstateProperty,
        ]);
      }


      // Return a context object with the snapshotted value
      return { previousRealEstateProperties };
    },
    // If the mutation fails,
    // use the context returned from onMutate to rollback
    onError: (err, newRealEstateProperty, context) => {
      console.error("Error saving record:", err, newRealEstateProperty);
      if (context?.previousRealEstateProperties) {
        queryClient.setQueryData(
          ["realEstateProperties"],
          context.previousRealEstateProperties
        );
      }
    },
    // Always refetch after error or success:
    onSettled: () => {
      queryClient.invalidateQueries({ queryKey: ["realEstateProperties"] });
    },
  });


  function RealEstatePropertyDetailView() {


    const {
      data: realEstateProperty,
      isLoading,
      isSuccess,
      isError: isErrorQuery,
    } = useQuery({
      queryKey: ["realEstateProperties", currentRealEstatePropertyId],
      queryFn: async () => {
        if (!currentRealEstatePropertyId) { return }


        const { data: property } = await client.models.RealEstateProperty.get({ id: currentRealEstatePropertyId });
        return property
      },
    });




    const updateMutation = useMutation({
      mutationFn: async (realEstatePropertyDetails: { id: string, name?: string, address?: string }) => {
        const { data: updatedProperty } = await client.models.RealEstateProperty.update(realEstatePropertyDetails);


        return updatedProperty;
      },
      // When mutate is called:
      onMutate: async (newRealEstateProperty: { id: string, name?: string, address?: string }) => {
        // Cancel any outgoing refetches
        // (so they don't overwrite our optimistic update)
        await queryClient.cancelQueries({
          queryKey: ["realEstateProperties", newRealEstateProperty.id],
        });


        await queryClient.cancelQueries({
          queryKey: ["realEstateProperties"],
        });


        // Snapshot the previous value
        const previousRealEstateProperty = queryClient.getQueryData([
          "realEstateProperties",
          newRealEstateProperty.id,
        ]);


        // Optimistically update to the new value
        if (previousRealEstateProperty) {
          queryClient.setQueryData(
            ["realEstateProperties", newRealEstateProperty.id],
            /**
             * `newRealEstateProperty` will at first only include updated values for
             * the record. To avoid only rendering optimistic values for updated
             * fields on the UI, include the previous values for all fields:
             */
            { ...previousRealEstateProperty, ...newRealEstateProperty }
          );
        }


        // Return a context with the previous and new realEstateProperty
        return { previousRealEstateProperty, newRealEstateProperty };
      },
      // If the mutation fails, use the context we returned above
      onError: (err, newRealEstateProperty, context) => {
        console.error("Error updating record:", err, newRealEstateProperty);
        if (context?.previousRealEstateProperty) {
          queryClient.setQueryData(
            ["realEstateProperties", context.newRealEstateProperty.id],
            context.previousRealEstateProperty
          );
        }
      },
      // Always refetch after error or success:
      onSettled: (newRealEstateProperty) => {
        if (newRealEstateProperty) {
          queryClient.invalidateQueries({
            queryKey: ["realEstateProperties", newRealEstateProperty.id],
          });
          queryClient.invalidateQueries({
            queryKey: ["realEstateProperties"],
          });
        }
      },
    });


    const deleteMutation = useMutation({
      mutationFn: async (realEstatePropertyDetails: { id: string }) => {
        const { data: deletedProperty } = await client.models.RealEstateProperty.delete(realEstatePropertyDetails);
        return deletedProperty;
      },
      // When mutate is called:
      onMutate: async (newRealEstateProperty) => {
        // Cancel any outgoing refetches
        // (so they don't overwrite our optimistic update)
        await queryClient.cancelQueries({
          queryKey: ["realEstateProperties", newRealEstateProperty.id],
        });


        await queryClient.cancelQueries({
          queryKey: ["realEstateProperties"],
        });


        // Snapshot the previous value
        const previousRealEstateProperty = queryClient.getQueryData([
          "realEstateProperties",
          newRealEstateProperty.id,
        ]);


        // Optimistically update to the new value
        if (previousRealEstateProperty) {
          queryClient.setQueryData(
            ["realEstateProperties", newRealEstateProperty.id],
            newRealEstateProperty
          );
        }


        // Return a context with the previous and new realEstateProperty
        return { previousRealEstateProperty, newRealEstateProperty };
      },
      // If the mutation fails, use the context we returned above
      onError: (err, newRealEstateProperty, context) => {
        console.error("Error deleting record:", err, newRealEstateProperty);
        if (context?.previousRealEstateProperty) {
          queryClient.setQueryData(
            ["realEstateProperties", context.newRealEstateProperty.id],
            context.previousRealEstateProperty
          );
        }
      },
      // Always refetch after error or success:
      onSettled: (newRealEstateProperty) => {
        if (newRealEstateProperty) {
          queryClient.invalidateQueries({
            queryKey: ["realEstateProperties", newRealEstateProperty.id],
          });
          queryClient.invalidateQueries({
            queryKey: ["realEstateProperties"],
          });
        }
      },
    });


    return (
      <div style={styles.detailViewContainer}>
        <h2>Real Estate Property Detail View</h2>
        {isErrorQuery && <div>{"Problem loading Real Estate Property"}</div>}
        {isLoading && (
          <div style={styles.loadingIndicator}>
            {"Loading Real Estate Property..."}
          </div>
        )}
        {isSuccess && (
          <div>
            <p>{`Name: ${realEstateProperty?.name}`}</p>
            <p>{`Address: ${realEstateProperty?.address}`}</p>
          </div>
        )}
        {realEstateProperty && (
          <div>
            <div>
              {updateMutation.isPending ? (
                "Updating Real Estate Property..."
              ) : (
                <>
                  {updateMutation.isError &&
                    updateMutation.error instanceof Error ? (
                    <div>An error occurred: {updateMutation.error.message}</div>
                  ) : null}


                  {updateMutation.isSuccess ? (
                    <div>Real Estate Property updated!</div>
                  ) : null}


                  <button
                    onClick={() =>
                      updateMutation.mutate({
                        id: realEstateProperty.id,
                        name: `Updated Home ${Date.now()}`,
                      })
                    }
                  >
                    Update Name
                  </button>
                  <button
                    onClick={() =>
                      updateMutation.mutate({
                        id: realEstateProperty.id,
                        address: `${Math.floor(
                          1000 + Math.random() * 9000
                        )} Main St`,
                      })
                    }
                  >
                    Update Address
                  </button>
                </>
              )}
            </div>


            <div>
              {deleteMutation.isPending ? (
                "Deleting Real Estate Property..."
              ) : (
                <>
                  {deleteMutation.isError &&
                    deleteMutation.error instanceof Error ? (
                    <div>An error occurred: {deleteMutation.error.message}</div>
                  ) : null}


                  {deleteMutation.isSuccess ? (
                    <div>Real Estate Property deleted!</div>
                  ) : null}


                  <button
                    onClick={() =>
                      deleteMutation.mutate({
                        id: realEstateProperty.id,
                      })
                    }
                  >
                    Delete
                  </button>
                </>
              )}
            </div>
          </div>
        )}
        <button onClick={() => setCurrentRealEstatePropertyId(null)}>
          Back
        </button>
      </div>
    );




  }
  return (
    <div>
      {!currentRealEstatePropertyId && (
        <div style={styles.appContainer}>
          <h1>Real Estate Properties:</h1>
          <div>
            {createMutation.isPending ? (
              "Adding Real Estate Property..."
            ) : (
              <>
                {createMutation.isError &&
                createMutation.error instanceof Error ? (
                  <div>An error occurred: {createMutation.error.message}</div>
                ) : null}


                {createMutation.isSuccess ? (
                  <div>Real Estate Property added!</div>
                ) : null}


                <button
                  onClick={() => {
                    createMutation.mutate({
                      name: `New Home ${Date.now()}`,
                      address: `${Math.floor(
                        1000 + Math.random() * 9000
                      )} Main St`,
                    });
                  }}
                >
                  Add RealEstateProperty
                </button>
              </>
            )}
          </div>
          <ul style={styles.propertiesList}>
            {isLoading && (
              <div style={styles.loadingIndicator}>
                {"Loading Real Estate Properties..."}
              </div>
            )}
            {isErrorQuery && (
              <div>{"Problem loading Real Estate Properties"}</div>
            )}
            {isSuccess &&
              realEstateProperties?.map((realEstateProperty, idx) => {
                if (!realEstateProperty) return null;
                return (
                  <li
                    style={styles.listItem}
                    key={`${idx}-${realEstateProperty.id}`}
                  >
                    <p>{realEstateProperty.name}</p>
                    <button
                      style={styles.detailViewButton}
                      onClick={() =>
                        setCurrentRealEstatePropertyId(realEstateProperty.id)
                      }
                    >
                      Detail View
                    </button>
                  </li>
                );
              })}
          </ul>
        </div>
      )}
      {currentRealEstatePropertyId && <RealEstatePropertyDetailView />}
      <GlobalLoadingIndicator />
    </div>
  );


}


export default App


const styles = {
  appContainer: {
    display: "flex",
    flexDirection: "column",
    alignItems: "center",
  },
  detailViewButton: { marginLeft: "1rem" },
  detailViewContainer: { border: "1px solid black", padding: "3rem" },
  globalLoadingIndicator: {
    position: "fixed",
    top: 0,
    left: 0,
    width: "100%",
    height: "100%",
    border: "4px solid blue",
    pointerEvents: "none",
  },
  listItem: {
    display: "flex",
    justifyContent: "space-between",
    border: "1px dotted grey",
    padding: ".5rem",
    margin: ".1rem",
  },
  loadingIndicator: {
    border: "1px solid black",
    padding: "1rem",
    margin: "1rem",
  },
  propertiesList: {
    display: "flex",
    flexDirection: "column",
    alignItems: "center",
    justifyContent: "start",
    width: "50%",
    border: "1px solid black",
    padding: "1rem",
    listStyleType: "none",
  },
} as const;
PREVIOUS
Connect to data from Server-side Runtimes
NEXT
Modify Amplify-generated AWS resources

--------------------------------------------------------------------------------

Title: Manage Data with Amplify console - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/manage-with-amplify-console/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Manage Data with Amplify console
Manage Data with Amplify console

The Data manager page in the Amplify Console offers a user-friendly interface for managing the backend GraphQL API data of an application. It enables real-time creation and updates of application data, eliminating the need to build separate admin views.

If you have not yet created a data resource, visit the Data setup guide.

Access Data manager

After you've deployed your data resource, you can access the manager on Amplify console.

Log in to the Amplify console and choose your app.
Select the branch you would like to access.
Select Data from the left navigation bar.
Then, select Data manager.
To create a record
On the Data manager page, select a table from the Select table dropdown. For this example, we are using a Todo table.
Select Create Todo.
In the Add Todo pane, specify your custom values for the fields in the table. For example, enter my first todo for the Content field and toggle the Is done field.
Select Submit.
To update a record
On the Data manager page, select a table from the Select table dropdown.
From the list of records, select a record you want to update.
In the Edit Todo pane, make any changes to your record, and then select Submit.
To delete a record(s)
On the Data manager page, select a table from the Select table dropdown.
From the list of records, select the checkbox to the left of the record(s) you want to delete.
Select the Actions dropdown, and then select delete item(s) .
To Seed records
On the Data manager page, select a table from the Select table dropdown.
Select the Actions dropdown and then select Auto-generate data.
In the Auto-generate data pane, specify how many rows of data you want to generate and constraints for the generated data.
Then select Generate data

You can generate up to 100 records at a time.

Seed data cannot be generated for tables that have the following field types: AWSPhone, Enum, Custom Type, or Relationship

To download records
On the Data manager page, select a table from the Select table dropdown.
Select the Actions dropdown.
Here you have two options for downloading data.
Choose Download selected items (.csv) to download only the selected rows of data.
Choose Download all items (.csv) to download all rows of records on the currently selected table.
Once you have selected a download option, your data should immediately start downloading as a CSV file.
PREVIOUS
Modify Amplify-generated AWS resources

--------------------------------------------------------------------------------

Title: Modify Amplify-generated AWS resources - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/override-resources/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Modify Amplify-generated AWS resources
Modify Amplify-generated AWS resources

Amplify GraphQL API uses a variety of auto-generated, underlying AWS services and resources. You can customize these underlying resources to optimize the deployed stack for your specific use case.

In your Amplify app, you can access every underlying resource using CDK "L2" or "L1" constructs. Access the generated resources as L2 constructs via the .resources property on the returned stack or access the generated resources as L1 constructs using the .resources.cfnResources property.

Copy
code example
import { defineBackend } from '@aws-amplify/backend';
import { data } from './data/resource';


const backend = defineBackend({
  data
});


const dataResources = backend.data.resources;


Object.values(dataResources.cfnResources.amplifyDynamoDbTables).forEach((table) => {
  table.pointInTimeRecoveryEnabled = true;
});
Customize Amplify-generated AppSync GraphQL API resources

Apply all the customizations on backend.data.resources.graphqlApi or backend.data.resources.cfnResources.cfnGraphqlApi. For example, to enable X-Ray tracing for the AppSync GraphQL API:

Copy
code example
import { defineBackend } from '@aws-amplify/backend';
import { data } from './data/resource';


const backend = defineBackend({
  data
});


const dataResources = backend.data.resources;


dataResources.cfnResources.cfnGraphqlApi.xrayEnabled = true;
Customize Amplify-generated resources for data models

Pass in the model type name into backend.data.resources.amplifyDynamoDbTables["MODEL_NAME"] to modify the resources generated for that particular model type. For example, to enable time-to-live on the Todo @model type's DynamoDB table:

Copy
code example
import { defineBackend } from '@aws-amplify/backend';
import { data } from './data/resource';


const backend = defineBackend({
  data
});


const dataResources = backend.data.resources;


dataResources.cfnResources.amplifyDynamoDbTables["Todo"].timeToLiveAttribute = {
  attributeName: "ttl",
  enabled: true,
};
Example - Configure billing mode on a DynamoDB table

Set the DynamoDB billing mode for the DynamoDB table as either "PROVISIONED" or "PAY_PER_REQUEST".

Copy
code example
import { defineBackend } from '@aws-amplify/backend';
import { data } from './data/resource';
import { BillingMode } from "aws-cdk-lib/aws-dynamodb";


const backend = defineBackend({
  data
});
const dataResources = backend.data.resources;


dataResources.cfnResources.amplifyDynamoDbTables['Todo'].billingMode = BillingMode.PAY_PER_REQUEST;
Example - Configure provisioned throughput for a DynamoDB table

Override the default ProvisionedThroughput provisioned for each model table and its Global Secondary Indexes (GSI). This override is only valid if the "DynamoDBBillingMode" is set to "PROVISIONED".

Copy
code example
import { defineBackend } from '@aws-amplify/backend';
import { data } from './data/resource';


const backend = defineBackend({
  data
});


const dataResources = backend.data.resources;


dataResources.cfnResources.amplifyDynamoDbTables["Todo"].provisionedThroughput = {
  readCapacityUnits: 5,
  writeCapacityUnits: 5,
};
Example - Enable point-in-time recovery for a DynamoDB table

Enable/disable DynamoDB point-in-time recovery for each model table.

Copy
code example
import { defineBackend } from '@aws-amplify/backend';
import { data } from './data/resource';


const backend = defineBackend({
  data
});


const dataResources = backend.data.resources;


dataResources.cfnResources.amplifyDynamoDbTables['Todo'].pointInTimeRecoveryEnabled = true;
PREVIOUS
Optimistic UI
NEXT
Manage Data with Amplify console

--------------------------------------------------------------------------------

Title: Next.js server runtime - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/connect-from-server-runtime/nextjs-server-runtime/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Connect to data from Server-side Runtimes
/
Next.js server runtime
Next.js server runtime

This guide walks through how you can connect to Amplify Data from Next.js Server-side Runtimes (SSR). For Next.js applications, Amplify provides first-class support for the App Router (React Server Components, Route Handlers, and Server Actions), the Pages Router (Components, API Routes), and Middleware.

Before you begin, you will need:

A Next.js application created
Installed and configured Amplify libraries for Next.js
Deployed Amplify Data resources, or directly using AWS AppSync
Connect to Amplify Data from a Next.js server runtime

Connecting to Amplify Data will include choosing the correct data client for Next.js server runtimes, generating the data client, and then calling the API.

Step 1 - Choose the correct Data client for Next.js server runtimes

Amplify offers two specialized data clients for Next.js server runtimes (from @aws-amplify/adapter-nextjs/data) that you should use depending whether you retrieve the user tokens using cookies or NextRequest and NextResponse:

generateServerClientUsingCookies() 🍪 generates a data client with the Next.js cookies function from next/headers. Each API request dynamically refetches the cookies at runtime.
generateServerClientUsingReqRes() 🌐 generates a data client requiring NextRequest and NextResponse provided to an runWithAmplifyServerContext function to prevent token contamination.

Choose the correct data client based on your Next.js Router (App or Pages) and then the use case:

App Router
Pages Router
Use case	Required Data client
React Server Component	generateServerClientUsingCookies() 🍪
Server Actions	generateServerClientUsingCookies() 🍪
Route Handler	generateServerClientUsingCookies() 🍪
Middleware	generateServerClientUsingReqRes() 🌐
Step 2 - Generate the Data client for Next.js server runtimes
generateServerClientUsingCookies() 🍪
generateServerClientUsingReqRes() 🌐

To generate a Data client for the Next.js server runtime using cookies, you need to provide both your Amplify configuration and the cookies function from Next.js.

Copy
code example
import { type Schema } from '@/amplify/data/resource';
import { generateServerClientUsingCookies } from '@aws-amplify/adapter-nextjs/data';
import outputs from '@/amplify_outputs.json';
import { cookies } from 'next/headers';


export const cookieBasedClient = generateServerClientUsingCookies<Schema>({
  config: outputs,
  cookies,
});

We recommend you generate Amplify Data's server client in a utility file. Then, import the generated client in your Next.js React Server Components, Server Actions, or Route Handlers.

Step 3 - Call API using generated server Data clients

You can make any available query or mutation request with the generated server data clients; however, note that subscriptions are not available within server runtimes.

generateServerClientUsingCookies() 🍪
generateServerClientUsingReqRes() 🌐

Import the cookie-based server Data client in your Next.js React Server Component code and make your API requests.

Copy
code example
import { type Schema } from '@/amplify/data/resource';
import { generateServerClientUsingCookies } from '@aws-amplify/adapter-nextjs/data';
import outputs from '@/amplify_outputs.json';
import { cookies } from 'next/headers';


export const cookieBasedClient = generateServerClientUsingCookies<Schema>({
  config: outputs,
  cookies,
});


const fetchTodos = async () => {
  const { data: todos, errors } = await cookieBasedClient.models.Todo.list();


  if (!errors) {
    return todos;
  }
};
NEXT
Nuxt.js server runtime

--------------------------------------------------------------------------------

Title: Connect to external Amazon DynamoDB data sources - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/connect-to-existing-data-sources/connect-external-ddb-table/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Connect to existing data sources
/
Connect to external Amazon DynamoDB data sources
Connect to external Amazon DynamoDB data sources

The a.model() data model allows you to define a GraphQL schema for an AWS AppSync API where models are backed by DynamoDB Tables managed by Amplify. The generated schema also provides queries and mutations to the Amplify Data client. However, you may want to connect to an external DynamoDB table and execute custom business logic against it instead.

Using an external DynamoDB table as a data source may be useful if you need to leverage patterns such as single table design.

In the following sections, we walk through the steps to add and use an external DynamoDB table as a data source for your API:

Set up your Amazon DynamoDB table
Add your Amazon DynamoDB table as a data source
Define custom queries and mutations
Configure custom business logic handler code
Invoke custom queries or mutations
Step 1 - Set up your Amazon DynamoDB table

For the purpose of this guide we will define a Post type and create an external DynamoDB table that will store records for it. In Amplify Gen 2, customType adds a type to the schema that is not backed by an Amplify-generated DynamoDB table.

With the Post type defined, it can then be referenced as the return type when defining your custom queries and mutations.

First, add the Post custom type to your schema:

amplify/data/resource.ts
import { type ClientSchema, a, defineData } from "@aws-amplify/backend";


const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
    })
    .authorization(allow => [allow.publicApiKey()]),
Copy
highlighted code example
  Post: a.customType({
    id: a.id().required(),
    author: a.string().required(),
    title: a.string(),
    content: a.string(),
    url: a.string(),
    ups: a.integer(),
    downs: a.integer(),
    version: a.integer(),
  }),
});


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: 'apiKey',
    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});

NOTE: To comply with the GraphQL spec, at least one query is required for a schema to be valid. Otherwise, deployments will fail with a schema error. The Amplify Data schema is auto-generated with a Todo model and corresponding queries under the hood. You can leave the Todo model in the schema until you add the first custom query to the schema in the next steps.

Once the deployment successfully completes, navigate to the AppSync console and select your Amplify-generated API. Follow these steps to create a new DynamoDB table:

On the Schema page, choose Create Resources.

Choose Use existing type, then choose the Post type.

Set the Primary key to id and the Sort key to None.

Disable Automatically generate GraphQL. In this example, we'll create the resolver ourselves.

Choose Create.

You now have a new DynamoDB table named PostTable, which you can see by visiting Data sources in the side tab. You will use this table as the data source for your custom queries and mutations to your Amazon DynamoDB table.

Step 2 - Add your Amazon DynamoDB table as a data source

In your amplify/backend.ts file, add your DynamoDB table as a data source for your API:

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import { aws_dynamodb } from "aws-cdk-lib";


export const backend = defineBackend({
  auth,
  data,
});


Copy
highlighted code example
const externalDataSourcesStack = backend.createStack("MyExternalDataSources");


const externalTable = aws_dynamodb.Table.fromTableName(
  externalDataSourcesStack,
  "MyExternalPostTable",
  "PostTable"
);


backend.data.addDynamoDbDataSource(
  "ExternalPostTableDataSource",
  externalTable
);
Step 3 - Define custom queries and mutations

Now that your DynamoDB table has been added as a data source, you can reference it in custom queries and mutations using the a.handler.custom() modifier which accepts the name of the data source and an entry point for your resolvers.

Use the following code examples to add addPost, getPost, updatePost, and deletePost as custom queries and mutations to your schema:

addPost
getPost
updatePost
deletePost
amplify/data/resource.ts
import { type ClientSchema, a, defineData } from "@aws-amplify/backend";


const schema = a.schema({
  Post: a.customType({
    author: a.string().required(),
    title: a.string(),
    content: a.string(),
    url: a.string(),
    ups: a.integer(),
    downs: a.integer(),
    version: a.integer(),
  }),
Copy
highlighted code example
  addPost: a
    .mutation()
    .arguments({
      id: a.id(),
      author: a.string().required(),
      title: a.string(),
      content: a.string(),
      url: a.string(),
    })
    .returns(a.ref("Post"))
    .authorization(allow => [allow.publicApiKey()])
    .handler(
      a.handler.custom({
        dataSource: "ExternalPostTableDataSource",
        entry: "./addPost.js",
      })
    ),
});


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: 'apiKey',
    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});
Step 4 - Configure custom business logic handler code

Next, create the following files in your amplify/data folder and use the code examples to define custom resolvers for the custom queries and mutations added to your schema from the previous step. These are AppSync JavaScript resolvers

addPost
getPost
updatePost
deletePost
amplify/data/addPost.js
Copy
amplify/data/addPost.js code example
import { util } from "@aws-appsync/utils";
import * as ddb from "@aws-appsync/utils/dynamodb";


export function request(ctx) {
  const item = { ...ctx.arguments, ups: 1, downs: 0, version: 1 };
  const key = { id: ctx.args.id ?? util.autoId() };
  return ddb.put({ key, item });
}


export function response(ctx) {
  return ctx.result;
}
Step 5 - Invoke custom queries or mutations

From your generated Data client, you can find all your custom queries and mutations under the client.queries. and client.mutations. APIs respectively.

addPost
getPost
updatePost
deletePost
App.tsx
Copy
App.tsx code example
const { data, errors } = await client.mutations.addPost({
  title: "My Post",
  content: "My Content",
  author: "Chris",
});
Conclusion

In this guide, you’ve added an external DynamoDB table as a data source to an Amplify GraphQL API and defined custom queries and mutations, handled by AppSync JS resolvers, to manipulate Post items in an external DynamoDB table using the Amplify Gen 2 Data client.

To clean up, you can delete your sandbox by accepting the prompt when terminating the sandbox process in your terminal. Alternatively, you can also use the AWS Amplify console to manage and delete sandbox environments.

To delete your external DynamoDB table, you can navigate to the AppSync console and click on the name of the table in the data sources list. This takes you to the DynamoDB console where you can delete the table.

All DynamoDB operations & example resolvers
GetItem

Reference - The GetItem request lets you tell the AWS AppSync DynamoDB function to make a GetItem request to DynamoDB, and enables you to specify:

The key of the item in DynamoDB

Whether to use a consistent read or not

Example:

Copy
code example
export function request(ctx) {
  const {foo, bar} = ctx.args
  return {
    operation : "GetItem",
    key : util.dynamodb.toMapValues({foo, bar}),
    consistentRead : true
  }
}
PutItem

PutItem - The PutItem request mapping document lets you tell the AWS AppSync DynamoDB function to make a PutItem request to DynamoDB, and enables you to specify the following:

The key of the item in DynamoDB

The full contents of the item (composed of key and attributeValues)

Conditions for the operation to succeed

Example:

Copy
code example
import { util } from '@aws-appsync/utils';
export function request(ctx) {
  const { foo, bar, ...values} = ctx.args
  return {
    operation: 'PutItem',
    key: util.dynamodb.toMapValues({foo, bar}),
    attributeValues: util.dynamodb.toMapValues(values),
  };
}
UpdateItem

UpdateItem - The UpdateItem request enables you to tell the AWS AppSync DynamoDB function to make a UpdateItem request to DynamoDB and allows you to specify the following:

The key of the item in DynamoDB

An update expression describing how to update the item in DynamoDB

Conditions for the operation to succeed

Example:

Copy
code example
import { util } from '@aws-appsync/utils';
export function request(ctx) {
  const { id } = ctx.args;
  return {
    operation: 'UpdateItem',
    key: util.dynamodb.toMapValues({ id }),
    update: {
      expression: 'ADD #voteField :plusOne, version :plusOne',
      expressionNames: { '#voteField': 'upvotes' },
      expressionValues: { ':plusOne': { N: 1 } },
    },
  };
}
DeleteItem

DeleteItem - The DeleteItem request lets you tell the AWS AppSync DynamoDB function to make a DeleteItem request to DynamoDB, and enables you to specify the following:

The key of the item in DynamoDB

Conditions for the operation to succeed

Example:

Copy
code example
import { util } from '@aws-appsync/utils';
export function request(ctx) {
  return {
    operation: 'DeleteItem',
    key: util.dynamodb.toMapValues({ id: ctx.args.id }),
  };
}
Query

Query - The Query request object lets you tell the AWS AppSync DynamoDB resolver to make a Query request to DynamoDB, and enables you to specify the following:

Key expression

Which index to use

Any additional filter

How many items to return

Whether to use consistent reads

query direction (forward or backward)

Pagination token

Example:

Copy
code example
import { util } from '@aws-appsync/utils';


export function request(ctx) {
  const { owner } = ctx.args;
  return {
    operation: 'Query',
    query: {
      expression: 'ownerId = :ownerId',
      expressionValues: util.dynamodb.toMapValues({ ':ownerId': owner }),
    },
    index: 'owner-index',
  };
}
Scan

Scan - The Scan request lets you tell the AWS AppSync DynamoDB function to make a Scan request to DynamoDB, and enables you to specify the following:

A filter to exclude results

Which index to use

How many items to return

Whether to use consistent reads

Pagination token

Parallel scans

Example:

Copy
code example
export function request(ctx) {
  return { operation: 'Scan' };
}
Sync

Sync - The Sync request object lets you retrieve all the results from a DynamoDB table and then receive only the data altered since your last query (the delta updates). Sync requests can only be made to versioned DynamoDB data sources. You can specify the following:

A filter to exclude results

How many items to return

Pagination Token

When your last Sync operation was started

Example:

Copy
code example
export function request(ctx) {
  const { nextToken, lastSync } = ctx.args;
  return { operation: 'Sync', limit: 100, nextToken, lastSync };
}
BatchGetItem

BatchGetItem - The BatchGetItem request object lets you tell the AWS AppSync DynamoDB function to make a BatchGetItem request to DynamoDB to retrieve multiple items, potentially across multiple tables. For this request object, you must specify the following:

The table names where to retrieve the items from

The keys of the items to retrieve from each table

The DynamoDB BatchGetItem limits apply and no condition expression can be provided.

Example:

Copy
code example
import { util } from '@aws-appsync/utils';


export function request(ctx) {
  const { authorId, postId } = ctx.args;
  return {
    operation: 'BatchGetItem',
    tables: {
      authors: [util.dynamodb.toMapValues({ authorId })],
      posts: [util.dynamodb.toMapValues({ authorId, postId })],
    },
  };
}
BatchDeleteItem

BatchDeleteItem - The BatchDeleteItem request object lets you tell the AWS AppSync DynamoDB function to make a BatchWriteItem request to DynamoDB to delete multiple items, potentially across multiple tables. For this request object, you must specify the following:

The table names where to delete the items from

The keys of the items to delete from each table

The DynamoDB BatchWriteItem limits apply and no condition expression can be provided.

Example:

Copy
code example
import { util } from '@aws-appsync/utils';


export function request(ctx) {
  const { authorId, postId } = ctx.args;
  return {
    operation: 'BatchDeleteItem',
    tables: {
      authors: [util.dynamodb.toMapValues({ authorId })],
      posts: [util.dynamodb.toMapValues({ authorId, postId })],
    },
  };
}
BatchPutItem

BatchPutItem - The BatchPutItem request object lets you tell the AWS AppSync DynamoDB function to make a BatchWriteItem request to DynamoDB to put multiple items, potentially across multiple tables. For this request object, you must specify the following:

The table names where to put the items in

The full items to put in each table

The DynamoDB BatchWriteItem limits apply and no condition expression can be provided.

Example:

Copy
code example
import { util } from '@aws-appsync/utils';


export function request(ctx) {
  const { authorId, postId, name, title } = ctx.args;
  return {
    operation: 'BatchPutItem',
    tables: {
      authors: [util.dynamodb.toMapValues({ authorId, name })],
      posts: [util.dynamodb.toMapValues({ authorId, postId, title })],
    },
  };
}
TransactGetItems

TransactGetItems - The TransactGetItems request object lets you to tell the AWS AppSync DynamoDB function to make a TransactGetItems request to DynamoDB to retrieve multiple items, potentially across multiple tables. For this request object, you must specify the following:

The table name of each request item where to retrieve the item from

The key of each request item to retrieve from each table

The DynamoDB TransactGetItems limits apply and no condition expression can be provided.

Example:

Copy
code example
import { util } from '@aws-appsync/utils';


export function request(ctx) {
  const { authorId, postId } = ctx.args;
  return {
    operation: 'TransactGetItems',
    transactItems: [
      {
        table: 'posts',
        key: util.dynamodb.toMapValues({ postId }),
      },
      {
        table: 'authors',
        key: util.dynamodb.toMapValues({ authorId }),
      },
    ],
  };
}
TransactWriteItems

TransactWriteItems - The TransactWriteItems request object lets you tell the AWS AppSync DynamoDB function to make a TransactWriteItems request to DynamoDB to write multiple items, potentially to multiple tables. For this request object, you must specify the following:

The destination table name of each request item

The operation of each request item to perform. There are four types of operations that are supported: PutItem, UpdateItem, DeleteItem, and ConditionCheck

The key of each request item to write

The DynamoDB TransactWriteItems limits apply.

Example:

Copy
code example
import { util } from '@aws-appsync/utils';


export function request(ctx) {
  const { authorId, postId, title, description, oldTitle, authorName } = ctx.args;
  return {
    operation: 'TransactWriteItems',
    transactItems: [
      {
        table: 'posts',
        operation: 'PutItem',
        key: util.dynamodb.toMapValues({ postId }),
        attributeValues: util.dynamodb.toMapValues({ title, description }),
        condition: util.transform.toDynamoDBConditionExpression({
          title: { eq: oldTitle },
        }),
      },
      {
        table: 'authors',
        operation: 'UpdateItem',
        key: util.dynamodb.toMapValues({ authorId }),
        update: {
          expression: 'SET authorName = :name',
          expressionValues: util.dynamodb.toMapValues({ ':name': authorName }),
        },
      },
    ],
  };
}
PREVIOUS
Connect your app to existing MySQL and PostgreSQL database

--------------------------------------------------------------------------------

Title: Connect your app to existing MySQL and PostgreSQL database - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/connect-to-existing-data-sources/connect-postgres-mysql-database/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Connect to existing data sources
/
Connect your app to existing MySQL and PostgreSQL database
Connect your app to existing MySQL and PostgreSQL database

Amplify's native integration supports any MySQL or Postgres database, no matter if they're hosted on AWS within a VPC or outside of AWS with a 3rd party hosted database provider.

You must create a connection string using the following database information to get started:

Database hostname
Database port
Database username
Database user password
Database name

Only databases with certificates from well-known certificate providers are supported. Support for databases using custom or self-signed SSL certificates is under active development.

Amplify's MySQL and PostgreSQL feature builds on top of AWS Lambda with a Node.js runtime. By default, Node.js includes root certificate authority (CA) certificates from well-known certificate providers. Lambda Node.js runtimes up to Node.js 18 augments these certificates with Amazon-specific CA certificates, making it easier to create functions accessing other AWS services.

Step 1 - Set secrets for database connection

First, provide all the database connection information as secrets, you can use the Amplify sandbox's secret functionality to set them or go to the Amplify console to set secrets in a shared environment:

Copy
code example
npx ampx sandbox secret set SQL_CONNECTION_STRING
MySQL
PostgreSQL

Connection string format for MySQL

mysql://user:password@hostname:port/db-name
Step 2 - Generate TypeScript representation of your database schema

Run the following command to generate the Data schema with your database connection information. It'll infer an a.model() representation for all database tables that have primary key specified.

Copy
code example
npx ampx generate schema-from-database --connection-uri-secret SQL_CONNECTION_STRING --out amplify/data/schema.sql.ts
Info
Connecting to a database behind the VPC
Info
Handling of implicit fields (id, createdAt, updatedAt)
Learn more
RDS Proxy for improved connectivity

This creates a new schema.sql.ts with a schema reflecting the types of your database. Do not edit the schema.sql.ts file directly. Import the schema to your amplify/data/resource.ts file and apply any additive changes there. This ensures that you can continuously regenerate the TypeScript schema representation of your SQL database without losing any additive changes that you apply out-of-band.

import { type ClientSchema, a, defineData } from '@aws-amplify/backend';
Copy
highlighted code example
import { schema as generatedSqlSchema } from './schema.sql';


// Add a global authorization rule
const sqlSchema = generatedSqlSchema.authorization(allow => allow.guest())


// Relational database sources can coexist with DynamoDB tables managed by Amplify.
const schema = a.schema({
  Todo: a.model({
    content: a.string(),
  }).authorization(allow => [allow.guest()])
});


// Use the a.combine() operator to stitch together the models backed by DynamoDB
// and the models backed by Postgres or MySQL databases.
Copy
highlighted code example
const combinedSchema = a.combine([schema, sqlSchema]);


// Don't forget to update your client types to take into account the types from
// both schemas.
Copy
highlighted code example
export type Schema = ClientSchema<typeof combinedSchema>;


export const data = defineData({
  // Update the data definition to use the combined schema, instead of just
  // your DynamoDB-backed schema
Copy
highlighted code example
  schema: combinedSchema
});
Step 3 - Fine-grained authorization rules

Use the .setAuthorization() modifier to set model-level and field-level authorization rules for the SQL-backed data models. Review Customize your auth rules for detailed authorization rule options.

// Add an authorization rule to the schema
Copy
highlighted code example
const sqlSchema = generatedSqlSchema.setAuthorization((models) => [
  // Model-level authorization rules
  models.event.authorization((allow) => [allow.publicApiKey()]),
  // Field-level authorization rules
  models.event.fields.id.authorization(allow => [allow.publicApiKey(), allow.guest()]),
  models.event.fields.created_at.authorization(allow => [allow.publicApiKey(), allow.guest()])
]);
Step 4 - Deploy your Data resources using the cloud sandbox

Finally, you can now validate your Data resources with your cloud sandbox:

Copy
code example
npx ampx sandbox

On the client side, you can now make create, read, update, delete, and subscribe to your SQL-backed data models:

Copy
code example
const { data: events } = await client.models.event.list()
Step 5 - Configuring database connection for production

When deploying your app to production, you need to add the database connection string as a secret. Make sure to add the appropriate database connection string with the same secret name you used in the sandbox environment. For example, we used SQL_CONNECTION_STRING above.

Rename generated models and fields

To improve the ergonomics of your API, you might want to rename the generate fields or types to better accommodate your use case. Use the renameModels() and renameModelFields() modifiers to rename the auto-inferred data models and their fields.

// Rename models or fields to be more idiomatic for frontend code
const sqlSchema = generatedSqlSchema.authorization(allow => allow.guest())
Copy
highlighted code example
  .renameModels(() => [
    //⌄⌄⌄⌄⌄ existing model name based on table name
    ['event', 'Event']
    //        ^^^^^^ renamed data model name
  ])
Add relationships between tables
const sqlSchema = generatedSqlSchema
  .authorization(allow => allow.guest())
Copy
highlighted code example
  .setRelationships((models) => [
    models.Note.relationships({
      comments: a.hasMany("Comment", "note_id"),
    }),
    models.Comment.relationships({
      note: a.belongsTo("Note", "note_id")
    })
  ]);
Add custom queries, mutations, subscriptions auto-generated SQL data schema

Use the .addToSchema(...) to add in additional queries, mutations, and subscriptions to your auto-generated SQL data schema.

Note: you can't add additional data models via a.model(). They should be exclusively generated via npx ampx generate schema-from-database.

Use an inline SQL statement as a query or mutation handler
// Add custom mutations or queries that execute SQL statements
const sqlSchema = generatedSqlSchema.authorization(allow => allow.guest())
Copy
highlighted code example
  .addToSchema({
    listEventsWithDecodedLatLong: a.query()
      // reference custom types added to the schema
      .returns(a.ref("EventWithDecodedCoord").array())
      .handler(a.handler.inlineSql(
          `SELECT
            id,
            name,
            address,
            ST_X(geom) AS longitude,
            ST_Y(geom) AS latitude
          FROM locations;`
      ))
      .authorization(allow => [allow.guest()]),


      // Define custom types to provide end-to-end typed results
      // for custom queries / mutations
      EventWithDecodedCoord: a.customType({
        id: a.integer(),
        name: a.string(),
        address: a.string(),
        longitude: a.float(),
        latitude: a.float(),
      })
  })
Reference an existing SQL file as a query or mutation handler

You can define the different SQL handlers in separate .sql files and reference them in your custom queries / mutations.

First, configure the custom query or mutation in your amplify/data/resource.ts file:

const sqlSchema = generatedSqlSchema.authorization(allow => allow.guest())
  .addToSchema({
    createNewLocationWithLongLat: a.mutation()
      .arguments({
        lat: a.float().required(),
        long: a.float().required(),
        name: a.string().required(),
        address: a.string().required()
      })
      .returns(a.json().array())
      .authorization(allow => allow.authenticated())
Copy
highlighted code example
      .handler(a.handler.sqlReference('./createNewLocationWithLongLat.sql'))
  })

Next, add a corresponding sql file to handle the request:

MySQL
PostgreSQL
createNewLocationWithLongLat.sql
Copy
createNewLocationWithLongLat.sql code example
INSERT INTO locations (name, address, geom)
VALUES (:name, :address, ST_GEOMFROMTEXT(CONCAT('POINT (', :long, ' ', :lat, ')'), 4326));

The return type for custom queries and mutations expecting to return row data from SQL statements must be an array of the corresponding model. This is true even for custom get queries, where a single row is expected.

Example

getPostBySlug: a
  .query()
  .arguments({
    slug: a.string().required(),
  })
Copy
highlighted code example
  .returns(a.ref("Post").array())
  .handler(
    a.handler.inlineSql(`
    SELECT id, title, slug, content, created_at, updated_at
    FROM posts
    WHERE slug = :slug;
    `)
  )
How does it work?

The Amplify uses AWS Lambda functions to enable features like querying data from your database. To work properly, these Lambda functions need access to common logic and dependencies.

Amplify provides this shared code in the form of Lambda Layers. You can think of Lambda Layers as a package of reusable runtime code that Lambda functions can reference.

When you deploy an Amplify API, it will create two Lambda functions:

SQL Lambda

This allows you to query and write data to your database from your API.

NOTE: If the database is in a VPC, this Lambda function will be deployed in the same VPC as the database. The usage of Amazon Virtual Private Cloud (VPC) or VPC peering, with AWS Lambda functions will incur additional charges as explained, this comes with an additional cost as explained on the Amazon Elastic Compute Cloud (EC2) on-demand pricing page.

Updater Lambda

This automatically keeps the SQL Lambda up-to-date by managing its Lambda Layers.

A Lambda layer that includes all the core SQL connection logic lives within the AWS Amplify service account but is executed within your AWS account, when invoked by the SQL Lambda. This allows the Amplify service team to own the ongoing maintenance and security enhancements of the SQL connection logic.

This allows the Amplify team to maintain and enhance the SQL Layer without needing direct access to your Lambdas. If updates to the Layer are needed, the Updater Lambda will receive a signal from Amplify and automatically update the SQL Lambda with the latest Layer.

Mapping of SQL data types to field types for auto-generated schema

Note: MySQL does not support time zone offsets in date time or timestamp fields. Instead, we will convert these values to datetime, without the offset. Unlike MySQL, PostgreSQL does support date time or timestamp values with an offset.

SQL	Mapped field types
String	
char	a.string()
varchar	a.string()
tinytext	a.string()
text	a.string()
mediumtext	a.string()
longtext	a.string()
Geometry	
geometry	a.string()
point	a.string()
linestring	a.string()
geometryCollection	a.string()
Numeric	
smallint	a.integer()
mediumint	a.integer()
int	a.integer()
integer	a.integer()
bigint	a.integer()
tinyint	a.integer()
float	a.float()
double	a.float()
decimal	a.float()
dec	a.float()
numeric	a.float()
Date and Time	
date	a.date()
datetime	a.datetime()
timestamp	a.datetime()
time	a.time()
year	a.integer()
Binary	
binary	a.string()
varbinary	a.string()
tinyblob	a.string()
blob	a.string()
mediumblob	a.string()
longblob	a.string()
Others	
bool	a.boolean()
boolean	a.boolean()
bit	a.integer()
json	a.json()
enum	a.enum()
Troubleshooting
Debug Mode

To return the actual SQL error instead of a generic error from underlying API responses, an environment variable DEBUG_MODE can be set to true on the Amplify-generated SQL Lambda function. You can find this Lambda function in the AWS Lambda console with the naming convention of: <stack-name>-<api-name>-SQLLambdaFunction<hash>.

My SQL table doesn't get generated when running npx ampx generate schema-from-database

This is likely because the table doesn't have a designated primary key. A primary key is required for npx ampx generate schema-from-database to infer the table structure and create a create, read, update, and delete API.

NEXT
Connect to external Amazon DynamoDB data sources

--------------------------------------------------------------------------------

Title: Connect to data from Server-side Runtimes - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/connect-from-server-runtime/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Connect to data from Server-side Runtimes
Connect to data from Server-side Runtimes
Next.js server runtime
Connect to Amplify Data from Next.js Server-side Runtime (SSR).
Nuxt.js server runtime
Connect to Amplify Data from Nuxt.js Server-side Runtime (SSR).

--------------------------------------------------------------------------------

Title: Connect to existing data sources - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/connect-to-existing-data-sources/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Connect to existing data sources
Connect to existing data sources
Connect your app to existing MySQL and PostgreSQL database
Learn how to connect your app to existing MySQL and PostgreSQL database.
Connect to external Amazon DynamoDB data sources
Connect to external Amazon DynamoDB data sources with custom queries and mutations

--------------------------------------------------------------------------------

Title: Working with files/attachments - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/working-with-files/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Working with files/attachments
Working with files/attachments

The Storage and GraphQL API categories can be used together to associate a file, such as an image or video, with a particular record. For example, you might create a User model with a profile picture, or a Post model with an associated image. With Amplify's GraphQL API and Storage categories, you can reference the file within the model itself to create an association.

Set up the project

Set up your project by following the instructions in the Quickstart guide.

Define the model

Open amplify/data/resource.ts and add the following model as shown below:

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
import { type ClientSchema, a, defineData } from "@aws-amplify/backend";


const schema = a.schema({
  Song: a
    .model({
      id: a.id().required(),
      name: a.string().required(),
      coverArtPath: a.string(),
    })
    .authorization((allow) => [allow.publicApiKey()]),
});


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: "apiKey",


    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});
Setup the Storage

Next, Let's configure Storage and allow access to all authenticated(signed in) users of your application. create a file amplify/storage/resource.ts and add the following code,This will restrict file access to only the signed-in user.

amplify/storage/resource.ts
Copy
amplify/storage/resource.ts code example
import { defineStorage } from "@aws-amplify/backend";


export const storage = defineStorage({
  name: "amplify-gen2-files",
  access: (allow) => ({
    "images/*": [allow.authenticated.to(["read", "write", "delete"])],
  }),
});

Configure the storage in the amplify/backend.ts file as demonstrated below:

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import { storage } from "./storage/resource";


export const backend = defineBackend({
  auth,
  data,
  storage,
});
Configuring authorization

Your application needs authorization credentials for reading and writing to both Storage and the Data, except in the case where all data and files are intended to be publicly accessible.

The Storage and Data categories govern data access based on their own authorization patterns, meaning that it's necessary to configure appropriate auth roles for each individual category. Although both categories share the same access credentials set up through the Auth category, they work independently from one another. For instance, adding an allow.authenticated() to the Data does not guard against file access in the Storage category. Likewise, adding authorization rules to the Storage category does not guard against data access in the API.

When you configure Storage, Amplify will configure appropriate IAM policies on the bucket using a Cognito Identity Pool role. You will then have the option of adding CRUD (Create, Update, Read and Delete) based permissions as well, so that Authenticated and Guest users will be granted limited permissions within these levels. Even after adding this configuration, all Storage access is still guest by default. To guard against accidental public access, the Storage access levels must either be configured on the Storage object globally, or set within individual function calls. This guide uses the former approach, setting all Storage access to authenticated users.

The ability to independently configure authorization rules for each category allows for more granular control over data access, and adds greater flexibility. For scenarios where authorization patterns must be mixed and matched, configure the access level on individual Storage function calls. For example, you may want to use entity_id CRUD access on an individual Storage function call for files that should only be accessible by the owner (such as personal files), authenticated read access to allow all logged in users to view common files (such as images in a shared photo album), and guest read access to allow all users to view a file (such as a public profile picture).

For more details on how to configure Storage authorization levels, see the Storage documentation. For more on configuring Data authorization, see the API documentation.

Create a record with an associated file

You can create a record via the Amplify Data client, upload a file to Storage, and finally update the record to associate it with the uploaded file. Use the following example with the Amplify Data client and Amplify Storage library helpers, uploadData and getUrl, to create a record and associate it the file with the record.

The API record's id is prepended to the Storage file name to ensure uniqueness. If this is excluded, multiple API records could then be associated with the same file path unintentionally.

src/App.tsx
Copy
src/App.tsx code example
import { generateClient } from "aws-amplify/api";
import { uploadData, getUrl } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";


// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});


// Create the API record:
const response = await client.models.Song.create({
  name: `My first song`,
});


const song = response.data;


if (!song) return;


// Upload the Storage file:
const result = await uploadData({
  path: `images/${song.id}-${file.name}`,
  data: file,
  options: {
    contentType: "image/png", // contentType is optional
  },
}).result;


// Add the file association to the record:
const updateResponse = await client.models.Song.update({
  id: song.id,
  coverArtPath: result?.path,
});


const updatedSong = updateResponse.data;


setCurrentSong(updatedSong);


// If the record has no associated file, we can return early.
if (!updatedSong.coverArtPath) return;


// Retrieve the file's signed URL:
const signedURL = await getUrl({ path: updatedSong.coverArtPath });
Add or update a file for an associated record

To associate a file with a record, update the record with the path returned by the Storage upload. The following example uploads the file using Storage, updates the record with the file's path, then retrieves the signed URL to download the image. If an image is already associated with the record, this will update the record with the new image.

src/App.tsx
Copy
src/App.tsx code example
import { generateClient } from "aws-amplify/api";
import { uploadData, getUrl } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";


// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});


// Upload the Storage file:
const result = await uploadData({
  path: `images/${currentSong.id}-${file.name}`,
  data: file,
  options: {
    contentType: "image/png", // contentType is optional
  },
}).result;


// Add the file association to the record:
const response = await client.models.Song.update({
  id: currentSong.id,
  coverArtPath: result?.path,
});


const updatedSong = response.data;


setCurrentSong(updatedSong);


// If the record has no associated file, we can return early.
if (!updatedSong?.coverArtPath) return;


// Retrieve the file's signed URL:
const signedURL = await getUrl({ path: updatedSong.coverArtPath });
Query a record and retrieve the associated file

To retrieve the file associated with a record, first query the record, then use Storage to get the signed URL. The signed URL can then be used to download the file, display an image, etc:

src/App.tsx
Copy
src/App.tsx code example
import { generateClient } from "aws-amplify/api";
import { getUrl } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";


// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});


const response = await client.models.Song.get({
  id: currentSong.id,
});


const song = response.data;


// If the record has no associated file, we can return early.
if (!song?.coverArtPath) return;


// Retrieve the signed URL:
const signedURL = await getUrl({ path: song.coverArtPath });
Delete and remove files associated with API records

There are three common deletion workflows when working with Storage files and the GraphQL API:

Remove the file association, continue to persist both file and record.
Remove the record association and delete the file.
Delete both file and record.
Remove the file association, continue to persist both file and record

The following example removes the file association from the record, but does not delete the file from S3, nor the record from the database.

src/App.tsx
Copy
src/App.tsx code example
import { generateClient } from "aws-amplify/api";
import type { Schema } from "../amplify/data/resource";


// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});


const response = await client.models.Song.get({
  id: currentSong.id,
});


const song = response.data;


// If the record has no associated file, we can return early.
if (!song?.coverArtPath) return;


const updatedSong = await client.models.Song.update({
  id: song.id,
  coverArtPath: null,
});
Remove the record association and delete the file

The following example removes the file from the record, then deletes the file from S3:

src/App.tsx
Copy
src/App.tsx code example
import { generateClient } from "aws-amplify/api";
import { remove } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";


// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});
const response = await client.models.Song.get({
  id: currentSong.id,
});
const song = response?.data;


// If the record has no associated file, we can return early.
if (!song?.coverArtPath) return;


// Remove associated file from record
const updatedSong = await client.models.Song.update({
  id: song.id,
  coverArtPath: null,
});


// Delete the file from S3:
await remove({ path: song.coverArtPath });
Delete both file and record
src/App.tsx
Copy
src/App.tsx code example
import { generateClient } from "aws-amplify/api";
import { remove } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";


// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});
const response = await client.models.Song.get({
  id: currentSong.id,
});


const song = response.data;


// If the record has no associated file, we can return early.
if (!song?.coverArtPath) return;


await remove({ path: song.coverArtPath });


// Delete the record from the API:
await client.models.Song.delete({ id: song.id });
Working with multiple files

You may want to add multiple files to a single record, such as a user profile with multiple images. To do this, you can add a list of file keys to the record. The following example adds a list of file keys to a record:

GraphQL schema to associate a data model with multiple files

Add the following model in `amplify/data/resource.ts" file.

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
const schema = a.schema({
  PhotoAlbum: a
    .model({
      id: a.id().required(),
      name: a.string().required(),
      imagePaths: a.string().array(),
    })
    .authorization((allow) => [allow.publicApiKey()]),
});

CRUD operations when working with multiple files is the same as when working with a single file, with the exception that we are now working with a list of image keys, as opposed to a single image key.

Create a record with multiple associated files

First create a record via the GraphQL API, then upload the files to Storage, and finally add the associations between the record and files.

src/App.tsx
Copy
src/App.tsx code example
import { generateClient } from "aws-amplify/api";
import { uploadData, getUrl } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";


// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});


// Create the API record:
const response = await client.models.PhotoAlbum.create({
  name: `My first photoAlbum`,
});


const photoAlbum = response.data.createPhotoAlbum;


if (!photoAlbum) return;


// Upload all files to Storage:
const imagePaths = await Promise.all(
  Array.from(e.target.files).map(async (file) => {
    const result = await uploadData({
      path: `images/${photoAlbum.id}-${file.name}`,
      data: file,
      options: {
        contentType: "image/png", // contentType is optional
      },
    }).result;


    return result.path;
  })
);


const updatePhotoAlbumDetails = {
  id: photoAlbum.id,
  imagePaths: imagePaths,
};


// Add the file association to the record:
const updateResponse = await client.graphql({
  query: mutations.updatePhotoAlbum,
  variables: { input: updatePhotoAlbumDetails },
});


const updatedPhotoAlbum = updateResponse.data.updatePhotoAlbum;


// If the record has no associated file, we can return early.
if (!updatedPhotoAlbum.imageKeys?.length) return;


// Retrieve signed urls for all files:
const signedUrls = await Promise.all(
  updatedPhotoAlbum?.imagePaths.map(
    async (path) => await getUrl({ path: path! })
  )
);
Add new files to an associated record

To associate additional files with a record, update the record with the paths returned by the Storage uploads.

src/App.tsx
Copy
src/App.tsx code example
import { generateClient } from "aws-amplify/api";
import { uploadData, getUrl } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";


// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});


// Upload all files to Storage:
const newimagePaths = await Promise.all(
  Array.from(e.target.files).map(async (file) => {
    const result = await uploadData({
      path: `images/${currentPhotoAlbum.id}-${file.name}`,
      data: file,
      options: {
        contentType: "image/png", // contentType is optional
      },
    }).result;


    return result.path;
  })
);


// Query existing record to retrieve currently associated files:
const queriedResponse = await client.models.PhotoAlbum.get({
  id: currentPhotoAlbum.id,
});


const photoAlbum = queriedResponse.data;


if (!photoAlbum?.imagePaths) return;


// Merge existing and new file paths:
const updatedimagePaths = [...newimagePaths, ...photoAlbum.imagePaths];


// Update record with merged file associations:
const response = await client.models.PhotoAlbum.update({
  id: currentPhotoAlbum.id,
  imagePaths: updatedimagePaths,
});


const updatedPhotoAlbum = response.data;


// If the record has no associated file, we can return early.
if (!updatedPhotoAlbum?.imageKeys) return;


// Retrieve signed urls for merged image paths:
const signedUrls = await Promise.all(
  updatedPhotoAlbum?.imagePaths.map(
    async (path) => await getUrl({ path: path! })
  )
);
Update the file for an associated record

Updating a file for an associated record is the same as updating a file for a single file record, with the exception that you will need to update the list of file keys.

src/App.tsx
Copy
src/App.tsx code example
import { generateClient } from "aws-amplify/api";
import { uploadData, getUrl } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";


// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});


// Upload new file to Storage:
const result = await uploadData({
  path: `images/${currentPhotoAlbum.id}-${file.name}`,
  data: file,
  options: {
    contentType: "image/png", // contentType is optional
  },
}).result;


const newFilePath = result.path;


// Query existing record to retrieve currently associated files:
const queriedResponse = await client.models.PhotoAlbum.get({
  id: currentPhotoAlbum.id,
});


const photoAlbum = queriedResponse.data;


if (!photoAlbum?.imagePaths?.length) return;


// Retrieve last image path:
const [lastImagePath] = photoAlbum.imagePaths.slice(-1);


// Remove last file association by path
const updatedimagePaths = [
  ...photoAlbum.imagePaths.filter((path) => path !== lastImagePath),
  newFilePath,
];


// Update record with updated file associations:
const response = await client.models.PhotoAlbum.update({
  id: currentPhotoAlbum.id,
  imagePaths: updatedimagePaths,
});


const updatedPhotoAlbum = response.data;


// If the record has no associated file, we can return early.
if (!updatedPhotoAlbum?.imagePaths) return;


// Retrieve signed urls for merged image paths:
const signedUrls = await Promise.all(
  updatedPhotoAlbum?.imagePaths.map(
    async (path) => await getUrl({ path: path! })
  )
);
Query a record and retrieve the associated files

To retrieve the files associated with a record, first query the record, then use Storage to retrieve all of the signed URLs.

src/App.tsx
Copy
src/App.tsx code example
async function getImagesForPhotoAlbum() {
import { generateClient } from "aws-amplify/api";
import { uploadData, getUrl } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";


// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});


// Query the record to get the file paths:
const response = await client.models.PhotoAlbum.get({
  id: currentPhotoAlbum.id,
});


const photoAlbum = response.data;


// If the record has no associated files, we can return early.
if (!photoAlbum?.imagePaths) return;


// Retrieve the signed URLs for the associated images:
const signedUrls = await Promise.all(
  photoAlbum.imagePaths.map(async (imagePath) => {
    if (!imagePath) return;
    return await getUrl({ path: imagePath });
  })
);
}
Delete and remove files associated with API records

The workflow for deleting and removing files associated with API records is the same as when working with a single file, except that when performing a delete you will need to iterate over the list of file paths and call Storage.remove() for each file.

Remove the file association, continue to persist both files and record
src/App.tsx
Copy
src/App.tsx code example
import { generateClient } from "aws-amplify/api";
import type { Schema } from "../amplify/data/resource";


// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});


const response = await client.models.PhotoAlbum.get({
  id: currentPhotoAlbum.id,
});


const photoAlbum = response.data;


// If the record has no associated file, we can return early.
if (!photoAlbum?.imagePaths) return;


const updatedPhotoAlbum = await client.models.PhotoAlbum.update({
  id: photoAlbum.id,
  imagePaths: null,
});
Remove the record association and delete the files
src/App.tsx
Copy
src/App.tsx code example
import { generateClient } from "aws-amplify/api";
import { remove } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";


// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});


const response = await client.models.PhotoAlbum.get({
  id: currentPhotoAlbum.id,
});


const photoAlbum = response.data;


// If the record has no associated files, we can return early.
if (!photoAlbum?.imagePaths) return;


// Remove associated files from record
const updateResponse = await client.models.PhotoAlbum.update({
  id: photoAlbum.id,
  imagePaths: null, // Set the file association to `null`
});


const updatedPhotoAlbum = updateResponse.data;


// Delete the files from S3:
await Promise.all(
  photoAlbum?.imagePaths.map(async (imagePath) => {
    if (!imagePath) return;
    await remove({ path: imagePath });
  })
);
Delete record and all associated files
src/App.tsx
Copy
src/App.tsx code example
import { generateClient } from "aws-amplify/api";
import { remove } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";


// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});


const response = await client.models.PhotoAlbum.get({
  id: currentPhotoAlbum.id,
});


const photoAlbum = response.data;


if (!photoAlbum) return;


await client.models.PhotoAlbum.delete({
  id: photoAlbum.id,
});


setCurrentPhotoAlbum(null);


// If the record has no associated file, we can return early.
if (!photoAlbum?.imagePaths) return;


await Promise.all(
  photoAlbum?.imagePaths.map(async (imagePath) => {
    if (!imagePath) return;
    await remove({ path: imagePath });
  })
);
Data consistency when working with records and files

The recommended access patterns in these docs attempt to remove deleted files, but favor leaving orphans over leaving records that point to non-existent files. This optimizes for read latency by ensuring clients rarely attempt to fetch a non-existent file from Storage. However, any app that deletes files can inherently cause records on-device to point to non-existent files.

One example is when we create an API record, associate the Storage file with that record, and then retrieve the file's signed URL. "Device A" calls the GraphQL API to create API_Record_1, and then associates that record with First_Photo. Before "Device A" is about to retrieve the signed URL, "Device B" might query API_Record_1, delete First_Photo, and update the record accordingly. However, "Device A" is still using the old API_Record_1, which is now out-of-date. Even though the shared global state is correctly in sync at every stage, the individual device ("Device A") has an out-of-date record that points to a non-existent file. Similar issues can conceivably occur for updates. Depending on your app, some of these mismatches can be minimized even more with real-time data / GraphQL subscriptions.

It is important to understand when these mismatches can occur and to add meaningful error handling around these cases. This guide does not include exhaustive error handling, real-time subscriptions, re-querying of outdated records, or attempts to retry failed operations. However, these are all important considerations for a production-level application.

Complete examples
Single File (TS)
Multi-File (TS)
src/App.tsx
Copy
src/App.tsx code example
import "./App.css";
import { generateClient } from "aws-amplify/api";
import { uploadData, getUrl, remove } from "aws-amplify/storage";
import React, { useState } from "react";
import type { Schema } from "../amplify/data/resource";
import "@aws-amplify/ui-react/styles.css";
import {
  type WithAuthenticatorProps,
  withAuthenticator,
} from "@aws-amplify/ui-react";
import { Amplify } from "aws-amplify";
import outputs from "../amplify_outputs.json";


Amplify.configure(outputs);


// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});


type Song = Schema["Song"]["type"];


function App({ signOut, user }: WithAuthenticatorProps) {


  const [currentSong, setCurrentSong] = useState<Song | null>(null);


  // Used to display image for current song:
  const [currentImageUrl, setCurrentImageUrl] = useState<
    string | null | undefined
    >("");


  async function createSongWithImage(e: React.ChangeEvent<HTMLInputElement>) {
    if (!e.target.files) return;
    const file = e.target.files[0];
    try {


      // Create the API record:
      const response = await client.models.Song.create({
        name: `My first song`,
      });


      const song = response.data;


      if (!song) return;


      // Upload the Storage file:
      const result = await uploadData({
        path: `images/${song.id}-${file.name}`,
        data: file,
        options: {
          contentType: "image/png", // contentType is optional
        },
      }).result;


      // Add the file association to the record:
      const updateResponse = await client.models.Song.update({
        id: song.id,
        coverArtPath: result?.path,
      });


      const updatedSong = updateResponse.data;
      setCurrentSong(updatedSong);


      // If the record has no associated file, we can return early.
      if (!updatedSong?.coverArtPath) return;


      // Retrieve the file's signed URL:
      const signedURL = await getUrl({ path: updatedSong.coverArtPath });


      setCurrentImageUrl(signedURL.url.toString());
    } catch (error) {
      console.error("Error create song / file:", error);
    }
  }


  // Upload image, add to song, retrieve signed URL and retrieve the image.
  // Also updates image if one already exists.
  async function addNewImageToSong(e: React.ChangeEvent<HTMLInputElement>) {


    if (!currentSong) return;


    if (!e.target.files) return;


    const file = e.target.files[0];


    try {
      // Upload the Storage file:
      const result = await uploadData({
        path: `images/${currentSong.id}-${file.name}`,
        data: file,
        options: {
          contentType: "image/png", // contentType is optional
        },
      }).result;


      // Add the file association to the record:
      const response = await client.models.Song.update({
        id: currentSong.id,
        coverArtPath: result?.path,
      });


      const updatedSong = response.data;


      setCurrentSong(updatedSong);


      // If the record has no associated file, we can return early.
      if (!updatedSong?.coverArtPath) return;


      // Retrieve the file's signed URL:
      const signedURL = await getUrl({ path: updatedSong.coverArtPath });
      setCurrentImageUrl(signedURL.url.toString());


    } catch (error) {
      console.error("Error uploading image / adding image to song: ", error);
    }
  }


  async function getImageForCurrentSong() {
    if (!currentSong) return;


    try {
      // Query the record to get the file path:
      const response = await client.models.Song.get({
        id: currentSong.id,
      });


      const song = response.data;


      // If the record has no associated file, we can return early.
      if (!song?.coverArtPath) return;


      // Retrieve the signed URL:
      const signedURL = await getUrl({ path: song.coverArtPath });
      setCurrentImageUrl(signedURL.url.toString());
    } catch (error) {
      console.error("Error getting song / image:", error);
    }
  }


  // Remove the file association, continue to persist both file and record
  async function removeImageFromSong() {


    if (!currentSong) return;


    try {
      const response = await client.models.Song.get({
        id: currentSong.id,
      });


      const song = response.data;


      // If the record has no associated file, we can return early.
      if (!song?.coverArtPath) return;


      const updatedSong = await client.models.Song.update({
        id: song.id,
        coverArtPath: null,
      });


      // If successful, the response here will be `null`:
      setCurrentSong(updatedSong.data);


      setCurrentImageUrl(updatedSong.data?.coverArtPath);


    } catch (error) {
      console.error("Error removing image from song: ", error);
    }
  }


  // Remove the record association and delete the file
  async function deleteImageForCurrentSong() {


    if (!currentSong) return;


    try {
      const response = await client.models.Song.get({
        id: currentSong.id,
      });


      const song = response?.data;


      // If the record has no associated file, we can return early.
      if (!song?.coverArtPath) return;


      // Remove associated file from record
      const updatedSong = await client.models.Song.update({
        id: song.id,
        coverArtPath: null,
      });


      // Delete the file from S3:
      await remove({ path: song.coverArtPath });


      // If successful, the response here will be `null`:
      setCurrentSong(updatedSong.data);


      setCurrentImageUrl(updatedSong.data?.coverArtPath);


    } catch (error) {
      console.error("Error deleting image: ", error);
    }
  }


  // Delete both file and record
  async function deleteCurrentSongAndImage() {


    if (!currentSong) return;
    try {
      const response = await client.models.Song.get({
        id: currentSong.id,
      });
      const song = response.data;


      // If the record has no associated file, we can return early.
      if (!song?.coverArtPath) return;


      await remove({ path: song.coverArtPath });


      // Delete the record from the API:
      await client.models.Song.delete({ id: song.id });


      clearLocalState();


    } catch (error) {
      console.error("Error deleting song: ", error);
    }
  }


  function clearLocalState() {
    setCurrentSong(null);
    setCurrentImageUrl("");
  }


  return (
    <>
      <h1>Hello {user?.username}</h1>
      <button onClick={signOut}>Sign out</button>
      <div>
        <label>
          <h2>{`Current Song: ${currentSong?.id}`}</h2>
          Create song with file:
          <input id="name" type="file" onChange={createSongWithImage} />
        </label>
        <label>
          Add / update song image:
          <input
            id="name"
            type="file"
            onChange={addNewImageToSong}
            disabled={!currentSong}
          />
        </label>
        <button
          onClick={getImageForCurrentSong}
          disabled={!currentSong || !currentImageUrl}
        >
          Get image for current song
        </button>
        <button
          onClick={removeImageFromSong}
          disabled={!currentSong || !currentImageUrl}
        >
          Remove image from current song (does not delete image)
        </button>
        <button
          onClick={deleteImageForCurrentSong}
          disabled={!currentSong || !currentImageUrl}
        >
          Remove image from current song, then delete image
        </button>
        <button onClick={deleteCurrentSongAndImage} disabled={!currentSong}>
          Delete current song (and image, if it exists)
        </button>
        <button onClick={signOut} className="app-button">
          Sign out
        </button>
      </div>
    </>
  );
}


export default withAuthenticator(App);
PREVIOUS
Add custom queries and mutations
NEXT
Add custom real-time subscriptions

--------------------------------------------------------------------------------

Title: Add custom real-time subscriptions - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/custom-subscription/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Add custom real-time subscriptions
Add custom real-time subscriptions

Create a custom real-time subscription for any mutation to enable PubSub use cases.

Define a custom subscription

For every custom subscription, you need to set:

the mutation(s) that should trigger a subscription event,
a return type that matches the subscribed mutations' return type,
authorization rules.

Optionally, you can set filter arguments to customize the server-side subscription filter rules.

Use a.subscription() to define your custom subscription in your amplify/data/resource.ts file:

amplify/data/resource.ts
import { type ClientSchema, a, defineData } from '@aws-amplify/backend';


const schema = a.schema({
  // Message type that's used for this PubSub sample
  Message: a.customType({
    content: a.string().required(),
    channelName: a.string().required()
  }),


  // Message publish mutation
  publish: a.mutation()
    .arguments({
      channelName: a.string().required(),
      content: a.string().required()
    })
    .returns(a.ref('Message'))
    .handler(a.handler.custom({ entry: './publish.js' }))
    .authorization(allow => [allow.publicApiKey()]),


Copy
highlighted code example
  // Subscribe to incoming messages
  receive: a.subscription()
    // subscribes to the 'publish' mutation
    .for(a.ref('publish')) 
    // subscription handler to set custom filters
    .handler(a.handler.custom({entry: './receive.js'})) 
    // authorization rules as to who can subscribe to the data
    .authorization(allow => [allow.publicApiKey()]),


  // A data model to manage channels
  Channel: a.model({
    name: a.string(),
  }).authorization(allow => [allow.publicApiKey()]),
});


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema
});

For this example, we're building a generic PubSub capability. This requires us to convert the arguments for publish into the Channel's format. Create a new publish.js file in your amplify/data/ folder with the following contents:

amplify/data/publish.js
Copy
amplify/data/publish.js code example
// This handler simply passes through the arguments of the mutation through as the result
export function request() {
  return {}
}


/**
 * @param {import('@aws-appsync/utils').Context} ctx
 */
export function response(ctx) {
  return ctx.args
}

Next, create a new receive.js file in your amplify/data/ folder to define handlers for your subscription. In this case, it'll just be a simple passthrough. In the next section, we'll explore how to use this handler to construct more advanced subscription filters.

Note: We're planning a developer experience enhancement in the near future that'll create this passthrough under the hood.

amplify/data/receive.js
Copy
amplify/data/receive.js code example
export function request() {
  return {};
}


export const response = (ctx) => {
  return ctx.result;
};
Subscribe to custom subscriptions client-side

From your generated Data client, you can find all your custom subscriptions under client.subscriptions. Subscribe using the .subscribe() function and then use the next function to handle incoming events.

Copy
code example
import { generateClient } from 'aws-amplify/data'
import type { Schema } from '../amplify/data/resource'


const client = generateClient<Schema>()


const sub = client.subscriptions.receive()
  .subscribe({
    next: event => {
      console.log(event)
    }
  }
)

You can try publishing an event using the custom mutation to test the real-time subscription.

Copy
code example
client.mutations.publish({
  channelName: "world",
  content: "My first message!"
})

Your subscription event should be received and logs the payload into your app's developer console. Unsubscribe your subscription to disconnect using the unsubscribe() function.

Copy
code example
sub.unsubscribe()
(Optionally) Add server-side subscription filters

You can add subscription filters by adding arguments to the custom subscriptions.

If you want to customize the filters, modify the subscription handler. For this example, we'll allow a customer to pass in a namePrefix parameter that allows the end users to only receive channel events in channels that start with the namePrefix.

amplify/data/resource.ts
import { type ClientSchema, a, defineData } from '@aws-amplify/backend';


const schema = a.schema({
  Channel: a.model({
    name: a.string(),
  }).authorization(allow => [allow.publicApiKey()]),


  Message: a.customType({
    content: a.string().required(),
    channelName: a.string().required()
  }),


  publish: a.mutation()
    .arguments({
      channelName: a.string().required(),
      content: a.string().required()
    })
    .returns(a.ref('Message'))
    .handler(a.handler.custom({ entry: './publish.js' }))
    .authorization(allow => [allow.publicApiKey()]),


  receive: a.subscription()
    .for(a.ref('publish'))
Copy
highlighted code example
    .arguments({ namePrefix: a.string() })
    .handler(a.handler.custom({entry: './receive.js'}))
    .authorization(allow => [allow.publicApiKey()])
});


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema
});

In your handler, you can set custom subscription filters based on arguments passed into the custom subscription. For this example, create a new receive.js file alongside the amplify/data/resource.ts file:

Copy
code example
import { util, extensions } from "@aws-appsync/utils"


// Subscription handlers must return a `null` payload on the request
export function request() { return { payload: null } }


/**
 * @param {import('@aws-appsync/utils').Context} ctx
 */
export function response(ctx) {
  const filter = {
    channelName: {
      beginsWith: ctx.args.namePrefix
    }
  }


  extensions.setSubscriptionFilter(util.transform.toSubscriptionFilter(filter))


  return null
}
PREVIOUS
Working with files/attachments
NEXT
Connect to existing data sources

--------------------------------------------------------------------------------

Title: Connect to an external HTTP endpoint - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/custom-business-logic/connect-http-datasource/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Add custom queries and mutations
/
Connect to an external HTTP endpoint
Connect to an external HTTP endpoint

The HTTP Datasource allows you to quickly configure HTTP resolvers within your Data API.

This guide will demonstrate how to establish a connection to an external REST API using an HTTP data source and use Amplify Data's custom mutations and queries to interact with the REST API.

Step 1 - Set up your custom type

For the purpose of this guide we will define a Post type and use an existing external REST API that will store records for it. In Amplify Gen 2, customType adds a type to the schema that is not backed by an Amplify-generated DynamoDB table.

With the Post type defined, it can then be referenced as the return type when defining your custom queries and mutations.

First, add the Post custom type to your schema:

amplify/data/resource.ts
import { type ClientSchema, a, defineData } from "@aws-amplify/backend";


const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
    })
    .authorization(allow => [allow.publicApiKey()]),
Copy
highlighted code example
  Post: a.customType({
    title: a.string(),
    content: a.string(),
    author: a.string().required(),
  }),
});


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: 'apiKey',
    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});
Step 2 - Add your REST API or HTTP API as Datasource

To integrate the external REST API or HTTP API, you'll need to set it up as the HTTP Datasource. Add the following code in your amplify/backend.ts file.

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import { data } from "./data/resource";


const backend = defineBackend({
  auth,
  data,
});


const httpDataSource = backend.data.addHttpDataSource(
  "HttpDataSource",
  "https://www.example.com"
);
Step 3 - Define custom queries and mutations

Now that your REST API has been added as a data source, you can reference it in custom queries and mutations using the a.handler.custom() modifier which accepts the name of the data source and an entry point for your resolvers.

Use the following code examples to add addPost, getPost, updatePost, and deletePost as custom queries and mutations to your schema:

addPost
getPost
updatePost
deletePost
amplify/data/resource.ts
import { type ClientSchema, a, defineData } from "@aws-amplify/backend";


const schema = a.schema({
  Post: a.customType({
    title: a.string(),
    content: a.string(),
    author: a.string().required(),
  }),
Copy
highlighted code example
  addPost: a
    .mutation()
    .arguments({
      title: a.string(),
      content: a.string(),
      author: a.string().required(),
    })
    .returns(a.ref("Post"))
    .authorization(allow => [allow.publicApiKey()])
    .handler(
      a.handler.custom({
        dataSource: "HttpDataSource",
        entry: "./addPost.js",
      })
    ),
});


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: 'apiKey',
    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});
Step 4 - Configure custom business logic handler code

Next, create the following files in your amplify/data folder and use the code examples to define custom resolvers for the custom queries and mutations added to your schema from the previous step. These are AppSync JavaScript resolvers.

addPost
getPost
updatePost
deletePost
amplify/data/addPost.js
Copy
amplify/data/addPost.js code example
import { util } from "@aws-appsync/utils";


export function request(ctx) {
  return {
    method: "POST",
    resourcePath: "/post",
    params: {
      headers: {
        "Content-Type": "application/json",
      },
      body: {
        title: ctx.arguments.title,
        content: ctx.arguments.content,
        author: ctx.arguments.author,
      },
    },
  };
}


export function response(ctx) {
  if (ctx.error) {
    return util.error(ctx.error.message, ctx.error.type);
  }
  if (ctx.result.statusCode == 200) {
    return JSON.parse(ctx.result.body).data;
  } else {
    return util.appendError(ctx.result.body, "ctx.result.statusCode");
  }
}
Step 5 - Invoke custom queries or mutations

From your generated Data client, you can find all your custom queries and mutations under the client.queries. and client.mutations. APIs respectively.

addPost
getPost
updatePost
deletePost
App.tsx
Copy
App.tsx code example
const { data, errors } = await client.mutations.addPost({
  title: "My Post",
  content: "My Content",
  author: "Chris",
});
Conclusion

In this guide, you’ve added an external REST API as a HTTP data source to an Amplify Data API and defined custom queries and mutations, handled by AppSync JS resolvers, to manipulate Post items in an external REST API using the Amplify Gen 2 Data client.

To clean up, you can delete your sandbox by accepting the prompt when terminating the sandbox process in your terminal. Alternatively, you can also use the AWS Amplify console to manage and delete sandbox environments.

PREVIOUS
Connect to Amazon Translate for language translation APIs

--------------------------------------------------------------------------------

Title: Connect to Amazon Translate for language translation APIs - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/custom-business-logic/connect-amazon-translate/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Add custom queries and mutations
/
Connect to Amazon Translate for language translation APIs
Connect to Amazon Translate for language translation APIs

Amazon Translate is a neural machine translation service provided by Amazon Web Services (AWS). It uses advanced deep learning technologies to deliver fast and high-quality language translation. With Amazon Translate, you can easily add multilingual support to your applications and services, enabling users to communicate and interact in their preferred language.

Key features of Amazon Translate include:

Accurate and Fluent Translations: Amazon Translate produces translations that are both accurate and natural-sounding, providing a seamless experience for users.

Support for Multiple Languages: The service supports a broad range of languages, allowing you to expand your application’s reach to diverse audiences around the world.

Real-Time and Batch Translation: Amazon Translate can handle real-time translation for dynamic content and batch translation for larger volumes of text, making it suitable for various use cases.

Cost-Effective and Scalable: With its pay-as-you-go pricing model and automatic scaling, Amazon Translate is an economical and flexible solution for adding translation capabilities to your applications.

In this section, you will learn how to integrate Amazon Translate into your application using AWS Amplify, enabling you to leverage its powerful translation capabilities effortlessly.

Step 1 - Set up the project

Set up your project by following the instructions in the Quickstart guide.

Step 2 - Install Amazon Translate libraries

To install the Amazon Translate SDK, run the following command in your project's root folder:

Terminal
Copy
Terminal code example
npm add @aws-sdk/client-translate
Step 3 - Add your Amazon Translate as Datasource

To access Amazon Translate service, you need to add Amazon Translate as an HTTP Data Source and configure the proper IAM policy for AWS Lambda to utilize the desired feature effectively. Update amplify/backend.ts file as shown below.

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from "./data/resource";
import { Stack } from 'aws-cdk-lib';
import { PolicyStatement } from 'aws-cdk-lib/aws-iam';


const backend = defineBackend({
 auth,
 data
});


const dataStack = Stack.of(backend.data)


const translateDataSource = backend.data.addHttpDataSource(
 "TranslateDataSource",
 `https://translate.${dataStack.region}.amazonaws.com`,
 {
   authorizationConfig: {
     signingRegion: dataStack.region,
     signingServiceName: "translate",
   },
 }
);


translateDataSource.grantPrincipal.addToPrincipalPolicy(
 new PolicyStatement({
   actions: ["translate:TranslateText"],
   resources: ["*"],
 })
);
Step 4 - Configure custom business logic handler

Next, create the following translate.js file in your amplify/data folder and use the code below to define custom resolvers.

amplify/data/translate.js
Copy
amplify/data/translate.js code example
export function request(ctx) {
  return {
    method: 'POST',
    resourcePath: '/',
    params: {
      body: {
        SourceLanguageCode: ctx.arguments.sourceLanguage,
        TargetLanguageCode: ctx.arguments.targetLanguage,
        Text: ctx.arguments.text
      },
      headers: {
        'Content-Type': 'application/x-amz-json-1.1',
        'X-Amz-Target': 'AWSShineFrontendService_20170701.TranslateText'
      }
    },
  }
}


export function response(ctx) {
  return JSON.parse(ctx.result.body).TranslatedText
}
Step 5 - Define the custom query

After adding Amazon Translate as a data source, you can reference it in a custom query using the a.handler.custom() modifier, which takes the name of the data source and an entry point for your resolvers. In your amplify/data/resource.ts file, specify TranslateDataSource as the data source and translate.js as the entry point, as shown below.

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
import { type ClientSchema, a, defineData } from '@aws-amplify/backend';




const schema = a.schema({
  translate: a.query()
    .arguments({
      sourceLanguage: a.string().required(),
      targetLanguage: a.string().required(),
      text: a.string().required()
    })
    .returns(a.string())
    .authorization(allow => [allow.publicApiKey()])
    .handler(a.handler.custom({
      dataSource: "TranslateDataSource",
      entry: './translate.js'
    }))
});


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: 'apiKey',
    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});
Step 6 - Configure the frontend

Import and load the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point.

main.tsx
Copy
main.tsx code example
import { Amplify } from "aws-amplify";
import outputs from "../amplify_outputs.json";


Amplify.configure(outputs);
Invoke the API

Sample frontend code to translate text from one language to another.

Copy
code example
import { generateClient } from 'aws-amplify/data';
import { type Schema } from '../amplify/data/resource';


const client = generateClient<Schema>();




const { data } = await client.queries.translate({
  sourceLanguage: "en",
  targetLanguage: "es",
  text: "Hello World!",
});
PREVIOUS
Connect to Amazon Rekognition for Image Analysis APIs
NEXT
Connect to an external HTTP endpoint

--------------------------------------------------------------------------------

Title: Connect to Amazon Rekognition for Image Analysis APIs - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/custom-business-logic/connect-amazon-rekognition/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Add custom queries and mutations
/
Connect to Amazon Rekognition for Image Analysis APIs
Connect to Amazon Rekognition for Image Analysis APIs

Amazon Rekognition is an advanced machine learning service provided by Amazon Web Services (AWS), allowing developers to incorporate image and video analysis into their applications. It uses state-of-the-art machine learning models to analyze images and videos, providing valuable insights such as object and scene detection, text recognition, face analysis, and more.

Key features of Amazon Rekognition include:

Object and Scene Detection: Amazon Rekognition can identify thousands of objects and scenes in images and videos, providing valuable context for your media content.

Text Detection and Recognition: The service can detect and recognize text within images and videos, making it an invaluable tool for applications requiring text extraction.

Facial Analysis: Amazon Rekognition offers accurate facial analysis, enabling you to detect, analyze, and compare faces in images and videos.

Facial Recognition: You can build applications with the capability to recognize and verify individuals using facial recognition.

Content Moderation: Amazon Rekognition can analyze images and videos to identify inappropriate or objectionable content, helping you maintain safe and compliant content.

In this section, you will learn how to integrate Amazon Rekognition into your application using AWS Amplify, leveraging its powerful image analysis capabilities seamlessly.

Step 1 - Set up the project

Set up your project by following the instructions in the Quickstart guide.

Step 2 - Install Rekognition Libraries

Create a new API endpoint that'll use the the AWS SDK to call the Amazon Rekognition service. To install the Amazon Rekognition SDK, run the following command in your project's root folder:

Terminal
Copy
Terminal code example
npm add @aws-sdk/client-rekognition
Step 3 - Setup Storage

Create a file named amplify/storage/resource.ts and add the following content to configure a storage resource:

amplify/storage/resource.ts
Copy
amplify/storage/resource.ts code example
import { defineStorage } from '@aws-amplify/backend';


export const storage = defineStorage({
  name: 'predictions_gen2'
});
Step 4 - Add your Amazon Rekognition as Datasource

To use the Amazon Rekognition service, you need to add Amazon Rekognition as an HTTP Data Source and configure the proper IAM policy for Lambda to effectively utilize the desired feature and grant permission to access the storage. In this case, you can add the rekognition:DetectText and rekognition:DetectLabels actions to the policy. Update the amplify/backend.ts file as shown below.

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';
import { Stack } from 'aws-cdk-lib';
import { PolicyStatement } from 'aws-cdk-lib/aws-iam';
import { storage } from './storage/resource';


const backend = defineBackend({
 auth,
 data,
 storage
});


const dataStack = Stack.of(backend.data)


// Set environment variables for the S3 Bucket name
backend.data.resources.cfnResources.cfnGraphqlApi.environmentVariables = {
 S3_BUCKET_NAME: backend.storage.resources.bucket.bucketName,
};


const rekognitionDataSource = backend.data.addHttpDataSource(
 "RekognitionDataSource",
 `https://rekognition.${dataStack.region}.amazonaws.com`,
 {
   authorizationConfig: {
     signingRegion: dataStack.region,
     signingServiceName: "rekognition",
   },
 }
);


rekognitionDataSource.grantPrincipal.addToPrincipalPolicy(
 new PolicyStatement({
   actions: ["rekognition:DetectText", "rekognition:DetectLabels"],
   resources: ["*"],
 })
);


backend.storage.resources.bucket.grantReadWrite(
 rekognitionDataSource.grantPrincipal
);
Step 5 - Configure the function handler

Define the function handler by creating a new file, amplify/data/identifyText.ts. This function analyzes the image and extracts text using the Amazon Rekognition DetectText service.

amplify/data/identifyText.ts
Copy
amplify/data/identifyText.ts code example
export function request(ctx) {
  return {
    method: "POST",
    resourcePath: "/",
    params: {
      body: {
        Image: {
          S3Object: {
            Bucket: ctx.env.S3_BUCKET_NAME,
            Name: ctx.arguments.path,
          },
        },
      },
      headers: {
        "Content-Type": "application/x-amz-json-1.1",
        "X-Amz-Target": "RekognitionService.DetectText",
      },
    },
  };
}


export function response(ctx) {
  return JSON.parse(ctx.result.body)
    .TextDetections.filter((item) => item.Type === "LINE")
    .map((item) => item.DetectedText)
    .join("\n")
    .trim();
}
Step 6 - Define the custom query

After adding Amazon Rekognition as a data source, you can reference it in custom query using the a.handler.custom() modifier, which takes the name of the data source and an entry point for your resolvers. In your amplify/data/resource.ts file, specify RekognitionDataSource as the data source and identifyText.js as the entry point, as shown below.

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
import { type ClientSchema, a, defineData } from "@aws-amplify/backend";


const schema = a.schema({
  identifyText: a
    .query()
    .arguments({
      path: a.string(),
    })
    .returns(a.string())
    .authorization((allow) => [allow.publicApiKey()])
    .handler(
      a.handler.custom({
        entry: "./identifyText.js",
        dataSource: "RekognitionDataSource",
      })
    ),
});


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: "apiKey",
    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});
Step 7 - Update Storage permissions

Customize your storage settings to manage access to various paths within your storage bucket. Modify the file amplify/storage/resource.ts as shown below.

amplify/storage/resource.ts
Copy
amplify/storage/resource.ts code example
import { defineStorage } from "@aws-amplify/backend"


export const storage = defineStorage({
  name: "predictions_gen2",
  access: allow => ({
    'public/*': [
      allow.guest.to(['list', 'write', 'get'])
    ]
  })
})
Step 8 - Configure the frontend

Import and load the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point.

main.tsx
Copy
main.tsx code example
import { Amplify } from "aws-amplify";
import outputs from "../amplify_outputs.json";


Amplify.configure(outputs);
Invoke the Text Recognition API

This code sets up a React app to upload an image to an S3 bucket and then use Amazon Rekognition to recognize the text in the uploaded image.

App.tsx
Copy
App.tsx code example
import { type ChangeEvent, useState } from "react";
import { generateClient } from "aws-amplify/api";
import { uploadData } from "aws-amplify/storage";
import { Schema } from "@/amplify/data/resource";
import "./App.css";


// Generating the client
const client = generateClient<Schema>();


type IdentifyTextReturnType = Schema["identifyText"]["returnType"];


function App() {
  // State to hold the recognized text
  const [path, setPath] = useState<string>("");
  const [textData, setTextData] = useState<IdentifyTextReturnType>();


  // Function to handle file upload to S3 bucket
  const handleTranslate = async (event: ChangeEvent<HTMLInputElement>) => {
    if (event.target.files) {
      const file = event.target.files[0];


      const s3Path = "public/" + file.name;


      try {
        uploadData({
          path: s3Path,
          data: file,
        });


        setPath(s3Path);
      } catch (error) {
        console.error(error);
      }
    }
  };


  // Function to recognize text from the uploaded image
  const recognizeText = async () => {
    // Identifying text in the uploaded image
    const { data } = await client.queries.identifyText({
      path, // File name
    });
    setTextData(data);
  };


  return (
    <div>
      <h1>Amazon Rekognition Text Recognition</h1>
      <div>
        <input type="file" onChange={handleTranslate} />
        <button onClick={recognizeText}>Recognize Text</button>
        <div>
          <h3>Recognized Text:</h3>
          {textData}
        </div>
      </div>
    </div>
  );
}


export default App;
PREVIOUS
Connect to Amazon Bedrock for generative AI use cases
NEXT
Connect to Amazon Translate for language translation APIs

--------------------------------------------------------------------------------

Title: Connect to Amazon Polly for Text-To-Speech APIs - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/custom-business-logic/connect-amazon-polly/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Add custom queries and mutations
/
Connect to Amazon Polly for Text-To-Speech APIs
Connect to Amazon Polly for Text-To-Speech APIs

Amazon Polly is a text-to-speech (TTS) service offered by Amazon Web Services (AWS). It uses advanced deep learning technologies to convert written text into lifelike speech, enabling you to create applications with speech capabilities in various languages and voices.

With Amazon Polly, you can easily add voice interactions and accessibility features to your applications. The service supports a wide range of use cases, such as providing audio content for the visually impaired, enhancing e-learning experiences, creating interactive voice response (IVR) systems, and more.

Key features of Amazon Polly include:

Multiple Voices and Languages: Amazon Polly supports dozens of voices across various languages and dialects, giving you the flexibility to choose the most appropriate voice for your use case.

High-Quality Speech: Amazon Polly's neural and standard voices offer natural and realistic speech quality.

Speech Marks and Speech Synthesis Markup Language: Customize your speech output with Speech Synthesis Markup Language tags and obtain speech timing information with speech marks.

Scalable and Cost-Effective: Amazon Polly's pay-as-you-go pricing model makes it a cost-effective solution for adding speech capabilities to your applications.

In this section, you'll learn how to integrate Amazon Polly into your application using AWS Amplify, enabling you to leverage its powerful text-to-speech capabilities seamlessly.

Step 1 - Setup the project

Set up your project by following the instructions in the Quickstart guide.

Step 2 - Install Polly Libraries

We'll create a new API endpoint that'll use the the AWS SDK to call the Amazon Polly service. To install the Amazon Polly SDK, run the following command in your project's root folder:

Terminal
Copy
Terminal code example
npm add @aws-sdk/client-polly
Step 3 - Setup Storage

Create a file named amplify/storage/resource.ts and add the following content to configure a storage resource:

amplify/storage/resource.ts
Copy
amplify/storage/resource.ts code example
import { defineStorage } from '@aws-amplify/backend';


export const storage = defineStorage({
  name: 'predictions_gen2'
});
Step 4 - Configure IAM Roles

To access Amazon Polly service, you need to configure the proper IAM policy for Lambda to utilize the desired feature effectively. Update the amplify/backend.ts file with the following code to add the necessary permissions to a lambda's Role policy.

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import { data, convertTextToSpeech } from "./data/resource";
import { Stack } from "aws-cdk-lib";
import { PolicyStatement } from "aws-cdk-lib/aws-iam";
import { storage } from "./storage/resource";


const backend = defineBackend({
 auth,
 data,
 storage,
 convertTextToSpeech,
});


backend.convertTextToSpeech.resources.lambda.addToRolePolicy(
 new PolicyStatement({
   actions: ["polly:StartSpeechSynthesisTask"],
   resources: ["*"],
 })
);
Step 5 - Configure the function handler

Define the function handler by creating a new file, amplify/data/convertTextToSpeech.ts. This function converts text into speech using Amazon Polly and stores the synthesized speech as an MP3 file in an S3 bucket.

amplify/data/convertTextToSpeech.ts
Copy
amplify/data/convertTextToSpeech.ts code example
import { Schema } from "./resource";
import {
  PollyClient,
  StartSpeechSynthesisTaskCommand,
} from "@aws-sdk/client-polly";
import { env } from "$amplify/env/convertTextToSpeech";


export const handler: Schema["convertTextToSpeech"]["functionHandler"] = async (
  event
) => {
  const client = new PollyClient();
  const task = new StartSpeechSynthesisTaskCommand({
    OutputFormat: "mp3",
    SampleRate: "8000",
    Text: event.arguments.text,
    TextType: "text",
    VoiceId: "Amy",
    OutputS3BucketName: env.PREDICTIONS_GEN_2_BUCKET_NAME,
    OutputS3KeyPrefix: "public/",
  });
  const result = await client.send(task);


  return (
    result.SynthesisTask?.OutputUri?.replace(
      "https://s3.us-east-1.amazonaws.com/" +
        env.PREDICTIONS_GEN_2_BUCKET_NAME +
        "/public/",
      ""
    ) ?? ""
  );
};
Step 6 - Define the custom mutation and function

In your amplify/data/resource.ts file, define the function using defineFunction and then reference the function with your mutation using a.handler.function() as a handler.

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
import {
  type ClientSchema,
  a,
  defineData,
  defineFunction,
} from "@aws-amplify/backend";


export const convertTextToSpeech = defineFunction({
  entry: "./convertTextToSpeech.ts",
});


const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
    })
    .authorization(allow => [allow.publicApiKey()]),
  convertTextToSpeech: a
    .mutation()
    .arguments({
      text: a.string().required(),
    })
    .returns(a.string().required())
    .authorization(allow => [allow.publicApiKey()])
    .handler(a.handler.function(convertTextToSpeech)),
});


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: "apiKey",
    // API Key is used for allow.publicApiKey() rules
    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});

NOTE: At least one query is required for a schema to be valid. Otherwise, deployments will fail a schema error. The Amplify Data schema is auto-generated with a Todo model and corresponding queries under the hood. You can leave the Todo model in the schema until you add the first custom query to the schema in the next steps.

Step 7 - Update Storage permissions

Customize your storage settings to manage access to various paths within your storage bucket. It's necessary to update the Storage resource to provide access to the convertTextToSpeech resource. Modify the file amplify/storage/resource.ts as shown below.

amplify/storage/resource.ts
Copy
amplify/storage/resource.ts code example
import { defineStorage } from "@aws-amplify/backend";
import { convertTextToSpeech } from "../data/resource";


export const storage = defineStorage({
  name: "predictions_gen2",
  access: (allow) => ({
    "public/*": [
      allow.resource(convertTextToSpeech).to(["write"]),
      allow.guest.to(["read", "write"]),
    ],
  }),
});
Step 8 - Configure the frontend

Import and load the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point.

main.tsx
Copy
main.tsx code example
import { Amplify } from "aws-amplify";
import outputs from "../amplify_outputs.json";


Amplify.configure(outputs);
Invoke the API

Example frontend code to create an audio buffer for playback using a text input.

App.tsx
Copy
App.tsx code example
import "./App.css";
import { generateClient } from "aws-amplify/api";
import type { Schema } from "../amplify/data/resource";
import { getUrl } from "aws-amplify/storage";
import { useState } from "react";


const client = generateClient<Schema>();


type PollyReturnType = Schema["convertTextToSpeech"]["returnType"];


function App() {
  const [src, setSrc] = useState("");
  const [file, setFile] = useState<PollyReturnType>("");
  return (
    <div className="flex flex-col">
      <button
        onClick={async () => {
          const { data, errors } = await client.mutations.convertTextToSpeech({
            text: "Hello World!",
          });


          if (!errors && data) {
            setFile(data);
          } else {
            console.log(errors);
          }
        }}
      >
        Synth
      </button>
      <button
        onClick={async () => {
          const res = await getUrl({
            path: "public/" + file,
          });


          setSrc(res.url.toString());
        }}
      >
        Fetch audio
      </button>
      <a href={src}>Get audio file</a>
    </div>
  );
}


export default App;
PREVIOUS
Connect to Amazon EventBridge to send and receive events
NEXT
Connect to Amazon Bedrock for generative AI use cases

--------------------------------------------------------------------------------

Title: Connect to Amazon Bedrock for generative AI use cases - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/custom-business-logic/connect-bedrock/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Add custom queries and mutations
/
Connect to Amazon Bedrock for generative AI use cases
Connect to Amazon Bedrock for generative AI use cases

Amazon Bedrock is a fully managed service that removes the complexity of using foundation models (FMs) for generative AI development. It acts as a central hub, offering a curated selection of high-performing FMs from leading AI companies like Anthropic, AI21 Labs, Cohere, and Amazon itself.

Amazon Bedrock streamlines generative AI development by providing:

Choice and Flexibility: Experiment and evaluate a wide range of FMs to find the perfect fit for your use case.

Simplified Integration: Access and use FMs through a single, unified API, reducing development time.

Enhanced Security and Privacy: Benefit from built-in safeguards to protect your data and prevent misuse.

Responsible AI Features: Implement guardrails to control outputs and mitigate bias.

In the following sections, we walk through the steps to add Amazon Bedrock to your API as a data source and connect to it from your Amplify app:

Add Amazon Bedrock as a data source
Define a custom query
Configure custom business logic handler code
Invoke a custom query to prompt a generative AI model
Step 1 - Add Amazon Bedrock as a data source

To connect to Amazon Bedrock as a data source, you can choose between two methods - using a Lambda function or a custom resolver powered by AppSync JavaScript resolvers. The following steps demonstrate both methods:

Function
Custom resolver powered by AppSync JavaScript resolvers

In your amplify/backend.ts file, replace the content with the following code to add a lambda function to your backend and grant it permission to invoke a generative AI model in Amazon Bedrock. The generateHaikuFunction lambda function will be defined in and exported from the amplify/data/resource.ts file in the next steps:

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import { data, MODEL_ID, generateHaikuFunction } from "./data/resource";
import { Effect, PolicyStatement } from "aws-cdk-lib/aws-iam";


export const backend = defineBackend({
  auth,
  data,
  generateHaikuFunction,
});


backend.generateHaikuFunction.resources.lambda.addToRolePolicy(
  new PolicyStatement({
    effect: Effect.ALLOW,
    actions: ["bedrock:InvokeModel"],
    resources: [
      `arn:aws:bedrock:*::foundation-model/${MODEL_ID}`,
    ],
  })
);

For the purpose of this guide, we will use Anthropic's Claude 3 Haiku to generate content. If you want to use a different model, you can find the ID for your model of choice in the Amazon Bedrock documentation's list of model IDs or the Amazon Bedrock console and replace the value of MODEL_ID.

The availability of Amazon Bedrock and its foundation models may vary by region.

The policy statement in the code above assumes that your Amplify app is deployed in a region supported by Amazon Bedrock and the Claude 3 Haiku model. If you are deploying your app in a region where Amazon Bedrock is not available, update the code above accordingly.

For a list of supported regions please refer to the Amazon Bedrock documentation.

Step 2 - Define a custom query
Function
Custom resolver powered by AppSync JavaScript resolvers

Next, replace the contents of your amplify/data/resource.ts file with the following code. This will define and export a lambda function that was granted permission to invoke a generative AI model in Amazon Bedrock in the previous step. A custom query named generateHaiku is added to the schema with the generateHaikuFunction as the handler using the a.handler.function() modifier:

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
import {
  type ClientSchema,
  a,
  defineData,
  defineFunction,
} from "@aws-amplify/backend";


export const MODEL_ID = "anthropic.claude-3-haiku-20240307-v1:0";


export const generateHaikuFunction = defineFunction({
  entry: "./generateHaiku.ts",
  environment: {
    MODEL_ID,
  },
});


const schema = a.schema({
  generateHaiku: a
    .query()
    .arguments({ prompt: a.string().required() })
    .returns(a.string())
    .authorization((allow) => [allow.publicApiKey()])
    .handler(a.handler.function(generateHaikuFunction)),
});


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: "apiKey",
    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});
Step 3 - Configure custom business logic handler code
Function
Custom resolver powered by AppSync JavaScript resolvers

Next, create a generateHaiku.ts file in your amplify/data folder and use the following code to define a custom resolver for the custom query added to your schema in the previous step:

The following code uses the BedrockRuntimeClient from the @aws-sdk/client-bedrock-runtime package to invoke the generative AI model in Amazon Bedrock. The handler function takes the user prompt as an argument, invokes the model, and returns the generated haiku.

amplify/data/generateHaiku.ts
Copy
amplify/data/generateHaiku.ts code example
import type { Schema } from "./resource";
import {
  BedrockRuntimeClient,
  InvokeModelCommand,
  InvokeModelCommandInput,
} from "@aws-sdk/client-bedrock-runtime";


// initialize bedrock runtime client
const client = new BedrockRuntimeClient();


export const handler: Schema["generateHaiku"]["functionHandler"] = async (
  event,
  context
) => {
  // User prompt
  const prompt = event.arguments.prompt;


  // Invoke model
  const input = {
    modelId: process.env.MODEL_ID,
    contentType: "application/json",
    accept: "application/json",
    body: JSON.stringify({
      anthropic_version: "bedrock-2023-05-31",
      system:
        "You are a an expert at crafting a haiku. You are able to craft a haiku out of anything and therefore answer only in haiku.",
      messages: [
        {
          role: "user",
          content: [
            {
              type: "text",
              text: prompt,
            },
          ],
        },
      ],
      max_tokens: 1000,
      temperature: 0.5,
    }),
  } as InvokeModelCommandInput;


  const command = new InvokeModelCommand(input);


  const response = await client.send(command);


  // Parse the response and return the generated haiku
  const data = JSON.parse(Buffer.from(response.body).toString());


  return data.content[0].text;
};

The code above uses the Messages API, which is supported by chat models such as Anthropic's Claude 3 Haiku.

The system prompt is used to give the model a persona or directives to follow, and the messages array can contain a history of messages. The max_tokens parameter controls the maximum number of tokens the model can generate, and the temperature parameter determines the randomness, or creativity, of the generated response.

Step 4 - Invoke a custom query to prompt a generative AI model

From your generated Data client, you can find all your custom queries and mutations under the client.queries and client.mutations APIs respectively.

The custom query below will prompt a generative AI model to create a haiku based on the given prompt. Replace the prompt value with your desired prompt text or user input and invoke the query as shown below:

App.tsx
Copy
App.tsx code example
const { data, errors } = await client.queries.generateHaiku({
  prompt: "Frank Herbert's Dune",
});

Here's an example of a simple UI that prompts a generative AI model to create a haiku based on user input:

App.tsx
Copy
App.tsx code example
import { FormEvent, useState } from "react";


import { generateClient } from "aws-amplify/api";
import { Schema } from "@/amplify/data/resource";


import { Amplify } from "aws-amplify";
import outputs from "@/amplify_outputs.json";


Amplify.configure(outputs);


const client = generateClient<Schema>();


export default function App() {
  const [prompt, setPrompt] = useState<string>("");
  const [answer, setAnswer] = useState<string | null>(null);


  const sendPrompt = async (e: FormEvent<HTMLFormElement>) => {
    e.preventDefault();


    const { data, errors } = await client.queries.generateHaiku({
      prompt,
    });


    if (!errors) {
      setAnswer(data);
      setPrompt("");
    } else {
      console.log(errors);
    }
  };


  return (
    <main className="flex min-h-screen flex-col items-center justify-center p-24 dark:text-white">
      <div>
        <h1 className="text-3xl font-bold text-center mb-4">Haiku Generator</h1>


        <form className="mb-4 self-center max-w-[500px]" onSubmit={sendPrompt}>
          <input
            className="text-black p-2 w-full"
            placeholder="Enter a prompt..."
            name="prompt"
            value={prompt}
            onChange={(e) => setPrompt(e.target.value)}
          />
        </form>


        <div className="text-center">
          <pre>{answer}</pre>
        </div>
      </div>
    </main>
  );
}

Conclusion

In this guide, you learned how to connect to Amazon Bedrock from your Amplify app. By adding Bedrock as a data source, defining a custom query, configuring custom business logic handler code, and invoking custom queries, you can leverage the power of generative AI models in your application.

To clean up, you can delete your sandbox by accepting the prompt when terminating the sandbox process in your terminal. Alternatively, you can also use the AWS Amplify console to manage and delete sandbox environments.

PREVIOUS
Connect to Amazon Polly for Text-To-Speech APIs
NEXT
Connect to Amazon Rekognition for Image Analysis APIs

--------------------------------------------------------------------------------

Title: Connect to Amazon EventBridge to send and receive events - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/custom-business-logic/connect-eventbridge-datasource/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Add custom queries and mutations
/
Connect to Amazon EventBridge to send and receive events
Connect to Amazon EventBridge to send and receive events

Amazon EventBridge is a serverless event bus that simplifies how applications communicate with each other. It acts as a central hub for events generated by various sources, including AWS services, custom applications, and third-party SaaS providers.

EventBridge delivers this event data in real-time, allowing you to build applications that react swiftly to changes. You define rules to filter and route these events to specific destinations, known as targets. Targets can include services like AWS Lambda, Amazon SQS Queues, Amazon SNS Topics. For the purpose of this guide, we will use AWS AppSync as the target for events.

By adopting an event-driven architecture with EventBridge, you can achieve:

Loose Coupling: Applications become independent and communicate through events, improving scalability and maintainability.

Increased Resilience: System failures are isolated as events are delivered asynchronously, ensuring overall application availability.

Simplified Integration: EventBridge provides a unified interface for integrating diverse event sources, streamlining development.

This section will guide you through adding an event bus as a datasource to your API, defining routing rules, and configuring targets to build robust event-driven applications with AWS Amplify Gen 2 and Amazon EventBridge.

Set up your API
Add your Amazon EventBridge event bus as a data source
Define custom queries and mutations
Configure custom business logic handler code
Invoke custom mutations to send events to EventBridge
Subscribe to mutations invoked by EventBridge
Invoke mutations and trigger subscriptions from EventBridge
Step 1 - Set up your API

For the purpose of this guide, we will define an OrderStatusChange custom type that represents an order status change event. This type includes fields for the order ID, status, and message.

In your amplify/data/resource.ts file, use the following code to define an OrderStatusChange custom type and an OrderStatus enum, adding them to your schema:

amplify/data/resource.ts
import { type ClientSchema, a, defineData } from "@aws-amplify/backend";


const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
    })
    .authorization(allow => [allow.publicApiKey()]),
Copy
highlighted code example
  OrderStatus: a.enum(["OrderPending", "OrderShipped", "OrderDelivered"]),
  OrderStatusChange: a.customType({
    orderId: a.id().required(),
    status: a.ref("OrderStatus").required(),
    message: a.string().required(),
  }),
});


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: 'apiKey',
    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});

NOTE: At least one query is required for a schema to be valid. Otherwise, deployments will fail a schema error. The Amplify Data schema is auto-generated with a Todo model and corresponding queries under the hood. You can leave the Todo model in the schema until you add the first custom query to the schema in the next steps.

Step 2 - Add your Amazon EventBridge event bus as a data source

In your amplify/backend.ts file, use the following code to add the default event bus as a data source for your API:

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import { aws_events } from "aws-cdk-lib";
import {
  Effect,
  PolicyDocument,
  PolicyStatement,
  Role,
  ServicePrincipal,
} from "aws-cdk-lib/aws-iam";


export const backend = defineBackend({
  auth,
  data,
});


// Create a new stack for the EventBridge data source
const eventStack = backend.createStack("MyExternalDataSources");


// Reference or create an EventBridge EventBus
const eventBus = aws_events.EventBus.fromEventBusName(
  eventStack,
  "MyEventBus",
  "default"
);


// Add the EventBridge data source
Copy
highlighted code example
backend.data.addEventBridgeDataSource("MyEventBridgeDataSource", eventBus);


// Create a policy statement to allow invoking the AppSync API's mutations
const policyStatement = new PolicyStatement({
  effect: Effect.ALLOW,
  actions: ["appsync:GraphQL"],
  resources: [`${backend.data.resources.graphqlApi.arn}/types/Mutation/*`],
});


// Create a role for the EventBus to assume
const eventBusRole = new Role(eventStack, "AppSyncInvokeRole", {
  assumedBy: new ServicePrincipal("events.amazonaws.com"),
  inlinePolicies: {
    PolicyStatement: new PolicyDocument({
      statements: [policyStatement],
    }),
  },
});


// Create an EventBridge rule to route events to the AppSync API
const rule = new aws_events.CfnRule(eventStack, "MyOrderRule", {
  eventBusName: eventBus.eventBusName,
  name: "broadcastOrderStatusChange",
  eventPattern: {
    source: ["amplify.orders"],
    /* The shape of the event pattern must match EventBridge's event message structure.
    So, this field must be spelled as "detail-type". Otherwise, events will not trigger the rule.


    https://docs.aws.amazon.com/AmazonS3/latest/userguide/ev-events.html
    */
    ["detail-type"]: ["OrderStatusChange"],
    detail: {
      orderId: [{ exists: true }],
      status: ["PENDING", "SHIPPED", "DELIVERED"],
      message: [{ exists: true }],
    },
  },
  targets: [
    {
      id: "orderStatusChangeReceiver",
      arn: backend.data.resources.cfnResources.cfnGraphqlApi
        .attrGraphQlEndpointArn,
      roleArn: eventBusRole.roleArn,
      appSyncParameters: {
        graphQlOperation: `
        mutation PublishOrderFromEventBridge(
          $orderId: String!
          $status: String!
          $message: String!
        ) {
          publishOrderFromEventBridge(orderId: $orderId, status: $status, message: $message) {
            orderId
            status
            message
          }
        }`,
      },
      inputTransformer: {
        inputPathsMap: {
          orderId: "$.detail.orderId",
          status: "$.detail.status",
          message: "$.detail.message",
        },
        inputTemplate: JSON.stringify({
          orderId: "<orderId>",
          status: "<status>",
          message: "<message>",
        }),
      },
    },
  ],
});

The selection set returned by the mutation must match the selection set of the subscription. If the selection set of the mutation is different from the selection set of the subscription, the subscription will not receive the event.

In the code snippet above, the addEventBridgeDataSource method is used to add the default event bus as a data source to your API. This allows you to reference the event bus in your custom queries and mutations.

The CfnRule construct is used to create an EventBridge rule that routes events to the AppSync API. The rule specifies the event pattern to match and the target to invoke when the event is received. In this example, the target is an AppSync mutation named publishOrderFromEventBridge.

The appSyncParameters property specifies the mutation to invoke when the event is received. The inputTransformer property maps the event data to the mutation arguments.

Step 3 - Define custom queries and mutations

Now that your event bus has been added as a data source, you can reference it in custom queries and mutations using the a.handler.custom() modifier which accepts the name of the data source and an entry point for your resolver.

Use the following code to add publishOrderToEventBridge and publishOrderFromEventBridge custom mutations, and an onOrderStatusChange custom subscription to your schema:

amplify/data/resource.ts
import { type ClientSchema, a, defineData } from "@aws-amplify/backend";


const schema = a.schema({
  // ...
  OrderStatus: a.enum(["OrderPending", "OrderShipped", "OrderDelivered"]),
  OrderStatusChange: a.customType({
    orderId: a.id().required(),
    status: a.ref("OrderStatus").required(),
    message: a.string().required(),
  }),
Copy
highlighted code example
  publishOrderToEventBridge: a
    .mutation()
    .arguments({
      orderId: a.id().required(),
      status: a.string().required(),
      message: a.string().required(),
    })
    .returns(a.ref("OrderStatusChange"))
    .authorization((allow) => [allow.publicApiKey()])
    .handler(
      a.handler.custom({
        dataSource: "EventBridgeDataSource",
        entry: "./publishOrderToEventBridge.js",
      })
    ),
  publishOrderFromEventBridge: a
    .mutation()
    .arguments({
      orderId: a.id().required(),
      status: a.string().required(),
      message: a.string().required(),
    })
    .returns(a.ref("OrderStatusChange"))
    .authorization((allow) => [allow.publicApiKey(), allow.guest()])
    .handler(
      a.handler.custom({
        entry: "./publishOrderFromEventBridge.js",
      })
    ),
  onOrderFromEventBridge: a
    .subscription()
    .for(a.ref("publishOrderFromEventBridge"))
    .authorization((allow) => [allow.publicApiKey()])
    .handler(
      a.handler.custom({
        entry: "./onOrderFromEventBridge.js",
      })
    ),
});


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema,
  name: "MyLibrary",
  authorizationModes: {
    defaultAuthorizationMode: "apiKey",
    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});

In the code snippet above:

The publishOrderToEventBridge custom mutation uses an EventBridge data source and so it is able to publish events to the event bus from its resolver.

The publishOrderFromEventBridge custom mutation uses a None data source as a passthrough and is invoked by the EventBridge rule when an event is received that matches the rule pattern. The allow.guest rule uses IAM under the hood and allows the mutation to be invoked by the EventBridge rule.

The onOrderFromEventBridge custom subscription can be triggered either by EventBridge invoking the publishOrderFromEventBridge mutation or by a client invoking the publishOrderToEventBridge mutation.

Step 4 - Configure custom business logic handler code

Next, create the following files in your amplify/data folder and use the code examples to define custom resolvers for the custom queries and mutations added to your schema from the previous step. These are AppSync JavaScript resolvers

Subscription
Publish Order to EventBridge
Publish Order From EventBridge

The following code defines the custom business logic handler for the onOrderStatusChange subscription. Since the subscription uses a None data source the response function is empty as the subscription does not require any additional processing.

amplify/data/onOrderStatusChange.js
Copy
amplify/data/onOrderStatusChange.js code example
export function request(ctx) {
  return {
    payload: {},
  };
}


export function response(ctx) {
}
Step 5 - Invoke custom mutations to send events to EventBridge

From your generated Data client, you can find all your custom queries and mutations under the client.queries and client.mutations APIs respectively.

The custom mutation below will publish an order status change event to the event bus:

App.tsx
Copy
App.tsx code example
await client.mutations.publishOrderToEventBridge({
  orderId: "12345",
  status: "SHIPPED",
  message: "Order has been shipped",
});
Step 6 - Subscribe to mutations invoked by EventBridge

To subscribe to events from your event bus, you can use the client.subscriptions API:

App.tsx
Copy
App.tsx code example
// Subscribe to the mutations triggered by the EventBridge rule
const sub = client.subscriptions.onOrderStatusChange().subscribe({
  next: (data) => {
    console.log(data);
  },
});


//...


// Clean up subscription
sub.unsubscribe();
Step 7 - Invoke a mutation and trigger a subscription from EventBridge

You can test your custom mutation and subscriptions by using the EventBridge console to send an event which will invoke the custom mutation. You can then observe the results from the subscription being triggered:

Navigate to the Amazon EventBridge console and choose "Send Events"

Fill out the form, specifying the event source to be amplify.orders and the detail-type to be OrderStatusChange.

Choose "Send" and observe the subscription output in the AppSync Queries console.

Conclusion

In this guide, you’ve added an Amazon EventBridge event bus as a data source to an Amplify API and defined custom queries and mutations to publish and receive events from the event bus. You’ve also configured custom business logic handler code to handle the event data and invoke the appropriate mutations.

To clean up, you can delete your sandbox by accepting the prompt when terminating the sandbox process in your terminal. Alternatively, you can also use the AWS Amplify console to manage and delete sandbox environments.

PREVIOUS
Connect to Amazon OpenSearch for search and aggregate queries
NEXT
Connect to Amazon Polly for Text-To-Speech APIs

--------------------------------------------------------------------------------

Title: Connect to Amazon OpenSearch for search and aggregate queries - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/custom-business-logic/search-and-aggregate-queries/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Add custom queries and mutations
/
Connect to Amazon OpenSearch for search and aggregate queries
Connect to Amazon OpenSearch for search and aggregate queries

Amazon OpenSearch Service provides a managed platform for deploying search and analytics solutions with OpenSearch or Elasticsearch. The zero-ETL integration between Amazon DynamoDB and OpenSearch Service allows seamless search on DynamoDB data by automatically replicating and transforming it without requiring custom code or infrastructure. This integration simplifies processes and reduces the operational workload of managing data pipelines.

DynamoDB users gain access to advanced OpenSearch features like full-text search, fuzzy search, auto-complete, and vector search for machine learning capabilities. Amazon OpenSearch Ingestion synchronizes data between DynamoDB and OpenSearch Service, enabling near-instant updates and comprehensive insights across multiple DynamoDB tables. Developers can adjust index mapping templates to match Amazon DynamoDB fields with OpenSearch Service indexes.

Amazon OpenSearch Ingestion, combined with S3 exports and DynamoDB streams, facilitates seamless data input from DynamoDB tables and automatic ingestion into OpenSearch. Additionally, the pipeline can back up data to S3 for potential future re-ingestion as needed.

Step 1: Setup the project

Begin by setting up your project by following the instructions in the Quickstart guide. For the purpose of this guide, we'll sync a Todo table from DynamoDB to OpenSearch.

Firstly, add the Todo model to your schema:

amplify/data/resource.ts
import { type ClientSchema, a, defineData } from "@aws-amplify/backend";


const schema = a.schema({
Copy
highlighted code example
  Todo: a
    .model({
      content: a.string(),
      done: a.boolean(),
      priority: a.enum(["low", "medium", "high"]),
    })
    .authorization((allow) => [allow.publicApiKey()])
});


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: "apiKey",
    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});

Important considerations:

Ensure Point in Time Recovery (PITR) is enabled, which is crucial for the pipeline integration. Enable DynamoDB streams to capture item changes that will be ingested into OpenSearch.

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import { data } from "./data/resource";
Copy
highlighted code example
import * as dynamodb from "aws-cdk-lib/aws-dynamodb";


const backend = defineBackend({
  auth,
  data,
});


Copy
highlighted code example
const todoTable =
  backend.data.resources.cfnResources.amplifyDynamoDbTables["Todo"];


// Update table settings
todoTable.pointInTimeRecoveryEnabled = true;


todoTable.streamSpecification = {
  streamViewType: dynamodb.StreamViewType.NEW_IMAGE,
};


// Get the DynamoDB table ARN
const tableArn = backend.data.resources.tables["Todo"].tableArn;
// Get the DynamoDB table name
const tableName = backend.data.resources.tables["Todo"].tableName;
Step 2: Setting Up the OpenSearch Instance

Create an OpenSearch instance with encryption.

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import { data } from "./data/resource";
Copy
highlighted code example
import * as opensearch from "aws-cdk-lib/aws-opensearchservice";
import {  Stack } from "aws-cdk-lib";


const todoTable =
  backend.data.resources.cfnResources.amplifyDynamoDbTables["Todo"];


// Update table settings
todoTable.pointInTimeRecoveryEnabled = true;


todoTable.streamSpecification = {
  streamViewType: dynamodb.StreamViewType.NEW_IMAGE,
};


// Get the DynamoDB table ARN
const tableArn = backend.data.resources.tables["Todo"].tableArn;
// Get the DynamoDB table name
const tableName = backend.data.resources.tables["Todo"].tableName;


Copy
highlighted code example
// Get the data stack
const dataStack = Stack.of(backend.data);


// Create the OpenSearch domain
const openSearchDomain = new opensearch.Domain(
  dataStack,
  "OpenSearchDomain",
  {
    version: opensearch.EngineVersion.OPENSEARCH_2_11,
    nodeToNodeEncryption: true,
    encryptionAtRest: {
      enabled: true,
    },
  }
);
Step 3: Setting Up Zero ETL from DynamoDB to OpenSearch
Step 3a: Setup Storage and IAM Role

Establish Storage to back up raw events consumed by the OpenSearch pipeline. Generate a file named amplify/storage/resource.ts and insert the provided content to set up a storage resource. Tailor your storage configurations to regulate access to different paths within your storage bucket.

amplify/storage/resource.ts
Copy
amplify/storage/resource.ts code example
import { defineStorage } from "@aws-amplify/backend"


export const storage = defineStorage({
  name: "opensearch-backup-bucket-amplify-gen-2",
  access: allow => ({
    'public/*': [
      allow.guest.to(['list', 'write', 'get'])
    ]
  })
})

Get the s3BucketArn and s3BucketName values from storage resource as shown below. Additionally, configure an IAM role for the pipeline and assign the roles as indicated below. For further information on the required IAM roles, please refer to the Setting up roles and users documentation.

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import * as dynamodb from "aws-cdk-lib/aws-dynamodb";
import * as opensearch from "aws-cdk-lib/aws-opensearchservice";
import { Stack } from "aws-cdk-lib";


Copy
highlighted code example
import { storage } from "./storage/resource";
import * as iam from "aws-cdk-lib/aws-iam";


// Define backend resources
const backend = defineBackend({
  auth,
  data,
Copy
highlighted code example
  storage,
});


const todoTable =
  backend.data.resources.cfnResources.amplifyDynamoDbTables["Todo"];


// Update table settings
todoTable.pointInTimeRecoveryEnabled = true;


todoTable.streamSpecification = {
  streamViewType: dynamodb.StreamViewType.NEW_IMAGE,
};


// Get the DynamoDB table ARN
const tableArn = backend.data.resources.tables["Todo"].tableArn;
// Get the DynamoDB table name
const tableName = backend.data.resources.tables["Todo"].tableName;


// Get the data stack
const dataStack = Stack.of(backend.data);


// Create the OpenSearch domain
const openSearchDomain = new opensearch.Domain(
  dataStack,
  "OpenSearchDomain",
  {
    version: opensearch.EngineVersion.OPENSEARCH_2_11,
    nodeToNodeEncryption: true,
    encryptionAtRest: {
      enabled: true,
    },
  }
);
Copy
highlighted code example
// Get the S3Bucket ARN
const s3BucketArn = backend.storage.resources.bucket.bucketArn;
// Get the S3Bucket Name
const s3BucketName = backend.storage.resources.bucket.bucketName;


//Get the region
const region = dataStack.region;


// Create an IAM role for OpenSearch integration
const openSearchIntegrationPipelineRole = new iam.Role(
  dataStack,
  "OpenSearchIntegrationPipelineRole",
  {
    assumedBy: new iam.ServicePrincipal("osis-pipelines.amazonaws.com"),
    inlinePolicies: {
      openSearchPipelinePolicy: new iam.PolicyDocument({
        statements: [
          new iam.PolicyStatement({
            actions: ["es:DescribeDomain"],
            resources: [
              openSearchDomain.domainArn,
              openSearchDomain.domainArn + "/*",
            ],
            effect: iam.Effect.ALLOW,
          }),
          new iam.PolicyStatement({
            actions: ["es:ESHttp*"],
            resources: [
              openSearchDomain.domainArn,
              openSearchDomain.domainArn + "/*",
            ],
            effect: iam.Effect.ALLOW,
          }),
          new iam.PolicyStatement({
            effect: iam.Effect.ALLOW,
            actions: [
              "s3:GetObject",
              "s3:AbortMultipartUpload",
              "s3:PutObject",
              "s3:PutObjectAcl",
            ],
            resources: [s3BucketArn, s3BucketArn + "/*"],
          }),
          new iam.PolicyStatement({
            effect: iam.Effect.ALLOW,
            actions: [
              "dynamodb:DescribeTable",
              "dynamodb:DescribeContinuousBackups",
              "dynamodb:ExportTableToPointInTime",
              "dynamodb:DescribeExport",
              "dynamodb:DescribeStream",
              "dynamodb:GetRecords",
              "dynamodb:GetShardIterator",
            ],
            resources: [tableArn, tableArn + "/*"],
          }),
        ],
      }),
    },
    managedPolicies: [
      iam.ManagedPolicy.fromAwsManagedPolicyName(
        "AmazonOpenSearchIngestionFullAccess"
      ),
    ],
  }
);

For the S3 bucket, follow standard security practices: block public access, encrypt data at rest, and enable versioning.

The IAM role should allow the OpenSearch Ingestion Service (OSIS) pipelines to assume it. Grant specific OpenSearch Service permissions and also provide DynamoDB and S3 access. You may customize permissions to follow the principle of least privilege.

Step 3b: OpenSearch Service Pipeline

Define the pipeline construct and its configuration.

When using OpenSearch, you can define the index template or mapping in advance based on your data structure, which allows you to set data types for each field in the document. This approach can be incredibly powerful for precise data ingestion and search. For more information on index mapping/templates, please refer to OpenSearch documentation.

Customize the template_content JSON-representation to define the data structure for the ingestion pipeline.

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import * as dynamodb from "aws-cdk-lib/aws-dynamodb";
import * as opensearch from "aws-cdk-lib/aws-opensearchservice";
import { Stack } from "aws-cdk-lib"; 
import { storage } from "./storage/resource";
import * as iam from "aws-cdk-lib/aws-iam";
 
// Define backend resources
const backend = defineBackend({
  auth,
  data,
  storage,
});


const todoTable =
  backend.data.resources.cfnResources.amplifyDynamoDbTables["Todo"];


// Update table settings
todoTable.pointInTimeRecoveryEnabled = true;


todoTable.streamSpecification = {
  streamViewType: dynamodb.StreamViewType.NEW_IMAGE,
};


// Get the DynamoDB table ARN
const tableArn = backend.data.resources.tables["Todo"].tableArn;
// Get the DynamoDB table name
const tableName = backend.data.resources.tables["Todo"].tableName;


// Get the data stack
const dataStack = Stack.of(backend.data);


// Create the OpenSearch domain
const openSearchDomain = new opensearch.Domain(
  dataStack,
  "OpenSearchDomain",
  {
    version: opensearch.EngineVersion.OPENSEARCH_2_11,
    nodeToNodeEncryption: true,
    encryptionAtRest: {
      enabled: true,
    },
  }
);


// Get the S3Bucket ARN
const s3BucketArn = backend.storage.resources.bucket.bucketArn;
// Get the S3Bucket Name
const s3BucketName = backend.storage.resources.bucket.bucketName;


//Get the region
const region = dataStack.region;


// Create an IAM role for OpenSearch integration
const openSearchIntegrationPipelineRole = new iam.Role(
  dataStack,
  "OpenSearchIntegrationPipelineRole",
  {
    assumedBy: new iam.ServicePrincipal("osis-pipelines.amazonaws.com"),
    inlinePolicies: {
      openSearchPipelinePolicy: new iam.PolicyDocument({
        statements: [
          new iam.PolicyStatement({
            actions: ["es:DescribeDomain"],
            resources: [
              openSearchDomain.domainArn,
              openSearchDomain.domainArn + "/*",
            ],
            effect: iam.Effect.ALLOW,
          }),
          new iam.PolicyStatement({
            actions: ["es:ESHttp*"],
            resources: [
              openSearchDomain.domainArn,
              openSearchDomain.domainArn + "/*",
            ],
            effect: iam.Effect.ALLOW,
          }),
          new iam.PolicyStatement({
            effect: iam.Effect.ALLOW,
            actions: [
              "s3:GetObject",
              "s3:AbortMultipartUpload",
              "s3:PutObject",
              "s3:PutObjectAcl",
            ],
            resources: [s3BucketArn, s3BucketArn + "/*"],
          }),
          new iam.PolicyStatement({
            effect: iam.Effect.ALLOW,
            actions: [
              "dynamodb:DescribeTable",
              "dynamodb:DescribeContinuousBackups",
              "dynamodb:ExportTableToPointInTime",
              "dynamodb:DescribeExport",
              "dynamodb:DescribeStream",
              "dynamodb:GetRecords",
              "dynamodb:GetShardIterator",
            ],
            resources: [tableArn, tableArn + "/*"],
          }),
        ],
      }),
    },
    managedPolicies: [
      iam.ManagedPolicy.fromAwsManagedPolicyName(
        "AmazonOpenSearchIngestionFullAccess"
      ),
    ],
  }
);


Copy
highlighted code example


// Define OpenSearch index mappings
const indexName = "todo";


const indexMapping = {
  settings: {
    number_of_shards: 1,
    number_of_replicas: 0,
  },
  mappings: {
    properties: {
      id: {
        type: "keyword",
      },
      isDone: {
        type: "boolean",
      },
      content: {
        type: "text",
      },
    },
  },
};

The configuration is a data-prepper feature of OpenSearch. For specific documentation on DynamoDB configuration, refer to OpenSearch data-prepper documentation.

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import * as dynamodb from "aws-cdk-lib/aws-dynamodb";
import * as opensearch from "aws-cdk-lib/aws-opensearchservice";
import { Stack } from "aws-cdk-lib"; 
import { storage } from "./storage/resource";
import * as iam from "aws-cdk-lib/aws-iam";
 
// Define backend resources
const backend = defineBackend({
  auth,
  data,
  storage,
});


const todoTable =
  backend.data.resources.cfnResources.amplifyDynamoDbTables["Todo"];


// Update table settings
todoTable.pointInTimeRecoveryEnabled = true;


todoTable.streamSpecification = {
  streamViewType: dynamodb.StreamViewType.NEW_IMAGE,
};


// Get the DynamoDB table ARN
const tableArn = backend.data.resources.tables["Todo"].tableArn;
// Get the DynamoDB table name
const tableName = backend.data.resources.tables["Todo"].tableName;


// Get the data stack
const dataStack = Stack.of(backend.data);


// Create the OpenSearch domain
const openSearchDomain = new opensearch.Domain(
  dataStack,
  "OpenSearchDomain",
  {
    version: opensearch.EngineVersion.OPENSEARCH_2_11,
    nodeToNodeEncryption: true,
    encryptionAtRest: {
      enabled: true,
    },
  }
);


// Get the S3Bucket ARN
const s3BucketArn = backend.storage.resources.bucket.bucketArn;
// Get the S3Bucket Name
const s3BucketName = backend.storage.resources.bucket.bucketName;


//Get the region
const region = dataStack.region;


// Create an IAM role for OpenSearch integration
const openSearchIntegrationPipelineRole = new iam.Role(
  dataStack,
  "OpenSearchIntegrationPipelineRole",
  {
    assumedBy: new iam.ServicePrincipal("osis-pipelines.amazonaws.com"),
    inlinePolicies: {
      openSearchPipelinePolicy: new iam.PolicyDocument({
        statements: [
          new iam.PolicyStatement({
            actions: ["es:DescribeDomain"],
            resources: [
              openSearchDomain.domainArn,
              openSearchDomain.domainArn + "/*",
            ],
            effect: iam.Effect.ALLOW,
          }),
          new iam.PolicyStatement({
            actions: ["es:ESHttp*"],
            resources: [
              openSearchDomain.domainArn,
              openSearchDomain.domainArn + "/*",
            ],
            effect: iam.Effect.ALLOW,
          }),
          new iam.PolicyStatement({
            effect: iam.Effect.ALLOW,
            actions: [
              "s3:GetObject",
              "s3:AbortMultipartUpload",
              "s3:PutObject",
              "s3:PutObjectAcl",
            ],
            resources: [s3BucketArn, s3BucketArn + "/*"],
          }),
          new iam.PolicyStatement({
            effect: iam.Effect.ALLOW,
            actions: [
              "dynamodb:DescribeTable",
              "dynamodb:DescribeContinuousBackups",
              "dynamodb:ExportTableToPointInTime",
              "dynamodb:DescribeExport",
              "dynamodb:DescribeStream",
              "dynamodb:GetRecords",
              "dynamodb:GetShardIterator",
            ],
            resources: [tableArn, tableArn + "/*"],
          }),
        ],
      }),
    },
    managedPolicies: [
      iam.ManagedPolicy.fromAwsManagedPolicyName(
        "AmazonOpenSearchIngestionFullAccess"
      ),
    ],
  }
);


// Define OpenSearch index mappings
const indexName = "todo";


const indexMapping = {
  settings: {
    number_of_shards: 1,
    number_of_replicas: 0,
  },
  mappings: {
    properties: {
      id: {
        type: "keyword",
      },
      isDone: {
        type: "boolean",
      },
      content: {
        type: "text",
      },
      priority: {
        type: "text",
      },
    },
  },
};


Copy
highlighted code example


// OpenSearch template definition
const openSearchTemplate = `
version: "2"
dynamodb-pipeline:
  source:
    dynamodb:
      acknowledgments: true
      tables:
        - table_arn: "${tableArn}"
          stream:
            start_position: "LATEST"
          export:
            s3_bucket: "${s3BucketName}"
            s3_region: "${region}"
            s3_prefix: "${tableName}/"
      aws:
        sts_role_arn: "${openSearchIntegrationPipelineRole.roleArn}"
        region: "${region}"
  sink:
    - opensearch:
        hosts:
          - "https://${openSearchDomain.domainEndpoint}"
        index: "${indexName}"
        index_type: "custom"
        template_content: |
          ${JSON.stringify(indexMapping)}
        document_id: '\${getMetadata("primary_key")}'
        action: '\${getMetadata("opensearch_action")}'
        document_version: '\${getMetadata("document_version")}'
        document_version_type: "external"
        bulk_size: 4
        aws:
          sts_role_arn: "${openSearchIntegrationPipelineRole.roleArn}"
          region: "${region}"
`;

This configuration defines the desired behavior of the pipeline for a single model.

In the source configuration, DynamoDB is specified as the data source, along with the target table for ingestion and the starting point of the stream. Additionally, besides ingesting the stream into OpenSearch, a target S3 bucket is defined for backup purposes. Furthermore, an IAM role is set for the ingestion pipeline, ensuring it possesses the necessary permissions and policies as detailed in the documentation.

Regarding the sink configuration, the OpenSearch domain cluster is specified by setting the host, index name, type, and template content (index mapping) for data formatting. Document-related metadata is configured along with the maximum bulk size for requests to OpenSearch in MB. Once again, an IAM role is specified for the sink portion of the pipeline. For further details on Sink configuration, please refer to the OpenSearch documentation.

The sink configuration is an array. To create a different index on the same table, you can achieve this by adding a second OpenSearch configuration to the sink array.

To index multiple tables, you'll need to configure multiple pipelines in the configuration. For further guidance, please consult the pipeline section of the OpenSearch documentation.

NOTE: An OpenSearch Ingestion pipeline supports only one DynamoDB table as its source. For more details on current limitations, Please refer to Amazon OpenSearch Limitation section.

Now, create the OSIS pipeline resource:

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import * as dynamodb from "aws-cdk-lib/aws-dynamodb";
import * as opensearch from "aws-cdk-lib/aws-opensearchservice";
import { Stack } from "aws-cdk-lib"; 
import { storage } from "./storage/resource";
import * as iam from "aws-cdk-lib/aws-iam";
Copy
highlighted code example
import * as osis from "aws-cdk-lib/aws-osis";
import * as logs from "aws-cdk-lib/aws-logs";
import { RemovalPolicy } from "aws-cdk-lib"; 
// Define backend resources
const backend = defineBackend({
  auth,
  data,
  storage,
});


const todoTable =
  backend.data.resources.cfnResources.amplifyDynamoDbTables["Todo"];


// Update table settings
todoTable.pointInTimeRecoveryEnabled = true;


todoTable.streamSpecification = {
  streamViewType: dynamodb.StreamViewType.NEW_IMAGE,
};


// Get the DynamoDB table ARN
const tableArn = backend.data.resources.tables["Todo"].tableArn;
// Get the DynamoDB table name
const tableName = backend.data.resources.tables["Todo"].tableName;


// Get the data stack
const dataStack = Stack.of(backend.data);


// Create the OpenSearch domain
const openSearchDomain = new opensearch.Domain(
  dataStack,
  "OpenSearchDomain",
  {
    version: opensearch.EngineVersion.OPENSEARCH_2_11,
    nodeToNodeEncryption: true,
    encryptionAtRest: {
      enabled: true,
    },
  }
);


// Get the S3Bucket ARN
const s3BucketArn = backend.storage.resources.bucket.bucketArn;
// Get the S3Bucket Name
const s3BucketName = backend.storage.resources.bucket.bucketName;


//Get the region
const region = dataStack.region;


// Create an IAM role for OpenSearch integration
const openSearchIntegrationPipelineRole = new iam.Role(
  dataStack,
  "OpenSearchIntegrationPipelineRole",
  {
    assumedBy: new iam.ServicePrincipal("osis-pipelines.amazonaws.com"),
    inlinePolicies: {
      openSearchPipelinePolicy: new iam.PolicyDocument({
        statements: [
          new iam.PolicyStatement({
            actions: ["es:DescribeDomain"],
            resources: [
              openSearchDomain.domainArn,
              openSearchDomain.domainArn + "/*",
            ],
            effect: iam.Effect.ALLOW,
          }),
          new iam.PolicyStatement({
            actions: ["es:ESHttp*"],
            resources: [
              openSearchDomain.domainArn,
              openSearchDomain.domainArn + "/*",
            ],
            effect: iam.Effect.ALLOW,
          }),
          new iam.PolicyStatement({
            effect: iam.Effect.ALLOW,
            actions: [
              "s3:GetObject",
              "s3:AbortMultipartUpload",
              "s3:PutObject",
              "s3:PutObjectAcl",
            ],
            resources: [s3BucketArn, s3BucketArn + "/*"],
          }),
          new iam.PolicyStatement({
            effect: iam.Effect.ALLOW,
            actions: [
              "dynamodb:DescribeTable",
              "dynamodb:DescribeContinuousBackups",
              "dynamodb:ExportTableToPointInTime",
              "dynamodb:DescribeExport",
              "dynamodb:DescribeStream",
              "dynamodb:GetRecords",
              "dynamodb:GetShardIterator",
            ],
            resources: [tableArn, tableArn + "/*"],
          }),
        ],
      }),
    },
    managedPolicies: [
      iam.ManagedPolicy.fromAwsManagedPolicyName(
        "AmazonOpenSearchIngestionFullAccess"
      ),
    ],
  }
);


// Define OpenSearch index mappings
const indexName = "todo";


const indexMapping = {
  settings: {
    number_of_shards: 1,
    number_of_replicas: 0,
  },
  mappings: {
    properties: {
      id: {
        type: "keyword",
      },
      isDone: {
        type: "boolean",
      },
      content: {
        type: "text",
      },
      priority: {
        type: "text",
      },
    },
  },
};


// OpenSearch template definition
const openSearchTemplate = `
version: "2"
dynamodb-pipeline:
  source:
    dynamodb:
      acknowledgments: true
      tables:
        - table_arn: "${tableArn}"
          stream:
            start_position: "LATEST"
          export:
            s3_bucket: "${s3BucketName}"
            s3_region: "${region}"
            s3_prefix: "${tableName}/"
      aws:
        sts_role_arn: "${openSearchIntegrationPipelineRole.roleArn}"
        region: "${region}"
  sink:
    - opensearch:
        hosts:
          - "https://${openSearchDomain.domainEndpoint}"
        index: "${indexName}"
        index_type: "custom"
        template_content: |
          ${JSON.stringify(indexMapping)}
        document_id: '\${getMetadata("primary_key")}'
        action: '\${getMetadata("opensearch_action")}'
        document_version: '\${getMetadata("document_version")}'
        document_version_type: "external"
        bulk_size: 4
        aws:
          sts_role_arn: "${openSearchIntegrationPipelineRole.roleArn}"
          region: "${region}"
`;


Copy
highlighted code example
// Create a CloudWatch log group
const logGroup = new logs.LogGroup(dataStack, "LogGroup", {
  logGroupName: "/aws/vended-logs/OpenSearchService/pipelines/1",
  removalPolicy: RemovalPolicy.DESTROY,
});


// Create an OpenSearch Integration Service pipeline
const cfnPipeline = new osis.CfnPipeline(
  dataStack,
  "OpenSearchIntegrationPipeline",
  {
    maxUnits: 4,
    minUnits: 1,
    pipelineConfigurationBody: openSearchTemplate,
    pipelineName: "dynamodb-integration-2",
    logPublishingOptions: {
      isLoggingEnabled: true,
      cloudWatchLogDestination: {
        logGroup: logGroup.logGroupName,
      },
    },
  }
);



After deploying the resources, you can test the data ingestion process by adding an item to the Todo table. However, before doing that, let's verify that the pipeline has been set up correctly.

In the AWS console, navigate to OpenSearch and then to the pipelines section. You should find your configured pipeline and review its settings to ensure they match your expectations:

You can also check this in the DynamoDB console by going to the Integrations section of the tables.

Step 4: Expose new queries on OpenSearch
Step 4a:Add OpenSearch Datasource to backend

First, Add the OpenSearch data source to the data backend. Add the following code to the end of the amplify/backend.ts file.

amplify/backend.ts
Copy
amplify/backend.ts code example
// Add OpenSearch data source 
const osDataSource = backend.data.addOpenSearchDataSource(
  "osDataSource",
  openSearchDomain
);
Step 4b: Create Resolver and attach to query

Let's create the search resolver. Create a new file named amplify/data/searchTodoResolver.js and paste the following code. For additional details please refer to Amazon OpenSearch Service Resolvers

amplify/data/searchTodoResolver.js
Copy
amplify/data/searchTodoResolver.js code example
import { util } from "@aws-appsync/utils";


/**
 * Searches for documents by using an input term
 * @param {import('@aws-appsync/utils').Context} ctx the context
 * @returns {*} the request
 */


export function request(ctx) {
  return {
    operation: "GET",
    path: "/todo/_search",
  };
}


/**
 * Returns the fetched items
 * @param {import('@aws-appsync/utils').Context} ctx the context
 * @returns {*} the result
 */


export function response(ctx) {
  if (ctx.error) {
    util.error(ctx.error.message, ctx.error.type);
  }
  return ctx.result.hits.hits.map((hit) => hit._source);
}
Step 4c: Add the AppSync Resolver for the Search Query

Update the schema and add a searchTodo query.

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
      done: a.boolean(),
      priority: a.enum(["low", "medium", "high"]),
    })
    .authorization((allow) => [allow.publicApiKey()]),


Copy
highlighted code example
    searchTodos: a
    .query()
    .returns(a.ref("Todo").array())
    .authorization((allow) => [allow.publicApiKey()])
    .handler(
      a.handler.custom({
        entry: "./searchTodoResolver.js",
        dataSource: "osDataSource",
      })
    ),


});

Once you've deployed the resources, you can verify the changes by checking the AppSync console. Run the 'searchTodo' query and review the results to confirm their accuracy.

NEXT
Connect to Amazon EventBridge to send and receive events

--------------------------------------------------------------------------------

Title: Add custom queries and mutations - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/custom-business-logic/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Add custom queries and mutations
Add custom queries and mutations

The a.model() data model provides a solid foundation for querying, mutating, and fetching data. However, you may need additional customizations to meet specific requirements around custom API requests, response formatting, and/or fetching from external data sources.

In the following sections, we walk through the three steps to create a custom query or mutation:

Define a custom query or mutation
Configure custom business logic handler code
Invoke the custom query or mutation
Step 1 - Define a custom query or mutation
Type	When to choose
Query	When the request only needs to read data and will not modify any backend data
Mutation	When the request will modify backend data

For every custom query or mutation, you need to set a return type and, optionally, arguments. Use a.query() or a.mutation() to define your custom query or mutation in your amplify/data/resource.ts file:

Custom query
Custom mutation
Copy
code example
import { type ClientSchema, a, defineData } from '@aws-amplify/backend';


const schema = a.schema({
  // 1. Define your return type as a custom type
  EchoResponse: a.customType({
    content: a.string(),
    executionDuration: a.float()
  }),


  // 2. Define your query with the return type and, optionally, arguments
  echo: a
    .query()
    // arguments that this query accepts
    .arguments({
      content: a.string()
    })
    // return type of the query
    .returns(a.ref('EchoResponse'))
    // only allow signed-in users to call this API
    .authorization(allow => [allow.authenticated()])
});


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema
});
Step 2 - Configure custom business logic handler code

After your query or mutation is defined, you need to author your custom business logic. You can either define it in a function or using a custom resolver powered by AppSync JavaScript resolver.

Function
Custom resolver powered by AppSync JavaScript resolvers

In your amplify/data/echo-handler/ folder, create a handler.ts file. You can import a utility type for your function handler via the Schema type from your backend resource. This gives you type-safe handler parameters and return values.

amplify/data/echo-handler/handler.ts
Copy
amplify/data/echo-handler/handler.ts code example
import type { Schema } from '../resource'


export const handler: Schema["echo"]["functionHandler"] = async (event, context) => {
  const start = performance.now();
  return {
    content: `Echoing content: ${event.arguments.content}`,
    executionDuration: performance.now() - start
  };
};

In your amplify/data/resource.ts file, define the function using defineFunction and then reference the function with your query or mutation using a.handler.function() as a handler.

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
import {
  type ClientSchema,
  a,
  defineData,
  defineFunction // 1.Import "defineFunction" to create new functions
} from '@aws-amplify/backend';


// 2. define a function
const echoHandler = defineFunction({
  entry: './echo-handler/handler.ts'
})


const schema = a.schema({
  EchoResponse: a.customType({
    content: a.string(),
    executionDuration: a.float()
  }),


  echo: a
    .query()
    .arguments({ content: a.string() })
    .returns(a.ref('EchoResponse'))
    .authorization(allow => [allow.publicApiKey()])
    // 3. set the function has the handler
    .handler(a.handler.function(echoHandler))
});


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: 'apiKey',
    apiKeyAuthorizationMode: {
      expiresInDays: 30
    },
  },
});

All handlers must be of the same type. For example, you can't mix and match a.handler.function with a.handler.custom within a single .handler() modifier.

Step 3 - Invoke the custom query or mutation

From your generated Data client, you can find all your custom queries and mutations under the client.queries. and client.mutations. APIs respectively.

Custom query
Custom mutation
Copy
code example
const { data, errors } = await client.queries.echo({
  content: 'hello world!!!'
});
PREVIOUS
Customize your auth rules
NEXT
Working with files/attachments

--------------------------------------------------------------------------------

Title: Grant Lambda function access to API and Data - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/customize-authz/grant-lambda-function-access-to-api/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Customize your auth rules
/
Grant Lambda function access to API and Data
Grant Lambda function access to API and Data

Function access to defineData can be configured using an authorization rule on the schema object.

amplify/data/resource.ts
import {
  a,
  defineData,
  defineFunction,
  type ClientSchema
} from '@aws-amplify/backend';


const functionWithDataAccess = defineFunction({
  entry: '../functions/data-access.ts'
});


const schema = a
  .schema({
    Todo: a.model({
      name: a.string(),
      description: a.string()
    })
  })
Copy
highlighted code example
  .authorization(allow => [allow.resource(functionWithDataAccess)]);


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema
});

The object returned from defineFunction can be passed directly to allow.resource() in the schema authorization rules. This will grant the function the ability to execute Query, Mutation, and Subscription operations against the GraphQL API. Use the .to() method to narrow down access to one or more operations.

const schema = a
  .schema({
    Todo: a.model({
      name: a.string(),
      description: a.string()
    })
  })
Copy
highlighted code example
  .authorization(allow => [
    allow.resource(functionWithDataAccess).to(['query', 'listen'])
  ]); // allow query and subscription operations but not mutations

When configuring function access, the function will be provided the API endpoint as an environment variable named <defineDataName>_GRAPHQL_ENDPOINT, where defineDataName is transformed to SCREAMING_SNAKE_CASE. The default name is AMPLIFY_DATA_GRAPHQL_ENDPOINT unless you have specified a different name in defineData.

Function access can only be configured on the schema object. It cannot be configured on individual models or fields.

Access the API using aws-amplify

In the handler file for your function, configure the Amplify data client

amplify/functions/data-access.ts
Copy
amplify/functions/data-access.ts code example
import { Amplify } from 'aws-amplify';
import { generateClient } from 'aws-amplify/data';
import { Schema } from '../data/resource';
import { env } from '$amplify/env/<function-name>'; // replace with your function name




Amplify.configure(
  {
    API: {
      GraphQL: {
        endpoint: env.<amplifyData>_GRAPHQL_ENDPOINT, // replace with your defineData name
        region: env.AWS_REGION,
        defaultAuthMode: 'identityPool'
      }
    }
  },
  {
    Auth: {
      credentialsProvider: {
        getCredentialsAndIdentityId: async () => ({
          credentials: {
            accessKeyId: env.AWS_ACCESS_KEY_ID,
            secretAccessKey: env.AWS_SECRET_ACCESS_KEY,
            sessionToken: env.AWS_SESSION_TOKEN,
          },
        }),
        clearCredentialsAndIdentityId: () => {
          /* noop */
        },
      },
    },
  }
);


const dataClient = generateClient<Schema>();


export const handler = async (event) => {
  // your function code goes here
}

Use the command below to generate GraphQL client code to call your data backend.

Note: We are working on bringing the end-to-end typed experience to connect to your data from within function resources without needing this step. If you'd like to provide feedback the experience or have early access, join our Discord community.

Terminal
Copy
Terminal code example
npx ampx generate graphql-client-code --out <path-function-handler-dir>/graphql

Note: Whenever you update your data model, you will need to run the command above again.

Once you have generated the client code, update the function to access the data. The following code creates a todo and then lists all todos.

amplify/functions/data-access.ts
Copy
amplify/functions/data-access.ts code example
const client = generateClient<Schema>();


export const handler = async (event) => {
  await client.graphql({
    query: createTodo,
    variables: {
      input: {
        name: "My first todo",
        description: "This is my first todo",
      },
    },
  });




  await client.graphql({
    query: listTodos,
  });


  return event;
};
PREVIOUS
Configure custom identity and group claims

--------------------------------------------------------------------------------

Title: Configure custom identity and group claims - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/customize-authz/configure-custom-identity-and-group-claim/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Customize your auth rules
/
Configure custom identity and group claims
Configure custom identity and group claims

Amplify Data supports using custom identity and group claims if you do not wish to use the default Amazon Cognito-provided cognito:groups or the double-colon-delimited claims, sub::username, from your JWT token. This can be helpful if you are using tokens from a 3rd party OIDC system or if you wish to populate a claim with a list of groups from an external system, such as when using a Pre Token Generation Lambda Trigger which reads from a database.

To use custom claims specify identityClaim or groupClaim as appropriate. In the example below, the identityClaim is specified and the record owner will check against this user_id claim. Similarly, if the user_groups claim contains a "Moderator" string then access will be granted.

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
import { a, defineData, type ClientSchema } from '@aws-amplify/backend';


const schema = a.schema({
  Post: a
    .model({
      id: a.id(),
      owner: a.string(),
      postname: a.string(),
      content: a.string(),
    })
    .authorization(allow => [
      allow.owner().identityClaim('user_id'),
      allow.groups(['Moderator']).withClaimIn('user_groups'),
    ]),
});


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({ schema });

In your application, you can perform CRUD operations against the model using client.models.<model-name> with the userPool auth mode.

import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition


const client = generateClient<Schema>();


const { errors, data: newTodo } = await client.models.Todo.create(
  {
    postname: 'My New Post'
    content: 'My post content',
  },
Copy
highlighted code example
  {
    authMode: 'userPool',
  }
);
PREVIOUS
Use OpenID Connect as an authorization provider
NEXT
Grant Lambda function access to API and Data

--------------------------------------------------------------------------------

Title: Custom data access using Lambda functions - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/customize-authz/custom-data-access-patterns/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Customize your auth rules
/
Custom data access using Lambda functions
Custom data access using Lambda functions

You can define your own custom authorization rule with a Lambda function.

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
import {
  type ClientSchema,
  a,
  defineData,
  defineFunction,
} from '@aws-amplify/backend';


const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
    })
    // STEP 1
    // Indicate which models / fields should use a custom authorization rule
    .authorization(allow => [allow.custom()]),
});


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: 'lambda',
    // STEP 2
    // Pass in the function to be used for a custom authorization rule
    lambdaAuthorizationMode: {
      function: defineFunction({
        entry: './custom-authorizer.ts',
      }),
      // (Optional) STEP 3
      // Configure the token's time to live
      timeToLiveInSeconds: 300,
    },
  },
});

In your application, you can perform CRUD operations against the model using client.models.<model-name> with the lambda auth mode.

import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition


const client = generateClient<Schema>();


const { errors, data: newTodo } = await client.models.Todo.create(
  {
    content: 'My new todo',
  },
Copy
highlighted code example
  {
    authMode: 'lambda',
  }
);

The Lambda function of choice will receive an authorization token from the client and execute the desired authorization logic. The AppSync GraphQL API will receive a payload from Lambda after invocation to allow or deny the API call accordingly.

To configure a Lambda function as the authorization mode, create a new file amplify/data/custom-authorizer.ts. You can use this Lambda function code template as a starting point for your authorization handler code:

Copy
code example
// amplify/data/custom-authorizer.ts


// This is sample code. Update this to suite your needs
import type { AppSyncAuthorizerHandler } from 'aws-lambda'; // types imported from @types/aws-lambda


type ResolverContext = {
  userid: string;
  info: string;
  more_info: string;
};


export const handler: AppSyncAuthorizerHandler<ResolverContext> = async (
  event
) => {
  console.log(`EVENT: ${JSON.stringify(event)}`);
  const {
    authorizationToken,
    requestContext: { apiId, accountId }
  } = event;
  const response = {
    isAuthorized: authorizationToken === 'custom-authorized',
    resolverContext: {
      // eslint-disable-next-line spellcheck/spell-checker
      userid: 'user-id',
      info: 'contextual information A',
      more_info: 'contextual information B'
    },
    deniedFields: [
      `arn:aws:appsync:${process.env.AWS_REGION}:${accountId}:apis/${apiId}/types/Event/fields/comments`,
      `Mutation.createEvent`
    ],
    ttlOverride: 300
  };
  console.log(`RESPONSE: ${JSON.stringify(response, null, 2)}`);
  return response;
};

You can use the template above as a starting point for your custom authorization rule. The authorization Lambda function receives the following event:

Copy
code example
{
    "authorizationToken": "ExampleAuthToken123123123", # Authorization token specified by client
    "requestContext": {
        "apiId": "aaaaaa123123123example123", # AppSync API ID
        "accountId": "111122223333", # AWS Account ID
        "requestId": "f4081827-1111-4444-5555-5cf4695f339f",
        "queryString": "mutation CreateEvent {...}\n\nquery MyQuery {...}\n", # GraphQL query
        "operationName": "MyQuery", # GraphQL operation name
        "variables": {} # any additional variables supplied to the operation
    }
}

Your Lambda authorization function needs to return the following JSON:

Copy
code example
{
  // required
  "isAuthorized": true, // if "false" then an UnauthorizedException is raised, access is denied
  "resolverContext": { "banana": "very yellow" }, // JSON object visible as $ctx.identity.resolverContext in VTL resolver templates


  // optional
  "deniedFields": ["TypeName.FieldName"], // Forces the fields to "null" when returned to the client
  "ttlOverride": 10 // The number of seconds that the response should be cached for. Overrides default specified in "amplify update api"
}

Review the Amplify documentation to set the custom authorization token for the Data client.

PREVIOUS
User group-based data access
NEXT
Use OpenID Connect as an authorization provider

--------------------------------------------------------------------------------

Title: Use OpenID Connect as an authorization provider - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/customize-authz/using-oidc-authorization-provider/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Customize your auth rules
/
Use OpenID Connect as an authorization provider
Use OpenID Connect as an authorization provider

Private, owner, and group authorization can be configured with an OpenID Connect (OIDC) authorization mode. Add "oidc" to the authorization rule as the provider. Use the oidcAuthorizationMode property to configure the OpenID Connect provider name, OpenID Connect provider domain, Client ID, Issued at TTL, and Auth Time TTL.

The example below highlights the supported authorization strategies with a oidc authorization provider. For owner and group-based authorization, you also will need to specify a custom identity and group claim.

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
// amplify/data/resource.ts
import { a, defineData, type ClientSchema } from '@aws-amplify/backend';


const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
    })
    .authorization(allow => [
      allow.owner('oidc').identityClaim('user_id'),
      allow.authenticated('oidc'),
      allow
        .groups(['testGroupName'], 'oidc')
        .withClaimIn('user_groups'),
    ]),
});


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: 'oidc',
    oidcAuthorizationMode: {
      oidcProviderName: 'oidc-provider-name',
      oidcIssuerUrl: 'https://example.com',
      clientId: 'client-id',
      tokenExpiryFromAuthInSeconds: 300,
      tokenExpireFromIssueInSeconds: 600,
    },
  },
});

In your application, you can perform CRUD operations against the model using client.models.<model-name> by specifying the oidc auth mode.

import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition


const client = generateClient<Schema>();


const { errors, data: todos } = await client.models.Todo.list({
Copy
highlighted code example
  authMode: "oidc",
});
PREVIOUS
Custom data access using Lambda functions
NEXT
Configure custom identity and group claims

--------------------------------------------------------------------------------

Title: User group-based data access - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/customize-authz/user-group-based-data-access/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Customize your auth rules
/
User group-based data access
User group-based data access

You can use the group authorization strategy to restrict access based on user groups. The user group authorization strategy allows restricting data access to specific user groups or groups defined dynamically on each data record.

Add authorization rules for specific user groups

When you want to restrict access to a specific set of user groups, provide the group names in the groups parameter. In the example below, only users that are part of the "Admin" user group are granted access to the Salary model.

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
// allow one specific group
const schema = a.schema({
  Salary: a
    .model({
      wage: a.float(),
      currency: a.string(),
    })
    .authorization(allow => [allow.group('Admin')]),
});

In your application, you can perform CRUD operations against the model using client.models.<model-name> with the userPool auth mode.

import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition


const client = generateClient<Schema>();


// As a signed-in user that belongs to the 'Admin' User Pool Group
const { errors, data: newSalary } = await client.models.Salary.create(
  {
    wage: 50.25,
    currency: 'USD'
  },
Copy
highlighted code example
  {
    authMode: 'userPool',
  }
);

This can then be updated to allow access to multiple defined groups; in this example below we added access for "Leadership".

Copy
code example
// allow multiple specific groups
const schema = a.schema({
  Salary: a
    .model({
      wage: a.float(),
      currency: a.string(),
    })
    .authorization(allow => [allow.groups(['Admin', 'Leadership'])]),
});
Add authorization rules for dynamically set user groups

With dynamic group authorization, each record contains an attribute specifying what Cognito groups should be able to access it. Use the first argument to specify which attribute in the underlying data store holds this group information. To specify that a single group should have access, use a field of type a.string(). To specify that multiple groups should have access, use a field of type a.string().array().

Copy
code example
// Dynamic group authorization with multiple groups
const schema = a.schema({
  Post: a
    .model({
      title: a.string(),
      groups: a.string().array(),
    })
    .authorization(allow => [allow.groupsDefinedIn('groups')]),
});
Copy
code example
// Dynamic group authorization with a single group
const schema = a.schema({
  Post: a
    .model({
      title: a.string(),
      group: a.string(),
    })
    .authorization(allow => [allow.groupDefinedIn('group')]),
});

By default, group authorization leverages Amazon Cognito user pool groups but you can also use OpenID Connect with group authorization. See OpenID Connect as an authorization provider.

Known limitations for real-time subscriptions when using dynamic group authorization:

If you authorize based on a single group per record, then subscriptions are only supported if the user is part of 5 or fewer user groups
If you authorize via an array of groups (groups: a.string().array() used in the example above),
subscriptions are only supported if the user is part of 20 or fewer groups
you can only authorize 20 or fewer user groups per record
PREVIOUS
Signed-in user data access
NEXT
Custom data access using Lambda functions

--------------------------------------------------------------------------------

Title: Signed-in user data access - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/customize-authz/signed-in-user-data-access/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Customize your auth rules
/
Signed-in user data access
Signed-in user data access

The authenticated authorization strategy restricts record access to only signed-in users authenticated through IAM, Cognito, or OpenID Connect, applying the authorization rule to all users. It provides a simple way to make data private to all authenticated users.

Add signed-in user authorization rule

You can use the authenticated authorization strategy to restrict a record's access to every signed-in user.

Note: If you want to restrict a record's access to a specific user, see Per-user/per-owner data access. The authenticated authorization strategy detailed on this page applies the authorization rule for data access to every signed-in user.

In the example below, anyone with a valid JWT token from the Cognito user pool is allowed access to all Todos.

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
    })
    .authorization(allow => [allow.authenticated()]),
});

In your application, you can perform CRUD operations against the model using client.models.<model-name> with the userPool auth mode.

import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition


const client = generateClient<Schema>();


const { errors, data: newTodo } = await client.models.Todo.create(
  {
    content: 'My new todo',
  },
Copy
highlighted code example
  {
    authMode: 'userPool',
  }
);
Use identity pool for signed-in user authentication

You can also override the authorization provider. In the example below, identityPool is specified as the provider which allows you to use an "Unauthenticated Role" from the Cognito identity pool for public access instead of an API key. Your Auth resources defined in amplify/auth/resource.ts generates scoped down IAM policies for the "Unauthenticated role" in the Cognito identity pool automatically.

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
    })
    .authorization(allow => [allow.authenticated('identityPool')]),
});

In your application, you can perform CRUD operations against the model using client.models.<model-name> with the iam auth mode.

The user must be logged in for the Amplify Library to use the authenticated role from your Cognito identity pool.

import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition


const client = generateClient<Schema>();


const { errors, data: newTodo } = await client.models.Todo.create(
  {
    content: 'My new todo',
  },
Copy
highlighted code example
  {
    authMode: 'identityPool',
  }
);

In addition, you can also use OpenID Connect with authenticated authorization. See OpenID Connect as an authorization provider.

PREVIOUS
Multi-user data access
NEXT
User group-based data access

--------------------------------------------------------------------------------

Title: Per-user/per-owner data access - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/customize-authz/per-user-per-owner-data-access/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Customize your auth rules
/
Per-user/per-owner data access
Per-user/per-owner data access

The owner authorization strategy restricts operations on a record to only the record's owner. When configured, the owner field will automatically be added and populated with the identity of the created user. The API will authorize against the owner field to allow or deny operations.

Add per-user/per-owner authorization rule

You can use the owner authorization strategy to restrict a record's access to a specific user. When owner authorization is configured, only the record's owner is allowed the specified operations.

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
// The "owner" of a Todo is allowed to create, read, update, and delete their own todos
const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
    })
    .authorization(allow => [allow.owner()]),
});
amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
// The "owner" of a Todo record is only allowed to create, read, and update it.
// The "owner" of a Todo record is denied to delete it.
const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
    })
    .authorization(allow => [allow.owner().to(['create', 'read', 'update'])]),
});

In your application, you can perform CRUD operations against the model using client.models.<model-name> with the userPool auth mode.

import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition


const client = generateClient<Schema>();


const { errors, data: newTodo } = await client.models.Todo.create(
  {
    content: 'My new todo',
  },
Copy
highlighted code example
  {
    authMode: 'userPool',
  }
);

Behind the scenes, Amplify will automatically add a owner: a.string() field to each record which contains the record owner's identity information upon record creation.

By default, the Cognito user pool's user information is populated into the owner field. The value saved includes sub and username in the format <sub>::<username>. The API will authorize against the full value of <sub>::<username> or sub / username separately and return username. You can alternatively configure OpenID Connect as an authorization provider.

By default, owners can reassign the owner of their existing record to another user.

To prevent an owner from reassigning their record to another user, protect the owner field (by default owner: String) with a field-level authorization rule. For example, in a social media app, you would want to prevent Alice from being able to reassign Alice's Post to Bob.

Copy
code example
const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
      owner: a.string().authorization(allow => [allow.owner().to(['read', 'delete'])]),
    })
    .authorization(allow => [allow.owner()]),
});
Customize the owner field

You can override the owner field to your own preferred field, by specifying a custom ownerField in the authorization rule.

Copy
code example
const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
      author: a.string(), // record owner information now stored in "author" field
    })
    .authorization(allow => [allow.ownerDefinedIn('author')]),
});
PREVIOUS
Public data access
NEXT
Multi-user data access

--------------------------------------------------------------------------------

Title: Multi-user data access - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/customize-authz/multi-user-data-access/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Customize your auth rules
/
Multi-user data access
Multi-user data access

The ownersDefinedIn rule grants a set of users access to a record by automatically creating an owners field to store the allowed record owners. You can override the default owners field name by specifying inField with the desired field name to store the owner information. You can dynamically manage which users can access a record by updating the owner field.

Add multi-user authorization rule

If you want to grant a set of users access to a record, you use the ownersDefinedIn rule. This automatically creates a owners: a.string().array() field to store the allowed owners.

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
      owners: a.string().array(),
    })
    .authorization(allow => [allow.ownersDefinedIn('owners')]),
});

In your application, you can perform CRUD operations against the model using client.models.<model-name> with the userPool auth mode.

import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition


const client = generateClient<Schema>();


// Create a record with current user as first owner
const { errors, data: newTodo } = await client.models.Todo.create(
  {
    content: 'My new todo',
  },
Copy
highlighted code example
  {
    authMode: 'userPool',
  }
);

Add another user as an owner

await client.models.Todo.update(
  {
    id: newTodo.id,
    owners: [...(newTodo.owners as string[]), otherUserId],
  },
Copy
highlighted code example
  {
    authMode: "userPool"
  }
);
Override to a list of owners

You can override the inField to a list of owners. Use this if you want a dynamic set of users to have access to a record. In the example below, the authors list is populated with the creator of the record upon record creation. The creator can then update the authors field with additional users. Any user listed in the authors field can access the record.

Copy
code example
const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
      authors: a.string().array(), // record owner information now stored in "authors" field
    })
    .authorization(allow => [allow.ownersDefinedIn('authors')]),
});
PREVIOUS
Per-user/per-owner data access
NEXT
Signed-in user data access

--------------------------------------------------------------------------------

Title: Customize your auth rules - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/customize-authz/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Customize your auth rules
Customize your auth rules

Use the .authorization() modifier to configure authorization rules for public, signed-in user, per user, and per user group data access. Authorization rules operate on the deny-by-default principle. Meaning that if an authorization rule is not specifically configured, it is denied.

Copy
code example
const schema = a.schema({
  Post: a.model({
    content: a.string()
  }).authorization(allow => [
    // Allow anyone auth'd with an API key to read everyone's posts.
    allow.publicApiKey().to(['read']),
    // Allow signed-in user to create, read, update,
    // and delete their __OWN__ posts.
    allow.owner(),
  ])
})

In the example above, everyone (public) can read every Post but authenticated users (owner) can create, read, update, and delete their own posts. Amplify also allows you to restrict the allowed operations, combine multiple authorization rules, and apply fine-grained field-level authorization.

Available authorization strategies

Use the guide below to select the correct authorization strategy for your use case:

Recommended use case	Strategy	authMode
Public data access where users or devices are anonymous. Anyone with the AppSync API key is granted access.	publicApiKey	apiKey
Recommended for production environment's public data access. Public data access where unauthenticated users or devices are granted permissions using Amazon Cognito identity pool's role for unauthenticated identities.	guest	identityPool
Per user data access. Access is restricted to the "owner" of a record. Leverages amplify/auth/resource.ts Cognito user pool by default.	owner/ownerDefinedIn/ownersDefinedIn	userPool / oidc
Any signed-in data access. Unlike owner-based access, any signed-in user has access.	authenticated	userPool / oidc / identityPool
Per user group data access. A specific or dynamically configured group of users has access.	group/groupDefinedIn/groups/groupsDefinedIn	userPool / oidc
Define your own custom authorization rule within a serverless function.	custom	lambda
Understand how authorization rules are applied

Authorization rules can be applied globally across all data models in a schema, onto specific data models, and onto specific fields.

Amplify will always use the most specific authorization rule that is available. For example, if there is an authorization rule for a field and an authorization rule for the model that the field belongs to, Amplify will evaluate against the field-level authorization rule. Review Field-level authorization rules to learn more.

If there are multiple authorization rules present, they will be logically OR'ed. Review Configure multiple authorization rules to learn more. For userPools and oidc authorization modes, the rules are evaluated in the sequence authenticated > group(s) > owner(s)DefinedIn > group(s)DefinedIn.

Global authorization rule (only for getting started)

To help you get started, you can define an authorization rule on the data schema that will be applied to all data models that do not have a model-level authorization rule. Instead of having a global authorization rule for all production environments, we recommend creating specific authorization rules for each model or field.

The global authorization rule below uses allow.publicApiKey(). This example allows anyone to create, read, update, and delete and is applied to every data model.

Copy
code example
const schema = a.schema({
  // Because no model-level authorization rule is present
  // this model will use the global authorization rule.
  Todo: a.model({
    content: a.string()
  }),


  // Will use model-level authorization rule
  Notes: a.model({
    content: a.string()
    // [Model-level authorization rule]
  }).authorization(allow => [allow.publicApiKey().to(['read'])])


// [Global authorization rule]
}).authorization(allow => [
  allow.publicApiKey()
])
Model-level authorization rules

Add an authorization rule to a model to apply the authorization rule to all fields of that model.

Copy
code example
const schema = a.schema({
  Post: a.model({
    content: a.string(),
    createdBy: a.string()
    // [Model-level authorization rule]
    // All fields (content, createdBy) will be protected by
    // this authorization rule
  }).authorization(allow => [
    allow.publicApiKey().to(['read']),
    allow.owner(),
  ])
})
Field-level authorization rules

When an authorization rule is added to a field, it will strictly define the authorization rules applied on the field. Field-level authorization rules do not inherit model-level authorization rules. Meaning, only the specified field-level authorization rule is applied.

In the example below:

Owners are allowed to create, read, update, and delete Employee records they own
Any signed in user has read access and can read data with the exception of the ssn field
Only the ssn field has owner auth applied and this field-level auth rule means that model-level auth rules are not applied
Copy
code example
const schema = a.schema({
  Employee: a.model({
    name: a.string(),
    email: a.string(),
    // [Field-level authorization rule]
    // This auth rule will be used for the "ssn" field
    // All other fields will use the model-level auth rule
    ssn: a.string().authorization(allow => [allow.owner()]),
  })


  // [Model-level authorization rule]
  .authorization(allow => [
    allow.authenticated().to(["read"]),
    allow.owner()
  ]),
});
Non-model authorization rules

Non-model types are any types added to the schema without using a.model(). These consist of modifiers such as a.customType(), a.enum(),a.query(), a.mutation(), or a.subscription().

Dynamic authorization rules such as allow.owner(), allow.ownerDefinedIn(), allow.groupDefinedIn() are not supported for non-model types.

Copy
code example
const schema = a.schema({
  // ...
  listCustomType: a
    .query()
    .returns(a.ref("CustomType").array())
    .handler(
      a.handler.custom({
        entry: "./handler.js",
      })
    )
    .authorization((allow) => [
      // Static auth rules - Supported
      allow.guest(),
      allow.publicApiKey(),
      allow.authenticated(),
      allow.group("Admin"),
      allow.groups(["Teacher", "Student"]),


      // Dynamic auth rules - Not supported
      allow.owner(),
      allow.ownerDefinedIn("owner"),
      allow.ownersDefinedIn("otherOwners"),
      allow.groupDefinedIn("group"),
      allow.groupsDefinedIn("otherGroups"),
    ]),
});

There are TS warnings and validation checks in place that will cause a sandbox deployment to fail if unsupported auth rules are defined on custom queries and mutations.

Configure multiple authorization rules

When combining multiple authorization rules, they are "logically OR"-ed. In the following example:

Any user (using Amazon Cognito identity pool's unauthenticated roles) is allowed to read all posts
Owners are allowed to create, read, update, and delete their own posts
Copy
code example
const schema = a.schema({
  Post: a.model({
    title: a.string(),
    content: a.string()
  }).authorization(allow => [
    allow.guest().to(["read"]),
    allow.owner()
  ])
})

On the client side, make sure to always authenticate with the corresponding authorization mode.

Copy
code example
import { generateClient } from 'aws-amplify/data'
import type { Schema } from '@/amplify/data/resource' // Path to your backend resource definition


const client = generateClient<Schema>()


// Creating a post is restricted to Cognito User Pools
const { data: newPostResult , errors } = await client.models.Post.create({
	query: queries.createPost,
	variables: { input: { title: 'Hello World' } },
	authMode: 'userPool',
});


// Listing posts is available to unauthenticated users (verified by Amazon Cognito identity pool's unauthenticated role)
const { data: listPostsResult , errors } = await client.models.Post.list({
	query: queries.listPosts,
	authMode: 'identityPool',
});

Note: Authorization rules are only supported on data models (model-level and field-level) and custom operations (queries, mutations and subscriptions). They are not fully supported on custom types.

Learn more about specific authorization strategies
Public data access
The public authorization strategy grants everyone access to the API, which is protected behind the scenes with an API key. You can also override the authorization provider to use an unauthenticated IAM role from Cognito instead of an API key for public access.
Per-user/per-owner data access
The owner authorization strategy restricts operations on a record to only the record's owner. When configured, the owner field (default 'owner') will automatically be added and populated with the identity of the created user. The API will authorize against the 'owner' field to allow or deny operations.
Multi-user data access
The 'ownersDefinedIn' rule grants a set of users access to a record by automatically creating an 'owners' field to store the allowed record owners. You can override the default owners field name by specifying 'inField' with the desired field name to store the owner information. You can dynamically manage which users can access a record by updating the owner field.
Signed-in user data access
The 'private' authorization strategy restricts record access to only signed-in users authenticated through IAM, Cognito, or OpenID Connect, applying the authorization rule to all users. It provides a simple way to make data private to all authenticated users.
User group-based data access
The user group authorization strategy allows restricting data access to specific user groups or groups defined dynamically on each data record. Both static and dynamic group authorization options are available, with some limitations around real-time subscriptions when using dynamic group authorization.
Custom data access using Lambda functions
Define a custom authorization rule with a Lambda function.
Use OpenID Connect as an authorization provider
Use OpenID Connect with 'private', 'owner', and 'group' authorization strategies.
Configure custom identity and group claims
Amplify Data allows you to configure custom identity and group claims instead of using the default Cognito claims, which can be useful if you want to populate claims from an external source like a database or 3rd party auth provider. The example shows how to check the 'user_id' identity claim and the 'user_groups' group claim that could come from a custom pre token generation Lambda trigger. Defining these custom claims provides more flexibility in authorization rules.
Grant Lambda function access to API and Data
Amplify Data uses a 'deny-by-default' authorization model. Function access must be explicitly defined in the schema.

--------------------------------------------------------------------------------

Title: Public data access - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/customize-authz/public-data-access/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Customize your auth rules
/
Public data access
Public data access

The public authorization strategy grants everyone access to the API, which is protected behind the scenes with an API key. You can also override the authorization provider to use an unauthenticated IAM role from Cognito instead of an API key for public access.

Add public authorization rule using API key-based authentication

To grant everyone access, use the .public() authorization strategy. Behind the scenes, the API will be protected with an API key.

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
    })
    .authorization(allow => [allow.publicApiKey()]),
});

In your application, you can perform CRUD operations against the model using client.models.<model-name> by specifying the apiKey auth mode.

import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition


const client = generateClient<Schema>();


const { errors, data: newTodo } = await client.models.Todo.create(
  {
    content: 'My new todo',
  },
Copy
highlighted code example
  {
    authMode: 'apiKey',
  }
);
Add public authorization rule using Amazon Cognito identity pool's unauthenticated role

You can also override the authorization provider. In the example below, identityPool is specified as the provider which allows you to use an "Unauthenticated Role" from the Cognito identity pool for public access instead of an API key. Your Auth resources defined in amplify/auth/resource.ts generates scoped down IAM policies for the "Unauthenticated role" in the Cognito identity pool automatically.

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
    })
    .authorization(allow => [allow.guest()]),
});

In your application, you can perform CRUD operations against the model using client.models.<model-name> with the identityPool auth mode.

If you're not using the auto-generated amplify_outputs.json file, then you must set the Amplify Library resource configuration's allowGuestAccess flag to true. This lets the Amplify Library use the unauthenticated role from your Cognito identity pool when your user isn't logged in.

Amplify configuration
src/App.tsx
import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition


const client = generateClient<Schema>();


const { errors, data: newTodo } = await client.models.Todo.create(
  {
    content: 'My new todo',
  },
Copy
highlighted code example
  {
    authMode: 'identityPool',
  }
);
NEXT
Per-user/per-owner data access

--------------------------------------------------------------------------------

Title: Modeling relationships - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/data-modeling/relationships/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Customize your data model
/
Modeling relationships
Modeling relationships

When modeling application data, you often need to establish relationships between different data models. In Amplify Data, you can create one-to-many, one-to-one, and many-to-many relationships in your Data schema. On the client-side, Amplify Data allows you to lazy or eager load of related data.

With Amplify Data Construct @aws-amplify/data-construct@1.8.4, an improvement was made to how relational field data is handled in subscriptions when different authorization rules apply to related models in a schema. The improvement redacts the values for the relational fields, displaying them as null or empty, to prevent unauthorized access to relational data.

This redaction occurs whenever it cannot be determined that the child model will be protected by the same permissions as the parent model.

Because subscriptions are tied to mutations and the selection set provided in the result of a mutation is then passed through to the subscription, relational fields in the result of mutations must be redacted.

If an authorized end-user needs access to the redacted relational fields, they should perform a query to read the relational data.

Additionally, subscriptions will inherit related authorization when relational fields are set as required. To better protect relational data, consider modifying the schema to use optional relational fields.

Types of relationships
Relationship	Code	Description	Example
one to many	a.hasMany(...) & a.belongsTo(...)	Creates a one-to-many relationship between two models.	A Team has many Members. A Member belongs to a Team.
one to one	a.hasOne(...) & a.belongsTo(...)	Creates a one-to-one relationship between two models.	A Customer has one Cart. A Cart belongs to one Customer.
many to many	Two a.hasMany(...) & a.belongsTo(...) on join tables	Create two one-to-many relationships between the related models in a join table.	A Post has many Tags. A Tag has many Posts.
Model one-to-many relationships

Create a one-to-many relationship between two models using the hasMany() and belongsTo() method. In the example below, a Team has many Members and a Member belongs to exactly one Team.

Create a reference field called teamId on the Member model. This reference field's type MUST match the type of Team's identifier. In this case, it's an auto-generated id: a.id().required() field.
Add a relationship field called team that references the teamId field. This allows you to query for the team information from the Member model.
Add a relationship field called members that references the teamId field on the Member model.
Copy
code example
const schema = a.schema({
  Member: a.model({
    name: a.string().required(),
    // 1. Create a reference field
    teamId: a.id(),
    // 2. Create a belongsTo relationship with the reference field
    team: a.belongsTo('Team', 'teamId'),
  })
  .authorization(allow => [allow.publicApiKey()]),


  Team: a.model({
    mantra: a.string().required(),
    // 3. Create a hasMany relationship with the reference field
    //    from the `Member`s model.
    members: a.hasMany('Member', 'teamId'),
  })
  .authorization(allow => [allow.publicApiKey()]),
});
Create a "Has Many" relationship between records
Copy
code example
const { data: team } = await client.models.Team.create({
  mantra: 'Go Frontend!',
});


const { data: member } = await client.models.Member.create({
  name: "Tim",
  teamId: team.id,
});
Update a "Has Many" relationship between records
Copy
code example
const { data: newTeam } = await client.models.Team.create({
  mantra: 'Go Fullstack',
});


await client.models.Member.update({
  id: "MY_MEMBER_ID",
  teamId: newTeam.id,
});
Delete a "Has Many" relationship between records

If your reference field is not required, then you can "delete" a one-to-many relationship by setting the relationship value to null.

Copy
code example
await client.models.Member.update({
  id: "MY_MEMBER_ID",
  teamId: null,
});
Lazy load a "Has Many" relationship
Copy
code example
const { data: team } = await client.models.Team.get({ id: "MY_TEAM_ID"});


const { data: members } = await team.members();


members.forEach(member => console.log(member.id));
Eagerly load a "Has Many" relationship
Copy
code example
const { data: teamWithMembers } = await client.models.Team.get(
  { id: "MY_TEAM_ID" },
  { selectionSet: ["id", "members.*"] },
);


teamWithMembers.members.forEach(member => console.log(member.id));
Model a "one-to-one" relationship

Create a one-to-one relationship between two models using the hasOne() and belongsTo() methods. In the example below, a Customer has a Cart and a Cart belongs to a Customer.

Create a reference field called customerId on the Cart model. This reference field's type MUST match the type of Customer's identifier. In this case, it's an auto-generated id: a.id().required() field.
Add a relationship field called customer that references the customerId field. This allows you to query for the customer information from the Cart model.
Add a relationship field called activeCart that references the customerId field on the Cart model.
Copy
code example
const schema = a.schema({
  Cart: a.model({
    items: a.string().required().array(),
    // 1. Create reference field
    customerId: a.id(),
    // 2. Create relationship field with the reference field
    customer: a.belongsTo('Customer', 'customerId'),
  }),
  Customer: a.model({
    name: a.string(),
    // 3. Create relationship field with the reference field
    //    from the Cart model
    activeCart: a.hasOne('Cart', 'customerId')
  }),
});
Create a "Has One" relationship between records

To create a "has one" relationship between records, first create the parent item and then create the child item and assign the parent.

Copy
code example
const { data: customer, errors } = await client.models.Customer.create({
  name: "Rene",
});




const { data: cart } = await client.models.Cart.create({
  items: ["Tomato", "Ice", "Mint"],
  customerId: customer?.id,
});
Update a "Has One" relationship between records

To update a "Has One" relationship between records, you first retrieve the child item and then update the reference to the parent to another parent. For example, to reassign a Cart to another Customer:

Copy
code example
const { data: newCustomer } = await client.models.Customer.create({
  name: 'Ian',
});


await client.models.Cart.update({
  id: cart.id,
  customerId: newCustomer?.id,
});
Delete a "Has One" relationship between records

You can set the relationship field to null to delete a "Has One" relationship between records.

Copy
code example
await client.models.Cart.update({
  id: project.id,
  customerId: null,
});
Lazy load a "Has One" relationship
Copy
code example
const { data: cart } = await client.models.Cart.get({ id: "MY_CART_ID"});
const { data: customer } = await cart.customer();
Eagerly load a "Has One" relationship
Copy
code example
const { data: cart } = await client.models.Cart.get(
  { id: "MY_CART_ID" },
  { selectionSet: ['id', 'customer.*'] },
);


console.log(cart.customer.id)
Model a "many-to-many" relationship

In order to create a many-to-many relationship between two models, you have to create a model that serves as a "join table". This "join table" should contain two one-to-many relationships between the two related entities. For example, to model a Post that has many Tags and a Tag has many Posts, you'll need to create a new PostTag model that represents the relationship between these two entities.

const schema = a.schema({
  PostTag: a.model({
    // 1. Create reference fields to both ends of
    //    the many-to-many relationship
Copy
highlighted code example
    postId: a.id().required(),
    tagId: a.id().required(),
    // 2. Create relationship fields to both ends of
    //    the many-to-many relationship using their
    //    respective reference fields
Copy
highlighted code example
    post: a.belongsTo('Post', 'postId'),
    tag: a.belongsTo('Tag', 'tagId'),
  }),
  Post: a.model({
    title: a.string(),
    content: a.string(),
    // 3. Add relationship field to the join model
    //    with the reference of `postId`
Copy
highlighted code example
    tags: a.hasMany('PostTag', 'postId'),
  }),
  Tag: a.model({
    name: a.string(),
    // 4. Add relationship field to the join model
    //    with the reference of `tagId`
Copy
highlighted code example
    posts: a.hasMany('PostTag', 'tagId'),
  }),
}).authorization(allow => [allow.publicApiKey()]);
Model multiple relationships between two models

Relationships are defined uniquely by their reference fields. For example, a Post can have separate relationships with a Person model for author and editor.

const schema = a.schema({
  Post: a.model({
    title: a.string().required(),
    content: a.string().required(),
Copy
highlighted code example
    authorId: a.id(),
    author: a.belongsTo('Person', 'authorId'),
    editorId: a.id(),
    editor: a.belongsTo('Person', 'editorId'),
  }),
  Person: a.model({
    name: a.string(),
Copy
highlighted code example
    editedPosts: a.hasMany('Post', 'editorId'),
    authoredPosts: a.hasMany('Post', 'authorId'),
  }),
}).authorization(allow => [allow.publicApiKey()]);

On the client-side, you can fetch the related data with the following code:

Copy
code example
const client = generateClient<Schema>();


const { data: post } = await client.models.Post.get({ id: "SOME_POST_ID" });


const { data: author } = await post?.author();
const { data: editor } = await post?.editor();
Model relationships for models with sort keys in their identifier

In cases where your data model uses sort keys in the identifier, you need to also add reference fields and store the sort key fields in the related data model:

const schema = a.schema({
  Post: a.model({
    title: a.string().required(),
    content: a.string().required(),
    // Reference fields must correspond to identifier fields.
Copy
highlighted code example
    authorName: a.string(),
    authorDoB: a.date(),
    // Must pass references in the same order as identifiers.
    author: a.belongsTo('Person', ['authorName', 'authorDoB']),
  }),
  Person: a.model({
    name: a.string().required(),
    dateOfBirth: a.date().required(),
    // Must reference all reference fields corresponding to the
    // identifier of this model.
    authoredPosts: a.hasMany('Post', ['authorName', 'authorDoB']),
Copy
highlighted code example
  }).identifier(['name', 'dateOfBirth']),
}).authorization(allow => [allow.publicApiKey()]);
Make relationships required or optional

Amplify Data's relationships use reference fields to determine if a relationship is required or not. If you mark a reference field as required, then you can't "delete" a relationship between two models. You'd have to delete the related record as a whole.

const schema = a.schema({
  Post: a.model({
    title: a.string().required(),
    content: a.string().required(),
    // You must supply an author when creating the post
    // Author can't be set to `null`.
Copy
highlighted code example
    authorId: a.id().required(),
    author: a.belongsTo('Person', 'authorId'),
    // You can optionally supply an editor when creating the post.
    // Editor can also be set to `null`.
Copy
highlighted code example
    editorId: a.id(),
    editor: a.belongsTo('Person', 'editorId'),
  }),
  Person: a.model({
    name: a.string(),
Copy
highlighted code example
    editedPosts: a.hasMany('Post', 'editorId'),
    authoredPosts: a.hasMany('Post', 'authorId'),
  }),
})
PREVIOUS
Add fields to data model
NEXT
Customize data model identifiers

--------------------------------------------------------------------------------

Title: Customize secondary indexes - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/data-modeling/secondary-index/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Customize your data model
/
Customize secondary indexes
Customize secondary indexes

You can optimize your list queries based on "secondary indexes". For example, if you have a Customer model, you can query based on the customer's id identifier field by default but you can add a secondary index based on the accountRepresentativeId to get list customers for a given account representative.

A secondary index consists of a "hash key" and, optionally, a "sort key". Use the "hash key" to perform strict equality and the "sort key" for greater than (gt), greater than or equal to (ge), less than (lt), less than or equal to (le), equals (eq), begins with, and between operations.

amplify/data/resource.ts
export const schema = a.schema({
  Customer: a
    .model({
      name: a.string(),
      phoneNumber: a.phone(),
      accountRepresentativeId: a.id().required(),
    })
Copy
highlighted code example
    .secondaryIndexes((index) => [index("accountRepresentativeId")])
    .authorization(allow => [allow.publicApiKey()]),
});

The example client query below allows you to query for "Customer" records based on their accountRepresentativeId:

src/App.tsx
import { type Schema } from '../amplify/data/resource';
import { generateClient } from 'aws-amplify/data';


const client = generateClient<Schema>();


const { data, errors } =
Copy
highlighted code example
  await client.models.Customer.listCustomerByAccountRepresentativeId({
    accountRepresentativeId: "YOUR_REP_ID",
  });
Review how this works under the hood with Amazon DynamoDB
Add sort keys to secondary indexes

You can define "sort keys" to add a set of flexible filters to your query, such as "greater than" (gt), "greater than or equal to" (ge), "less than" (lt), "less than or equal to" (le), "equals" (eq), "begins with" (beginsWith), and "between" operations.

amplify/data/resource.ts
export const schema = a.schema({
  Customer: a
    .model({
      name: a.string(),
      phoneNumber: a.phone(),
      accountRepresentativeId: a.id().required(),
    })
    .secondaryIndexes((index) => [
      index("accountRepresentativeId")
Copy
highlighted code example
        .sortKeys(["name"]),
    ])
    .authorization(allow => [allow.owner()]),
});

On the client side, you should find a new listBy... query that's named after hash key and sort keys. For example, in this case: listByAccountRepresentativeIdAndName. You can supply the filter as part of this new list query:

src/App.tsx
const { data, errors } =
Copy
highlighted code example
  await client.models.Customer.listCustomerByAccountRepresentativeIdAndName({
    accountRepresentativeId: "YOUR_REP_ID",
    name: {
      beginsWith: "Rene",
    },
  });
Customize the query field for secondary indexes

You can also customize the auto-generated query name under client.models.<MODEL_NAME>.listBy... by setting the queryField() modifier.

amplify/data/resource.ts
const schema = a.schema({
  Customer: a
    .model({
      name: a.string(),
      phoneNumber: a.phone(),
      accountRepresentativeId: a.id().required(),
    })
    .secondaryIndexes((index) => [
      index("accountRepresentativeId")
Copy
highlighted code example
        .queryField("listByRep"),
    ])
    .authorization(allow => [allow.owner()]),
});

In your client app code, you'll see query updated under the Data client:

src/App.tsx
const {
  data,
  errors
Copy
highlighted code example
} = await client.models.Customer.listByRep({
  accountRepresentativeId: 'YOUR_REP_ID',
})
Customize the name of secondary indexes

To customize the underlying DynamoDB's index name, you can optionally provide the name() modifier.

amplify/data/resource.ts
const schema = a.schema({
  Customer: a
    .model({
      name: a.string(),
      phoneNumber: a.phone(),
      accountRepresentativeId: a.id().required(),
    })
    .secondaryIndexes((index) => [
      index("accountRepresentativeId")
Copy
highlighted code example
        .name("MyCustomIndexName"),
    ])
    .authorization(allow => [allow.owner()]),
});
PREVIOUS
Customize data model identifiers

--------------------------------------------------------------------------------

Title: Add fields to data model - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/data-modeling/add-fields/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Customize your data model
/
Add fields to data model
Add fields to data model

Amplify Data supports all AWS AppSync scalar types as field types. The following scalar types are available:

Field type	Description	TypeScript validation	GraphQL Scalar Type
a.id()	A unique identifier for an object. This scalar is serialized like a String but isn't meant to be human-readable. If not specified on create operations, a UUID will be generated.	string	ID
a.string()	A UTF-8 character sequence.	string	String
a.integer()	An integer value between -(2^31) and 2^31-1.	number but rounded to closest integer value upon query/mutation	Int
a.float()	An IEEE 754 floating point value.	number	Float
a.boolean()	A Boolean value, either true or false.	boolean	Boolean
a.date()	An extended ISO 8601 date string in the format YYYY-MM-DD.	string	AWSDate
a.time()	An extended ISO 8601 time string in the format hh:mm:ss.sss.	string	AWSTime
a.datetime()	An extended ISO 8601 date and time string in the format YYYY-MM-DDThh:mm:ss.sssZ.	string	AWSDateTime
a.timestamp()	An integer value representing the number of seconds before or after 1970-01-01-T00:00Z.	number	AWSTimestamp
a.email()	An email address in the format local-part@domain-part as defined by RFC 822.	string with local-part and domain-part type enforcement	AWSEmail
a.json()	A JSON string. Any valid JSON construct is automatically parsed and loaded in the resolver code as maps, lists, or scalar values, rather than as the literal input strings. Unquoted strings or otherwise invalid JSON result in a validation error.	any	AWSJSON
a.phone()	A phone number. This value is stored as a string. Phone numbers can contain either spaces or hyphens to separate digit groups. Phone numbers without a country code are assumed to be US/North American numbers adhering to the North American Numbering Plan.	string validation only happening service-side	AWSPhone
a.url()	A URL as defined by RFC 1738. For example, https://www.amazon.com/dp/B000NZW3KC/ or mailto:example@example.com. URLs must contain a schema (http, mailto) and can't contain two forward slashes (//) in the path part.	string but with type enforcement on the schema part	AWSURL
a.ipAddress()	A valid IPv4 or IPv6 address. IPv4 addresses are expected in quad-dotted notation (123.12.34.56). IPv6 addresses are expected in non-bracketed, colon-separated format (1a2b:3c4b:1234:4567). You can include an optional CIDR suffix (123.45.67.89/16) to indicate subnet mask.	string with type enforcement for IPv4 and IPv6 pattern	AWSIPAddress
Specify a custom field type

Sometimes, the built-in types do not meet the needs of your application. In those cases, you can specify custom types. You can either define the custom types inline or explicitly define the custom type in the schema.

Inline definition: The "location" field will become a new non-model type that uses PascalCase, a naming convention in which the first letter of each word in a compound word is capitalized. If there are conflicts with another schema-level definition (model, custom type, enum), you will receive a Type error with a warning that you need to sift the value out as a separate item and use a "ref".

Copy
code example
a.schema({
  Post: a.model({
    location: a.customType({
      lat: a.float(),
      long: a.float(),
    }),
    content: a.string(),
  }),
});

Explicit definition: Specify the "Location" as a.customType() in your schema. To use the custom type, reference it through a.ref() in the respective field definitions.

Copy
code example
a.schema({
  Location: a.customType({
      lat: a.float(),
      long: a.float(),
  }),


  Post: a.model({
    location: a.ref('Location'),
    content: a.string(),
  }),


  User: a.model({
    lastKnownLocation: a.ref('Location'),
  }),
});

To set or read the location field on the client side, you can expand a nested object and the type system will auto-infer the allowed values.

Copy
code example
const { data: newPost, errors } = await client.models.Post.create({
  location: {
    lat: 48.837006,
    long: 8.28245,
  },
});


console.log(newPost?.location?.lat, newPost?.location?.long);
Specify an enum field type

Enum has a similar developer experience as custom types: short-hand and long-form approaches.

Short-hand approach

Copy
code example
a.schema({
  Post: a.model({
    privacySetting: a.enum(['PRIVATE', 'FRIENDS_ONLY', 'PUBLIC']),
    content: a.string(),
  }),
});

Long-form approach

Copy
code example
a.schema({
  PrivacySetting: a.enum([
    'PRIVATE',
    'FRIENDS_ONLY',
    'PUBLIC'
  ]),


  Post: a.model({
    content: a.string(),
    privacySetting: a.ref('PrivacySetting'),
  }),


  Video: a.model({
    privacySetting: a.ref('PrivacySetting'),
  }),
});

When creating a new item client-side, the enums are also type-enforced:

Copy
code example
client.models.Post.create({
  content: 'hello',
  // WORKS - value auto-completed
  privacySetting: 'PRIVATE',


  // DOES NOT WORK - TYPE ERROR
  privacySetting: 'NOT_PUBLIC',
});
List enum values client-side

You can list available enum values client-side using the client.enums.<ENUM_NAME>.values() API. For example, this allows you to display the available enum values within a dropdown UI.

Copy
code example
const availableSettings = client.enums.PrivacySetting.values()
// availableSettings returns ["PRIVATE", "FRIENDS_ONLY", "PUBLIC"]
Mark fields as required

By default, fields are optional. To mark a field as required, use the .required() modifier.

Copy
code example
const schema = a.schema({
  Todo: a.model({
    content: a.string().required(),
  }),
});
Mark fields as arrays

Any field can be modified to be an array using the .array() modifier.

Copy
code example
const schema = a.schema({
  Todo: a.model({
    content: a.string().required(),
    notes: a.string().array(),
  }),
});
Assign default values for fields

You can use the .default(...) modifier to specify a default value for optional scalar type fields and arrays. The .default(...) modifier is not available for custom types, enums, or relationships.

Copy
code example
const schema = a.schema({
  Todo: a.model({
    content: a.string().default('My new Todo'),
  }),
});

Note: The .default(...) modifier can't be applied to required fields.

NEXT
Modeling relationships

--------------------------------------------------------------------------------

Title: Customize data model identifiers - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/data-modeling/identifiers/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Customize your data model
/
Customize data model identifiers
Customize data model identifiers

Identifiers are defined using the .identifier() method on a model definition. Usage of the .identifier() method is optional; when it's not present, the model will automatically have a field called id of type ID that is automatically generated unless manually specified.

Copy
code example
const schema = a.schema({
  Todo: a.model({
    content: a.string(),
    completed: a.boolean(),
  })
  .authorization(allow => [allow.publicApiKey()]),
});
Copy
code example
const client = generateClient<Schema>();


const todo = await client.models.Todo.create({ content: 'Buy Milk', completed: false });
console.log(`New Todo created: ${todo.id}`); // New Todo created: 5DB6B4CC-CD41-49F5-9844-57C0AB506B69

If you want, you can use Amplify Data to define single-field and composite identifiers:

Single-field identifier with a consumer-provided value (type: id or string, and must be marked required)
Composite identifier with a set of consumer-provided values (type: id or string, and must be marked required)
Single-field identifier

If the default id identifier field needs to be customized, you can do so by passing the name of another field.

Copy
code example
const schema = a.schema({
  Todo: a.model({
    todoId: a.id().required(),
    content: a.string(),
    completed: a.boolean(),
  })
  .identifier(['todoId'])
  .authorization(allow => [allow.publicApiKey()]),
});
Copy
code example
const client = generateClient<Schema>();


const { data: todo, errors } = await client.models.Todo.create({ todoId: 'MyUniqueTodoId', content: 'Buy Milk', completed: false });
console.log(`New Todo created: ${todo.todoId}`); // New Todo created: MyUniqueTodoId
Composite identifier

For cases where items are uniquely identified by more than a single field, you can pass an array of the field names to the identifier() function:

Copy
code example
const schema = a.schema({
  StoreBranch: a.model({
    geoId: a.id().required(),
    name: a.string().required(),
    country: a.string(),
    state: a.string(),
    city: a.string(),
    zipCode: a.string(),
    streetAddress: a.string(),
  }).identifier(['geoId', 'name'])
  .authorization(allow => [allow.publicApiKey()]),
});
Copy
code example
const client = generateClient<Schema>();


const branch = await client.models.StoreBranch.get({ geoId: '123', name: 'Downtown' }); // All identifier fields are required when retrieving an item
PREVIOUS
Modeling relationships
NEXT
Customize secondary indexes

--------------------------------------------------------------------------------

Title: Subscribe to real-time events - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/subscribe-data/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Subscribe to real-time events
Subscribe to real-time events

In this guide, we will outline the benefits of enabling real-time data integrations and how to set up and filter these subscriptions. We will also cover how to unsubscribe from subscriptions.

Before you begin, you will need:

An application connected to the API
Data already created to modify

With Amplify Data Construct @aws-amplify/data-construct@1.8.4, an improvement was made to how relational field data is handled in subscriptions when different authorization rules apply to related models in a schema. The improvement redacts the values for the relational fields, displaying them as null or empty, to prevent unauthorized access to relational data.

This redaction occurs whenever it cannot be determined that the child model will be protected by the same permissions as the parent model.

Because subscriptions are tied to mutations and the selection set provided in the result of a mutation is then passed through to the subscription, relational fields in the result of mutations must be redacted.

If an authorized end-user needs access to the redacted relational fields, they should perform a query to read the relational data.

Additionally, subscriptions will inherit related authorization when relational fields are set as required. To better protect relational data, consider modifying the schema to use optional relational fields.

Set up a real-time list query

The recommended way to fetch a list of data is to use observeQuery to get a real-time list of your app data at all times. You can integrate observeQuery with React's useState and useEffect hooks in the following way:

Copy
code example
import { useState, useEffect } from 'react';
import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource';


type Todo = Schema['Todo']['type'];


const client = generateClient<Schema>();


export default function MyComponent() {
  const [todos, setTodos] = useState<Todo[]>([]);


  useEffect(() => {
    const sub = client.models.Todo.observeQuery().subscribe({
      next: ({ items, isSynced }) => {
        setTodos([...items]);
      },
    });
    return () => sub.unsubscribe();
  }, []);


  return (
    <ul>
      {todos.map((todo) => (
        <li key={todo.id}>{todo.content}</li>
      ))}
    </ul>
  );
}

observeQuery fetches and paginates through all of your available data in the cloud. While data is syncing from the cloud, snapshots will contain all of the items synced so far and an isSynced status of false. When the sync process is complete, a snapshot will be emitted with all the records in the local store and an isSynced status of true.

Set up a real-time event subscription

Subscriptions is a feature that allows the server to send data to its clients when a specific event happens. For example, you can subscribe to an event when a new record is created, updated, or deleted through the API. Subscriptions are automatically available for any a.model() in your Amplify Data schema.

Copy
code example
import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource';


const client = generateClient<Schema>();


// Subscribe to creation of Todo
const createSub = client.models.Todo.onCreate().subscribe({
  next: (data) => console.log(data),
  error: (error) => console.warn(error),
});


// Subscribe to update of Todo
const updateSub = client.models.Todo.onUpdate().subscribe({
  next: (data) => console.log(data),
  error: (error) => console.warn(error),
});


// Subscribe to deletion of Todo
const deleteSub = client.models.Todo.onDelete().subscribe({
  next: (data) => console.log(data),
  error: (error) => console.warn(error),
});


// Stop receiving data updates from the subscription
createSub.unsubscribe();
updateSub.unsubscribe();
deleteSub.unsubscribe();
Set up server-side subscription filters

Subscriptions take an optional filter argument to define service-side subscription filters:

Copy
code example
import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource';


const client = generateClient<Schema>();


const sub = client.models.Todo.onCreate({
  filter: {
    content: {
      contains: 'groceries',
    },
  },
}).subscribe({
  next: (data) => console.log(data),
  error: (error) => console.warn(error),
});

If you want to get all subscription events, don't specify any filter parameters.

Limitations:

Specifying an empty object {} as a filter is not recommended. Using {} as a filter might cause inconsistent behavior based on your data model's authorization rules.
If you're using dynamic group authorization and you authorize based on a single group per record, subscriptions are only supported if the user is part of five or fewer user groups.
Additionally, if you authorize by using an array of groups (groups: [String]),
subscriptions are only supported if the user is part of 20 or fewer groups
you can only authorize 20 or fewer user groups per record
Subscription connection status updates

Now that your application is set up and using subscriptions, you may want to know when the subscription is finally established, or reflect to your users when the subscription isn't healthy. You can monitor the connection state for changes through the Hub local eventing system.

Copy
code example
import { CONNECTION_STATE_CHANGE, ConnectionState } from 'aws-amplify/data';
import { Hub } from 'aws-amplify/utils';


Hub.listen('api', (data: any) => {
  const { payload } = data;
  if (payload.event === CONNECTION_STATE_CHANGE) {
    const connectionState = payload.data.connectionState as ConnectionState;
    console.log(connectionState);
  }
});
Subscription connection states
Connected - Connected and working with no issues.
ConnectedPendingDisconnect - The connection has no active subscriptions and is disconnecting.
ConnectedPendingKeepAlive - The connection is open, but has missed expected keep-alive messages.
ConnectedPendingNetwork - The connection is open, but the network connection has been disrupted. When the network recovers, the connection will continue serving traffic.
Connecting - Attempting to connect.
ConnectionDisrupted - The connection is disrupted and the network is available.
ConnectionDisruptedPendingNetwork - The connection is disrupted and the network connection is unavailable.
Disconnected - Connection has no active subscriptions and is disconnecting.
Troubleshooting
Troubleshoot connection issues and automated reconnection
Unsubscribe from a subscription

You can also unsubscribe from events by using subscriptions by implementing the following:

Copy
code example
// Stop receiving data updates from the subscription
sub.unsubscribe();
Conclusion

Congratulations! You have finished the Subscribe to real-time events guide. In this guide, you set up subscriptions for real-time events and learned how to filter and cancel these subscriptions when needed.

Next steps

Our recommended next steps include continuing to build out and customize your information architecture for your data. Some resources that will help with this work include:

Customize your auth rules
Customize your data model
Add custom business logic
PREVIOUS
Read application data
NEXT
Customize your data model

--------------------------------------------------------------------------------

Title: Customize your data model - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/data-modeling/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Customize your data model
Customize your data model
Data modeling capabilities

Every data model is defined as part of a data schema (a.schema()). You can enhance your data model with various fields, customize their identifiers, apply authorization rules, or model relationships. Every data model (a.model()) automatically provides create, read, update, and delete API operations as well as real-time subscription events. Below is a quick tour of the many functionalities you can add to your data model:

Copy
code example
import { type ClientSchema, a, defineData } from '@aws-amplify/backend';


const schema = a
  .schema({
    Customer: a
      .model({
        customerId: a.id().required(),
        // fields can be of various scalar types,
        // such as string, boolean, float, integers etc.
        name: a.string(),
        // fields can be of custom types
        location: a.customType({
          // fields can be required or optional
          lat: a.float().required(),
          long: a.float().required(),
        }),
        // fields can be enums
        engagementStage: a.enum(["PROSPECT", "INTERESTED", "PURCHASED"]),
        collectionId: a.id(),
        collection: a.belongsTo("Collection", "collectionId")
        // Use custom identifiers. By default, it uses an `id: a.id()` field
      })
      .identifier(["customerId"]),
    Collection: a
      .model({
        customers: a.hasMany("Customer", "collectionId"), // setup relationships between types
        tags: a.string().array(), // fields can be arrays
        representativeId: a.id().required(),
        // customize secondary indexes to optimize your query performance
      })
      .secondaryIndexes((index) => [index("representativeId")]),
  })
  .authorization((allow) => [allow.publicApiKey()]);


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: "apiKey",
    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});
Add fields to data model
Configure built-in and custom field types.
Modeling relationships
Learn about the types of model relationships and modeling relationships.
Customize data model identifiers
Define the primary key for a model using single-field or composite identifiers.
Customize secondary indexes
Define the secondary indexes for your data model to optimize query performance
Gen 1 schema support

If you are coming from Gen 1, you can continue to use the GraphQL Schema Definition Language (SDL) for defining your schema. However, we strongly recommend you use the TypeScript-first schema builder experience in your project as it provides type safety and is the recommended way of working with Amplify going forward.

Note: Some features available in Gen 1 GraphQL SDL are not available in Gen 2. See the feature matrix for features supported in Gen 2.

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
import { defineData } from '@aws-amplify/backend';


const schema = /* GraphQL */`
  type Todo @model @auth(rules: [{ allow: owner }]) {
    content: String
    isDone: Boolean
  }
`;


export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: "apiKey",
    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});

--------------------------------------------------------------------------------

Title: Create, update, and delete application data - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/mutate-data/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Create, update, and delete application data
Create, update, and delete application data

In this guide, you will learn how to create, update, and delete your data using Amplify Libraries' Data client.

Before you begin, you will need:

An application connected to the API
Create an item

You can create an item by first generating the Data client with your backend Data schema. Then you can add an item:

Copy
code example
import { generateClient } from 'aws-amplify/data';
import { type Schema } from '../amplify/data/resource'


const client = generateClient<Schema>();


const { errors, data: newTodo } = await client.models.Todo.create({
  content: "My new todo",
  isDone: true,
})

Note: You do not need to specify createdAt or updatedAt fields because Amplify automatically populates these fields for you.

Update an item

To update the item, use the update function:

Copy
code example
import { generateClient } from 'aws-amplify/data';
import { type Schema } from '../amplify/data/resource';


const client = generateClient<Schema>();


const todo = {
  id: 'some_id',
  content: 'Updated content',
};


const { data: updatedTodo, errors } = await client.models.Todo.update(todo);

Notes:

You do not need to specify the updatedAt field. Amplify will automatically populate this field for you.
If you specify extra input fields not expected by the API, this query will fail. You can see this in the errors field returned by the query. With Amplify Data, errors are not thrown like exceptions. Instead, any errors are captured and returned as part of the query result in the errors field.
Delete an item

You can then delete the Todo by using the delete mutation. To specify which item to delete, you only need to provide the id of that item:

Copy
code example
import { generateClient } from 'aws-amplify/data';
import { type Schema } from '../amplify/data/resource'


const client = generateClient<Schema>();


const toBeDeletedTodo = {
  id: '123123213'
}


const { data: deletedTodo, errors } = await client.models.Todo.delete(toBeDeletedTodo)

Note: When deleting items in many-to-many relationships, the join table records must be deleted before deleting the associated records. For example, for a many-to-many relationship between Posts and Tags, delete the PostTags join record before deleting a Post or Tag. Review Many-to-many relationships for more details.

Troubleshooting
Troubleshoot unauthorized errors
Cancel create, update, and delete requests

You can cancel any mutation API request by calling .cancel on the mutation request promise that's returned by .create(...), .update(...), or .delete(...).

Copy
code example
const promise = client.models.Todo.create({ content: 'New Todo ' });
//  ^ Note: we're not awaiting the request, we're returning the promise


try {
  await promise;
} catch (error) {
  console.log(error);
  // If the error is because the request was cancelled you can confirm here.
  if (client.isCancelError(error)) {
    console.log(error.message); // "my message for cancellation"
    // handle user cancellation logic
  }
}


//...


// To cancel the above request
client.cancel(promise, 'my message for cancellation');

You need to ensure that the promise returned from .create(), .update(), and .delete() has not been modified. Typically, async functions wrap the promise being returned into another promise. For example, the following will not work:

Copy
code example
async function makeAPICall() {
  return client.models.Todo.create({ content: 'New Todo' });
}
const promise = makeAPICall();


// The following will NOT cancel the request.
client.cancel(promise, 'my error message');
Conclusion

Congratulations! You have finished the Create, update, and delete application data guide. In this guide, you created, updated, and deleted your app data.

Next steps

Our recommended next steps include using the API to query data and subscribe to real-time events to look for mutations in your data. Some resources that will help with this work include:

Read application data
Subscribe to real-time events
PREVIOUS
Connect your app code to API
NEXT
Read application data

--------------------------------------------------------------------------------

Title: Read application data - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/query-data/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Read application data
Read application data

You can read application data using the Amplify Data client. In this guide, we will review the difference between reading data and getting data, how to filter query results to get just the data you need, and how to paginate results to make your data more manageable. We will also show you how to cancel these requests when needed.

Before you begin, you will need:

An application connected to the API
Data already created to view
List and get your data

Queries are used to read data through the API and include the list and get operations. Amplify Data automatically creates list and get queries for any a.model() type in your schema. The list query retrieves multiple items, such as Todo items, without needing to specific an identifier for a particular record. This is best suited for getting an overview or summary of items, or for enhancing the list operation to filter the items by specific criteria. When you want to query a single entry by an identifier, you would use get to retrieve a specific Todo item.

Note: The cost structure of your underlying data source can impact the cost to run some queries. For example, the list operation uses Amazon DynamoDB "scan operations," which can use more read request units than the get operation. You will want to review the associated costs for these operations for your data source. In our example, we are using DynamoDB. You can learn more about how DynamoDB costs are calculated by visiting Amazon DynamoDB pricing.

You can list items by first generating the Data client with your backend Data schema. Then you can list items of your desired model:

Copy
code example
import { generateClient } from 'aws-amplify/data';
import { type Schema } from '@/amplify/data/resource';


const client = generateClient<Schema>();


// list all items
const { data: todos, errors } = await client.models.Todo.list();


// get a specific item
const { data: todo, errors } = await client.models.Todo.get({
  id: '...',
});
Troubleshooting
Troubleshoot unauthorized errors
Filter list queries

As your data grows, you will need to paginate your list queries. Fortunately, this is already built in to Amplify Data.

Copy
code example
import { generateClient } from 'aws-amplify/data';
import { type Schema } from '@/amplify/data/resource';


const client = generateClient<Schema>();


const { data: todos, errors } = await client.models.Todo.list({
  filter: {
    content: {
      beginsWith: 'hello'
    }
  }
});
Compound filters

You can combine filters with and, or, and not Boolean logic. Observe that filter is recursive in respect to those fields. So if, for example, you wanted to filter for priority values of 1 or 2, you would do this:

Copy
code example
import { generateClient } from 'aws-amplify/data';
import { type Schema } from '@/amplify/data/resource';


const client = generateClient<Schema>();


const { data: todos, errors } = await client.models.Todo.list({
  filter: {
    or: [
      {
        priority: { eq: '1' }
      },
      {
        priority: { eq: '2' }
      }
    ]
  }
});

Note that querying for priority of 1 and 2 would return no results, because this is Boolean logic instead of natural language.

Paginate list queries

To paginate your list query results, make a subsequent list query request with the nextToken and limit input variable set. The limit variable limits how many results are returned. The response will include a nextToken you can use to request the next page of data. A nextToken is a very long string that represents the cursor to the starting item of the next query made with these filters.

Copy
code example
import { generateClient } from 'aws-amplify/data';
import { type Schema } from '@/amplify/data/resource';


const client = generateClient<Schema>();


const {
  data: todos,
  nextToken, // Repeat this API call with the nextToken until the returned nextToken is `null`
  errors
} = await client.models.Todo.list({
  limit: 100, // default value is 100
  nextToken: 'eyJ2ZXJzaW9uejE1a2...' // previous nextToken
});

If you're building a React application, you can use the usePagination hook in Amplify UI to help with managing the pagination user experience.

Copy
code example
import * as React from 'react';
import { Pagination } from '@aws-amplify/ui-react';


export const PaginationHasMorePagesExample = () => {
  const [pageTokens, setPageTokens] = React.useState([null]);
  const [currentPageIndex, setCurrentPageIndex] = React.useState(1);
  const [hasMorePages, setHasMorePages] = React.useState(true);


  const handleNextPage = async () => {
    if (hasMorePages && currentPageIndex === pageTokens.length) {
      const { data: todos, nextToken } = await client.models.Todo.list({
        nextToken: pageTokens[pageTokens.length - 1]
      });


      if (!nextToken) {
        setHasMorePages(false);
      }


      setPageTokens([...pageTokens, nextToken]);
    }


    setCurrentPageIndex(currentPageIndex + 1);
  };


  return (
    <Pagination
      currentPage={currentPageIndex}
      totalPages={pageTokens.length}
      hasMorePages={hasMorePages}
      onNext={handleNextPage}
      onPrevious={() => setCurrentPageIndex(currentPageIndex - 1)}
      onChange={(pageIndex) => setCurrentPageIndex(pageIndex)}
    />
  );
};

Limitations:

There is no API to get a total page count at this time. Note that scanning all items is a potentially expensive operation.
You cannot query by page number; you have to query by nextToken.
Fetch only the data you need with custom selection set

A business domain model may contain many models with numerous fields. However, apps typically only need subsets of the data or fields to meet the requirements of different components or screens. It is necessary to have a mechanism to retrieve subsets of models and their relationships. This mechanism would help optimize data usage for screens and components by only transferring needed data. Having this capability would improve the app's data efficiency, latency, and the end user's perceived performance.

A custom selection set allows consumers to specify, on a per-call basis, the fields the consumer wants to retrieve; this is possible for all operations that return data (CRUDL + observeQuery). The desired fields are specified in a strongly typed way (discoverable through IntelliSense) with a "dot notation".

Copy
code example
// same way for all CRUDL: .create, .get, .update, .delete, .list, .observeQuery
const { data: blogWithSubsetOfData, errors } = await client.models.Blog.get(
  { id: blog.id },
  {
    selectionSet: ['author.email', 'posts.*'],
  }
);
TypeScript type helpers for Amplify Data

When using TypeScript, you frequently need to specify data model types for type generics. For instance, with React's useState, you provide a type in TypeScript to ensure type-safety in your component code using the state. Use the Schema["MODEL_NAME"]["type"] pattern to get TypeScript types for the shapes of data models returned from the backend API. This allows you to get consumable TypeScript types for the shapes of the data model return values coming from the backend API.

Copy
code example
import { type Schema } from '@/amplify/data/resource';


type Post = Schema['Post']['type'];


const [posts, setPosts] = useState<Post[]>([]);

You can combine the Schema["MODEL_NAME"]["type"] type with the SelectionSet helper type to describe the return type of API requests using the selectionSet parameter:

Copy
code example
import type { SelectionSet } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource';




const selectionSet = ['content', 'blog.author.*', 'comments.*'] as const;
type PostWithComments = SelectionSet<Schema['Post']['type'], typeof selectionSet>;


// ...
const [posts, setPosts] = useState<PostWithComments[]>([]);


const fetchPosts = async () => {
  const { data: postsWithComments } = await client.models.Post.list({
    selectionSet,
  });
  setPosts(postsWithComments);
}
Cancel read requests

You can cancel any query API request by calling .cancel on the query request promise that's returned by .list(...) or .get(...).

Copy
code example
const promise = client.models.Todo.list();
//  ^ Note: we're not awaiting the request, we're returning the promise


try {
  await promise;
} catch (error) {
  console.log(error);
  // If the error is because the request was cancelled you can confirm here.
  if (client.isCancelError(error)) {
    console.log(error.message); // "my message for cancellation"
    // handle user cancellation logic
  }
}
...


// To cancel the above request
client.cancel(promise, "my message for cancellation");

You need to ensure that the promise returned from .list() or .get() has not been modified. Typically, async functions wrap the promise being returned into another promise. For example, the following will not work:

Copy
code example
async function makeAPICall() {
  return client.models.Todo.list();
}
const promise = makeAPICall();


// The following will NOT cancel the request.
client.cancel(promise, 'my error message');
Conclusion

Congratulations! You have finished the Read application data guide. In this guide, you learned how to read your data through get and list queries.

Next steps

Our recommended next steps include subscribing to real-time events to look for mutations in your data and continuing to build out and customize your information architecture for your data. Some resources that will help with this work include:

Subscribe to real-time events
Customize your auth rules
Customize your data model
Add custom business logic
PREVIOUS
Create, update, and delete application data
NEXT
Subscribe to real-time events

--------------------------------------------------------------------------------

Title: Connect your app code to API - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/connect-to-API/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Connect your app code to API
Connect your app code to API

In this guide, you will connect your application code to the backend API using the Amplify Libraries. Before you begin, you will need:

Your cloud sandbox with an Amplify Data resource up and running (npx ampx sandbox)
A frontend application set up with the Amplify library installed
npm installed
Configure the Amplify Library

When you deploy you're iterating on your backend (npx ampx sandbox), an amplify_outputs.json file is generated for you. This file contains your API's endpoint information and auth configurations. Add the following code to your app's entrypoint to initialize and configure the Amplify client library:

Copy
code example
import { Amplify } from 'aws-amplify';
import outputs from '../amplify_outputs.json';


Amplify.configure(outputs);
Generate the Amplify Data client

Once the Amplify library is configured, you can generate a "Data client" for your frontend code to make fully-typed API requests to your backend.

If you're using Amplify with a JavaScript-only frontend (i.e. not TypeScript), then you can still get a fully-typed data fetching experience by annotating the generated client with a JSDoc comment. Select the JavaScript in the code block below to see how.

To generate a new Data client, use the following code:

TypeScript
JavaScript
Copy
code example
import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition


const client = generateClient<Schema>();


// Now you should be able to make CRUDL operations with the
// Data client
const fetchTodos = async () => {
  const { data: todos, errors } = await client.models.Todo.list();
};
Configure authorization mode

The Authorization Mode determines how a request should be authorized with the backend. By default, Amplify Data uses the "userPool" authorization which uses the signed-in user credentials to sign an API request. If you use a allow.publicApiKey() authorization rules for your data models, you need to use "apiKey" as an authorization mode. Review Customize your auth rules to learn more about which authorization modes to choose for which type of request. A Default Authorization Mode is provided as part of the amplify_outputs.json that is generated upon a successful deployment.

You can generate different Data clients with different authorization modes or pass in the authorization mode at the request time.

Set authorization mode on a per-client basis

To apply the same authorization mode on all requests from a Data client, specify the authMode parameter on the generateClient function.

API Key
Amazon Cognito user pool
AWS IAM (including Amazon Cognito identity pool roles)
OpenID Connect (OIDC)
Lambda Authorizer

Use "API Key" as your authorization mode when if defined the allow.publicApiKey() authorization rule.

Copy
code example
import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition


const client = generateClient<Schema>({
  authMode: 'apiKey',
});
Set authorization mode on the request-level

You can also specify the authorization mode on each individual API request. This is useful if your application typically only uses one authorization mode with a small number of exceptions.

API Key
Amazon Cognito user pool
AWS IAM (including Amazon Cognito identity pool roles)
OpenID Connect (OIDC)
Lambda Authorizer
Copy
code example
const { data: todos, errors } = await client.models.Todo.list({
  authMode: 'apiKey',
});
Set custom request headers

When working with the Amplify Data endpoint, you may need to set request headers for authorization purposes or to pass additional metadata from your frontend to the backend API.

This is done by specifying a headers parameter into the configuration. You can define headers either on a per Data client-level or on a per-request level:

Custom headers per Data client
Custom headers per request
Copy
code example
import type { Schema } from '../amplify/data/resource';
import { generateClient } from 'aws-amplify/data';


const client = generateClient<Schema>({
  headers: {
    'My-Custom-Header': 'my value',
  },
});

The examples above show you how to set static headers but you can also programmatically set headers by specifying an async function for headers:

Custom headers per Data client
Custom headers per request
Copy
code example
import type { Schema } from '../amplify/data/resource';
import { generateClient } from 'aws-amplify/data';


const client = generateClient<Schema>({
  headers: async (requestOptions) => {
    console.log(requestOptions);
    /* The request options allow you to customize your headers based on the request options such
       as http method, headers, request URI, and query string. These options are typically used
       to create a request signature.
    {
      method: '...',
      headers: { },
      uri: '/',
      queryString: ""
    }
    */
    return {
      'My-Custom-Header': 'my value',
    };
  },
});
PREVIOUS
Set up Amplify Data
NEXT
Create, update, and delete application data

--------------------------------------------------------------------------------

Title: Set up Amplify Data - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/set-up-data/
HTML Content:
Next.js
/
Build & connect backend
/
Data
/
Set up Amplify Data
Set up Amplify Data

In this guide, you will learn how to set up Amplify Data. This includes building a real-time API and database using TypeScript to define your data model, and securing your API with authorization rules. We will also explore using AWS Lambda to scale to custom use cases.

Before you begin, you will need:

Node.js v18.16.0 or later
npm v6.14.4 or later
git v2.14.1 or later

With Amplify Data, you can build a secure, real-time API backed by a database in minutes. After you define your data model using TypeScript, Amplify will deploy a real-time API for you. This API is powered by AWS AppSync and connected to an Amazon DynamoDB database. You can secure your API with authorization rules and scale to custom use cases with AWS Lambda.

Building your data backend

If you've run npm create amplify@latest already, you should see an amplify/data/resource.ts file, which is the central location to configure your data backend. The most important element is the schema object, which defines your backend data models (a.model()) and custom queries (a.query()), mutations (a.mutation()), and subscriptions (a.subscription()).

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
import { a, defineData, type ClientSchema } from '@aws-amplify/backend';


const schema = a.schema({
  Todo: a.model({
      content: a.string(),
      isDone: a.boolean()
    })
    .authorization(allow => [allow.publicApiKey()])
});


// Used for code completion / highlighting when making requests from frontend
export type Schema = ClientSchema<typeof schema>;


// defines the data resource to be deployed
export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: 'apiKey',
    apiKeyAuthorizationMode: { expiresInDays: 30 }
  }
});

Every a.model() automatically creates the following resources in the cloud:

a DynamoDB database table to store records
query and mutation APIs to create, read (list/get), update, and delete records
createdAt and updatedAt fields that help you keep track of when each record was initially created or when it was last updated
real-time APIs to subscribe for create, update, and delete events of records

The allow.publicApiKey() rule designates that anyone authenticated using an API key can create, read, update, and delete todos.

To deploy these resources to your cloud sandbox, run the following CLI command in your terminal:

Terminal
Copy
Terminal code example
npx ampx sandbox
Connect your application code to the data backend

Once the cloud sandbox is up and running, it will also create an amplify_outputs.json file, which includes the relevant connection information to your data backend, like your API endpoint URL and API key.

To connect your frontend code to your backend, you need to:

Configure the Amplify library with the Amplify client configuration file (amplify_outputs.json)
Generate a new API client from the Amplify library
Make an API request with end-to-end type-safety

First, install the Amplify client library to your project:

Terminal
Copy
Terminal code example
npm add aws-amplify

In your app's entry point, typically main.tsx for React apps created using Vite, make the following edits:

src/main.tsx
Copy
src/main.tsx code example
import { Amplify } from 'aws-amplify';
import outputs from '../amplify_outputs.json';


Amplify.configure(outputs);
Write data to your backend

Let's first add a button to create a new todo item. To make a "create Todo" API request, generate the data client using generateClient() in your frontend code, and then call .create() operation for the Todo model. The Data client is a fully typed client that gives you in-IDE code completion. To enable this in-IDE code completion capability, pass in the Schema type to the generateClient function.

src/TodoList.tsx
Copy
src/TodoList.tsx code example
import type { Schema } from '../amplify/data/resource'
import { generateClient } from 'aws-amplify/data'


const client = generateClient<Schema>()


export default function TodoList() {
  const createTodo = async () => {
    await client.models.Todo.create({
      content: window.prompt("Todo content?"),
      isDone: false
    })
  }


  return <div>
    <button onClick={createTodo}>Add new todo</button>
  </div>
}

Run the application in local development mode and check your network tab after creating a todo. You should see a successful request to a /graphql endpoint.

Try playing around with the code completion of .update(...) and .delete(...) to get a sense of other mutation operations.

Read data from your backend

Next, list all your todos and then refetch the todos after a todo has been added:

src/TodoList.tsx
Copy
src/TodoList.tsx code example
import { useState, useEffect } from "react";
import type { Schema } from "../amplify/data/resource";
import { generateClient } from "aws-amplify/data";


const client = generateClient<Schema>();


export default function TodoList() {
  const [todos, setTodos] = useState<Schema["Todo"]["type"][]>([]);


  const fetchTodos = async () => {
    const { data: items, errors } = await client.models.Todo.list();
    setTodos(items);
  };


  useEffect(() => {
    fetchTodos();
  }, []);


  const createTodo = async () => {
    await client.models.Todo.create({
      content: window.prompt("Todo content?"),
      isDone: false,
    });


    fetchTodos();
  }


  return (
    <div>
      <button onClick={createTodo}>Add new todo</button>
      <ul>
        {todos.map(({ id, content }) => (
          <li key={id}>{content}</li>
        ))}
      </ul>
    </div>
  );
}
Subscribe to real-time updates

You can also use observeQuery to subscribe to a live feed of your backend data. Let's refactor the code to use a real-time observeQuery instead.

src/App.tsx
Copy
src/App.tsx code example
import type { Schema } from "../amplify/data/resource";
import { useState, useEffect } from "react";
import { generateClient } from "aws-amplify/data";


const client = generateClient<Schema>();


export default function TodoList() {
  const [todos, setTodos] = useState<Schema["Todo"]["type"][]>([]);


  useEffect(() => {
    const sub = client.models.Todo.observeQuery().subscribe({
      next: ({ items }) => {
        setTodos([...items]);
      },
    });


    return () => sub.unsubscribe();
  }, []);


  const createTodo = async () => {
    await client.models.Todo.create({
      content: window.prompt("Todo content?"),
      isDone: false,
    });
    // no more manual refetchTodos required!
    // - fetchTodos()
  };


  return (
    <div>
      <button onClick={createTodo}>Add new todo</button>
      <ul>
        {todos.map(({ id, content }) => (
          <li key={id}>{content}</li>
        ))}
      </ul>
    </div>
  );
}

Now try to open your app in two browser windows and see how creating a todo in one window automatically adds the todo in the second window as well.

You can also use .onCreate, .onUpdate, or .onDelete to subscribe to specific events. Review Subscribe to real-time events to learn more about subscribing to specific mutation events.

Conclusion

Success! You've learned how to create your first real-time API and database with Amplify Data.

Next steps

There's so much more to discover with Amplify Data. Learn more about:

How to model your database table and their access patterns
Secure your API with fine-grained authorization rules
Create relationships between different database model
Add custom business logic
NEXT
Connect your app code to API

--------------------------------------------------------------------------------

Title: Data - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/data/
HTML Content:
Next.js
/
Build & connect backend
/
Data
Data
Set up Amplify Data
Create a new cloud API that connects your app with new or existing data sources.
Connect your app code to API
Learn how to connect your app code to an API.
Create, update, and delete application data
Mutate application data in an API by generating the client, adding items, updating existing items, deleting items, troubleshooting unauthorized errors, and canceling requests.
Read application data
Read application data using list and get queries. You can filter query results, paginate list queries, specify only the data fields needed, and cancel requests. This guide covers how to perform these tasks to optimize data access in your application.
Subscribe to real-time events
Set up real-time data subscriptions in your app to get live updates, filter those subscriptions on the server side, and unsubscribe when no longer needed.
Customize your data model
Learn how to customize your data model.
Customize your auth rules
Learn how to customize and combine your authorization rules.
Add custom queries and mutations
Customize your business logic for queries and mutations.
Working with files/attachments
Working with files/attachments.
Add custom real-time subscriptions
Customize your business logic to create custom real-time subscriptions.
Connect to existing data sources
Learn how to connect your Data API to existing DynamoDB tables, MySQL databases, or PostgreSQL databases.
Connect to data from Server-side Runtimes
Connect to Amplify Data from Next.js and Nuxt.js Server-side Runtimes (SSR).
Optimistic UI
Learn more about implementing optimistic UI with Amplify Data API.
Modify Amplify-generated AWS resources
Modify and customize existing AWS resources generated by the Amplify GraphQL API.
Manage Data with Amplify console
Manage GraphQL data with Amplify console

--------------------------------------------------------------------------------

Title: Advanced workflows - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/advanced-workflows/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Advanced workflows
Advanced workflows
Subscribing to Events

You can take specific actions when users sign-in or sign-out by subscribing to authentication events in your app. Please see our Hub Module Developer Guide for more information.

Identity Pool Federation

You can alternatively create your own custom credentials provider to get AWS credentials directly from Cognito Federated Identities and not use User Pool federation. You must supply the custom credentials provider to Amplify via the Amplify.configure method call. Below, you can see sample code of how such a custom provider can be built to achieve the use case.

Copy
code example
import { Amplify } from 'aws-amplify';
import {
  fetchAuthSession,
  CredentialsAndIdentityIdProvider,
  CredentialsAndIdentityId,
  GetCredentialsOptions,
  AuthTokens,
} from 'aws-amplify/auth';


// Note: This example requires installing `@aws-sdk/client-cognito-identity` to obtain Cognito credentials
// npm i @aws-sdk/client-cognito-identity
import { CognitoIdentity } from '@aws-sdk/client-cognito-identity';


// You can make use of the sdk to get identityId and credentials
const cognitoidentity = new CognitoIdentity({
  region: '<region-from-config>',
});


// Note: The custom provider class must implement CredentialsAndIdentityIdProvider
class CustomCredentialsProvider implements CredentialsAndIdentityIdProvider {


  // Example class member that holds the login information
  federatedLogin?: {
    domain: string,
    token: string
  };


  // Custom method to load the federated login information
  loadFederatedLogin(login?: typeof this.federatedLogin) {
    // You may also persist this by caching if needed
    this.federatedLogin = login;
  }


  async getCredentialsAndIdentityId(
    getCredentialsOptions: GetCredentialsOptions
  ): Promise<CredentialsAndIdentityId | undefined> {
    try {


      // You can add in some validation to check if the token is available before proceeding
      // You can also refresh the token if it's expired before proceeding


      const getIdResult = await cognitoidentity.getId({
        // Get the identityPoolId from config
        IdentityPoolId: '<identity-pool-id-from-config>',
        Logins: { [this.federatedLogin.domain]: this.federatedLogin.token },
      });


      const cognitoCredentialsResult = await cognitoidentity.getCredentialsForIdentity({
        IdentityId: getIdResult.IdentityId,
        Logins: { [this.federatedLogin.domain]: this.federatedLogin.token },
      });


      const credentials: CredentialsAndIdentityId = {
        credentials: {
          accessKeyId: cognitoCredentialsResult.Credentials?.AccessKeyId,
          secretAccessKey: cognitoCredentialsResult.Credentials?.SecretKey,
          sessionToken: cognitoCredentialsResult.Credentials?.SessionToken,
          expiration: cognitoCredentialsResult.Credentials?.Expiration,
        },
        identityId: getIdResult.IdentityId,
      };
      return credentials;
    } catch (e) {
      console.log('Error getting credentials: ', e);
    }
  }
  // Implement this to clear any cached credentials and identityId. This can be called when signing out of the federation service.
  clearCredentialsAndIdentityId(): void {}
}


// Create an instance of your custom provider
const customCredentialsProvider = new CustomCredentialsProvider();
Amplify.configure(awsconfig, {
  Auth: {
    // Supply the custom credentials provider to Amplify
    credentialsProvider: customCredentialsProvider
  },
});

Now that the custom credentials provider is built and supplied to Amplify.configure, let's look at how you can use the custom credentials provider to finish federation into Cognito identity pool.

Facebook sign-in (React)
Copy
code example
import React, { useEffect } from 'react';
import {
  fetchAuthSession,
} from 'aws-amplify/auth';


// To federated sign in from Facebook
const SignInWithFacebook = () => {


  useEffect(() => {
    if (!window.FB) createScript();
  }, [])


  const signIn = () => {
    const fb = window.FB;
    fb.getLoginStatus(response => {
      if (response.status === 'connected') {
        getAWSCredentials(response.authResponse);
      } else {
        fb.login(
          response => {
            if (!response || !response.authResponse) {
              return;
            }
            customCredentialsProvider.loadFederatedLogin({
              domain: 'graph.facebook.com',
              token: response.authResponse.accessToken,
            });
            const fetchSessionResult = await fetchAuthSession(); // will return the credentials
            console.log('fetchSessionResult: ', fetchSessionResult);
          },
          {
            // the authorized scopes
            scope: 'public_profile,email'
          }
        );
      }
    });
  }


  const createScript = () => {
    // load the sdk
    window.fbAsyncInit = fbAsyncInit;
    const script = document.createElement('script');
    script.src = 'https://connect.facebook.net/en_US/sdk.js';
    script.async = true;
    script.onload = initFB;
    document.body.appendChild(script);
  }


  const initFB = () => {
    const fb = window.FB;
    console.log('FB SDK initialized');
  }


  const fbAsyncInit = () => {
    // init the fb sdk client
    const fb = window.FB;
    fb.init({
      appId   : 'your_facebook_app_id',
      cookie  : true,
      xfbml   : true,
      version : 'v2.11'
    });
  }


  return (
    <div>
      <button onClick={signIn}>Sign in with Facebook</button>
    </div>
  );
}
Google sign-in (React)
Copy
code example
import React, { useEffect } from 'react';
import jwt from 'jwt-decode';
import {
  fetchAuthSession,
} from 'aws-amplify/auth';


const SignInWithGoogle = () => {
  useEffect(() => {
  // Check for an existing Google client initialization
    if (!window.google?.accounts) createScript();
  }, []);


  // Load the Google client
  const createScript = () => {
    const script = document.createElement('script');
    script.src = 'https://accounts.google.com/gsi/client';
    script.async = true;
    script.defer = true;
    script.onload = initGsi;
    document.body.appendChild(script);
  }


  // Initialize Google client and render Google button
  const initGsi = () => {
    if (window.google?.accounts) {
      window.google.accounts.id.initialize({
        client_id: process.env.GOOGLE_CLIENT_ID,
        callback: (response: any) => {
          customCredentialsProvider.loadFederatedLogin({
            domain: 'accounts.google.com',
            token: response.credential,
          });
          const fetchSessionResult = await fetchAuthSession(); // will return the credentials
          console.log('fetchSessionResult: ', fetchSessionResult);
        },
      });
      window.google.accounts.id.renderButton(
        document.getElementById('googleSignInButton'),
        { theme: 'outline', size: 'large' }
      );
    }
  }


  return (
    <div>
      <button id='googleSignInButton'/>
    </div>
  );
}
Federate with Auth0

You can use Auth0 as one of the providers of your Cognito Identity Pool. This will allow users authenticated via Auth0 have access to your AWS resources.

Step 1. Follow Auth0 integration instructions for Cognito Federated Identity Pools

Step 2. Login with Auth0, then use the id token returned to get AWS credentials from Cognito Federated Identity Pools using custom credentials provider you created at the start:

Copy
code example
import { fetchAuthSession } from 'aws-amplify/auth';


const { idToken, domain, name, email, phoneNumber } = getFromAuth0(); // get the user credentials and info from auth0


async function getCognitoCredentials() {
  try {
    customCredentialsProvider.loadFederatedLogin({
      domain,
      token: idToken
    });
    const fetchSessionResult = await fetchAuthSession(); // will return the credentials
    console.log('fetchSessionResult: ', fetchSessionResult);
  } catch (err) {
    console.log(err);
  }
}
Lambda Triggers

With the triggers property of defineAuth and defineFunction from the new Functions implementation, you can define Lambda Triggers for your Cognito User Pool. These enable you to add custom functionality to your registration and authentication flows. Check out a preSignUp hook example here.

Pre Authentication and Pre Sign-up Lambda triggers

If you have a Pre Authentication Lambda trigger enabled, you can pass clientMetadata as an option for signIn. This metadata can be used to implement additional validations around authentication.

Copy
code example
import { signIn } from 'aws-amplify/auth';


async function handleSignIn(username: string, password: string) {
  try {
    await signIn({
      username,
      password,
      options: {
        clientMetadata: {} // Optional, an object of key-value pairs which can contain any key and will be passed to your Lambda trigger as-is.
      }
    });
  } catch (err) {
    console.log(err);
  }
}
Passing metadata to other Lambda triggers

Many Cognito Lambda Triggers also accept unsanitized key/value pairs in the form of a clientMetadata attribute. This attribute can be specified for various Auth APIs which result in Cognito Lambda Trigger execution.

These APIs include:

signIn
signUp
confirmSignIn
confirmSignUp
resetPassword
confirmResetPassword
resendSignUpCode
updateUserAttributes

Please note that some of triggers which accept a validationData attribute will use clientMetadata as the value for validationData. Exercise caution with using clientMetadata when you are relying on validationData.

Working with AWS service objects

You can use AWS Service Interface Objects to work with AWS Services in authenticated State. You can call methods on any AWS Service interface object by passing your credentials from Amplify fetchAuthSession to the service call constructor:

Copy
code example
import { fetchAuthSession } from 'aws-amplify/auth';
import Route53 from 'aws-sdk/clients/route53';


async function changeResourceRecordSets() {
  try {
    const { credentials } = await fetchAuthSession();


    const route53 = new Route53({
      apiVersion: '2013-04-01',
      credentials
    });


    // more code working with route53 object
    //route53.changeResourceRecordSets();
  } catch (err) {
    console.log(err);
  }
}

Note: To work with Service Interface Objects, your Amazon Cognito users' IAM role must have the appropriate permissions to call the requested services.

Custom Token providers

Create a custom Auth token provider for situations where you would like provide your own tokens for a service. For example, using OIDC Auth with AppSync. You must supply the token provider to Amplify via the Amplify.configure method call. Below, you can see sample code of how such a custom provider can be built to achieve the use case.

Copy
code example
import { Amplify } from 'aws-amplify';
import { TokenProvider, decodeJWT } from 'aws-amplify/auth';


// ...


const myTokenProvider: TokenProvider = {
  async getTokens({ forceRefresh } = {}) {
    if (forceRefresh) {
      // try to obtain new tokens if possible
    }


    const accessTokenString = '<insert JWT from provider>';
    const idTokenString = '<insert JWT from provider>';
    
    return {
      accessToken: decodeJWT(accessTokenString),
      idToken: decodeJWT(idTokenString),
    };
  },
};


Amplify.configure(awsconfig, {
  Auth: {
    tokenProvider: myTokenProvider
  }
});
API reference

For the complete API documentation for Authentication module, visit our API Reference

PREVIOUS
Moving to production
NEXT
Use existing Cognito resources

--------------------------------------------------------------------------------

Title: Use existing Cognito resources - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/use-existing-cognito-resources/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Use existing Cognito resources
Use existing Cognito resources

Amplify Auth can be configured to use an existing Amazon Cognito user pool and identity pool. If you are in a team setting or part of a company that has previously created auth resources, you can configure the client library directly, or maintain references with AWS Cloud Development Kit (AWS CDK) in your Amplify backend.

Note: when using existing auth resources, it may be necessary to add additional policies or permissions for your authenticated and unauthenticated IAM roles. These changes must be performed manually.

Use auth resources without an Amplify backend

You can use existing resources without an Amplify backend by configuring the client library directly.

src/main.ts
Copy
src/main.ts code example
import { Amplify } from "aws-amplify"


Amplify.configure({
  Auth: {
    Cognito: {
      userPoolId: "<your-cognito-user-pool-id>",
      userPoolClientId: "<your-cognito-user-pool-client-id>",
      identityPoolId: "<your-cognito-identity-pool-id>",
      loginWith: {
        email: true,
      },
      signUpVerificationMethod: "code",
      userAttributes: {
        email: {
          required: true,
        },
      },
      allowGuestAccess: true,
      passwordFormat: {
        minLength: 8,
        requireLowercase: true,
        requireUppercase: true,
        requireNumbers: true,
        requireSpecialCharacters: true,
      },
    },
  },
})
Use auth resources with an Amplify backend

Warning: Amplify resources do not support including auth configurations by referencing with CDK. We are currently working to improve this experience by providing first-class support for referencing existing auth resources. View the RFC for referenceAuth for more details

Next steps
Learn how to connect your frontend
PREVIOUS
Advanced workflows

--------------------------------------------------------------------------------

Title: Moving to production - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/moving-to-production/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Moving to production
Moving to production

Amplify Auth provisions Amazon Cognito resources that are provisioned with limited capabilities for sending email and SMS messages. In its default state, it is not intended to handle production workloads, but is sufficient for developing your application and associated business logic.

Email

Cognito provides a default email functionality that limits how many emails can be sent in one day. When considering production workloads, Cognito can be configured to send emails using Amazon Simple Email Service (Amazon SES).

All new AWS accounts default to a "sandbox" status with Amazon SES. This comes with the primary caveat that you can only send mail to verified email addresses and domains

To get started with Amazon SES in production, you must first request production access. Once you submit your request the submission cannot be modified, however you will receive a response from AWS within 24 hours.

After you have configured your account for production access and have verified your sender email, you can configure your Cognito user pool to send emails using the verified sender:

amplify/backend.ts
Copy
amplify/backend.ts code example
import { Stack } from "aws-cdk-lib/core"
import { EmailIdentity } from "aws-cdk-lib/aws-ses"
import { defineBackend } from "@aws-amplify/backend"
import { auth } from "./auth/resource"


const backend = defineBackend({
  auth,
})


const { cfnUserPool } = backend.auth.resources.cfnResources
const authStack = Stack.of(cfnUserPool)


const email = EmailIdentity.fromEmailIdentityName(
  authStack,
  "EmailIdentity",
  // your email configured for use in SES
  process.env.EMAIL
)


cfnUserPool.emailConfiguration = {
  emailSendingAccount: "DEVELOPER",
  sourceArn: email.emailIdentityArn,
}

Now when emails are sent on new user sign-ups, password resets, etc., the sending account will be your verified email.

SMS

In order to send SMS authentication codes, you must request an origination number. Authentication codes will be sent from the origination number. If your AWS account is in the SMS sandbox, you must also add a destination phone number, which can be done by going to the Amazon Pinpoint Console, selecting SMS and voice in the navigation pane, and selecting Add phone number in the Destination phone numbers tab. To check if your AWS account is in the SMS sandbox, go to the SNS console, select the Text messaging (SMS) tab from the navigation pane, and check the status under the Account information section.

PREVIOUS
Modify Amplify-generated Cognito resources with CDK
NEXT
Advanced workflows

--------------------------------------------------------------------------------

Title: Modify Amplify-generated Cognito resources with CDK - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/modify-resources-with-cdk/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Modify Amplify-generated Cognito resources with CDK
Modify Amplify-generated Cognito resources with CDK

Amplify Auth provides sensible defaults for the underlying Amazon Cognito resource definitions. You can customize your authentication resource to enable it to behave exactly as needed for your use cases by modifying it directly using AWS Cloud Development Kit (CDK)

Override Cognito UserPool password policies

You can override the password policy by using the L1 cfnUserPool construct and adding a addPropertyOverride.

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';


const backend = defineBackend({
  auth,
});
// extract L1 CfnUserPool resources
const { cfnUserPool } = backend.auth.resources.cfnResources;
// modify cfnUserPool policies directly
cfnUserPool.policies = {
  passwordPolicy: {
    minimumLength: 10,
    requireLowercase: true,
    requireNumbers: true,
    requireSymbols: true,
    requireUppercase: true,
    temporaryPasswordValidityDays: 20,
  },
};
PREVIOUS
Grant access to auth resources
NEXT
Moving to production

--------------------------------------------------------------------------------

Title: Grant access to auth resources - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/grant-access-to-auth-resources/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Grant access to auth resources
Grant access to auth resources

Amplify Auth can be defined with an access property, which allows other resources to interact with auth by specifying actions.

amplify/auth/resource.ts
Copy
amplify/auth/resource.ts code example
import { defineAuth } from "@aws-amplify/backend"
import { addUserToGroup } from "../functions/add-user-to-group/resource"


/**
 * Define and configure your auth resource
 * @see https://docs.amplify.aws/gen2/build-a-backend/auth
 */
export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  access: (allow) => [
    allow.resource(addUserToGroup).to(["addUserToGroup"])
  ],
})

When you grant a function access to another resource in your Amplify backend it will configure environment variables for that function to make SDK calls to the AWS services it has access to. Those environment variables are typed and available as part of the env object.

List of actions
Action Name	Description	Cognito IAM Actions
manageUsers	Grants CRUD access to users in the UserPool	
cognito-idp:AdminConfirmSignUp
cognito-idp:AdminCreateUser
cognito-idp:AdminDeleteUser
cognito-idp:AdminDeleteUserAttributes
cognito-idp:AdminDisableUser
cognito-idp:AdminEnableUser
cognito-idp:AdminGetUser
cognito-idp:AdminListGroupsForUser
cognito-idp:AdminRespondToAuthChallenge
cognito-idp:AdminSetUserMFAPreference
cognito-idp:AdminSetUserSettings
cognito-idp:AdminUpdateUserAttributes
cognito-idp:AdminUserGlobalSignOut

manageGroupMembership	Grants permission to add and remove users from groups	
cognito-idp:AdminAddUserToGroup
cognito-idp:AdminRemoveUserFromGroup

manageGroups	Grants CRUD access to groups in the UserPool	
cognito-idp:GetGroup
cognito-idp:ListGroups
cognito-idp:CreateGroup
cognito-idp:DeleteGroup
cognito-idp:UpdateGroup

manageUserDevices	Manages devices registered to users	
cognito-idp:AdminForgetDevice
cognito-idp:AdminGetDevice
cognito-idp:AdminListDevices
cognito-idp:AdminUpdateDeviceStatus

managePasswordRecovery	Grants permission to reset user passwords	
cognito-idp:AdminResetUserPassword
cognito-idp:AdminSetUserPassword

addUserToGroup	Grants permission to add any user to any group.	
cognito-idp:AdminAddUserToGroup

createUser	Grants permission to create new users and send welcome messages via email or SMS.	
cognito-idp:AdminCreateUser

deleteUser	Grants permission to delete any user	
cognito-idp:AdminDeleteUser

deleteUserAttributes	Grants permission to delete attributes from any user	
cognito-idp:AdminDeleteUserAttributes

disableUser	Grants permission to deactivate any user	
cognito-idp:AdminDisableUser

enableUser	Grants permission to activate any user	
cognito-idp:AdminEnableUser

forgetDevice	Grants permission to deregister any user's devices	
cognito-idp:AdminForgetDevice

getDevice	Grants permission to get information about any user's devices	
cognito-idp:AdminGetDevice

getUser	Grants permission to look up any user by user name	
cognito-idp:AdminGetUser

listUsers	Grants permission to list users and their basic details in the UserPool	
cognito-idp:ListUsers

listDevices	Grants permission to list any user's remembered devices	
cognito-idp:AdminListDevices

listGroupsForUser	Grants permission to list the groups that any user belongs to	
cognito-idp:AdminListGroupsForUser

listUsersInGroup	Grants permission to list users in the specified group	
cognito-idp:ListUsersInGroup

removeUserFromGroup	Grants permission to remove any user from any group	
cognito-idp:AdminRemoveUserFromGroup

resetUserPassword	Grants permission to reset any user's password	
cognito-idp:AdminResetUserPassword

setUserMfaPreference	Grants permission to set any user's preferred MFA method	
cognito-idp:AdminSetUserMFAPreference

setUserPassword	Grants permission to set any user's password	
cognito-idp:AdminSetUserPassword

setUserSettings	Grants permission to set user settings for any user	
cognito-idp:AdminSetUserSettings

updateDeviceStatus	Grants permission to update the status of any user's remembered devices	
cognito-idp:AdminUpdateDeviceStatus

updateUserAttributes	Grants permission to updates any user's standard or custom attributes	
cognito-idp:AdminUpdateUserAttributes
PREVIOUS
Customize auth lifecycle
NEXT
Modify Amplify-generated Cognito resources with CDK

--------------------------------------------------------------------------------

Title: Triggers - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/customize-auth-lifecycle/triggers/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Customize auth lifecycle
/
Triggers
Triggers

Amplify Auth's behavior can be customized through the use of triggers. A trigger is defined as a Function, and is a mechanism to slot some logic to execute during the authentication flow. For example, you can use triggers to validate whether emails include an allowlisted domain, add a user to a group upon confirmation, or create a "UserProfile" model upon account confirmation.

Triggers translate to Cognito user pool Lambda triggers.

When you have a Lambda trigger assigned to your user pool, Amazon Cognito interrupts its default flow to request information from your function. Amazon Cognito generates a JSON event and passes it to your function. The event contains information about your user's request to create a user account, sign in, reset a password, or update an attribute. Your function then has an opportunity to take action, or to send the event back unmodified.

To get started, define a function and specify the triggers property on your auth resource:

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"


export const auth = defineAuth({
  loginWith: {
    email: true,
  },
Copy
highlighted code example
  triggers: {}
})

To learn more about use cases for triggers, visit the Functions examples.

PREVIOUS
Email customization

--------------------------------------------------------------------------------

Title: Email customization - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/customize-auth-lifecycle/email-customization/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Customize auth lifecycle
/
Email customization
Email customization

By default, Amplify Auth resources are scaffolded with email as the default method for your users to sign in. When you users sign up they receive a verification email to confirm their ownership of the email they specified during sign-up. Emails such as the verification email can be customized with your app's brand identity.

To get started, modify email: true to an object to begin customizing its default behavior:

amplify/auth/resource.ts
Copy
amplify/auth/resource.ts code example
import { defineAuth } from "@aws-amplify/backend"


export const auth = defineAuth({
  loginWith: {
-   email: true, 
+   email: {
+     verificationEmailStyle: "CODE",
+     verificationEmailSubject: "Welcome to my app!",
+     verificationEmailBody: (createCode) => `Use this code to confirm your account: ${createCode()}`,
+   },
  },
})
NEXT
Triggers

--------------------------------------------------------------------------------

Title: Customize auth lifecycle - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/customize-auth-lifecycle/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Customize auth lifecycle
Customize auth lifecycle
Email customization
Learn how to customize emails your users receive when signing up
Triggers
Learn how to use Cognito Lambda triggers to customize the authentication lifecycle

--------------------------------------------------------------------------------

Title: Manage users with Amplify console - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/manage-users/with-amplify-console/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Manage users
/
Manage users with Amplify console
Manage users with Amplify console

The User management page in the Amplify console provides a user-friendly interface for managing your application's users. You can create and manage users and groups, edit user attributes, and suspend users.

If you have not yet created an auth resource, visit the Auth setup guide.

Access User management

After you've deployed your auth resource, you can access the manager on Amplify Console.

Log in to the Amplify console and choose your app.
Select the branch you would like to access.
Select Authentication from the left navigation bar.
Then, select User management.
To create a user
On the User management page, select Users tab.
Select Create user.
In the Create user window, for Unique identifier enter a email address, username, or phone number. For Temporary password enter a password.
Choose Create user.

A user can be confirmed by using the pre-built UI components and Amplify libraries.

To create a group
On the User management page, choose the Groups tab and then choose Create group.
In the Create group window, for Title enter a name for the group.
Choose Create group.
To add a users to a group
On the User management page, choose the Groups tab.
Select the name of the group to add users to.
Choose Add users.
In the Add users to group window, choose how you want to search for users to add from the Search menu. You can choose Email, Phone number, or Username.
Add one user or multiple users to add to the group and then choose Add users.
To delete a group
On the User management page, choose the Groups tab.
In the Groups section, select the name of the group to delete.
Choose Delete.
A confirmation window is displayed. Enter Delete and choose, Confirm deletion.
PREVIOUS
Manage devices

--------------------------------------------------------------------------------

Title: Manage devices - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/manage-users/manage-devices/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Manage users
/
Manage devices
Manage devices

Amplify Auth enables you to track devices your users use for auditing, MFA, and more. Before you begin it is important to understand the terminology for device statuses:

Tracked: Every time the user signs in with a new device, the client is given the device key at the end of a successful authentication event. We use this device key to generate a salt and password verifier which is used to call the ConfirmDevice API. At this point, the device is considered to be tracked. Once the device is in a tracked state, you can use the Amazon Cognito console to see the time it started to be tracked, last authentication time, and other information about that device.
Remembered: Remembered devices are also tracked. During user authentication, the device key and secret pair assigned to a remembered device is used to authenticate the device to verify that it is the same device that the user previously used to sign in.
Not Remembered: A not-remembered device is a tracked device where Cognito has been configured to require users to "Opt-in" to remember a device, but the user has not opt-ed in to having the device remembered. This use case is used for users signing into their application from a device that they don't own.
Forgotten: a forgotten device is one removed from being remembered

Note: device tracking and remembering features are not available when using federating sign-in with external providers as devices are tracked on the upstream identity provider. These features are also not available when using Cognito's Hosted UI.

Remember devices

You can remember devices using the following:

Copy
code example
import { rememberDevice } from 'aws-amplify/auth';


await rememberDevice();
Forget devices

You can also forget devices but note that forgotten devices are neither remembered nor tracked.

Copy
code example
import { forgetDevice } from 'aws-amplify/auth';


await forgetDevice();
Fetch devices

You can fetch a list of remembered devices by using the following:

Copy
code example
import { fetchDevices } from 'aws-amplify/auth';


const output = await fetchDevices();

You can now set up devices to be remembered, forgotten, and fetched.

PREVIOUS
Manage passwords
NEXT
Manage users with Amplify console

--------------------------------------------------------------------------------

Title: With admin actions - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/manage-users/with-admin-actions/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Manage users
/
With admin actions
With admin actions

Amplify Auth can be managed with the AWS SDK's @aws-sdk/client-cognito-identity-provider package. This package is intended to use server-side, and can be used within a Function. This example focuses on the addUserToGroup action and will be defined as a custom mutation.

To get started, create an "ADMINS" group that will be used to authorize the mutation:

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"


export const auth = defineAuth({
  loginWith: {
    email: true,
  },
Copy
highlighted code example
  groups: ["ADMINS"]
})

Next, create the Function resource:

amplify/data/add-user-to-group/resource.ts
Copy
amplify/data/add-user-to-group/resource.ts code example
import { defineFunction } from "@aws-amplify/backend"


export const addUserToGroup = defineFunction({
  name: "add-user-to-group",
})

Then, in your auth resources, grant access for the function to perform the addUserToGroup action. Learn more about granting access to auth resources.

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"
Copy
highlighted code example
import { addUserToGroup } from "../data/add-user-to-group/resource"


export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  groups: ["ADMINS"],
Copy
highlighted code example
  access: (allow) => [
    allow.resource(addUserToGroup).to(["addUserToGroup"])
  ],
})

You're now ready to define the custom mutation. Here you will use the newly-created addUserToGroup function resource to handle the addUserToGroup mutation. This mutation can only be called by a user in the "ADMINS" group.

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
import type { ClientSchema } from "@aws-amplify/backend"
import { a, defineData } from "@aws-amplify/backend"
import { addUserToGroup } from "./resource"


const schema = a.schema({
  addUserToGroup: a
    .mutation()
    .arguments({
      userId: a.string().required(),
      groupName: a.string().required(),
    })
    .authorization((allow) => [allow.group("ADMINS")])
    .handler(a.handler.function(addUserToGroup))
    .returns(a.json())
})


export type Schema = ClientSchema<typeof schema>


export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: "iam",
  },
})

Lastly, create the function's handler using the exported client schema to type the handler function, and the generated env to specify the user pool ID you'd like to interact with:

amplify/data/add-user-to-group/handler.ts
Copy
amplify/data/add-user-to-group/handler.ts code example
import type { Schema } from "../resource"
import { env } from "$amplify/env/add-user-to-group"
import {
  AdminAddUserToGroupCommand,
  CognitoIdentityProviderClient,
} from "@aws-sdk/client-cognito-identity-provider"


type Handler = Schema["addUserToGroup"]["functionHandler"]
const client = new CognitoIdentityProviderClient()


export const handler: Handler = async (event) => {
  const { userId, groupName } = event.arguments
  const command = new AdminAddUserToGroupCommand({
    Username: userId,
    GroupName: groupName,
    UserPoolId: env.AMPLIFY_AUTH_USERPOOL_ID,
  })
  const response = await client.send(command)
  return response
}

In your frontend, use the generated client to call your mutation using the group name and the user's ID.

src/client.ts
Copy
src/client.ts code example
import type { Schema } from "../amplify/data/resource"
import { generateClient } from "aws-amplify/data"


const client = generateClient<Schema>()


await client.mutations.addUserToGroup({
  groupName: "ADMINS",
  userId: "5468d468-4061-70ed-8870-45c766d26225",
})
NEXT
Manage passwords

--------------------------------------------------------------------------------

Title: Manage passwords - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/manage-users/manage-passwords/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Manage users
/
Manage passwords
Manage passwords

Amplify Auth provides a secure way for your users to change their password or recover a forgotten password.

Understand password default settings

By default, your users can retrieve access to their accounts if they forgot their password by using either their phone or email. The following are the default account recovery methods used when either phone or email are used as login options.

Login option	User account verification channel
phone	Phone Number
email	Email
email and phone	Email
Reset Password

To reset a user's password, use the resetPassword API which will send a reset code to the destination (e.g. email or SMS) based on the user's settings.

Copy
code example
import { resetPassword } from 'aws-amplify/auth';


const output = await resetPassword({
  username: "hello@mycompany.com"
});


const { nextStep } = output;
switch (nextStep.resetPasswordStep) {
  case 'CONFIRM_RESET_PASSWORD_WITH_CODE':
    const codeDeliveryDetails = nextStep.codeDeliveryDetails;
    console.log(
      `Confirmation code was sent to ${codeDeliveryDetails.deliveryMedium}`
    );
    // Collect the confirmation code from the user and pass to confirmResetPassword.
    break;
  case 'DONE':
    console.log('Successfully reset password.');
    break;
}

To complete the password reset process, invoke the confirmResetPassword API with the code your user received and the new password they want to set.

Copy
code example
import { confirmResetPassword } from 'aws-amplify/auth';


await confirmResetPassword({
  username: "hello@mycompany.com",
  confirmationCode: "123456",
  newPassword: "hunter3",
});
Update password

You can update a signed in user's password using the updatePassword API.

Copy
code example
import { updatePassword } from 'aws-amplify/auth';


await updatePassword({
  oldPassword: "hunter2",
  newPassword: "hunter3",
});
Override default user account verification channel

You can always change the channel used by your authentication resources by overriding the following setting.

amplify/auth/resource.ts
import { defineAuth } from '@aws-amplify/backend';


export const auth = defineAuth({
  loginWith: {
    email: true
  },
Copy
highlighted code example
  accountRecovery: 'EMAIL_ONLY'
});
Override default password policy

You can customize the password format acceptable by your auth backend. By default your password policy is set to the following:

MinLength: 8 characters
requireLowercase: true
requireUppercase: true
requireDigits: true
tempPasswordValidity: 3 days
amplify/backend.ts
Copy
amplify/backend.ts code example
// amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';


const backend = defineBackend({
  auth,
  data
});


// extract L1 UserPool construct
const { cfnUserPool } = backend.auth.resources.cfnResources;
// from the CDK use `addPropertyOverride` to modify properties directly
cfnUserPool.addPropertyOverride('Policies.PasswordPolicy.MinimumLength', 32);
PREVIOUS
With admin actions
NEXT
Manage devices

--------------------------------------------------------------------------------

Title: Manage users - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/manage-users/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Manage users
Manage users
With admin actions
Learn how to manage users with Admin Actions
Manage passwords
Learn how to manage user passwords
Manage devices
Learn how to manage user devices
Manage users with Amplify console
Manage applications Cognito users and groups with Amplify console

--------------------------------------------------------------------------------

Title: Delete user account - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/connect-your-frontend/delete-user-account/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Connect your frontend
/
Delete user account
Delete user account

Empowering users to delete their account can improve trust and transparency. You can programmatically enable self-service account deletion with Amplify Auth.

If you have not yet created an Amplify Gen 2 app, visit the quickstart.

Allow users to delete their account

You can quickly set up account deletion for your users with the Amplify Libraries. Invoking the deleteUser API to delete a user from the Auth category will also sign out your user.

If your application uses a Cognito User Pool, which is the default configuration, this action will only delete the user from the Cognito User Pool. It will have no effect if you are federating with a Cognito Identity Pool alone.

Before invoking the deleteUser API, you may need to first delete associated user data that is not stored in Cognito. For example, if you are using Amplify Data to persist user data, you could follow these instructions to delete associated user data. This allows you to address any guidelines (such as GDPR) that require your app to delete data associated with a user who deletes their account.

You can enable account deletion using the following method:

Copy
code example
import { deleteUser } from 'aws-amplify/auth';


async function handleDeleteUser() {
  try {
    await deleteUser();
  } catch (error) {
    console.log(error);
  }
}

We recommend you update your UI to let your users know that their account is deleted and test the functionality with a test user. Note that your user will be signed out of your application when they delete their account.

PREVIOUS
Listen to auth events

--------------------------------------------------------------------------------

Title: Listen to auth events - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/connect-your-frontend/listen-to-auth-events/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Connect your frontend
/
Listen to auth events
Listen to auth events

Amplify Auth emits events during authentication flows, which enables you to react to user flows in real time and trigger custom business logic. For example, you may want to capture data, synchronize your app's state, and personalize the user's experience. You can listen to and respond to events across the Auth lifecycle such as sign-in and sign-out.

Expose hub events triggered in response to auth actions

You can use Amplify Hub with its built in Amplify Auth events to subscribe a listener using a publish-subscribe pattern and capture events between different parts of your application. The Amplify Auth category publishes in the auth channel when auth events such as signedIn or signedOut happen independent from your app code.

You can review the Amplify Hub guide to learn more.

Channels are logical group names that help you organize dispatching and listening. However, some channels are protected and cannot be used to publish custom events, and auth is one of these channels. Sending unexpected payloads to protected channels can have undesirable side effects such as impacting authentication flows. See the Amplify Hub guide for more protected channels.

Here is a basic example of setting up a listener that logs an event emitted through the auth channel:

Copy
code example
import { Hub } from 'aws-amplify/utils';


Hub.listen('auth', (data) => {
  console.log(data)
});

Once your app is set up to subscribe and listen to specific event types from the auth channel, the listeners will be notified asynchronously when an event occurs. This pattern allows for a one-to-many relationship where one auth event can be shared with many different listeners that have been subscribed. This lets your app react based on the event rather than proactively poll for information.

Additionally, you can set up your listener to extract data from the event payload and execute a callback that you define. For example, you might update UI elements in your app to reflect your user's authenticated state after the signedIn or signedOut events.

Listen to and log auth events

One of the most common workflows will be to log events. In this example you can see how you can listen and target specific auth events using a switch to log your own messages.

Copy
code example
import { Hub } from 'aws-amplify/utils';


Hub.listen('auth', ({ payload }) => {
  switch (payload.event) {
    case 'signedIn':
      console.log('user have been signedIn successfully.');
      break;
    case 'signedOut':
      console.log('user have been signedOut successfully.');
      break;
    case 'tokenRefresh':
      console.log('auth tokens have been refreshed.');
      break;
    case 'tokenRefresh_failure':
      console.log('failure while refreshing auth tokens.');
      break;
    case 'signInWithRedirect':
      console.log('signInWithRedirect API has successfully been resolved.');
      break;
    case 'signInWithRedirect_failure':
      console.log('failure while trying to resolve signInWithRedirect API.');
      break;
    case 'customOAuthState':
      logger.info('custom state returned from CognitoHosted UI');
      break;
  }
});
Stop listening to events

You can also stop listening for messages by calling the result of the Hub.listen() function. This may be useful if you no longer need to receive messages in your application flow. This can also help you avoid any memory leaks on low powered devices when you are sending large amounts of data through Amplify Hub on multiple channels.

To stop listening to a certain event, you need to wrap the listener function with a variable and call it once you no longer need it:

Copy
code example
/* start listening for messages */
const hubListenerCancelToken = Hub.listen('auth', (data) => {
  console.log('Listening for all auth events: ', data.payload.data);
});


/* later */
hubListenerCancelToken(); // stop listening for messages

You now have a few use cases and examples for listening to and responding to auth events.

PREVIOUS
Manage user attributes
NEXT
Delete user account

--------------------------------------------------------------------------------

Title: Manage user attributes - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/connect-your-frontend/manage-user-attributes/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Connect your frontend
/
Manage user attributes
Manage user attributes

User attributes such as email address, phone number help you identify individual users. Defining the user attributes you include for your user profiles makes user data easy to manage at scale. This information will help you personalize user journeys, tailor content, provide intuitive account control, and more. You can capture information upfront during sign-up or enable customers to update their profile after sign-up. In this section we take a closer look at working with user attributes, how to set them up and manage them.

Pass user attributes during sign-up

You can create user attributes during sign-up or when the user is authenticated. To do this as part of sign-up you can pass them in the userAttributes object of the signUp API:

Copy
code example
import { signUp } from "aws-amplify/auth";


await signUp({
  username: "jdoe",
  password: "mysecurerandompassword#123",
  options: {
    userAttributes: {
      email: "me@domain.com",
      phone_number: "+12128601234", // E.164 number convention
      given_name: "Jane",
      family_name: "Doe",
      nickname: "Jane",
    },
  },
});
Configure custom user attributes during sign-up

Custom attributes can be passed in with the userAttributes option of the signUp API:

Copy
code example
import { signUp } from "aws-amplify/auth";


await signUp({
  username: 'john.doe@example.com',
  password: 'hunter2',
  options: {
    userAttributes: {
      'custom:display_name': 'john_doe123',
    }
  }
});
Retrieve user attributes

You can retrieve user attributes for your users to read in their profile using the fetchUserAttributes API. This helps you personalize their frontend experience as well as control what they will see.

Copy
code example
import { fetchUserAttributes } from 'aws-amplify/auth';


await fetchUserAttributes();
Update user attribute

You can use the updateUserAttribute API to create or update existing user attributes.

TypeScript
JavaScript
Copy
code example
import {
  updateUserAttribute,
  type UpdateUserAttributeOutput
} from 'aws-amplify/auth';


async function handleUpdateUserAttribute(attributeKey: string, value: string) {
  try {
    const output = await updateUserAttribute({
      userAttribute: {
        attributeKey,
        value
      }
    });
    handleUpdateUserAttributeNextSteps(output);
  } catch (error) {
    console.log(error);
  }
}


function handleUpdateUserAttributeNextSteps(output: UpdateUserAttributeOutput) {
  const { nextStep } = output;


  switch (nextStep.updateAttributeStep) {
    case 'CONFIRM_ATTRIBUTE_WITH_CODE':
      const codeDeliveryDetails = nextStep.codeDeliveryDetails;
      console.log(
        `Confirmation code was sent to ${codeDeliveryDetails?.deliveryMedium}.`
      );
      // Collect the confirmation code from the user and pass to confirmUserAttribute.
      break;
    case 'DONE':
      console.log(`attribute was successfully updated.`);
      break;
  }
}

Note: If you change an attribute that requires confirmation (i.e. email or phone_number), the user will receive a confirmation code either to their email or cellphone. This code can be used with the confirmUserAttribute API to confirm the change.

Update user attributes

You can use the updateUserAttributes API to create or update multiple existing user attributes.

Copy
code example
import { updateUserAttributes, type UpdateUserAttributesOutput } from "aws-amplify/auth";


await updateUserAttributes({
  userAttributes: {
    email: "me@domain.com",
    name: "Jon Doe",
  },
});
Verify user attribute

Some attributes require confirmation for the attribute update to complete. If the attribute needs to be confirmed, part of the result of the updateUserAttribute or updateUserAttributes APIs will be CONFIRM_ATTRIBUTE_WITH_CODE. A confirmation code will be sent to the delivery medium mentioned in the delivery details. When the user gets the confirmation code, you can present a UI to the user to enter the code and invoke the confirmUserAttribute API with their input:

Copy
code example
import {
  confirmUserAttribute,
  type ConfirmUserAttributeInput
} from 'aws-amplify/auth';


async function handleConfirmUserAttribute({
  userAttributeKey,
  confirmationCode
}: ConfirmUserAttributeInput) {
  try {
    await confirmUserAttribute({ userAttributeKey, confirmationCode });
  } catch (error) {
    console.log(error);
  }
}
Send user attribute verification code

If an attribute needs to be verified while the user is authenticated, invoke the sendUserAttributeVerificationCode API as shown below:

Copy
code example
import {
  sendUserAttributeVerificationCode,
  type VerifiableUserAttributeKey
} from 'aws-amplify/auth';


async function handleSendUserAttributeVerificationCode(
  key: VerifiableUserAttributeKey
) {
  try {
    await sendUserAttributeVerificationCode({
      userAttributeKey: key
    });
  } catch (error) {
    console.log(error);
  }
}
Delete user attributes

The deleteUserAttributes API allows to delete one or more user attributes.

Copy
code example
import {
  deleteUserAttributes,
  type DeleteUserAttributesInput
} from 'aws-amplify/auth';


async function handleDeleteUserAttributes(
  keys: DeleteUserAttributesInput['userAttributeKeys']
) {
  try {
    await deleteUserAttributes({
      userAttributeKeys: ['custom:my_custom_attribute', ...keys]
    });
  } catch (error) {
    console.log(error);
  }
}
Next Steps
Learn how to set up password change and recovery
Learn how to set up custom attributes
PREVIOUS
Manage user sessions
NEXT
Listen to auth events

--------------------------------------------------------------------------------

Title: Manage user sessions - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/connect-your-frontend/manage-user-sessions/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Connect your frontend
/
Manage user sessions
Manage user sessions

Amplify Auth provides access to current user sessions and tokens to help you retrieve your user's information to determine if they are signed in with a valid session and control their access to your app.

Retrieve your current authenticated user

You can use the getCurrentUser API to get information about the currently authenticated user including the username, userId and signInDetails.

Copy
code example
import { getCurrentUser } from 'aws-amplify/auth';


const { username, userId, signInDetails } = await getCurrentUser();


console.log("username", username);
console.log("user id", userId);
console.log("sign-in details", signInDetails);

This method can be used to check if a user is signed in. It throws an error if the user is not authenticated.

The user's signInDetails are not supported when using the Hosted UI or the signInWithRedirect API.

Retrieve a user session

Your user's session is their signed-in state, which grants them access to your app. When your users sign in, their credentials are exchanged for temporary access tokens. You can get session details to access these tokens and use this information to validate user access or perform actions unique to that user.

If you only need the session details, you can use the fetchAuthSession API which returns a tokens object containing the JSON Web Tokens (JWT).

Copy
code example
import { fetchAuthSession } from 'aws-amplify/auth';


const session = await fetchAuthSession();


console.log("id token", session.tokens.idToken)
console.log("access token", session.tokens.accessToken)
Refreshing sessions

The fetchAuthSession API automatically refreshes the user's session when the authentication tokens have expired and a valid refreshToken is present. Additionally, you can also refresh the session explicitly by calling the fetchAuthSession API with the forceRefresh flag enabled.

Copy
code example
import { fetchAuthSession } from 'aws-amplify/auth';


await fetchAuthSession({ forceRefresh: true });

Warning: by default, sessions from external identity providers cannot be refreshed.

PREVIOUS
Sign-out
NEXT
Manage user attributes

--------------------------------------------------------------------------------

Title: Sign-out - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/connect-your-frontend/sign-out/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Connect your frontend
/
Sign-out
Sign-out

Amplify provides a client library that enables you to interact with backend resources such as Amplify Auth.

To sign a user out of your application use the signOut API.

Copy
code example
import { signOut } from 'aws-amplify/auth';


await signOut();

You can also sign out users from all devices by performing a global sign-out. This will also invalidate all refresh tokens issued to a user. The user's current access and ID tokens will remain valid on other devices until the refresh token expires (access and ID tokens expire one hour after they are issued).

Copy
code example
import { signOut } from 'aws-amplify/auth';


await signOut({ global: true });
Practical Example
src/App.tsx
import { Amplify } from "aws-amplify"
Copy
highlighted code example
import { signOut } from "aws-amplify/auth"
import outputs from "../amplify_outputs.json"


Amplify.configure(outputs)


export default function App() {
  async function handleSignOut() {
Copy
highlighted code example
    await signOut()
  }


  return (
    <button type="button" onClick={handleSignOut}>
      Sign out
    </button>
  )
}
PREVIOUS
Switching authentication flows
NEXT
Manage user sessions

--------------------------------------------------------------------------------

Title: Sign-in - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/connect-your-frontend/sign-in/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Connect your frontend
/
Sign-in
Sign-in

Amplify provides a client library that enables you to interact with backend resources such as Amplify Auth.

Using the signIn API
Copy
code example
import { signIn } from 'aws-amplify/auth'


await signIn({
  username: "hello@mycompany.com",
  password: "hunter2",
})

The signIn API response will include a nextStep property, which can be used to determine if further action is required. It may return the following next steps:

CONFIRM_SIGN_IN_WITH_NEW_PASSWORD_REQUIRED - The user was created with a temporary password and must set a new one. Complete the process with confirmSignIn.
CONFIRM_SIGN_IN_WITH_CUSTOM_CHALLENGE - The sign-in must be confirmed with a custom challenge response. Complete the process with confirmSignIn.
CONFIRM_SIGN_IN_WITH_TOTP_CODE - The sign-in must be confirmed with a TOTP code from the user. Complete the process with confirmSignIn.
CONTINUE_SIGN_IN_WITH_TOTP_SETUP - The TOTP setup process must be continued. Complete the process with confirmSignIn.
CONFIRM_SIGN_IN_WITH_SMS_CODE - The sign-in must be confirmed with a SMS code from the user. Complete the process with confirmSignIn.
CONTINUE_SIGN_IN_WITH_MFA_SELECTION - The user must select their mode of MFA verification before signing in. Complete the process with confirmSignIn.
RESET_PASSWORD - The user must reset their password via resetPassword.
CONFIRM_SIGN_UP - The user hasn't completed the sign-up flow fully and must be confirmed via confirmSignUp.
DONE - The sign in process has been completed.

For more information on handling the TOTP and MFA steps that may be returned, see multi-factor authentication.

Confirm sign-in
Practical Example
src/App.tsx
import type { FormEvent } from "react"
import { Amplify } from "aws-amplify"
Copy
highlighted code example
import { signIn } from "aws-amplify/auth"
import outputs from "../amplify_outputs.json"


Amplify.configure(outputs)


interface SignInFormElements extends HTMLFormControlsCollection {
  email: HTMLInputElement
  password: HTMLInputElement
}


interface SignInForm extends HTMLFormElement {
  readonly elements: SignInFormElements
}


export default function App() {
  async function handleSubmit(event: FormEvent<SignInForm>) {
    event.preventDefault()
    const form = event.currentTarget
    // ... validate inputs
    await signIn({
      username: form.elements.email.value,
      password: form.elements.password.value,
    })
  }


  return (
    <form onSubmit={handleSubmit}>
      <label htmlFor="email">Email:</label>
      <input type="text" id="email" name="email" />
      <label htmlFor="password">Password:</label>
      <input type="password" id="password" name="password" />
      <input type="submit" />
    </form>
  )
}
With multi-factor auth enabled

When multi-factor authentication (MFA) is required with SMS in your backend auth resource, you will need to pass the phone number during sign-up API call. If you are using the email or username as the primary sign-in mechanism, you will need to pass the phone_number attribute as a user attribute. This will change depending on if you enable SMS, TOTP, or both. Visit the multi-factor authentication documentation to learn more about enabling MFA on your backend auth resource.

You will then confirm sign-up, sign in, and receive a nextStep in the sign-in result of type CONFIRM_SIGN_IN_WITH_SMS_MFA_CODE. A confirmation code will also be texted to the phone number provided above. Pass the code you received to the confirmSignIn API:

Sign in with an external identity provider

To sign in using an external identity provider such as Google, use the signInWithRedirect function.

Copy
code example
import { signInWithRedirect } from "aws-amplify/auth"


signInWithRedirect({ provider: "Google" })

Note: if you do not pass an argument to signInWithRedirect it will redirect your users to the Cognito Hosted UI, which has limited support for customization.

Alternatively if you have configured OIDC or SAML-based identity providers in your auth resource, you can specify a "custom" provider in signInWithRedirect:

Copy
code example
import { signInWithRedirect } from "aws-amplify/auth"


signInWithRedirect({ provider: {
  custom: "MyOidcProvider"
}})
Auto sign-in

The autoSignIn API will automatically sign-in a user when it was previously enabled by the signUp API and after any of the following cases has completed:

User confirmed their account with a verification code sent to their phone or email (default option).
User confirmed their account with a verification link sent to their phone or email. In order to enable this option you need to go to the Amazon Cognito console, look for your userpool, then go to the Messaging tab and enable link mode inside the Verification message option. Finally you need to define the signUpVerificationMethod to link inside the Cognito option of your Auth config.
src/main.ts
Copy
src/main.ts code example
import { autoSignIn } from 'aws-amplify/auth';


await autoSignIn();
PREVIOUS
Sign-up
NEXT
Switching authentication flows

--------------------------------------------------------------------------------

Title: Switching authentication flows - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/connect-your-frontend/switching-authentication-flows/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Connect your frontend
/
Switching authentication flows
Switching authentication flows

For client side authentication there are three different flows:

USER_SRP_AUTH: The USER_SRP_AUTH flow uses the SRP protocol (Secure Remote Password) where the password never leaves the client and is unknown to the server. This is the recommended flow and is used by default.

USER_PASSWORD_AUTH: The USER_PASSWORD_AUTH flow will send user credentials to the backend without applying SRP encryption. If you want to migrate users to Cognito using the "Migration" trigger and avoid forcing users to reset their passwords, you will need to use this authentication type because the Lambda function invoked by the trigger needs to verify the supplied credentials.

CUSTOM_WITH_SRP & CUSTOM_WITHOUT_SRP: Allows for a series of challenge and response cycles that can be customized to meet different requirements.

The Auth flow can be customized when calling signIn, for example:

src/main.ts
Copy
src/main.ts code example
await signIn({
	username: "hello@mycompany.com",
  password: "hunter2",
  options: {
      authFlowType: 'USER_PASSWORD_AUTH'
  }
})

For more information about authentication flows, please visit AWS Cognito developer documentation

USER_PASSWORD_AUTH flow

A use case for the USER_PASSWORD_AUTH authentication flow is migrating users into Amazon Cognito

Set up auth backend

In order to use the authentication flow USER_PASSWORD_AUTH, your Cognito app client has to be configured to allow it. In the AWS Console, this is done by ticking the checkbox at General settings > App clients > Show Details (for the affected client) > Enable username-password (non-SRP) flow. If you're using the AWS CLI or CloudFormation, update your app client by adding USER_PASSWORD_AUTH to the list of "Explicit Auth Flows".

Migrate users with Amazon Cognito

Amazon Cognito provides a trigger to migrate users from your existing user directory seamlessly into Cognito. You achieve this by configuring your User Pool's "Migration" trigger which invokes a Lambda function whenever a user that does not already exist in the user pool authenticates, or resets their password.

In short, the Lambda function will validate the user credentials against your existing user directory and return a response object containing the user attributes and status on success. An error message will be returned if an error occurs. Visit Amazon Cognito user pools import guide for migration flow and more detailed instruction, and Amazon Cognito Lambda trigger guide on how to set up lambda to handle request and response objects.

CUSTOM_WITH_SRP & CUSTOM_WITHOUT_SRP flows

Amazon Cognito user pools supports customizing the authentication flow to enable custom challenge types, in addition to a password in order to verify the identity of users. These challenge types may include CAPTCHAs or dynamic challenge questions. The CUSTOM_WITH_SRP flow requires a password when calling signIn. Both of these flows map to the CUSTOM_AUTH flow in Cognito.

To define your challenges for custom authentication flow, you need to implement three Lambda triggers for Amazon Cognito.

For more information about working with Lambda Triggers for custom authentication challenges, please visit Amazon Cognito Developer Documentation.

Custom authentication flow

To initiate a custom authentication flow in your app, call signIn without a password. A custom challenge needs to be answered using the confirmSignIn API:

src/main.ts
Copy
src/main.ts code example
import { signIn, confirmSignIn } from 'aws-amplify/auth';


const challengeResponse = 'the answer for the challenge';


const { nextStep } = await signIn({
  username,
  options: {
    authFlowType: 'CUSTOM_WITHOUT_SRP',
  },
});


if (nextStep.signInStep === 'CONFIRM_SIGN_IN_WITH_CUSTOM_CHALLENGE') {
  // to send the answer of the custom challenge
  await confirmSignIn({ challengeResponse });
}
CAPTCHA authentication

To create a CAPTCHA challenge with a Lambda Trigger, please visit AWS Amplify Google reCAPTCHA challenge example for detailed examples.

For more information about working with Lambda Triggers for custom authentication challenges, please visit Amazon Cognito Developer Documentation.

PREVIOUS
Sign-in
NEXT
Sign-out

--------------------------------------------------------------------------------

Title: Sign-up - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/connect-your-frontend/sign-up/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Connect your frontend
/
Sign-up
Sign-up

Amplify provides a client library that enables you to interact with backend resources such as Amplify Auth.

To get started, you can use the signUp() API to create a new user in your backend:

Copy
code example
import { signUp } from "aws-amplify/auth"


const { isSignUpComplete, userId, nextStep } = await signUp({
  username: "hello@mycompany.com",
  password: "hunter2",
  options: {
    userAttributes: {
      email: "hello@mycompany.com",
      phone_number: "+15555555555" // E.164 number convention
    },
  }
});

The signUp API response will include a nextStep property, which can be used to determine if further action is required. It may return the following next steps:

CONFIRM_SIGN_UP - The sign up needs to be confirmed by collecting a code from the user and calling confirmSignUp.
DONE - The sign up process has been fully completed.
COMPLETE_AUTO_SIGN_IN - The sign up process needs to complete by invoking the autoSignIn API.
Confirm sign-up

By default, each user that signs up remains in the unconfirmed status until they verify with a confirmation code that was sent to their email or phone number. The following are the default verification methods used when either phone or email are used as loginWith options.

Login option	User account verification channel
phone	Phone Number
email	Email
email and phone	Email

You can confirm the sign-up after receiving a confirmation code from the user:

Copy
code example
import { confirmSignUp } from 'aws-amplify/auth';


const { isSignUpComplete, nextStep } = await confirmSignUp({
  username: "hello@mycompany.com",
  confirmationCode: "123456"
});

Note: When specifying email or phone as a way for your users to sign-in, these are attributes that are used in place of the username. Visit the concepts page to learn more about usernames.

Practical Example
src/App.tsx
import type { FormEvent } from "react"
import { Amplify } from "aws-amplify"
Copy
highlighted code example
import { signUp } from "aws-amplify/auth"
import outputs from "../amplify_outputs.json"


Amplify.configure(outputs)


interface SignUpFormElements extends HTMLFormControlsCollection {
  email: HTMLInputElement
  password: HTMLInputElement
}


interface SignUpForm extends HTMLFormElement {
  readonly elements: SignUpFormElements
}


export default function App() {
  async function handleSubmit(event: FormEvent<SignUpForm>) {
    event.preventDefault()
    const form = event.currentTarget
    // ... validate inputs
    await signUp({
      username: form.elements.email.value,
      password: form.elements.password.value,
    })
  }


  return (
    <form onSubmit={handleSubmit}>
      <label htmlFor="email">Email:</label>
      <input type="text" id="email" name="email" />
      <label htmlFor="password">Password:</label>
      <input type="password" id="password" name="password" />
      <input type="submit" />
    </form>
  )
}
PREVIOUS
Using the Authenticator
NEXT
Sign-in

--------------------------------------------------------------------------------

Title: Using the Authenticator - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/connect-your-frontend/using-the-authenticator/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Connect your frontend
/
Using the Authenticator
Using the Authenticator

The quickest way to get started with Amplify Auth in your frontend application is with the Authenticator component, which provides a customizable UI and complete authentication flows.

src/App.tsx
Copy
src/App.tsx code example
import { Authenticator } from '@aws-amplify/ui-react';
import { Amplify } from 'aws-amplify';
import '@aws-amplify/ui-react/styles.css';
import outputs from "../amplify_outputs.json";


Amplify.configure(outputs);


export default function App() {
  return (
    <Authenticator>
      {({ signOut, user }) => (
        <main>
          <h1>Hello {user?.username}</h1>
          <button onClick={signOut}>Sign out</button>
        </main>
      )}
    </Authenticator>
  );
}

The Authenticator component is automatically configured based on the outputs generated from your backend. To learn more about the Authenticator and how to customize its appearance, visit the Amplify UI documentation.

Conversely, you can bring your own UI and leverage the library from aws-amplify to handle authentication flows manually.

NEXT
Sign-up

--------------------------------------------------------------------------------

Title: Tokens and credentials - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/concepts/tokens-and-credentials/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Concepts
/
Tokens and credentials
Tokens and credentials

Amplify Auth interacts with its underlying Amazon Cognito user pool as an OpenID Connect (OIDC) provider. When users successfully authenticate you receive OIDC-compliant JSON web tokens (JWT). These tokens are used to identity your user, and access resources.

Access tokens are used to verify the bearer of the token (i.e. the Cognito user) is authorized to perform an action against a resource. Below is an example payload of an access token vended by Cognito:

Copy
code example
{
  "sub": "54288468-e051-706d-a73f-03892273d7e9",
  "iss": "https://cognito-idp.us-east-1.amazonaws.com/us-east-1_yoKn9s4Tq",
  "client_id": "1sg675g08g6g0e9f64grv9n5sk",
  "origin_jti": "0eadb994-a6e0-419e-b309-a7a0d522d72f",
  "event_id": "b180897a-181c-4f73-94bb-a2946e8b4ef1",
  "token_use": "access",
  "scope": "aws.cognito.signin.user.admin",
  "auth_time": 1714241873,
  "exp": 1714245473,
  "iat": 1714241873,
  "jti": "57f10a4d-a1f2-453b-8672-d1cfa8187047",
  "username": "54288468-e051-706d-a73f-03892273d7e9"
}

ID tokens are intended to be used within your frontend application only. This token contains personally identifiable information (PII) and should not be used to authorize access against a resource. Below is an example of an ID token with the default Amplify Auth configuration of email and password auth.

Copy
code example
{
  "sub": "54288468-e051-706d-a73f-03892273d7e9",
  "email_verified": true,
  "iss": "https://cognito-idp.us-east-1.amazonaws.com/us-east-1_yoKn9s4Tq",
  "cognito:username": "54288468-e051-706d-a73f-03892273d7e9",
  "origin_jti": "0eadb994-a6e0-419e-b309-a7a0d522d72f",
  "aud": "1sg675g08g6g0e9f64grv9n5sk",
  "event_id": "b180897a-181c-4f73-94bb-a2946e8b4ef1",
  "token_use": "id",
  "auth_time": 1714241873,
  "exp": 1714245473,
  "iat": 1714241873,
  "jti": "bb69af10-3ce0-47c2-8d8d-5bdc8630ab58",
  "email": "hello@mycompany.com"
}

When additional user attributes are specified for Amplify Auth, their values will be found in the ID token. For example, if a nickname attribute is requested it will be available on the ID token with the nickname claim:

Copy
code example
{
  "sub": "54288468-e051-706d-a73f-03892273d7e9",
  "email_verified": true,
  "iss": "https://cognito-idp.us-east-1.amazonaws.com/us-east-1_yoKn9s4Tq",
  "cognito:username": "54288468-e051-706d-a73f-03892273d7e9",
  "origin_jti": "0eadb994-a6e0-419e-b309-a7a0d522d72f",
  "aud": "1sg675g08g6g0e9f64grv9n5sk",
  "event_id": "b180897a-181c-4f73-94bb-a2946e8b4ef1",
  "token_use": "id",
  "auth_time": 1714241873,
+ "nickname": "hello",
  "exp": 1714245473,
  "iat": 1714241873,
  "jti": "bb69af10-3ce0-47c2-8d8d-5bdc8630ab58",
  "email": "hello@mycompany.com"
}

Conversely, user pool group claims are found in both the access token and ID token on the cognito:groups claim:

Copy
code example
{
  "sub": "54288468-e051-706d-a73f-03892273d7e9",
  "email_verified": true,
  "iss": "https://cognito-idp.us-east-1.amazonaws.com/us-east-1_yoKn9s4Tq",
  "cognito:username": "54288468-e051-706d-a73f-03892273d7e9",
  "cognito:groups": ["ADMINS"],
  "origin_jti": "0eadb994-a6e0-419e-b309-a7a0d522d72f",
  "aud": "1sg675g08g6g0e9f64grv9n5sk",
  "event_id": "b180897a-181c-4f73-94bb-a2946e8b4ef1",
  "token_use": "id",
  "auth_time": 1714241873,
  "nickname": "hello",
  "exp": 1714245473,
  "iat": 1714241873,
  "jti": "bb69af10-3ce0-47c2-8d8d-5bdc8630ab58",
  "email": "hello@mycompany.com"
}

Visit the AWS documentation for using tokens with Cognito user pools to learn more about tokens, how they're used with Cognito, and their intended usage.

Understand token management options

Token keys are automatically rotated for you for added security but you can update how they are stored, customize the refresh rate and expiration times, and revoke tokens on sign-out.

Update your token-saving mechanism

You can update the storage mechanism to choose where and how tokens are persisted in your application. The default option is localStorage. Additionally, you can import the sessionStorage, sharedInMemoryStorage or CookieStorage options as well.

If you want to customize your own mechanism, you can import the KeyValueStorageInterface interface and implement it in your own class.

Browser Local Storage

In Amplify the localStorage is the default storage mechanism. It saves the tokens in the browser's localStorage. This local storage will persist across browser sessions and tabs. You can explicitly set to this storage by calling:

Copy
code example
import { cognitoUserPoolsTokenProvider } from 'aws-amplify/auth/cognito';
import { defaultStorage } from 'aws-amplify/utils';


cognitoUserPoolsTokenProvider.setKeyValueStorage(defaultStorage);
Cookie Storage

CookieStorage saves the tokens in the browser's Cookies. The cookies will persist across browser sessions and tabs. You can explicitly set to this storage by calling:

Copy
code example
import { cognitoUserPoolsTokenProvider } from 'aws-amplify/auth/cognito';
import { CookieStorage } from 'aws-amplify/utils';


cognitoUserPoolsTokenProvider.setKeyValueStorage(new CookieStorage());
Browser Session Storage

sessionStorage saves the tokens in the browser's sessionStorage and these tokens will clear when a tab is closed. The benefit to this storage mechanism is that the session only lasts as long as the browser is open and you can sign out users when they close the tab. You can update to this storage by calling:

Copy
code example
import { cognitoUserPoolsTokenProvider } from 'aws-amplify/auth/cognito';
import { sessionStorage } from 'aws-amplify/utils';


cognitoUserPoolsTokenProvider.setKeyValueStorage(sessionStorage);
Custom Storage

You can implement your own custom storage mechanism by creating a class that implements the storage interface. Here is an example that uses memory storage:

Copy
code example
import { cognitoUserPoolsTokenProvider } from 'aws-amplify/auth/cognito';
import { KeyValueStorageInterface } from 'aws-amplify/utils';


class MyCustomStorage implements KeyValueStorageInterface {
  storageObject: Record<string, string> = {};
  async setItem(key: string, value: string): Promise<void> {
    this.storageObject[key] = value;
  }
  async getItem(key: string): Promise<string | null> {
    return this.storageObject[key];
  }
  async removeItem(key: string): Promise<void> {
    delete this.storageObject[key];
  }
  async clear(): Promise<void> {
    this.storageObject = {};
  }
}


cognitoUserPoolsTokenProvider.setKeyValueStorage(new MyCustomStorage());

When you get the current user session, the tokens will be saved in your custom location.

Token Revocation

Token revocation is enabled automatically in Amplify Auth. To revoke tokens you can set up global sign-out with signOut({ global: true }) to globally sign out your user from all of their devices.

Next steps
Learn how to customize the ID token
Learn how to use cookie storage server-side
PREVIOUS
Guest access

--------------------------------------------------------------------------------

Title: Connect your frontend - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/connect-your-frontend/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Connect your frontend
Connect your frontend
Using the Authenticator
Learn how to use the Authenticator connected component from the Amplify UI library
Sign-up
Learn how to sign up
Sign-in
Learn how to sign in
Switching authentication flows
Learn how to switch between different auth flows
Sign-out
Learn how to sign out
Manage user sessions
Learn how to manage user sessions
Manage user attributes
Learn about managing user attributes in your Amplify app
Listen to auth events
Learn how to listen to auth events
Delete user account
Enable users to delete their account.

--------------------------------------------------------------------------------

Title: External identity providers - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/concepts/external-identity-providers/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Concepts
/
External identity providers
External identity providers

Before you configure external sign-in with Amplify Auth you will need to set up your developer account with each provider you are using.

Note: Amazon Cognito provides first class support for Facebook Login, Google Sign-In, Login with Amazon, and Sign in with Apple for seamless setup. However you can configure other Identity Providers that support SAML or OpenID Connect (OIDC).

Warning: When configuring external sign-in it's important to exercise caution when designating attributes as "required." Different external identity providers have varied scopes in terms of the information they respond back to Cognito with. User pool attributes that are initially set up as "required" cannot be changed later, and may require you to migrate the users or create a new user pool.

Facebook Login
Google Sign-In
Login with Amazon
Sign in with Apple
Create a developer account with Facebook.
Sign in with your Facebook credentials.
Choose My Apps from the top navigation bar, and on the page that loads choose Create App. 
For your use case, choose Set up Facebook Login. 
For platform, choose Website and select No, I'm not building a game.
Give your Facebook app a name and choose Create app. 
On the left navigation bar, choose Settings and then Basic. 
Note the App ID and the App Secret. You will use them in the next section in the CLI flow.

Your developer accounts with the external providers are now set up and you can return to the Amplify specific configuration.

Configure external sign-in backend

In amplify/auth/resource.ts the external providers need to be added.

The following is an example of how you would set up access to all of the external providers supported by Amplify Auth. Please note you will need to configure your callbackUrls and logoutUrls URLs for your application, which will inform your backend resources how to behave when initiating sign in and sign out operations in your app.

Secrets must be created manually with ampx sandbox secret for use with cloud sandbox, or via the Amplify Console for branch environments.

amplify/auth/resource.ts
Copy
amplify/auth/resource.ts code example
import { defineAuth, secret } from '@aws-amplify/backend';


export const auth = defineAuth({
  loginWith: {
    externalProviders: {
      google: {
        clientId: secret('GOOGLE_CLIENT_ID'),
        clientSecret: secret('GOOGLE_CLIENT_SECRET')
      },
      signInWithApple: {
        clientId: secret('SIWA_CLIENT_ID'),
        keyId: secret('SIWA_KEY_ID'),
        privateKey: secret('SIWA_PRIVATE_KEY'),
        teamId: secret('SIWA_TEAM_ID')
      },
      loginWithAmazon: {
        clientId: secret('LOGINWITHAMAZON_CLIENT_ID'),
        clientSecret: secret('LOGINWITHAMAZON_CLIENT_SECRET')
      },
      facebook: {
        clientId: secret('FACEBOOK_CLIENT_ID'),
        clientSecret: secret('FACEBOOK_CLIENT_SECRET')
      },
      callbackUrls: [
        'http://localhost:3000/profile',
        'https://mywebsite.com/profile'
      ],
      logoutUrls: ['http://localhost:3000/', 'https://mywebsite.com'],
    }
  }
});

You need to now inform your external provider of the newly configured authentication resource and its OAuth redirect URI:

Facebook Login
Google Sign-In
Login with Amazon
Sign in with Apple

Sign In to your Facebook developer account with your Facebook credentials.

Choose My Apps from the top navigation bar, and on the Apps page, choose your app you created before.

On the left navigation bar, choose Products. Add Facebook Login if it isn't already added.

If already added, choose Settings under the Configure dropdown. 

Under Valid OAuth Redirect URIs type your user pool domain with the /oauth2/idpresponse endpoint.

https://<your-user-pool-domain>/oauth2/idpresponse

Save your changes.
Customizing scopes for retrieving user data from external providers

You can determine the pieces of data you want to retrieve from each external provider when setting them up in the amplify/auth/resource.ts file using scopes.

amplify/auth/resource.ts
import { defineAuth } from '@aws-amplify/backend';


export const auth = defineAuth({
  loginWith: {
    externalAuthProviders: {
      loginWithAmazon: {
        clientId: secret('LOGINWITHAMAZON_CLIENT_ID'),
        clientSecret: secret('LOGINWITHAMAZON_CLIENT_SECRET'),
Copy
highlighted code example
        scopes: ['email']
      },
      callbackUrls: [
        'http://localhost:3000/profile',
        'https://mywebsite.com/profile'
      ],
      logoutUrls: ['http://localhost:3000/', 'https://mywebsite.com'],
    }
  }
});
Attribute mapping

You can map which attributes are mapped between your external identity provider and your users created in Cognito. We will be able to have the best level of protection for developers if we ensure that attribute mappings that would not work are called out by the type system.

If you specify an attribute in your authentication resource as required, and it is not allowed for your external providers, signing in with that external provider will cause an error.

amplify/auth/resource.ts
import { defineAuth } from '@aws-amplify/backend';


export const auth = defineAuth({
  loginWith: {
    externalAuthProviders: {
      loginWithAmazon: {
        clientId: secret('LOGINWITHAMAZON_CLIENT_ID'),
        clientSecret: secret('LOGINWITHAMAZON_CLIENT_SECRET'),
Copy
highlighted code example
        userAttributeMapping: {
          email: 'email'
        }
      },
      callbackUrls: [
        'http://localhost:3000/profile',
        'https://mywebsite.com/profile'
      ],
      logoutUrls: ['http://localhost:3000/', 'https://mywebsite.com'],
    }
  }
});
Learn more about configuring the React Authenticator component for external providers
Configure OIDC provider

To setup a OIDC provider, you can configure them in your amplify/auth/resource.ts file. For example, if you would like to setup a Microsoft EntraID provider, you can do so as follows:

amplify/auth/resource.ts
Copy
amplify/auth/resource.ts code example
import { defineAuth, secret } from '@aws-amplify/backend';


export const auth = defineAuth({
  loginWith: {
    email: true,
    externalProviders: {
      oidc: [
        {
          name: 'MicrosoftEntraID',
          clientId: secret('MICROSOFT_ENTRA_ID_CLIENT_ID'),
          clientSecret: secret('MICROSOFT_ENTRA_ID_CLIENT_SECRET'),
          issuerUrl: '<your-issuer-url>',
        },
      ],
      logoutUrls: ['http://localhost:3000/', 'https://mywebsite.com'],
      callbackUrls: [
        'http://localhost:3000/profile',
        'https://mywebsite.com/profile',
      ],
    },
  },
});

Use the signInWithRedirect API to initiate sign-in with an OIDC identity provider.

src/my-client-side-js.js
Copy
src/my-client-side-js.js code example
import { signInWithRedirect } from 'aws-amplify/auth';


await signInWithRedirect({
  provider: {
    custom: 'MicrosoftEntraID'
  }
});
Configure SAML provider

To setup a SAML provider, you can configure them in your amplify/auth/resource.ts file. For example, if you would like to setup a Microsoft EntraID provider, you can do so as follows:

amplify/auth/resource.ts
Copy
amplify/auth/resource.ts code example
import { defineAuth } from '@aws-amplify/backend';


export const auth = defineAuth({
  loginWith: {
    email: true,
    externalProviders: {
      saml: {
        name: 'MicrosoftEntraIDSAML',
        metadata: {
          metadataContent: '<your-url-hosting-saml-metadata>', // or content of the metadata file
          metadataType: 'URL', // or 'FILE'
        },
      },
      logoutUrls: ['http://localhost:3000/', 'https://mywebsite.com'],
      callbackUrls: [
        'http://localhost:3000/profile',
        'https://mywebsite.com/profile',
      ],
    },
  },
});

Use the signInWithRedirect API to initiate sign-in with a SAML identity provider.

src/my-client-side-js.js
Copy
src/my-client-side-js.js code example
import { signInWithRedirect } from 'aws-amplify/auth';


await signInWithRedirect({
  provider: {
    custom: 'MicrosoftEntraIDSAML'
  }
});
Set up your frontend

If you are using the Authenticator component with Amplify, this feature works without any additional code. The guide below is for writing your own implementation.

Use the signInWithRedirect API to initiate sign-in with an external identity provider.

src/my-client-side-js.js
Copy
src/my-client-side-js.js code example
import { signInWithRedirect } from 'aws-amplify/auth';


await signInWithRedirect({
  provider: 'Apple'
});
(Required for Multi-Page Applications) Complete external Sign In after Redirect

If you are developing a multi-page application, and the redirected page is not the same page that initiated the sign in, you will need to add the following code to the redirected page to ensure the sign in gets completed:

src/my-redirected-page.ts
Copy
src/my-redirected-page.ts code example
import 'aws-amplify/auth/enable-oauth-listener';
import { getCurrentUser, fetchUserAttributes } from 'aws-amplify/auth';
import { Hub } from 'aws-amplify/utils';


Hub.listen("auth", ({ payload }) => {
  switch (payload.event) {
    case "signInWithRedirect":
      const user = await getCurrentUser();
      const userAttributes = await fetchUserAttributes();
      console.log({user, userAttributes});
      break;
    case "signInWithRedirect_failure":
      // handle sign in failure
      break;
    case "customOAuthState":
      const state = payload.data; // this will be customState provided on signInWithRedirect function
      console.log(state);
      break;
  }
});

Note: The listener only works on the client side in the context of a SSR-enabled project, so ensure to import the listener on the client side only. For example, in a Next.js project, you should add the above import statement to a component that renders on the client side only by 'use client'.

Under the hood
Why external Sign In needs to be explicitly handled for Multi-Page Applications
Next steps
Learn how to sign in with external providers
PREVIOUS
Multi-factor authentication
NEXT
Guest access

--------------------------------------------------------------------------------

Title: Guest access - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/concepts/guest-access/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Concepts
/
Guest access
Guest access

Amplify Auth can be configured to automatically obtain guest credentials once the device is online so that you are able to use other categories "anonymously" without the need to sign in. You will not be able to perform user specific methods while in this state such as updating attributes, changing your password, or getting the current user. However, you can obtain the unique Identity ID which is assigned to the device through the fetchAuthSession method described here.

Amplify Gen 2 enables guest access by default. To disable it, you can update the backend.ts file with the following changes:

amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend'
import { auth } from './auth/resource'
import { data } from './data/resource'


const backend = defineBackend({
  auth,
  data,
});


Copy
highlighted code example
const { cfnIdentityPool } = backend.auth.resources.cfnResources;
cfnIdentityPool.allowUnauthenticatedIdentities = false;
PREVIOUS
External identity providers
NEXT
Tokens and credentials

--------------------------------------------------------------------------------

Title: Multi-factor authentication - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/concepts/multi-factor-authentication/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Concepts
/
Multi-factor authentication
Multi-factor authentication

Amplify Auth supports Multi-factor Authentication (MFA) for user sign-in flows. MFA is an extra layer of security used to make sure that users trying to gain access to an account are who they say they are. It requires users to provide additional information to verify their identity. Amplify Auth supports the MFA methods with Time-based-One-Time Passwords (TOTP) as well as text messages (SMS). In this guide we will review how you can set up MFA using TOTP and SMS and the tradeoffs between these methods to help you choose the right set up for your application. We will also review how to set up MFA to remember a device and reduce sign-in friction for your users.

Configure multi-factor authentication

Use defineAuth to enable MFA for your app. The example below is setting up MFA with TOTP but not SMS as you can see that the phone number is not a required attribute. If you are using SMS, then the PhoneNumber attribute must be true.

amplify/auth/resource.ts
import { defineAuth } from '@aws-amplify/backend';


export const auth = defineAuth({
  loginWith: {
    email: true
  },
Copy
highlighted code example
  multifactor: {
    mode: 'OPTIONAL',
    totp: true
  }
});

When multi-factor authentication (MFA) is REQUIRED with SMS in your backend auth resource, you will need to pass the phone number during sign-up API call. If you are using the email or username as the primary sign-in mechanism, you will need to pass the phone_number attribute as a user attribute. This will change depending on if you enable SMS, TOTP, or both. Visit the multi-factor authentication documentation to learn more about enabling MFA on your backend auth resource.

Understand your MFA options

When enabling MFA you will have two key decisions to make:

MFA enforcement: As part of this setup you will determine how MFA is enforced. If you require MFA by setting MFA login to "ON", all your users will need to complete MFA to sign in. If you keep it "Optional", your users will have the choice whether to enable MFA or not for their account.
MFA methods: You will also specify which MFA method you are using - TOTP (Time-based One-time Password), SMS (text message), or both. We recommend that you use TOTP-based MFA as it is more secure and you can reserve SMS for account recovery.
Learn more
Compare TOTP and SMS MFA methods
Multi-factor authentication with SMS

Once you have setup SMS as your second layer of authentication with MFA as shown above, your users will get an authentication code via a text message to complete sign-in after they sign in with their username and password.

Warning: In order to send SMS authentication codes, you must request an origination number. Learn more about configuring your auth resource for production workloads.

Enable SMS MFA during sign-up

You will need to pass phone_number as a user attribute to enable SMS MFA for your users during sign-up. However, if the primary sign-in mechanism for your Cognito resource is phone_number (without enabling username), then you do not need to pass it as an attribute.

Copy
code example
import { signUp } from 'aws-amplify/auth';


await signUp({
  username: "hello@mycompany.com",
  password: "hunter2",
  options: {
    userAttributes: {
      phone_number: "+15555555555",
      email: "hello@mycompany.com",
    },
  },
});

By default, you have to verify a user account after they sign up using the confirmSignUp API, which will send a one-time password to the user's phone number or email, depending on your Amazon Cognito configuration.

Copy
code example
import { confirmSignUp } from 'aws-amplify/auth';


await confirmSignUp({
  username: "hello@mycompany.com",
  confirmationCode: "123456",
})
Manage SMS MFA during sign-in

After a user signs in, if they have MFA enabled for their account, a challenge will be returned that you would need to call the confirmSignIn API where the user provides their confirmation code sent to their phone number.

If MFA is ON or enabled for the user, you must call confirmSignIn with the OTP sent to their phone.

Copy
code example
import { confirmSignIn } from 'aws-amplify/auth';


await confirmSignIn({
  challengeResponse: "123456"
});

After a user has been signed in, call updateMFAPreference to record the MFA type as enabled for the user and optionally set it as preferred so that subsequent logins default to using this MFA type.

Copy
code example
import { updateMFAPreference } from 'aws-amplify/auth';


await updateMFAPreference({ sms: 'PREFERRED' });
Multi-factor authentication with TOTP

You can use Time-based One-Time Password (TOTP) for multi-factor authentication (MFA) in your web or mobile applications. The Amplify Auth category includes support for TOTP setup and verification using authenticator apps, offering an integrated solution and enhanced security for your users. These apps, such as Google Authenticator, Microsoft Authenticator, have the TOTP algorithm built-in and work by using a shared secret key and the current time to generate short-lived, six digit passwords.

Set up TOTP for a user

After you initiate a user sign in with the signIn API where a user is required to set up TOTP as an MFA method, the API call will return CONTINUE_SIGN_IN_WITH_TOTP_SETUP as a challenge and next step to handle in your app. You will get that challenge if the following conditions are met:

MFA is marked as Required in your user pool.
TOTP is enabled in your user pool.
User does not have TOTP MFA set up already.

The CONTINUE_SIGN_IN_WITH_TOTP_SETUP step signifies that the user must set up TOTP before they can sign in. The step returns an associated value of type TOTPSetupDetails which must be used to configure an authenticator app like Microsoft Authenticator or Google Authenticator. TOTPSetupDetails provides a helper method called getSetupURI which generates a URI that can be used, for example, in a button to open the user's installed authenticator app. For more advanced use cases, TOTPSetupDetails also contains a sharedSecret which can be used to either generate a QR code or be manually entered into an authenticator app.

Once the authenticator app is set up, the user can generate a TOTP code and provide it to the library to complete the sign in process.

Copy
code example
import { signIn, SignInOutput } from 'aws-amplify/auth';


const output = await signIn({
  username: "hello@mycompany.com",
  password: "hunter2"
});


const { nextStep } = output;
switch (nextStep.signInStep) {
  // ...
  case 'CONTINUE_SIGN_IN_WITH_TOTP_SETUP':
    const totpSetupDetails = nextStep.totpSetupDetails;
    const appName = 'my_app_name';
    const setupUri = totpSetupDetails.getSetupUri(appName);
    // Open setupUri with an authenticator APP to retrieve an OTP code
    break;
  // ...
}

The TOTP code can be obtained from the user via a text field or any other means. Once the user provides the TOTP code, call confirmSignIn with the TOTP code as the challengeResponse parameter.

Copy
code example
import { confirmSignIn } from 'aws-amplify/auth';


await confirmSignIn({
  challengeResponse: "123456"
});

After a user has been signed in, call updateMFAPreference to record the MFA type as enabled for the user and optionally set it as preferred so that subsequent logins default to using this MFA type.

Copy
code example
import { updateMFAPreference } from 'aws-amplify/auth';


await updateMFAPreference({ totp: 'PREFERRED' });
Enable TOTP after a user is signed in

TOTP MFA can be set up after a user has signed in. This can be done when the following conditions are met:

MFA is marked as Optional or Required in your user pool.
TOTP is marked as an enabled MFA method in your user pool.

TOTP can be set up by calling the setUpTOTP and verifyTOTPSetup APIs in the Auth category.

Invoke the setUpTOTP API to generate a TOTPSetupDetails object which should be used to configure an Authenticator app like Microsoft Authenticator or Google Authenticator. TOTPSetupDetails provides a helper method called getSetupURI which generates a URI that can be used, for example, in a button to open the user's installed Authenticator app. For more advanced use cases, TOTPSetupDetails also contains a sharedSecret which can be used to either generate a QR code or be manually entered into an Authenticator app.

that contains the sharedSecret which will be used to either to generate a QR code or can be manually entered into an Authenticator app.

Copy
code example
import { setUpTOTP } from 'aws-amplify/auth';


const totpSetupDetails = await setUpTOTP();
const appName = 'my_app_name';
const setupUri = totpSetupDetails.getSetupUri(appName);
// Open setupUri with an authenticator APP to retrieve an OTP code

Once the Authenticator app is set up, the user must generate a TOTP code and provide it to the library. Pass the code to verifyTOTPSetup to complete the TOTP setup process.

Copy
code example
import { verifyTOTPSetup } from 'aws-amplify/auth';


await verifyTOTPSetup({ code: "123456" });

After TOTP setup is complete, call updateMFAPreference to record the MFA type as enabled for the user and optionally set it as preferred so that subsequent logins default to using this MFA type.

Copy
code example
import { updateMFAPreference } from 'aws-amplify/auth';


await updateMFAPreference({ sms: 'ENABLED', totp: 'PREFERRED' });
Recover from a lost TOTP device

If a user loses access to their TOTP device, they will need to contact an administrator to get help accessing their account. Based on the Cognito user pool configuration, the administrator can use the AdminSetUserMFAPreference to either change the MFA preference to a different MFA method or to disable MFA for the user.

In a scenario where MFA is marked as "Required" in the Cognito User Pool and another MFA method is not set up, the administrator would need to first initiate an AdminUpdateUserAttributes call and update the user's phone number attribute. Once this is complete, the administrator can continue changing the MFA preference to SMS as suggested above.

Set up a user's preferred MFA method
Fetch the current user's MFA preferences

Invoke the following API to get the current MFA preference and enabled MFA types, if any, for the current user.

Copy
code example
import { fetchMFAPreference } from 'aws-amplify/auth';


const { enabled, preferred } = await fetchMFAPreference();
Update the current user's MFA preferences

Invoke the following API to update the MFA preference for the current user.

Only one MFA method can be marked as preferred at a time. If the user has multiple MFA methods enabled and tries to mark more than one MFA method as preferred, the API will throw an error.

Copy
code example
import { updateMFAPreference } from 'aws-amplify/auth';


await updateMFAPreference({ sms: 'ENABLED', totp: 'PREFERRED' });

If multiple MFA methods are enabled for the user, the signIn API will return CONTINUE_SIGN_IN_WITH_MFA_SELECTION as the next step in the auth flow. During this scenario, the user should be prompted to select the MFA method they want to use to sign in and their preference should be passed to confirmSignIn.

Copy
code example
import { confirmSignIn, SignInOutput } from 'aws-amplify/auth';


function handleSignInNextSteps(output: SignInOutput) {
  const { nextStep } = output;
  switch (nextStep.signInStep) {
    // ...
    case 'CONTINUE_SIGN_IN_WITH_MFA_SELECTION':
      const allowedMFATypes = nextStep.allowedMFATypes;
      const mfaType = promptUserForMFAType(allowedMFATypes);
    case 'CONFIRM_SIGN_IN_WITH_SMS_CODE':
      // display user to enter otp code;
      break;
    case 'CONFIRM_SIGN_IN_WITH_TOTP_CODE':
      // display user to enter otp code;
      break;
    // ...
  }
}


function promptUserForMFAType(
  allowedMFATypes?: ('SMS' | 'TOTP')[]
): 'SMS' | 'TOTP' {
  // Prompt user to select MFA type
}


async function handleMFASelection(mfaType: 'SMS' | 'TOTP') {
  try {
    const output = await confirmSignIn({
      challengeResponse: mfaType
    });
    handleSignInNextSteps(output);
  } catch (error) {
    console.log(error);
  }
}
Remember a device

Remembering a device is useful in conjunction with MFA because it allows the second factor requirement to be automatically met when your user signs in on that device and reduces friction in their sign-in experience. By default, this feature is turned off.

Note: The device tracking and remembering features are not available if any of the following conditions are met:

the federated OAuth flow with Cognito User Pools or Hosted UI is used, or
the User Pool uses email, phone_number, or alias attributes as sign-in methods
when the signIn API uses the USER_PASSWORD_AUTH as the authFlowType.
Configure device tracking

You can configure device tracking with deviceTracking construct.

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';


const backend = defineBackend({
  auth,
  data
});


const { cfnUserPool } = backend.auth.resources.cfnResources;


cfnUserPool.addPropertyOverride('DeviceConfiguration', {
  ChallengeRequiredOnNewDevice: true,
  DeviceOnlyRememberedOnUserPrompt: false
});
Learn more
Understand key terms used for tracking devices
Next steps
Learn how to sign-up with MFA enabled
Learn how to manage user devices
PREVIOUS
User groups
NEXT
External identity providers

--------------------------------------------------------------------------------

Title: User groups - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/concepts/user-groups/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Concepts
/
User groups
User groups

Amplify Auth provides a mechanism that allows you to group users. Assigning users to groups enable you to customize access for a collection of users, or leverage for auditing purposes. For example, only "ADMINS" users are permitted to delete posts from a bulletin, or only "EDITORS" are permitted to modify posts in a "draft" state. To get started with groups, configure the groups property:

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"


export const auth = defineAuth({
  loginWith: {
    email: true,
  },
Copy
highlighted code example
  groups: ["ADMINS", "EDITORS"],
})

Note: There are a few limitations with groups, including a limit of 10,000 groups per user pool.

Defining access

Amplify resources enable you to define access for groups using common language. For example, you can use allow.groups in data:

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
import { type ClientSchema, a, defineData } from "@aws-amplify/backend"


const schema = a.schema({
  Article: a.model({}).authorization(allow => [
    allow.groups(["EDITORS"]).to(["read", "update"])
  ])
})


// ...

Or in storage:

amplify/storage/articles/resource.ts
Copy
amplify/storage/articles/resource.ts code example
import { defineStorage } from "@aws-amplify/backend"


export const storage = defineStorage({
  name: "articles",
  access: (allow) => ({
    "drafts/*": [allow.groups(["EDITORS"]).to(["read", "write"])],
  }),
})

By defining access with groups, Amplify configures authorization rules to read from the current user's groups. User pool groups are available as a claim in the user's ID token and access token as cognito:groups. Requests can be made to secure resources using the access token and validated against this claim to permit action on the resource.

Group roles

Each Cognito user pool group is assigned an IAM role. IAM roles can be modified to extend access to other AWS resources. Roles can be accessed from your backend on the role property of your group:

amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';


/**
 * @see https://docs.amplify.aws/react/build-a-backend/ to add storage, functions, and more
 */
const backend = defineBackend({
  auth,
  data,
});


Copy
highlighted code example
const { groups } = backend.auth.resources


// https://docs.aws.amazon.com/cdk/api/v2/docs/aws-cdk-lib.aws_iam.IRole.html
groups["ADMINS"].role
Next steps
Learn how to automatically add a user to a group upon account confirmation
Learn how to secure access to data models using groups
Learn how to secure access to storage objects using groups
PREVIOUS
User attributes
NEXT
Multi-factor authentication

--------------------------------------------------------------------------------

Title: User attributes - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/concepts/user-attributes/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Concepts
/
User attributes
User attributes

Amplify Auth stores user profile information in user attributes. When the default method for user sign-in, Amplify Auth will automatically configure an email or phoneNumber attribute that is required for sign-in.

To extend a user profile beyond the default email or phoneNumber attribute that is automatically configured when specified in your auth resource's loginWith property, you can configure attributes with the userAttributes property:

Warning: After you create your auth resource, you cannot switch an attribute between required and not required.

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"


export const auth = defineAuth({
  loginWith: {
    // this configures a required "email" attribute
    email: true,
  },
Copy
highlighted code example
  userAttributes: {
    // specify a "birthdate" attribute
    birthdate: {
      mutable: true,
      required: false,
    }
  },
})
Standard attributes

User attributes are defined as Cognito Standard Attributes. Attributes can be configured to be required for user sign-up in addition to whether the values are mutable. When configuring your resource to allow your users to login with email, an email must be specified for user sign-up and cannot be changed later. However additional attributes can be configured to be optional, and mutable after sign-up.

Custom attributes

In addition to the provided standard attributes, you can configure Custom Attributes. These are attributes that are typically unique to your use case, such as a tenant ID or a user's display name. Custom attributes are identified by the custom: prefix:

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"


export const auth = defineAuth({
  loginWith: {
    // this configures a required "email" attribute
    email: true,
  },
  userAttributes: {
Copy
highlighted code example
    "custom:display_name": {
      dataType: "String",
      mutable: true,
      maxLen: 16,
      minLen: 1,
    },
    "custom:favorite_number": {
      dataType: "Number",
      mutable: true,
      min: 1,
      max: 100,
    },
    "custom:is_beta_user": {
      dataType: "Boolean",
      mutable: true,
    },
    "custom:started_free_trial": {
      dataType: "DateTime",
      mutable: true,
    },
  },
})

Unlike standard attributes, custom attributes cannot natively be required for sign-up, however can be codified to require some value by validating user attributes upon sign-up with a pre sign-up trigger.

Custom attributes can also be configured with specific data types. The following data types are supported:

String
Number
Boolean
DateTime

Shown in the snippet above, String and Number can be assigned minimum and maximum constraints. This is useful to defer simple validations to the underlying service, although does not extend to complex validations such as matching against a regular expression.

Next steps
Learn how attributes are surfaced to tokens
Learn how to manage your user attributes
PREVIOUS
Phone
NEXT
User groups

--------------------------------------------------------------------------------

Title: Phone - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/concepts/phone/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Concepts
/
Phone
Phone

By default Amplify Auth is scaffolded with email as the default method for user sign-in, however this can be changed or extended to also allow your users to sign in using their phone number.

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"


export const auth = defineAuth({
  loginWith: {
Copy
highlighted code example
    phone: true,
  },
})

This will configure the phone_number attribute that is required for sign-up and cannot be changed.

Next steps
Learn how to use the signIn API
Learn how to configure your account for production SMS workloads
PREVIOUS
Email
NEXT
User attributes

--------------------------------------------------------------------------------

Title: Email - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/concepts/email/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Concepts
/
Email
Email

By default Amplify Auth is scaffolded with email as the default method for user sign-in.

amplify/auth/resource.ts
Copy
amplify/auth/resource.ts code example
import { defineAuth } from "@aws-amplify/backend"


export const auth = defineAuth({
  loginWith: {
    email: true,
  },
})

This will configure an email attribute that is required for sign-up and cannot be changed.

Next steps
Learn how to use the signIn API
Learn how to customize emails
Learn how to configure your auth resource for production workloads
PREVIOUS
Usernames
NEXT
Phone

--------------------------------------------------------------------------------

Title: Usernames - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/concepts/usernames/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Concepts
/
Usernames
Usernames

Amplify Auth does not support signing in with only username and password, however can be configured to enable usernames for display purposes. Amazon Cognito offers two ways of provisioning login mechanisms:

Username attributes
Alias attributes

Each are described in more detail on the AWS documentation for Cognito user pool settings, however at a high-level can be described as follows:

Username attributes allow you to customize which attribute can be used as the "username", or allowing users to sign in with an email or phone in place of a username
Alias attributes allow you to specify with attribute(s) can be used with sign in in addition to a username

With Amazon Cognito, usernames are immutable, which means after the initial sign-up users are unable to change their username later. In some applications this may be undesirable, which can motivate the use of alias attributes. Alias attributes allow you to define a mutable "preferred username" in addition to an immutable username.

Amplify Auth leverages username attributes to configure Cognito to accept an email or a phone number as the "username". Users will then need to verify their ownership of specified email or phone number to confirm their account.

However, it is common to consider a "username" for display purposes. For example, you can configure your auth resource to accept a "preferred username" to be used as the display name:

amplify/auth/resource.ts
import { defineAuth } from '@aws-amplify/backend';


/**
 * Define and configure your auth resource
 * @see https://docs.amplify.aws/gen2/build-a-backend/auth
 */
export const auth = defineAuth({
  loginWith: {
    email: true,
  },
Copy
highlighted code example
  userAttributes: {
    preferredUsername: {
      mutable: true,
      required: false
    }
  }
});

This is not a username the user will be able to sign in with, but it can be used to mask their personal information such as their email or phone number when displaying publicly.

If you would like to override the default behavior and allow your users to sign up with an immutable username, you can use CDK to modify your auth resource's usernameAttributes configuration directly:

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from "@aws-amplify/backend"
import { auth } from "./auth/resource"
import { data } from "./data/resource"


const backend = defineBackend({
  auth,
  data,
})


const { cfnUserPool } = backend.auth.resources.cfnResources
// an empty array denotes "email" and "phone_number" cannot be used as a username
cfnUserPool.usernameAttributes = []
Next Steps
Learn how to configure email sign-up
Learn how to configure phone sign-up
NEXT
Email

--------------------------------------------------------------------------------

Title: Concepts - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/concepts/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Concepts
Concepts

Amplify helps you secure your application while providing an easy sign-in experience for your users. This experience is influenced by your security strategy. This security strategy includes the authentication method, security credentials, and enabling additional verification when needed.

Authentication is a process to validate who you are (abbreviated as AuthN). The system that does this validation is referred to as an Identity Provider or IdP. This can be your own self-hosted IdP or a cloud service. Oftentimes, this IdP is a external provider such as Apple, Facebook, Google, or Amazon.
Authorization is the process of validating what you can access (abbreviated as AuthZ). This is sometimes done by looking at tokens with custom logic, predefined rules, or signed requests with policies.

Common authentication methods and associated risks include:

External provider federation which enables easier access for your users but shares data with third parties.

You can improve security credentials and verification for these authentication methods by:

Modifying the default password policy to ensure your users create stronger passwords.
Requiring additional contact information from users before they can reset passwords.
Enabling multi-factor authentication (MFA) which adds a layer of security at sign-in but may also add friction for your users.
What is Amazon Cognito?

Amplify Auth is powered by Amazon Cognito. Amazon Cognito is an identity and access management service, enabling you to secure your web or mobile applications, and is comprised of two services:

Amazon Cognito User Pools is a full-featured user directory service to handle user registration, authentication, and account recovery
Amazon Cognito Federated Identities or Identity Pools is a service used to authorize your users to interact with other AWS services

Amplify interfaces with User Pools to store your user information, including federation with other OpenID providers like Apple, Facebook, Google, or Amazon, and leverages federated identities to manage user access to AWS resources.

Authorization is often done in one of two ways:

Clients pass the tokens to the backend that perform custom logic to allow or deny actions
Clients sign the requests and the backend validates the signature, allowing or denying actions depending on predefined policy. The predefined rules, known as IAM access policies, are automatically configured by Amplify.

The first is a common authorization method for HTTP or GraphQL APIs, while the second is necessary for interfacing with AWS services such as Amazon S3, Amazon Pinpoint, and others.

Before you build

Amazon Cognito can be customized based on your security strategy for authentication. However, some initial configuration options cannot be changed after the backend resources are configured:

User attributes that are used to identify your individual users (such as email and phone) cannot be renamed or deleted.
Sign-in methods (including username, email, and phone) cannot be added or changed after the initial configuration. This includes both defining which attributes are used to sign in and which attributes are required. Required attributes must have a value for all users once set.
Verification methods (including username and email) are the same as required attributes and cannot be removed once configured.
The sub attribute is a unique identifier within each user pool that cannot be modified and can be used to index and search users.
If MFA is set to required with phone number for all users, you will need to include MFA setup (i.e. mandating phone number) when users sign up.

Visit the Amazon Cognito documentation for more details on these settings, including User pool attributes and Adding MFA to a user pool.

Usernames
Learn more about what Amplify Auth provisions and supports
Email
Learn more about what Amplify Auth provisions and supports
Phone
Learn more about what Amplify Auth provisions and supports
User attributes
Learn more about what Amplify Auth provisions and supports
User groups
Learn more about what Amplify Auth provisions and supports
Multi-factor authentication
Learn more about what Amplify Auth provisions and supports
External identity providers
Learn more about what Amplify Auth provisions and supports
Guest access
Access services without needing to sign in.
Tokens and credentials
Learn about how tokens and credentials are used in Amplify applications

--------------------------------------------------------------------------------

Title: Set up Amplify Auth - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/set-up-auth/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
/
Set up Amplify Auth
Set up Amplify Auth

Amplify Auth is powered by Amazon Cognito. Cognito is a robust user directory service that handles user registration, authentication, account recovery, and other operations. Review the concepts to learn more.

To get started with defining your authentication resource, open or create the auth resource file:

amplify/auth/resource.ts
Copy
amplify/auth/resource.ts code example
import { defineAuth } from "@aws-amplify/backend"


/**
 * Define and configure your auth resource
 * @see https://docs.amplify.aws/gen2/build-a-backend/auth
 */
export const auth = defineAuth({
  loginWith: {
    email: true,
  },
})

By default, your auth resource is scaffolded using email as the default login mechanism. You can also configure your auth resource to allow signing in with phone numbers or an external provider such as Google, Facebook, Amazon, or Sign in with Apple.

Note: At a minimum you will need to pass a loginWith value to set up how your users sign in to your app. Signing in with email and password is configured by default if you do not provide any value.

Deploy auth resource

After you have chosen and defined your authentication resource, run the following command to create your resource in your personal cloud sandbox.

Terminal
Copy
Terminal code example
npx ampx sandbox

After a successful deployment, this command also generates an outputs file (amplify_outputs.json) to enable your frontend app to connect to your backend resources. The values you configure in your backend authentication resource are set in the generated outputs file to automatically configure the frontend Authenticator connected component.

Connect your application code to your auth resource

Creating and correctly implementing the sign-in flow can be challenging and time-consuming. Amplify's Authenticator UI component streamlines this by enabling you to rapidly build the entire authentication flow for your app. The component works seamlessly with configuration in amplify/auth/resource.ts to automatically connect with your backend resources.

Amplify has pre-built UI components for React, Vue, Angular, React Native, Swift, Android, and Flutter. In this guide, we are focusing on those for web applications.

Once you add the Authenticator component to your app, you can test the sign-up, sign-in, and sign-out functionality. You can also customize the Authenticator connected component to adjust colors and styling as needed.

Next steps

Now that you have completed setting up authentication in your Amplify app with email and password, you may also want to add some additional features. We recommend you learn more about:

Learn more about authentication concepts
Moving to production
NEXT
Concepts

--------------------------------------------------------------------------------

Title: Authentication - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/auth/
HTML Content:
Next.js
/
Build & connect backend
/
Authentication
Authentication
Set up Amplify Auth
Learn how to set up and connect your backend resources for authentication in Amplify.
Concepts
Learn more about what Amplify Auth provisions and supports
Connect your frontend
Learn how to connect your frontend to your backend auth resource
Manage users
Learn how to manage users
Customize auth lifecycle
Learn how to customize the auth lifecycle
Grant access to auth resources
Learn how to grant access to auth resources
Modify Amplify-generated Cognito resources with CDK
Learn how to modify Amplify-generated Cognito resources.
Moving to production
Learn how to configure your auth resources for production workloads
Advanced workflows
Learn more about advanced workflows in the Amplify auth category. This includes subscribing to events, identity pool federation, auth-related Lambda triggers and working with AWS service objects.
Use existing Cognito resources
Learn how to use existing auth resources

--------------------------------------------------------------------------------

Title: Gen 2 for Gen 1 customers - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/start/migrate-to-gen2/
HTML Content:
Next.js
/
Get started
/
Gen 2 for Gen 1 customers
Gen 2 for Gen 1 customers
Migrating from Gen 1 to Gen 2

We are actively developing migration tooling to aid in transitioning your project from Gen 1 to Gen 2. Until then, we recommend you continue working with your Gen 1 Amplify project. We remain committed to supporting both Gen 1 and Gen 2 for the foreseeable future. For new projects, we recommend adopting Gen 2 to take advantage of its enhanced capabilities. Meanwhile, customers on Gen 1 will continue to receive support for high-priority bugs and essential security updates.

Gen 1 vs. Gen 2 feature matrix

The tables below present a feature matrix for Gen 1 customers who are considering Gen 2 for their apps. This will help determine the support availability for various features.

Auth
Feature	Gen 1	Gen 2
Configure username	Yes	Yes with CDK
Configure email	Yes	Yes
Configure phone number	Yes	Yes
Facebook	Yes	Yes
Google	Yes	Yes
Amazon	Yes	Yes
Sign-in with Apple	Yes	Yes
Add user pool groups	Yes	Yes
User pool group preference	Yes	Yes
Email verification link redirect	Yes	Yes
Sign-up attributes	Yes	Yes
Auth trigger support	Yes	Yes
Auth trigger templates: Add Google reCaptcha Challenge	Yes	Yes
Auth trigger templates: Add user to Group	Yes	Yes
Auth trigger templates: Email Domain Filtering (denylist)	Yes	Yes
Auth trigger templates: Email Domain Filtering (allowlist)	Yes	Yes
Auth trigger templates: Override ID Token Claims	Yes	Yes
Auth trigger templates: Custom Auth Challenge Flow	Yes	No
Configure default password policy	Yes	Yes with CDK
Configure read/write capabilities for attributes	Yes	Yes with CDK
Oauth flow: Configure authorization v implicit grant	Yes	Yes with CDK
Admin queries	Yes	Yes with CDK
MFA login (on/off/optional)	Yes	Yes
MFA: SMS	Yes	Yes
MFA: TOTP	Yes	Yes
Zero-config Authenticator support	Yes	Yes
User management in console	Yes	Yes
Configure Oauth scopes	Yes	Yes
Email verification - code	Yes	Yes
Email Verification - Link	Yes	Yes
Oauth flow: Configure redirect URIs	Yes	Yes
Ability to set a friendly name for User Pool	Yes	Yes
Unauthenticated logins	Yes	Yes
Custom attributes	Yes	Yes with CDK
Oauth flow: Configure domain name prefix	Yes	Yes with CDK
Auth configuration in console	Yes	No
First class OIDC support	No	Yes
First class SAML support	No	Yes
Import auth	Yes	No
Data
Feature	Gen 1	Gen2
model	Yes	Yes
primaryKey	Yes	Yes
secondaryKey (name, sortKeyFields, query)	Yes	Yes
hasOne	Yes	Yes
hasMany	Yes	Yes
belongsTo	Yes	Yes
manyToMany	Yes	No
default	Yes	Yes
auth - model level		
auth - public - apiKey	Yes	Yes
auth - public - iam	Yes	Yes
auth - owner - userPools	Yes	Yes
auth - owner - ownerField - userPools	Yes	Yes
auth - owner - ownerField as array - userPools	Yes	Yes
auth - owner - oidc	Yes	Yes
auth - owner - ownerField - oidc	Yes	Yes
auth - owner - ownerField as array - oidc	Yes	Yes
auth - private - userPools	Yes	Yes
auth - private - oidc	Yes	Yes
auth - private - iam	Yes	Yes
auth - group - userPools	Yes	Yes
auth - group - dynamic - userPools	Yes	Yes
auth - group - oidc	Yes	Yes
auth - group - dynamic - oidc	Yes	Yes
auth - custom - function	Yes	Yes
auth - field level		
auth - public - apiKey	Yes	Yes
auth - public - iam	Yes	Yes
auth - owner - userPools	Yes	Yes
auth - owner - ownerField - userPools	Yes	Yes
auth - owner - ownerField as array - userPools	Yes	Yes
auth - owner - oidc	Yes	Yes
auth - owner - ownerField - oidc	Yes	Yes
auth - owner - ownerField as array - oidc	Yes	Yes
auth - private - userPools	Yes	Yes
auth - private - oidc	Yes	Yes
auth - private - iam	Yes	Yes
auth - group - userPools	Yes	Yes
auth - group - dynamic - userPools	Yes	Yes
auth - group - oidc	Yes	Yes
auth - group - dynamic - oidc	Yes	Yes
auth - custom - function	Yes	Yes
other directives		
searchable	Yes	No but we offer a guide using Zero-ETL DynamoDB-to-OpenSearch
predictions	Yes	No but we offer a guide with AI service integrations
Custom Mutations, Queries, Subscriptions	Yes	Yes
VTL handler	Yes	Yes with CDK
JavaScript resolver handler	No	Yes
function handler	Yes	Yes
http handler	Yes	Yes - we support custom data sources including http
Other configurations		
DataStore support	Yes	No but we'll offer a migration guide soon
Visual configuration	Yes	No - Gen 2 is code-first by design
@model queries, mutations, subscriptions, and timestamps modifiers	Yes	No
Custom GraphQL Transformer plugins	Yes	No
MySQL and PostgreSQL support	No	Yes
In-IDE end-to-end type safety	No	Yes
@hasOne, @hasMany, and @belongsTo on required fields	Yes	No
fields argument on @hasOne, @hasMany, and @belongsTo	Yes	No
Storage
Feature	Gen 1	Gen 2
Ability to provision S3 bucket	Yes	Yes
Auth and Guest access	Yes	Yes
Auth - Configure CRUD access	Yes	Yes
Configure Cognito Group CRUD access	Yes	Yes
Guest - Configure CRUD access	Yes	Yes
Lambda trigger for S3 bucket	Yes	Yes
Import an S3 bucket	Yes	Yes
File browser in console	Yes	Yes
Ability to override/custom	Yes	Yes
S3 Lambda triggers	Yes	Yes
Locally test	Yes	Yes - with sandbox environments
Visual configuration	Yes	No - Gen 2 is code-first by design
File Browser in console	Yes	Yes
Import S3 buckets	Yes	No
Functions
Feature	Gen 1	Gen 2
Function runtime: TypeScript	No	Yes
Function resource access permissions: auth	Yes	Yes
Function resource access permissions: function	Yes	Yes
Function resource access permissions: API	Yes	Yes
Function resource access permissions CRUD operations	Yes	Yes
Function resource access permissions: custom	No	Yes
Environment variables	Yes	Yes
Secrets	Yes	Yes
Cron jobs	Yes	Yes
Configure memory size	Yes	Yes
Function build options for Node.js	Yes	Yes
Function templates: AWS AppSync - GraphQL API request (with IAM)	Yes	Yes
Function templates: CRUD function for DynamoDB (Integration with API Gateway)	Yes	Yes
Function templates: GraphQL Lambda Authorizer	Yes	Yes
Function templates: Hello World	Yes	Yes
Function templates: Lambda trigger	Yes	Yes
Function logs in console	Yes	Yes
Function resource access permissions: geo	Yes	Yes with CDK
Function resource access permissions: analytics	Yes	Yes with CDK
Function runtime: .NET 6	Yes	Yes with CDK
Function runtime: Go	Yes	Yes with CDK
Function runtime: Java	Yes	Yes with CDK
Function runtime: JavaScript	Yes	Yes with CDK
Function runtime: Python	Yes	Yes with CDK
Lambda layers	Yes	No
Other categories
Feature	Gen 1	Gen 2
REST API	Yes	Yes with custom CDK
Analytics	Yes	Yes with custom CDK
Geo	Yes	Yes with custom CDK
Predictions	Yes	Yes with custom CDK
Interactions	Yes	Yes with custom CDK

--------------------------------------------------------------------------------

Title: Build & connect backend - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/build-a-backend/
HTML Content:
Next.js
/
Build & connect backend
Build & connect backend
Authentication
Learn about the authentication capabilities of AWS Amplify.
Data
Learn about the data capabilities of AWS Amplify.
Storage
Set up and connect to storage.
Functions
Use AWS Lambda functions to perform tasks and customize workflows.
Server-Side Rendering
Use Amplify Auth and Data APIs from Next.js server-side runtimes.
Add any AWS service
Learn how you can add any AWS service.
Use Amazon Q Developer with Amplify
Learn how to use Amazon Q Developer - inline code suggestions with Amplify
Troubleshooting
Debugging guides for frequent customer errors

--------------------------------------------------------------------------------

Title: Connect to AWS resources - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/start/connect-to-aws-resources/
HTML Content:
Next.js
/
Get started
/
Connect to AWS resources
Connect to AWS resources

Amplify client libraries provide you with the flexibility to directly connect your application to AWS resources such as AWS AppSync, Amazon Cognito, Amazon S3, and more.

To get started, client libraries must be configured. This is typically done by using the amplify_outputs.json file generated by the Amplify backend tooling, however using the client libraries does not require backend resources to be created by Amplify.

For JavaScript-based applications, the client library can be configured by using the generated outputs file:

src/main.ts
Copy
src/main.ts code example
import { Amplify } from "aws-amplify"
import outputs from "../amplify_outputs.json"


Amplify.configure(outputs)

Or by configuring the library directly by passing a ResourcesConfig object. For example, to configure the client library for use with Amazon Cognito, specify the Auth configuration:

src/main.ts
Copy
src/main.ts code example
import { Amplify } from "aws-amplify"


Amplify.configure({
  Auth: {
    Cognito: {
      userPoolId: "<your-cognito-user-pool-id>",
      userPoolClientId: "<your-cognito-user-pool-client-id>",
      identityPoolId: "<your-cognito-identity-pool-id>",
      loginWith: {
        email: true,
      },
      signUpVerificationMethod: "code",
      userAttributes: {
        email: {
          required: true,
        },
      },
      allowGuestAccess: true,
      passwordFormat: {
        minLength: 8,
        requireLowercase: true,
        requireUppercase: true,
        requireNumbers: true,
        requireSpecialCharacters: true,
      },
    },
  },
})

By configuring the client library, Amplify automates the communication with the underlying AWS resources, and provides a friendly API to author your business logic. In the snippet below, the signIn function does not require passing information from your Cognito resource to initiate the sign-in flow.

src/main.ts
Copy
src/main.ts code example
import { signIn } from "aws-amplify/auth"


await signIn({
  username: "john.doe@example.com",
  password: "hunter2",
})

For more information about how to use the Amplify client libraries with existing AWS resources, visit the guides:

Connect to Cognito

Connect to Cognito resources using Amplify Auth's client library

--------------------------------------------------------------------------------

Title: Manual installation - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/start/manual-installation/
HTML Content:
Next.js
/
Get started
/
Manual installation
Manual installation

To get started with AWS Amplify we recommend that you use our quickstart starter template. However, for some use cases, it may be preferable to start from scratch, either with a brand new directory or an existing frontend app. In that case we recommend to use npm with create-amplify.

Terminal
Copy
Terminal code example
npm create amplify@latest
Terminal
? Where should we create your project? (.) # press enter

Running this command will scaffold a lightweight Amplify project in your current project with the following files:

Copy
code example
├── amplify/
│   ├── auth/
│   │   └── resource.ts
│   ├── data/
│   │   └── resource.ts
│   ├── backend.ts
│   ├── tsconfig.json
│   └── package.json
├── node_modules/
├── .gitignore
├── package-lock.json
├── package.json
└── tsconfig.json

If needed, you can manually install AWS Amplify without using create-amplify or the starter template. This guide will walk you through how to initialize your project, install dependencies, and author your first backend.

Manual setup

First, if your frontend framework of choice doesn't have it already, create your project's package.json with npm init -y. Then, install the Amplify dependencies for building a backend:

Terminal
Copy
Terminal code example
npm add --save-dev @aws-amplify/backend@latest @aws-amplify/backend-cli@latest typescript

Note: TypeScript is not a requirement but is recommended for an optimal experience.

Next, create the entry point for your backend, amplify/backend.ts, with the following code:

Copy
code example
import { defineBackend } from '@aws-amplify/backend';


defineBackend({});

Now you can run npx ampx sandbox to create your first backend!

Amplify Gen 2 requires your backend to be configured for use with ECMAScript modules (ESM). If you encounter the following error during ampx sandbox, consider modifying your package.json with "type": "module":

Copy
code example
The current file is a CommonJS module whose imports will produce 'require' calls; however, the referenced file is an ECMAScript module and cannot be imported with 'require'. Consider writing a dynamic 'import("@aws-amplify/backend")' call instead.

Or, you can create a local file in the Amplify backend directory, amplify/package.json:

Copy
code example
{
  "type": "module"
}

You can use define* functions to define your resources. For example, you can define authentication:

amplify/auth/resource.ts
Copy
amplify/auth/resource.ts code example
import { defineAuth } from '@aws-amplify/backend';


export const auth = defineAuth({
  loginWith: {
    email: true
  }
});

Or define your data resource:

amplify/data/resource.ts
Copy
amplify/data/resource.ts code example
import { a, defineData, type ClientSchema } from '@aws-amplify/backend';


const schema = a.schema({});


export type Schema = ClientSchema<typeof schema>;
export const data = defineData({
  schema
});

Each of these newly defined resources are then imported and set in the backend definition:

amplify/backend.ts
Copy
amplify/backend.ts code example
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';


defineBackend({
  auth,
  data
});
Upgrade existing projects

You can also update an existing frontend app. To upgrade existing Amplify code-first DX (Gen 2) apps, use your Node.js package manager (for example, npm) to update relevant backend packages:

Terminal
Copy
Terminal code example
npm update @aws-amplify/backend@latest @aws-amplify/backend-cli@latest
Next steps

We recommend the following next steps:

Learn more about defining authentication
Learn more about defining data
Get started with cloud sandbox
Deploy and host your first app

--------------------------------------------------------------------------------

Title: Configure AWS for local development - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/start/account-setup/
HTML Content:
Next.js
/
Get started
/
Configure AWS for local development
Configure AWS for local development

Note: If you already have an AWS account and profile configured locally, you do not need to follow this guide. Please add theAmplifyBackendDeployFullAccess IAM role to your configured AWS profile.

This guide will help you set up Temporary credentials with IAM Identity Center and AWS Organizations, which will enable you to define Single-sign on (SSO), users, groups, permission sets, and more for your team. AWS Organizations can grow to house multiple AWS accounts. Users within the organization can traverse the AWS account(s) as their permission set allows.

Amplify leverages the standard local credentials chain provider to simplify access to AWS services. While this guide highlights IAM Identity Center, you can explore additional methods for authenticating with AWS locally.

IAM Identity Center terminology
Set up Identity Center

Follow the steps below if you have never set up AWS profiles before. If you already have a profile, attach the AmplifyBackendDeployFullAccess managed policy to your IAM user.

1. Create user with Amplify permissions

Sign in to the AWS Console to access IAM Identity Center page and choose Enable.

A dialog will open, prompting you to "Choose how to configure IAM Identity Center in your AWS environment." Select Enable with AWS Organizations and choose Continue.

Next, we are going to automate a number of steps that simulate the operations of setting up a user in the IAM Identity Center console. To get started open CloudShell, located in the console footer.

Paste the following command in the CloudShell terminal and enter an email address you would like to associate with this AWS account:

CloudShell
Copy
CloudShell code example
read -p "Enter email address: " user_email # hit enter
Enter email address: <your-email-address>

Now, run the following command

CloudShell
Copy
CloudShell code example
response=$(aws sso-admin list-instances)
ssoId=$(echo $response | jq '.Instances[0].IdentityStoreId' -r)
ssoArn=$(echo $response | jq '.Instances[0].InstanceArn' -r)
email_json=$(jq -n --arg email "$user_email" '{"Type":"Work","Value":$email}')
response=$(aws identitystore create-user --identity-store-id $ssoId --user-name amplify-admin --display-name 'Amplify Admin' --name Formatted=string,FamilyName=Admin,GivenName=Amplify --emails "$email_json")
userId=$(echo $response | jq '.UserId' -r)
response=$(aws sso-admin create-permission-set --name amplify-policy --instance-arn=$ssoArn --session-duration PT12H)
permissionSetArn=$(echo $response | jq '.PermissionSet.PermissionSetArn' -r)
aws sso-admin attach-managed-policy-to-permission-set --instance-arn $ssoArn --permission-set-arn $permissionSetArn --managed-policy-arn arn:aws:iam::aws:policy/service-role/AmplifyBackendDeployFullAccess
accountId=$(aws sts get-caller-identity | jq '.Account' -r)
aws sso-admin create-account-assignment --instance-arn $ssoArn --target-id $accountId --target-type AWS_ACCOUNT --permission-set-arn $permissionSetArn --principal-type USER --principal-id $userId
# Hit enter

To validate that this worked, run the following command in the CloudShell. If something failed in this process, please report an issue. Keep this information readily available for the next step.

CloudShell
Copy
highlighted code example
printf "\n\nStart session url: https://$ssoId.awsapps.com/start\nRegion: $AWS_REGION\nUsername: amplify-admin\n\n"


# you should see
Start session url: https://d-XXXXXXXXXX.awsapps.com/start
Region: us-east-1
Username: amplify-admin
A step-by-step walkthrough in the console
Prefer a manual set up?
2. Create password for user

Now create a password for the user that we need for the next step. In the IdC console, navigate to Users > amplify_admin > Reset password > Send an email to the user with instructions for resetting the password.

Check your email (make sure you also check your spam folder). Click on the Reset password link and choose a password of your choice. When signing in make sure to use amplify-admin as the Username.

Finish local setup

Now, set up an AWS profile that is linked to the user you just created on your local machine. There are a few options for getting IAM Identity Center user credentials, but we will use the AWS CLI configuration wizard.

3. Install the AWS CLI

Install the AWS CLI.

Mac
Windows
Linux

In your browser, download the macOS pkg file:

Install on Mac

4. Set up local AWS profile

Open your terminal, you are ready to configure an AWS profile that uses the SSO user. Use the information from CloudShell to populate the information below.

Terminal
Copy
highlighted code example
aws configure sso


| SSO session name (Recommended): amplify-admin
| SSO start URL: <START SESSION URL>
| SSO region: <your-region>
| SSO registration scopes [sso:account:access]: <leave blank>
| Attempting to automatically open the SSO authorization page in your default browser.
| If the browser does not open or you wish to use a different device to authorize this request, open the following URL:
|
| https://device.sso.us-east-2.amazonaws.com/
|
| Then enter the code:
|
| SOME-CODE


## browser opens

After you provide this information, the browser will automatically open asking you to sign in with the username and password you just created and configure a multi-factor device to authenticate.

Now return to the terminal and enter the following information:

Terminal
The only AWS account available to you is: <your-aws-account-id>
Using the account ID <your-aws-account-id>
The only role available to you is: amplify-policy
Using the role name "amplify-policy"
CLI default client Region [us-east-1]: <your-region>
CLI default output format [None]:

Make sure to set the profile name to default. Alternatively, remember the auto-generated profile name; you will need this later.

Terminal
CLI profile name [amplify-policy-<your-aws-account-id>]: default
To use this profile, specify the profile name using --profile, as shown:


aws s3 ls --profile default

If you inspect ~/.aws/config, you should now see the SSO profile:

~/.aws/config
Copy
~/.aws/config code example
[profile default]
sso_session = amplify-admin
sso_account_id = <your-aws-account-id>
sso_role_name = AdministratorAccess
region = <your-region>
[sso-session amplify-admin]
sso_start_url = https://xxxxxx.awsapps.com/start#
sso_region = <your-region>
sso_registration_scopes = sso:account:access
5. Bootstrap your AWS account

Now you are ready to use this AWS profile with AWS Amplify. Open your Amplify project and start the sandbox. If you have multiple local profiles or named your profile something other than default, you can specify a profile with --profile.

Terminal
Copy
highlighted code example
npx ampx sandbox


# OR


Copy
highlighted code example
npx ampx sandbox --profile <profile-name>

Before you can start deploying resources in the cloud sandbox environment, Amplify will need to complete a one-time bootstrap setup for the account and AWS Region before it can start deploying resources.

Learn more
What is bootstrapping?

During the first-time setup, npx ampx sandbox will ask you to sign in to the AWS Management Console. You must sign in as the account root user or as a user that has AdministratorAccess. Once signed in, you will be redirected to the Amplify console. On the Create new app page, choose Initialize setup now. It may take a few minutes for the bootstrapping process to complete.

Success

You have successfully completed the bootstrapping process and you can now return to the terminal to create a new Amplify sandbox environment:

Copy
code example
npx ampx sandbox --profile <value>

--------------------------------------------------------------------------------

Title: Next.js App Router - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/start/quickstart/nextjs-app-router-client-components/
HTML Content:
Next.js
/
Get started
/
Quickstart
/
Next.js App Router
Next.js App Router
Pre-requisites

This Quickstart guide will walk you through how to build a task list application with TypeScript, Next.js App Router with Client Components, and React. Before you begin, make sure you have the following installed:

Node.js v14.x or later
npm v6.14.4 or later
git v2.14.1 or later
If you are new to these technologies, we recommend you go through the official React, Next.js, and TypeScript tutorials first.
Deploy a fullstack app to AWS

We've created a starter "To-do" application to help get started faster. First, you will create a repository in your GitHub account using our starter Next template.

1. Create the repository

Use our starter template to create a repository in your GitHub account. This template scaffolds create-next-app with Amplify backend capabilities.

Create repository from template

Use the form in GitHub to finalize your repo's creation.

2. Deploy the starter app

Now that the repository has been created, deploy it with Amplify.

Deploy to AWS

Select Start with an existing app > GitHub. After you give Amplify access to your GitHub account via the popup window, pick the repository and main branch to deploy. Make no other changes and click through the flow to Save and deploy.

3. View deployed app
While you are waiting for your app to deploy (~5 mins)
Learn about the project structure

When the build completes, visit the newly deployed branch by selecting "View deployed URL". Since the build deployed an API, database, and authentication backend, you will be able to create new to-do items.

In the Amplify console, click into the deployment branch (in this case main) > select Data in the left-hand menu > Data manager to see the data entered in your database.

Make frontend updates

Let's learn how to enhance the app functionality by creating a delete flow for to-do list items.

4. Set up local environment

Now let's set up our local development environment to add features to the frontend. Click on your deployed branch and you will land on the Deployments page which shows you your build history and a list of deployed backend resources.

At the bottom of the page you will see a tab for Deployed backend resources. Click on the tab and then click the Download amplify_outputs.json file button.

Clone the repository locally.

Terminal
Copy
Terminal code example
git clone https://github.com/<github-user>/amplify-next-template.git
cd amplify-next-template && npm install

Now move the amplify_outputs.json file you downloaded above to the root of your project.

Copy
code example
├── amplify
├── src
├── amplify_outputs.json <== backend outputs file
├── package.json
└── tsconfig.json
Learn more
amplify_outputs.json
5. Implement delete functionality

Go to the app/page.tsx file and add in a new deleteTodo functionality and pass function into the <li> element's onClick handler.

app/page.tsx
function App() {
  // ...
Copy
highlighted code example
  function deleteTodo(id: string) {
    client.models.Todo.delete({ id })
  }


  return (
    <main>
      <h1>My todos</h1>
      <button onClick={createTodo}>+ new</button>
      <ul>
        {todos.map(todo => <li
Copy
highlighted code example
          onClick={() => deleteTodo(todo.id)}
          key={todo.id}>
          {todo.content}
        </li>)}
      </ul> 
      <div>
        🥳 App successfully hosted. Try creating a new todo.
        <br />
        <a href="https://docs.amplify.aws/nextjs/start/quickstart/nextjs-app-router-client-components/">Review next step of this tutorial.</a>
      </div>
    </main>
  )
}
See the complete amplify/data/resources.ts

Try out the deletion functionality now by starting the local dev server:

Terminal
Copy
Terminal code example
npm run dev

This should start a local dev server at http://localhost:3000.

6. Implement login UI

The starter application already has a pre-configured auth backend defined in the amplify/auth/resource.ts file. We've configured it to support email and password login but you can extend it to support a variety of login mechanisms, including Google, Amazon, Sign In With Apple, and Facebook.

The fastest way to get your login experience up and running is to use our Authenticator UI component. First, install the Amplify UI component library:

Copy
code example
npm add @aws-amplify/ui-react

Next, import the Authenticator UI component and wrap your <main> element.

app/page.tsx
Copy
highlighted code example
import { Authenticator } from '@aws-amplify/ui-react'
import '@aws-amplify/ui-react/styles.css'
// ... other imports


function App() {
  // ...
  return (
Copy
highlighted code example
    <Authenticator>
      {({ signOut, user }) => (
        <main>
          {/*...*/}
Copy
highlighted code example
          <button onClick={signOut}>Sign out</button>
        </main>
      )}
Copy
highlighted code example
    </Authenticator>
  )
}

The Authenticator component auto-detects your auth backend settings and renders the correct UI state based on the auth backend's authentication flow.

Try out your application in your localhost environment again. You should be presented with a login experience now.

To get these changes to the cloud, commit them to git and push the changes upstream.

Terminal
Copy
Terminal code example
git commit -am "added authenticator"
git push

Amplify automatically deploys the latest version of your app based on your git commits. In just a few minutes, when the application rebuilds, the hosted app will be updated to support the deletion functionality.

Make backend updates

Let's update our backend to implement per-user authorization rules, allowing each user to only access their own to-dos.

7. Set up local AWS credentials

To make backend updates, we are going to require AWS credentials to deploy backend updates from our local machine.

Skip ahead to step 8, if you already have an AWS profile with credentials on your local machine, and your AWS profile has the AmplifyBackendDeployFullAccess permission policy.

Otherwise, set up local AWS credentials that grant Amplify permissions to deploy backend updates from your local machine.

8. Deploy cloud sandbox

To update your backend without affecting the production branch, use Amplify's cloud sandbox. This feature provides a separate backend environment for each developer on a team, ideal for local development and testing.

To start your cloud sandbox, run the following command in a new Terminal window:

Terminal
Copy
Terminal code example
npx ampx sandbox

Once the cloud sandbox has been fully deployed (~5 min), you'll see the amplify_outputs.json file updated with connection information to a new isolated authentication and data backend.

The npx ampx sandbox command should run concurrently to your npm run dev. You can think of the cloud sandbox as the "localhost-equivalent for your app backend".

9. Implement per-user authorization

The to-do items in the starter are currently shared across all users, but, in most cases, you want data to be isolated on a per-user basis.

To isolate the data on a per-user basis, you can use an "owner-based authorization rule". Let's apply the owner-based authorization rule to your to-do items:

amplify/data/resource.ts
import { type ClientSchema, a, defineData } from '@aws-amplify/backend';


const schema = a.schema({
  Todo: a.model({
    content: a.string(),
Copy
highlighted code example
  }).authorization(allow => [allow.owner()]),
});


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema,
  authorizationModes: {
    // This tells the data client in your app (generateClient())
    // to sign API requests with the user authentication token. 
Copy
highlighted code example
    defaultAuthorizationMode: 'userPool',
  },
});

In the application client code, let's also render the username to distinguish different users once they're logged in. Go to your app/page.tsx file and render the user property.

app/page.tsx
// ... imports


function App() {
  // ...
  return (
    <Authenticator>
Copy
highlighted code example
      {({ signOut, user }) => (
        <main>
Copy
highlighted code example
          <h1>{user?.signInDetails?.loginId}'s todos</h1>
          {/* ... rest of the UI */}
        </main>
      )}
    </Authenticator>
  )
}

Now, let's go back to your local application and test out the user isolation of the to-do items.

You will need to sign up new users again because now you're working with the cloud sandbox instead of your production backend.

To get these changes to the cloud, commit them to git and push the changes upstream.

Terminal
Copy
Terminal code example
git commit -am "added per-user data isolation"
git push

Once your build completes in the Amplify Console, the main backend will update to support the changes made within the cloud sandbox. The data in the cloud sandbox is fully isolated and won't pollute your production database.

🥳 Success

That's it! You have successfully built a fullstack app on AWS Amplify. If you want to learn more about how to work with Amplify, here's the conceptual guide for how Amplify works.

--------------------------------------------------------------------------------

Title: Next.js Pages Router - Next.js - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/start/quickstart/nextjs-pages-router/
HTML Content:
Next.js
/
Get started
/
Quickstart
/
Next.js Pages Router
Next.js Pages Router
Pre-requisites

This Quickstart guide will walk you through how to build a task list application with TypeScript, Next.js App Router with Client Components, and React. Before you begin, make sure you have the following installed:

Node.js v14.x or later
npm v6.14.4 or later
git v2.14.1 or later
If you are new to these technologies, we recommend you go through the official React, Next.js, and TypeScript tutorials first.
Deploy a fullstack app to AWS

We've created a starter "To-do" application to help get started faster. First, you will create a repository in your GitHub account using our starter Next (Pages) template.

1. Create the repository

Use our starter template to create a repository in your GitHub account. This template scaffolds create-next-app with Amplify backend capabilities.

Create repository from template

Use the form in GitHub to finalize your repo's creation.

2. Deploy the starter app

Now that the repository has been created, deploy it with Amplify.

Deploy to AWS

Select Start with an existing app > GitHub. After you give Amplify access to your GitHub account via the popup window, pick the repository and main branch to deploy. Make no other changes and click through the flow to Save and deploy.

3. View deployed app
While you are waiting for your app to deploy (~5 mins)
Learn about the project structure

When the build completes, visit the newly deployed branch by selecting "View deployed URL". Since the build deployed an API, database, and authentication backend, you will be able to create new to-do items.

In the Amplify console, click into the deployment branch (in this case main) > select Data in the left-hand menu > Data manager to see the data entered in your database.

Make frontend updates

Let's learn how to enhance the app functionality by creating a delete flow for to-do list items.

4. Set up local environment

Now let's set up our local development environment to add features to the frontend. Click on your deployed branch and you will land on the Deployments page which shows you your build history and a list of deployed backend resources.

At the bottom of the page you will see a tab for Deployed backend resources. Click on the tab and then click the Download amplify_outputs.json file button.

Clone the repository locally.

Terminal
Copy
Terminal code example
git clone https://github.com/<github-user>/amplify-next-template.git
cd amplify-next-template && npm install

Now move the amplify_outputs.json file you downloaded above to the root of your project.

Copy
code example
├── amplify
├── src
├── amplify_outputs.json <== backend outputs file
├── package.json
└── tsconfig.json
Learn more
amplify_outputs.json
5. Implement delete functionality

Go to the pages/index.tsx file and add in a new deleteTodo functionality and pass function into the <li> element's onClick handler.

pages/index.tsx
function App() {
  // ...
Copy
highlighted code example
  function deleteTodo(id: string) {
    client.models.Todo.delete({ id })
  }


  return (
    <main>
      <h1>My todos</h1>
      <button onClick={createTodo}>+ new</button>
      <ul>
        {todos.map(todo => <li
Copy
highlighted code example
          onClick={() => deleteTodo(todo.id)}
          key={todo.id}>
          {todo.content}
        </li>)}
      </ul> 
      <div>
        🥳 App successfully hosted. Try creating a new todo.
        <br />
        <a href="https://docs.amplify.aws/nextjs/start/quickstart/nextjs-pages-router/">Review next step of this tutorial.</a>
      </div>
    </main>
  )
}
See the complete amplify/data/resources.ts

Try out the deletion functionality now by starting the local dev server:

Terminal
Copy
Terminal code example
npm run dev

This should start a local dev server at http://localhost:3000.

6. Implement login UI

The starter application already has a pre-configured auth backend defined in the amplify/auth/resource.ts file. We've configured it to support email and password login but you can extend it to support a variety of login mechanisms, including Google, Amazon, Sign In With Apple, and Facebook.

The fastest way to get your login experience up and running is to use our Authenticator UI component. First, install the Amplify UI component library:

Copy
code example
npm add @aws-amplify/ui-react

Next, import the Authenticator UI component and wrap your <main> element.

pages/index.tsx
Copy
highlighted code example
import { Authenticator } from '@aws-amplify/ui-react'
import '@aws-amplify/ui-react/styles.css'
// ... other imports


function App() {
  // ...
  return (
Copy
highlighted code example
    <Authenticator>
      {({ signOut, user }) => (
        <main>
          {/*...*/}
Copy
highlighted code example
          <button onClick={signOut}>Sign out</button>
        </main>
      )}
Copy
highlighted code example
    </Authenticator>
  )
}
See the complete amplify/auth/resources.ts

The Authenticator component auto-detects your auth backend settings and renders the correct UI state based on the auth backend's authentication flow.

Try out your application in your localhost environment again. You should be presented with a login experience now.

To get these changes to the cloud, commit them to git and push the changes upstream.

Terminal
Copy
Terminal code example
git commit -am "added authenticator"
git push

Amplify automatically deploys the latest version of your app based on your git commits. In just a few minutes, when the application rebuilds, the hosted app will be updated to support the deletion functionality.

Make backend updates

Let's update our backend to implement per-user authorization rules, allowing each user to only access their own to-dos.

7. Set up local AWS credentials

To make backend updates, we are going to require AWS credentials to deploy backend updates from our local machine.

Skip ahead to step 8, if you already have an AWS profile with credentials on your local machine, and your AWS profile has the AmplifyBackendDeployFullAccess permission policy.

Otherwise, set up local AWS credentials that grant Amplify permissions to deploy backend updates from your local machine.

8. Deploy cloud sandbox

To update your backend without affecting the production branch, use Amplify's cloud sandbox. This feature provides a separate backend environment for each developer on a team, ideal for local development and testing.

To start your cloud sandbox, run the following command in a new Terminal window:

Terminal
Copy
Terminal code example
npx ampx sandbox

Once the cloud sandbox has been fully deployed (~5 min), you'll see the amplify_outputs.json file updated with connection information to a new isolated authentication and data backend.

The npx ampx sandbox command should run concurrently to your npm run dev. You can think of the cloud sandbox as the "localhost-equivalent for your app backend".

9. Implement per-user authorization

The to-do items in the starter are currently shared across all users, but, in most cases, you want data to be isolated on a per-user basis.

To isolate the data on a per-user basis, you can use an "owner-based authorization rule". Let's apply the owner-based authorization rule to your to-do items:

amplify/data/resource.ts
import { type ClientSchema, a, defineData } from '@aws-amplify/backend';


const schema = a.schema({
  Todo: a.model({
    content: a.string(),
Copy
highlighted code example
  }).authorization(allow => [allow.owner()]),
});


export type Schema = ClientSchema<typeof schema>;


export const data = defineData({
  schema,
  authorizationModes: {
    // This tells the data client in your app (generateClient())
    // to sign API requests with the user authentication token. 
Copy
highlighted code example
    defaultAuthorizationMode: 'userPool',
  },
});

In the application client code, let's also render the username to distinguish different users once they're logged in. Go to your src/App.tsx file and render the user property.

pages/index.tsx
// ... imports


function App() {
  // ...
  return (
    <Authenticator>
Copy
highlighted code example
      {({ signOut, user }) => (
        <main>
Copy
highlighted code example
          <h1>{user?.signInDetails?.loginId}'s todos</h1>
          {/* ... rest of the UI */}
        </main>
      )}
    </Authenticator>
  )
}

Now, let's go back to your local application and test out the user isolation of the to-do items.

You will need to sign up new users again because now you're working with the cloud sandbox instead of your production backend.

To get these changes to the cloud, commit them to git and push the changes upstream.

Terminal
Copy
Terminal code example
git commit -am "added per-user data isolation"
git push

Once your build completes in the Amplify Console, the main backend will update to support the changes made within the cloud sandbox. The data in the cloud sandbox is fully isolated and won't pollute your production database.

🥳 Success

That's it! You have successfully built a fullstack app on AWS Amplify. If you want to learn more about how to work with Amplify, here's the conceptual guide for how Amplify works.

--------------------------------------------------------------------------------

Title: Quickstart - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/start/quickstart/
HTML Content:
Next.js
/
Get started
/
Quickstart
Quickstart

👋 Welcome to AWS Amplify! In this quickstart guide, you will:

Deploy a Next.js app
Build and connect to a database with real-time data updates
Configure authentication and authorization rules

We have two Quickstart guides you can follow:

Next.js Pages Router
Get started with AWS Amplify Gen 2 using the Next.js Pages Router.
Next.js App Router
Get started with AWS Amplify Gen 2 using the Next.js App Router.

--------------------------------------------------------------------------------

Title: Get started - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/start/
HTML Content:
Next.js
/
Get started
Get started

AWS Amplify is a collection of cloud services and libraries for fullstack application development. Amplify provides frontend libraries, UI components, backend building, and frontend hosting for building fullstack cloud apps. This tutorial will teach you how to use Amplify's new code-first developer experience to build a fullstack application with data, authentication, and frontend hosting which are all deployed to AWS. If you're completely new to AWS Amplify, you may want to read more about how it works and the concepts behind the second generation of AWS Amplify, which this tutorial will use.

Quickstart
Get started with AWS Amplify Gen 2 and React, Next.js, Angular, Vue, Flutter, React Native, Swift, Android, and JavaScript.
Configure AWS for local development
Learn how to set up your AWS account and configure it locally for use with Amplify.
Manual installation
Learn how to get started with AWS Amplify Gen 2 by manually installing.
Connect to AWS resources
You can use Amplify client libraries to connect directly to your AWS resources
Gen 2 for Gen 1 customers
Learn how to set up your AWS account and configure it locally for use with Amplify.

--------------------------------------------------------------------------------

Title: FAQ - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/how-amplify-works/faq/
HTML Content:
Next.js
/
How Amplify works
/
FAQ
FAQ

Is there a way to upgrade an existing Amplify project from Gen 1 to Gen 2?

We are still actively developing migration tooling to aid in transitioning your project from Gen 1 to Gen 2. Until then, we recommend you continue working with your Gen 1 Amplify project. We’ve put together a Gen 1 vs. Gen 2 feature support matrix here. We remain committed to supporting both Gen 1 and Gen 2 for the foreseeable future. For new projects, we recommend adopting Gen 2 to take advantage of its enhanced capabilities. Meanwhile, customers on Gen 1 will continue to receive support for high-priority bugs and essential security updates.

If I have a Gen 1 app, can I use Gen 2 in it?

Amplify Gen 1 and Gen 2 follow different architectural and tooling paradigms, which was necessary to address common customer feedback from Gen 1. You will need to use our upcoming migration tooling to move from a Gen 1 to Gen 2 app. You cannot use Amplify Gen 1 (Studio/CLI) in the same app as Gen 2.

Should I use Amplify Gen 1 or Gen 2 in new apps?

If you're building a new app, we recommend you use Amplify Gen 2.

Does Amplify Gen 2 support DataStore?

Amplify Gen 2 supports GraphQL APIs without DataStore. We will release migration support for moving DataStore Gen 1 apps to Gen 2.

What programming languages does Amplify Gen 2 support?

Amplify Gen 2 supports a wide range of programming languages for client-side development. This includes dedicated client-side libraries for JavaScript, TypeScript, Dart, Java, Kotlin, and Swift. For backend development, Amplify Gen 2 uses TypeScript.

In Gen 1, Amplify offered a set of use case categories for building applications (for example, Authentication, Analytics, API, DataStore, Geo, and Predictions). Are those same categories available in Gen 2?

Amplify Gen 2 offers built-in support for Auth, Data, Storage, and Functions. Other use cases can be implemented in Amplify Gen 2 as well using AWS Cloud Development Kit (AWS CDK) constructs which there is documentation for under the respective category name.

Can I use Gen 2 with a JavaScript frontend that doesn't use TypeScript?

Yes. Amplify Gen 2's TypeScript backend definition works with JavaScript frontends. In addition, you still get an end-to-end typed data fetching experience even with a pure JavaScript frontend. See Generate a Data client for the recommended JavaScript client code.

What if we want to add a feature like AI/ML or Amazon Location Service to our application in Gen 2?

Because Amplify builds on the AWS Cloud Development Kit (AWS CDK), any AWS services supported by the CDK can be added to your app using custom resources and L2/L1 AWS CDK constructs.

What happens once my application grows too big and I want to do more configuration with my application (add more features, other AWS services, etc.)?

You can stay with Amplify no matter how big your application grows. Amplify is layered on top of the AWS CDK and AWS CloudFormation. These provide a standardized way of interacting with AWS, so you can add any AWS service supported by CDK to your Amplify app. You can also override Amplify-generated configuration of your resources using the CDK. You can use any deployment pipeline you choose if you want more control over your CI.

How much does it cost to operate Amplify Gen2?

You can read all about Amplify's pricing on our pricing page.

Which Amplify JavaScript version is compatible with Gen 2?

Amplify JavaScript version 6.2.0 and above is compatible with backends created by Amplify Gen 2.

--------------------------------------------------------------------------------

Title: Concepts - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/how-amplify-works/concepts/
HTML Content:
Next.js
/
How Amplify works
/
Concepts
Concepts

AWS Amplify Gen 2 uses a TypeScript-based, code-first developer experience (DX) for defining backends. The Gen 2 DX offers a unified Amplify developer experience with hosting, backend, and UI-building capabilities and a code-first approach. Amplify empowers frontend developers to deploy cloud infrastructure by simply expressing their app’s data model, business logic, authentication, and authorization rules completely in TypeScript. Amplify automatically configures the correct cloud resources and removes the requirement to stitch together underlying AWS services.

Capabilities

You can use Amplify for end-to-end fullstack development.

Build fullstack apps with TypeScript

With the Gen 2 DX, you can provision backend infrastructure by authoring TypeScript. In the following diagram, the box at the bottom (outlined in pink), highlights the main difference in how you provision infrastructure compared to Gen 1. In Gen 1, you would use Studio's console or the CLI to provision infrastructure; in Gen 2, you author TypeScript code in files following a file-based convention (such as amplify/auth/resource.ts or amplify/auth/data.ts). With TypeScript types and classes for resources, you gain strict typing and IntelliSense in Visual Studio Code to prevent errors. A breaking change in the backend code immediately reflects as a type error in the co-located frontend code. The file-based convention follows the "convention over configuration" paradigm—you know exactly where to look for resource definitions when you group them by type in separate files.

Faster local development

Per-developer cloud sandbox environments are optimized for faster iterations. Each developer on a team gets an isolated cloud development environment against which they can test their changes. These cloud sandbox environments are meant for local development only, but they deploy high-fidelity AWS backends while you build. Depending on the workflow, iterative updates are now deployed up to 8X faster than Gen 1 deployments. In the diagram below, four developers are able to work on fullstack features independently without disrupting each other's environments.

Fullstack Git-based environments

All shared environments (such as production, staging, gamma) map 1:1 to Git branches in your repository. New features can be tested in ephemeral environments with pull request previews (or feature branches) before they are merged into production. Unlike the Gen 1 experience, which requires users to configure a number of steps in the CLI or Console to set up a fullstack environment, the Gen 2 experience is zero-config. Because of our code-first approach, the Git repository is always the source of truth for the state of the fullstack app—all backend resources are defined as code for reproducibility and portability across branches. This, along with central management of environment variables and secrets, simplifies the promotion workflow from lower to upper environments.

Unified management console

All branches can be managed in the new Amplify console. The Amplify Gen 2 console provides a single place for you to manage your builds, hosting settings (such as custom domains), deployed resources (such as data browser or user management), and environment variables and secrets. Even though you can access deployed resources directly in other AWS service consoles, the Amplify console will offer a first-party experience for the categories almost every app needs—data, auth, storage, and functions. For example, with Data, Amplify offers an API playground and a data manager (coming soon) with relationship building, seed data generation, and file upload capabilities.

Build an app
Data

The @aws-amplify/backend library offers a TypeScript-first Data library for setting up fully typed real-time APIs (powered by AWS AppSync GraphQL APIs) and NoSQL databases (powered by Amazon DynamoDB tables). After you generate an Amplify backend, you will have an amplify/data/resource.ts file, which will contain your app's data schema. The defineData function turns the schema into a fully functioning data backend with all the boilerplate handled automatically.

The schema-based approach is an evolution of the Amplify GraphQL API in Gen 1. It offers several benefits, including dot completion, IntelliSense, and type validation.

A data model for a chat app may look something like this, for example:

Copy
code example
const schema = a.schema({
  Chat: a.model({
    name: a.string(),
    message: a.hasMany('Message', 'chatId'),
  }),
  Message: a.model({
    text: a.string(),
    chat: a.belongsTo('Chat', 'chatId'),
    chatId: a.id()
  }),
});

On your app's frontend, you can use the generateClient function, which provides a typed client instance, making it easy to integrate CRUD (create, read, update, delete) operations for your models in your application code.

Gen 2 automatically generates your types without the explicit codegen step that was part of Gen 1.

Copy
code example
// generate your data client using the Schema from your backend
const client = generateClient<Schema>();


// list all messages
const { data } = await client.models.Message.list();


// create a new message
const { errors, data: newMessage } = await client.models.Message.create({
  text: 'My message text'
});
Auth

Auth works similarly to data. You can configure the authentication settings you want for your app in amplify/auth/resource.ts. If you want to change the verification email's subject line, you can change out the default generated code with the following:

amplify/auth/resource.ts
Copy
amplify/auth/resource.ts code example
export const auth = defineAuth({
  loginWith: {
    email: {
      verificationEmailSubject: 'Welcome 👋 Verify your email!'
    }
  }
});

You can customize your authentication flow with customized sign-in and registration flows, multi-factor authentication (MFA), and third-party social providers. Amplify deploys an Amazon Cognito instance in your AWS account when you add auth to your app.

Then, you could use the Amplify Authenticator component or the client libraries to add user flows.

Copy
code example
import { withAuthenticator } from '@aws-amplify/ui-react';


function App({ signOut, user }) {
  return (
    <>
      <h1>Hello {user.username}</h1>
      <button onClick={signOut}>Sign out</button>
    </>
  );
}


export default withAuthenticator(App);
UI building

Amplify makes it easy to quickly build web app user interfaces using the UI component library, Figma-to-code generation, and CRUD form-generation capabilities. Learn more.

Connecting to AWS beyond Amplify
Add any AWS resource

Gen 2 is layered on top of AWS Cloud Development Kit (CDK)—the Data and Auth capabilities in @aws-amplify/backend wrap L3 AWS CDK constructs. As a result, extending the resources generated by Amplify does not require any special configuration. The following example adds Amazon Location Services by adding a file: amplify/custom/maps/resource.ts.

Copy
code example
import { CfnOutput, Stack, StackProps } from 'aws-cdk-lib';
import * as locations from 'aws-cdk-lib/aws-location';
import { Construct } from 'constructs';


export class LocationMapStack extends Stack {
  constructor(scope: Construct, id: string, props?: StackProps) {
    super(scope, id, props);


    // Create the map resource
    const map = new locations.CfnMap(this, 'LocationMap', {
      configuration: {
        style: 'VectorEsriStreets' // map style
      },
      description: 'My Location Map',
      mapName: 'MyMap'
    });


    new CfnOutput(this, 'mapArn', {
      value: map.attrArn,
      exportName: 'mapArn'
    });
  }
}

This is then included in the amplify/backend.ts file so it gets deployed as part of your Amplify app.

Copy
code example
import { Backend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';
import { LocationMapStack } from './locationMapStack/resource';


const backend = new Backend({
  auth,
  data
});


new LocationMapStack(
  backend.getStack('LocationMapStack'),
  'myLocationResource',
  {}
);
Connect to existing resources

Amplify is designed to work with your existing AWS resources and configurations. For example, you can use Amplify's pre-built authentication UI components with an existing Amazon Cognito user pool you created and configured separately. Or you can display images and files from an existing Amazon S3 bucket in your app's user interface by integrating with Amplify Storage.

Amplify's libraries provide an interface to leverage your existing AWS services so that you can adopt Amplify's capabilities incrementally into your current workflows, without disrupting your existing backend infrastructure.

Next steps

Now that you have a conceptual understanding of AWS Amplify's capabilities, complete the quickstart tutorial to put it into action in an app.

--------------------------------------------------------------------------------

Title: How Amplify works - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/how-amplify-works/
HTML Content:
Next.js
/
How Amplify works
How Amplify works
Concepts
Learn about the Amplify fullstack TypeScript DX
FAQ
Frequently asked questions about the code-first DX.

--------------------------------------------------------------------------------

Title: Amplify Docs - AWS Amplify Gen 2 Documentation
URL: https://docs.amplify.aws/nextjs/
HTML Content:
Amplify Documentation for Next.js

AWS Amplify is everything frontend developers need to develop and deploy cloud-powered fullstack applications without hassle. Easily connect your frontend to the cloud for data modeling, authentication, storage, serverless functions, SSR app deployment, and more.

Get started
Toggle getting started guides navigation
How Amplify Works
Build fullstack apps with your framework of choice

You can use AWS Amplify with popular web and mobile frameworks like JavaScript, Flutter, Swift, and React. Build, connect, and host fullstack apps on AWS. Get started by selecting your preferred framework.

React
Next.js
Angular
Vue
JavaScript
React Native
Flutter
Android
Swift
Features
Code-first DX

The fullstack TypeScript developer experience lets you focus on your app code instead of infrastructure.

Fullstack Git deployments

Deploy your frontend and backend together on every code commit. Your Git branch is the source of truth.

Faster local development

Per-developer cloud sandbox environments let you quickly iterate during development.

Develop
TypeScript-first fullstack experience
Write TypeScript across your app's frontend and backend. Get schema validation, dot completion, and end-to-end types while you code.
Real-time data for modern apps
Sync frontend state to real-time backend updates. Just write TypeScript without thinking about WebSockets.
Authn and authz for secure apps
Choose the auth strategy (such as passwords, social, email links) and control data access based on users and groups.
Auto-generate CRUD forms wired to data
Map CRUD forms to your data model with form-level validations and error states built in.
Deploy
SSR/SSG/ISR hosting support
Deploy Next.js, Nuxt, React, Vue.js, Angular (and more) apps by simply connecting your Git repository.
Faster iterations with per-developer sandboxes
Per-developer cloud sandboxes provide high fidelity and faster deployment times to make local iteration quick.
Zero-config fullstack branches
Fullstack deployments from your Git branch. Autodeploy Git branches to set up staging, development, and production environments.
GUI to manage your data
Manage your app data, users and groups, and files in a single console.
Customize
Add any AWS service with CDK
Extend or customize with the AWS CDK to access 200+ AWS services.
Bring your own pipelines
Use your own pipelines to set up cross-account or multi-region, stage-based deployments.
Monorepo and multi-repo support
Enable support for all types of fullstack team workflows: monorepos, micro frontends, multi-repos, and more.
amplify/backend.ts
Copy
amplify/backend.ts code example
import * as sns from 'aws-cdk-lib/aws-sns';
import * as sqs from 'aws-cdk-lib/aws-sqs';
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource.js';
import { data } from './data/resource.js';


const backend = defineBackend({
  auth,
  data
});


const customResourceStack = backend.createStack('MyCustomResources');


new sqs.Queue(customResourceStack, 'CustomQueue');
new sns.Topic(customResourceStack, 'CustomTopic');

--------------------------------------------------------------------------------

